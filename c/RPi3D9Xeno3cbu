ort 22.
Jun 11 14:45:06 raspberrypi login[485]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:45:06 raspberrypi systemd-logind[332]: New session c1 of user root.
Jun 11 14:45:06 raspberrypi systemd: pam_unix(systemd-user:session): session opened for user root by (uid=0)
Jun 11 14:45:06 raspberrypi login[504]: ROOT LOGIN  on '/dev/tty1'
Jun 11 14:45:28 raspberrypi sshd[488]: Received signal 15; terminating.
Jun 11 14:45:33 raspberrypi systemd-logind[349]: New seat seat0.
Jun 11 14:45:41 raspberrypi sshd[489]: Server listening on 0.0.0.0 port 22.
Jun 11 14:45:41 raspberrypi sshd[489]: Server listening on :: port 22.
Jun 11 14:45:49 raspberrypi login[486]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:45:49 raspberrypi systemd-logind[349]: New session c1 of user root.
Jun 11 14:45:49 raspberrypi systemd: pam_unix(systemd-user:session): session opened for user root by (uid=0)
Jun 11 14:45:50 raspberrypi login[505]: ROOT LOGIN  on '/dev/tty1'
Jun 11 14:46:14 raspberrypi sshd[489]: Received signal 15; terminating.
Jun 11 14:46:18 raspberrypi systemd-logind[283]: New seat seat0.
Jun 11 14:46:26 raspberrypi sshd[466]: Server listening on 0.0.0.0 port 22.
Jun 11 14:46:26 raspberrypi sshd[466]: Server listening on :: port 22.
Jun 11 14:46:42 raspberrypi login[462]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:46:42 raspberrypi systemd-logind[283]: New session c1 of user root.
Jun 11 14:46:42 raspberrypi systemd: pam_unix(systemd-user:session): session opened for user root by (uid=0)
Jun 11 14:46:43 raspberrypi login[482]: ROOT LOGIN  on '/dev/tty1'
Jun 11 14:51:20 raspberrypi login[509]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:51:20 raspberrypi systemd-logind[283]: New session c2 of user root.
Jun 11 14:51:20 raspberrypi login[781]: ROOT LOGIN  on '/dev/tty2'
Jun 11 14:51:51 raspberrypi groupadd[1559]: group added to /etc/group: name=sambashare, GID=113
Jun 11 14:51:51 raspberrypi groupadd[1559]: group added to /etc/gshadow: name=sambashare
Jun 11 14:51:51 raspberrypi groupadd[1559]: new group: name=sambashare, GID=113
Jun 11 14:52:41 raspberrypi login[510]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:52:41 raspberrypi systemd-logind[283]: New session c3 of user root.
Jun 11 14:52:41 raspberrypi login[1781]: ROOT LOGIN  on '/dev/tty3'
Jun 11 14:55:17 raspberrypi sshd[466]: Received signal 15; terminating.
Jun 11 14:55:21 raspberrypi systemd-logind[322]: New seat seat0.
Jun 11 14:55:29 raspberrypi sshd[460]: Server listening on 0.0.0.0 port 22.
Jun 11 14:55:29 raspberrypi sshd[460]: Server listening on :: port 22.
Jun 11 14:55:34 raspberrypi login[456]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:55:34 raspberrypi systemd-logind[322]: New session c1 of user root.
Jun 11 14:55:34 raspberrypi systemd: pam_unix(systemd-user:session): session opened for user root by (uid=0)
Jun 11 14:55:35 raspberrypi login[483]: ROOT LOGIN  on '/dev/tty1'
Jun 11 14:56:51 raspberrypi login[502]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:56:51 raspberrypi login[503]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:56:51 raspberrypi systemd-logind[322]: New session c2 of user root.
Jun 11 14:56:51 raspberrypi systemd-logind[322]: New session c3 of user root.
Jun 11 14:56:52 raspberrypi login[525]: ROOT LOGIN  on '/dev/tty2'
Jun 11 14:56:52 raspberrypi login[530]: ROOT LOGIN  on '/dev/tty3'
Jun 11 14:56:56 raspberrypi login[561]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:56:56 raspberrypi systemd-logind[322]: New session c4 of user root.
Jun 11 14:56:56 raspberrypi login[574]: ROOT LOGIN  on '/dev/tty4'
Jun 11 14:56:58 raspberrypi login[591]: pam_unix(login:session): session opened for user root by LOGIN(uid=0)
Jun 11 14:56:58 raspberrypi systemd-logind[322]: New session c5 of user root.
Jun 11 14:56:58 raspberrypi login[601]: ROOT LOGIN /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2012 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

#ifndef __CVMX_DPI_DEFS_H__
#define __CVMX_DPI_DEFS_H__

#define CVMX_DPI_BIST_STATUS (CVMX_ADD_IO_SEG(0x0001DF0000000000ull))
#define CVMX_DPI_CTL (CVMX_ADD_IO_SEG(0x0001DF0000000040ull))
#define CVMX_DPI_DMAX_COUNTS(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000300ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_DBELL(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000200ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_ERR_RSP_STATUS(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000A80ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_IBUFF_SADDR(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000280ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_IFLIGHT(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000A00ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_NADDR(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000380ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_REQBNK0(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000400ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMAX_REQBNK1(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000480ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMA_CONTROL (CVMX_ADD_IO_SEG(0x0001DF0000000048ull))
#define CVMX_DPI_DMA_ENGX_EN(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000080ull) + ((offset) & 7) * 8)
#define CVMX_DPI_DMA_PPX_CNT(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000B00ull) + ((offset) & 31) * 8)
#define CVMX_DPI_ENGX_BUF(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000880ull) + ((offset) & 7) * 8)
#define CVMX_DPI_INFO_REG (CVMX_ADD_IO_SEG(0x0001DF0000000980ull))
#define CVMX_DPI_INT_EN (CVMX_ADD_IO_SEG(0x0001DF0000000010ull))
#define CVMX_DPI_INT_REG (CVMX_ADD_IO_SEG(0x0001DF0000000008ull))
#define CVMX_DPI_NCBX_CFG(block_id) (CVMX_ADD_IO_SEG(0x0001DF0000000800ull))
#define CVMX_DPI_PINT_INFO (CVMX_ADD_IO_SEG(0x0001DF0000000830ull))
#define CVMX_DPI_PKT_ERR_RSP (CVMX_ADD_IO_SEG(0x0001DF0000000078ull))
#define CVMX_DPI_REQ_ERR_RSP (CVMX_ADD_IO_SEG(0x0001DF0000000058ull))
#define CVMX_DPI_REQ_ERR_RSP_EN (CVMX_ADD_IO_SEG(0x0001DF0000000068ull))
#define CVMX_DPI_REQ_ERR_RST (CVMX_ADD_IO_SEG(0x0001DF0000000060ull))
#define CVMX_DPI_REQ_ERR_RST_EN (CVMX_ADD_IO_SEG(0x0001DF0000000070ull))
#define CVMX_DPI_REQ_ERR_SKIP_COMP (CVMX_ADD_IO_SEG(0x0001DF0000000838ull))
#define CVMX_DPI_REQ_GBL_EN (CVMX_ADD_IO_SEG(0x0001DF0000000050ull))
#define CVMX_DPI_SLI_PRTX_CFG(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000900ull) + ((offset) & 3) * 8)
static inline uint64_t CVMX_DPI_SLI_PRTX_ERR(unsigned long offset)
{
	switch (cvmx_get_octeon_family()) {
	case OCTEON_CN66XX & OCTEON_FAMILY_MASK:
		return CVMX_ADD_IO_SEG(0x0001DF0000000920ull) + (offset) * 8;
	case OCTEON_CNF71XX & OCTEON_FAMILY_MASK:
	case OCTEON_CN61XX & OCTEON_FAMILY_MASK:
	case OCTEON_CN68XX & OCTEON_FAMILY_MASK:

		if (OCTEON_IS_MODEL(OCTEON_CN68XX_PASS1))
			return CVMX_ADD_IO_SEG(0x0001DF0000000928ull) + (offset) * 8;

		if (OCTEON_IS_MODEL(OCTEON_CN68XX_PASS2))
			return CVMX_ADD_IO_SEG(0x0001DF0000000920ull) + (offset) * 8;
		return CVMX_ADD_IO_SEG(0x0001DF0000000920ull) + (offset) * 8;
	case OCTEON_CN63XX & OCTEON_FAMILY_MASK:
		return CVMX_ADD_IO_SEG(0x0001DF0000000928ull) + (offset) * 8;
	}
	return CVMX_ADD_IO_SEG(0x0001DF0000000920ull) + (offset) * 8;
}

#define CVMX_DPI_SLI_PRTX_ERR_INFO(offset) (CVMX_ADD_IO_SEG(0x0001DF0000000940ull) + ((offset) & 3) * 8)

union cvmx_dpi_bist_status {
	uint64_t u64;
	struct cvmx_dpi_bist_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_47_63:17;
		uint64_t bist:47;
#else
		uint64_t bist:47;
		uint64_t reserved_47_63:17;
#endif
	} s;
	struct cvmx_dpi_bist_status_s cn61xx;
	struct cvmx_dpi_bist_status_cn63xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_45_63:19;
		uint64_t bist:45;
#else
		uint64_t bist:45;
		uint64_t reserved_45_63:19;
#endif
	} cn63xx;
	struct cvmx_dpi_bist_status_cn63xxp1 {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_37_63:27;
		uint64_t bist:37;
#else
		uint64_t bist:37;
		uint64_t reserved_37_63:27;
#endif
	} cn63xxp1;
	struct cvmx_dpi_bist_status_s cn66xx;
	struct cvmx_dpi_bist_status_cn63xx cn68xx;
	struct cvmx_dpi_bist_status_cn63xx cn68xxp1;
	struct cvmx_dpi_bist_status_s cnf71xx;
};

union cvmx_dpi_ctl {
	uint64_t u64;
	struct cvmx_dpi_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_2_63:62;
		uint64_t clk:1;
		uint64_t en:1;
#else
		uint64_t en:1;
		uint64_t clk:1;
		uint64_t reserved_2_63:62;
#endif
	} s;
	struct cvmx_dpi_ctl_cn61xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_1_63:63;
		uint64_t en:1;
#else
		uint64_t en:1;
		uint64_t reserved_1_63:63;
#endif
	} cn61xx;
	struct cvmx_dpi_ctl_s cn63xx;
	struct cvmx_dpi_ctl_s cn63xxp1;
	struct cvmx_dpi_ctl_s cn66xx;
	struct cvmx_dpi_ctl_s cn68xx;
	struct cvmx_dpi_ctl_s cn68xxp1;
	struct cvmx_dpi_ctl_cn61xx cnf71xx;
};

union cvmx_dpi_dmax_counts {
	uint64_t u64;
	struct cvmx_dpi_dmax_counts_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_39_63:25;
		uint64_t fcnt:7;
		uint64_t dbell:32;
#else
		uint64_t dbell:32;
		uint64_t fcnt:7;
		uint64_t reserved_39_63:25;
#endif
	} s;
	struct cvmx_dpi_dmax_counts_s cn61xx;
	struct cvmx_dpi_dmax_counts_s cn63xx;
	struct cvmx_dpi_dmax_counts_s cn63xxp1;
	struct cvmx_dpi_dmax_counts_s cn66xx;
	struct cvmx_dpi_dmax_counts_s cn68xx;
	struct cvmx_dpi_dmax_counts_s cn68xxp1;
	struct cvmx_dpi_dmax_counts_s cnf71xx;
};

union cvmx_dpi_dmax_dbell {
	uint64_t u64;
	struct cvmx_dpi_dmax_dbell_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_16_63:48;
		uint64_t dbell:16;
#else
		uint64_t dbell:16;
		uint64_t reserved_16_63:48;
#endif
	} s;
	struct cvmx_dpi_dmax_dbell_s cn61xx;
	struct cvmx_dpi_dmax_dbell_s cn63xx;
	struct cvmx_dpi_dmax_dbell_s cn63xxp1;
	struct cvmx_dpi_dmax_dbell_s cn66xx;
	struct cvmx_dpi_dmax_dbell_s cn68xx;
	struct cvmx_dpi_dmax_dbell_s cn68xxp1;
	struct cvmx_dpi_dmax_dbell_s cnf71xx;
};

union cvmx_dpi_dmax_err_rsp_status {
	uint64_t u64;
	struct cvmx_dpi_dmax_err_rsp_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_6_63:58;
		uint64_t status:6;
#else
		uint64_t status:6;
		uint64_t reserved_6_63:58;
#endif
	} s;
	struct cvmx_dpi_dmax_err_rsp_status_s cn61xx;
	struct cvmx_dpi_dmax_err_rsp_status_s cn66xx;
	struct cvmx_dpi_dmax_err_rsp_status_s cn68xx;
	struct cvmx_dpi_dmax_err_rsp_status_s cn68xxp1;
	struct cvmx_dpi_dmax_err_rsp_status_s cnf71xx;
};

union cvmx_dpi_dmax_ibuff_saddr {
	uint64_t u64;
	struct cvmx_dpi_dmax_ibuff_saddr_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_62_63:2;
		uint64_t csize:14;
		uint64_t reserved_41_47:7;
		uint64_t idle:1;
		uint64_t saddr:33;
		uint64_t reserved_0_6:7;
#else
		uint64_t reserved_0_6:7;
		uint64_t saddr:33;
		uint64_t idle:1;
		uint64_t reserved_41_47:7;
		uint64_t csize:14;
		uint64_t reserved_62_63:2;
#endif
	} s;
	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_62_63:2;
		uint64_t csize:14;
		uint64_t reserved_41_47:7;
		uint64_t idle:1;
		uint64_t reserved_36_39:4;
		uint64_t saddr:29;
		uint64_t reserved_0_6:7;
#else
		uint64_t reserved_0_6:7;
		uint64_t saddr:29;
		uint64_t reserved_36_39:4;
		uint64_t idle:1;
		uint64_t reserved_41_47:7;
		uint64_t csize:14;
		uint64_t reserved_62_63:2;
#endif
	} cn61xx;
	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx cn63xx;
	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx cn63xxp1;
	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx cn66xx;
	struct cvmx_dpi_dmax_ibuff_saddr_s cn68xx;
	struct cvmx_dpi_dmax_ibuff_saddr_s cn68xxp1;
	struct cvmx_dpi_dmax_ibuff_saddr_cn61xx cnf71xx;
};

union cvmx_dpi_dmax_iflight {
	uint64_t u64;
	struct cvmx_dpi_dmax_iflight_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_3_63:61;
		uint64_t cnt:3;
#else
		uint64_t cnt:3;
		uint64_t reserved_3_63:61;
#endif
	} s;
	struct cvmx_dpi_dmax_iflight_s cn61xx;
	struct cvmx_dpi_dmax_iflight_s cn66xx;
	struct cvmx_dpi_dmax_iflight_s cn68xx;
	struct cvmx_dpi_dmax_iflight_s cn68xxp1;
	struct cvmx_dpi_dmax_iflight_s cnf71xx;
};

union cvmx_dpi_dmax_naddr {
	uint64_t u64;
	struct cvmx_dpi_dmax_naddr_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_40_63:24;
		uint64_t addr:40;
#else
		uint64_t addr:40;
		uint64_t reserved_40_63:24;
#endif
	} s;
	struct cvmx_dpi_dmax_naddr_cn61xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_36_63:28;
		uint64_t addr:36;
#else
		uint64_t addr:36;
		uint64_t reserved_36_63:28;
#endif
	} cn61xx;
	struct cvmx_dpi_dmax_naddr_cn61xx cn63xx;
	struct cvmx_dpi_dmax_naddr_cn61xx cn63xxp1;
	struct cvmx_dpi_dmax_naddr_cn61xx cn66xx;
	struct cvmx_dpi_dmax_naddr_s cn68xx;
	struct cvmx_dpi_dmax_naddr_s cn68xxp1;
	struct cvmx_dpi_dmax_naddr_cn61xx cnf71xx;
};

union cvmx_dpi_dmax_reqbnk0 {
	uint64_t u64;
	struct cvmx_dpi_dmax_reqbnk0_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t state:64;
#else
		uint64_t state:64;
#endif
	} s;
	struct cvmx_dpi_dmax_reqbnk0_s cn61xx;
	struct cvmx_dpi_dmax_reqbnk0_s cn63xx;
	struct cvmx_dpi_dmax_reqbnk0_s cn63xxp1;
	struct cvmx_dpi_dmax_reqbnk0_s cn66xx;
	struct cvmx_dpi_dmax_reqbnk0_s cn68xx;
	struct cvmx_dpi_dmax_reqbnk0_s cn68xxp1;
	struct cvmx_dpi_dmax_reqbnk0_s cnf71xx;
};

union cvmx_dpi_dmax_reqbnk1 {
	uint64_t u64;
	struct cvmx_dpi_dmax_reqbnk1_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t state:64;
#else
		uint64_t state:64;
#endif
	} s;
	struct cvmx_dpi_dmax_reqbnk1_s cn61xx;
	struct cvmx_dpi_dmax_reqbnk1_s cn63xx;
	struct cvmx_dpi_dmax_reqbnk1_s cn63xxp1;
	struct cvmx_dpi_dmax_reqbnk1_s cn66xx;
	struct cvmx_dpi_dmax_reqbnk1_s cn68xx;
	struct cvmx_dpi_dmax_reqbnk1_s cn68xxp1;
	struct cvmx_dpi_dmax_reqbnk1_s cnf71xx;
};

union cvmx_dpi_dma_control {
	uint64_t u64;
	struct cvmx_dpi_dma_control_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_62_63:2;
		uint64_t dici_mode:1;
		uint64_t pkt_en1:1;
		uint64_t ffp_dis:1;
		uint64_t commit_mode:1;
		uint64_t pkt_hp:1;
		uint64_t pkt_en:1;
		uint64_t reserved_54_55:2;
		uint64_t dma_enb:6;
		uint64_t reserved_34_47:14;
		uint64_t b0_lend:1;
		uint64_t dwb_denb:1;
		uint64_t dwb_ichk:9;
		uint64_t fpa_que:3;
		uint64_t o_add1:1;
		uint64_t o_ro:1;
		uint64_t o_ns:1;
		uint64_t o_es:2;
		uint64_t o_mode:1;
		uint64_t reserved_0_13:14;
#else
		uint64_t reserved_0_13:14;
		uint64_t o_mode:1;
		uint64_t o_es:2;
		uint64_t o_ns:1;
		uint64_t o_ro:1;
		uint64_t o_add1:1;
		uint64_t fpa_que:3;
		uint64_t dwb_ichk:9;
		uint64_t dwb_denb:1;
		uint64_t b0_lend:1;
		uint64_t reserved_34_47:14;
		uint64_t dma_enb:6;
		uint64_t reserved_54_55:2;
		uint64_t pkt_en:1;
		uint64_t pkt_hp:1;
		uint64_t commit_mode:1;
		uint64_t ffp_dis:1;
		uint64_t pkt_en1:1;
		uint64_t dici_mode:1;
		uint64_t reserved_62_63:2;
#endif
	} s;
	struct cvmx_dpi_dma_control_s cn61xx;
	struct cvmx_dpi_dma_control_cn63xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_61_63:3;
		uint64_t pkt_en1:1;
		uint64_t ffp_dis:1;
		uint64_t commit_mode:1;
		uint64_t pkt_hp:1;
		uint64_t pkt_en:1;
		uint64_t reserved_54_55:2;
		uint64_t dma_enb:6;
		uint64_t reserved_34_47:14;
		uint64_t b0_lend:1;
		uint64_t dwb_denb:1;
		uint64_t dwb_ichk:9;
		uint64_t fpa_que:3;
		uint64_t o_add1:1;
		uint64_t o_ro:1;
		uint64_t o_ns:1;
		uint64_t o_es:2;
		uint64_t o_mode:1;
		uint64_t reserved_0_13:14;
#else
		uint64_t reserved_0_13:14;
		uint64_t o_mode:1;
		uint64_t o_es:2;
		uint64_t o_ns:1;
		uint64_t o_ro:1;
		uint64_t o_add1:1;
		uint64_t fpa_que:3;
		uint64_t dwb_ichk:9;
		uint64_t dwb_denb:1;
		uint64_t b0_lend:1;
		uint64_t reserved_34_47:14;
		uint64_t dma_enb:6;
		uint64_t reserved_54_55:2;
		uint64_t pkt_en:1;
		uint64_t pkt_hp:1;
		uint64_t commit_mode:1;
		uint64_t ffp_dis:1;
		uint64_t pkt_en1:1;
		uint64_t reserved_61_63:3;
#endif
	} cn63xx;
	struct cvmx_dpi_dma_control_cn63xxp1 {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_59_63:5;
		uint64_t commit_mode:1;
		uint64_t pkt_hp:1;
		uint64_t pkt_en:1;
		uint64_t reserved_54_55:2;
		uint64_t dma_enb:6;
		uint64_t reserved_34_47:14;
		uint64_t b0_lend:1;
		uint64_t dwb_denb:1;
		uint64_t dwb_ichk:9;
		uint64_t fpa_que:3;
		uint64_t o_add1:1;
		uint64_t o_ro:1;
		uint64_t o_ns:1;
		uint64_t o_es:2;
		uint64_t o_mode:1;
		uint64_t reserved_0_13:14;
#else
		uint64_t reserved_0_13:14;
		uint64_t o_mode:1;
		uint64_t o_es:2;
		uint64_t o_ns:1;
		uint64_t o_ro:1;
		uint64_t o_add1:1;
		uint64_t fpa_que:3;
		uint64_t dwb_ichk:9;
		uint64_t dwb_denb:1;
		uint64_t b0_lend:1;
		uint64_t reserved_34_47:14;
		uint64_t dma_enb:6;
		uint64_t reserved_54_55:2;
		uint64_t pkt_en:1;
		uint64_t pkt_hp:1;
		uint64_t commit_mode:1;
		uint64_t reserved_59_63:5;
#endif
	} cn63xxp1;
	struct cvmx_dpi_dma_control_cn63xx cn66xx;
	struct cvmx_dpi_dma_control_s cn68xx;
	struct cvmx_dpi_dma_control_cn63xx cn68xxp1;
	struct cvmx_dpi_dma_control_s cnf71xx;
};

union cvmx_dpi_dma_engx_en {
	uint64_t u64;
	struct cvmx_dpi_dma_engx_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t qen:8;
#else
		uint64_t qen:8;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_dma_engx_en_s cn61xx;
	struct cvmx_dpi_dma_engx_en_s cn63xx;
	struct cvmx_dpi_dma_engx_en_s cn63xxp1;
	struct cvmx_dpi_dma_engx_en_s cn66xx;
	struct cvmx_dpi_dma_engx_en_s cn68xx;
	struct cvmx_dpi_dma_engx_en_s cn68xxp1;
	struct cvmx_dpi_dma_engx_en_s cnf71xx;
};

union cvmx_dpi_dma_ppx_cnt {
	uint64_t u64;
	struct cvmx_dpi_dma_ppx_cnt_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_16_63:48;
		uint64_t cnt:16;
#else
		uint64_t cnt:16;
		uint64_t reserved_16_63:48;
#endif
	} s;
	struct cvmx_dpi_dma_ppx_cnt_s cn61xx;
	struct cvmx_dpi_dma_ppx_cnt_s cn68xx;
	struct cvmx_dpi_dma_ppx_cnt_s cnf71xx;
};

union cvmx_dpi_engx_buf {
	uint64_t u64;
	struct cvmx_dpi_engx_buf_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_37_63:27;
		uint64_t compblks:5;
		uint64_t reserved_9_31:23;
		uint64_t base:5;
		uint64_t blks:4;
#else
		uint64_t blks:4;
		uint64_t base:5;
		uint64_t reserved_9_31:23;
		uint64_t compblks:5;
		uint64_t reserved_37_63:27;
#endif
	} s;
	struct cvmx_dpi_engx_buf_s cn61xx;
	struct cvmx_dpi_engx_buf_cn63xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t base:4;
		uint64_t blks:4;
#else
		uint64_t blks:4;
		uint64_t base:4;
		uint64_t reserved_8_63:56;
#endif
	} cn63xx;
	struct cvmx_dpi_engx_buf_cn63xx cn63xxp1;
	struct cvmx_dpi_engx_buf_s cn66xx;
	struct cvmx_dpi_engx_buf_s cn68xx;
	struct cvmx_dpi_engx_buf_s cn68xxp1;
	struct cvmx_dpi_engx_buf_s cnf71xx;
};

union cvmx_dpi_info_reg {
	uint64_t u64;
	struct cvmx_dpi_info_reg_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t ffp:4;
		uint64_t reserved_2_3:2;
		uint64_t ncb:1;
		uint64_t rsl:1;
#else
		uint64_t rsl:1;
		uint64_t ncb:1;
		uint64_t reserved_2_3:2;
		uint64_t ffp:4;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_info_reg_s cn61xx;
	struct cvmx_dpi_info_reg_s cn63xx;
	struct cvmx_dpi_info_reg_cn63xxp1 {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_2_63:62;
		uint64_t ncb:1;
		uint64_t rsl:1;
#else
		uint64_t rsl:1;
		uint64_t ncb:1;
		uint64_t reserved_2_63:62;
#endif
	} cn63xxp1;
	struct cvmx_dpi_info_reg_s cn66xx;
	struct cvmx_dpi_info_reg_s cn68xx;
	struct cvmx_dpi_info_reg_s cn68xxp1;
	struct cvmx_dpi_info_reg_s cnf71xx;
};

union cvmx_dpi_int_en {
	uint64_t u64;
	struct cvmx_dpi_int_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_28_63:36;
		uint64_t sprt3_rst:1;
		uint64_t sprt2_rst:1;
		uint64_t sprt1_rst:1;
		uint64_t sprt0_rst:1;
		uint64_t reserved_23_23:1;
		uint64_t req_badfil:1;
		uint64_t req_inull:1;
		uint64_t req_anull:1;
		uint64_t req_undflw:1;
		uint64_t req_ovrflw:1;
		uint64_t req_badlen:1;
		uint64_t req_badadr:1;
		uint64_t dmadbo:8;
		uint64_t reserved_2_7:6;
		uint64_t nfovr:1;
		uint64_t nderr:1;
#else
		uint64_t nderr:1;
		uint64_t nfovr:1;
		uint64_t reserved_2_7:6;
		uint64_t dmadbo:8;
		uint64_t req_badadr:1;
		uint64_t req_badlen:1;
		uint64_t req_ovrflw:1;
		uint64_t req_undflw:1;
		uint64_t req_anull:1;
		uint64_t req_inull:1;
		uint64_t req_badfil:1;
		uint64_t reserved_23_23:1;
		uint64_t sprt0_rst:1;
		uint64_t sprt1_rst:1;
		uint64_t sprt2_rst:1;
		uint64_t sprt3_rst:1;
		uint64_t reserved_28_63:36;
#endif
	} s;
	struct cvmx_dpi_int_en_s cn61xx;
	struct cvmx_dpi_int_en_cn63xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_26_63:38;
		uint64_t sprt1_rst:1;
		uint64_t sprt0_rst:1;
		uint64_t reserved_23_23:1;
		uint64_t req_badfil:1;
		uint64_t req_inull:1;
		uint64_t req_anull:1;
		uint64_t req_undflw:1;
		uint64_t req_ovrflw:1;
		uint64_t req_badlen:1;
		uint64_t req_badadr:1;
		uint64_t dmadbo:8;
		uint64_t reserved_2_7:6;
		uint64_t nfovr:1;
		uint64_t nderr:1;
#else
		uint64_t nderr:1;
		uint64_t nfovr:1;
		uint64_t reserved_2_7:6;
		uint64_t dmadbo:8;
		uint64_t req_badadr:1;
		uint64_t req_badlen:1;
		uint64_t req_ovrflw:1;
		uint64_t req_undflw:1;
		uint64_t req_anull:1;
		uint64_t req_inull:1;
		uint64_t req_badfil:1;
		uint64_t reserved_23_23:1;
		uint64_t sprt0_rst:1;
		uint64_t sprt1_rst:1;
		uint64_t reserved_26_63:38;
#endif
	} cn63xx;
	struct cvmx_dpi_int_en_cn63xx cn63xxp1;
	struct cvmx_dpi_int_en_s cn66xx;
	struct cvmx_dpi_int_en_cn63xx cn68xx;
	struct cvmx_dpi_int_en_cn63xx cn68xxp1;
	struct cvmx_dpi_int_en_s cnf71xx;
};

union cvmx_dpi_int_reg {
	uint64_t u64;
	struct cvmx_dpi_int_reg_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_28_63:36;
		uint64_t sprt3_rst:1;
		uint64_t sprt2_rst:1;
		uint64_t sprt1_rst:1;
		uint64_t sprt0_rst:1;
		uint64_t reserved_23_23:1;
		uint64_t req_badfil:1;
		uint64_t req_inull:1;
		uint64_t req_anull:1;
		uint64_t req_undflw:1;
		uint64_t req_ovrflw:1;
		uint64_t req_badlen:1;
		uint64_t req_badadr:1;
		uint64_t dmadbo:8;
		uint64_t reserved_2_7:6;
		uint64_t nfovr:1;
		uint64_t nderr:1;
#else
		uint64_t nderr:1;
		uint64_t nfovr:1;
		uint64_t reserved_2_7:6;
		uint64_t dmadbo:8;
		uint64_t req_badadr:1;
		uint64_t req_badlen:1;
		uint64_t req_ovrflw:1;
		uint64_t req_undflw:1;
		uint64_t req_anull:1;
		uint64_t req_inull:1;
		uint64_t req_badfil:1;
		uint64_t reserved_23_23:1;
		uint64_t sprt0_rst:1;
		uint64_t sprt1_rst:1;
		uint64_t sprt2_rst:1;
		uint64_t sprt3_rst:1;
		uint64_t reserved_28_63:36;
#endif
	} s;
	struct cvmx_dpi_int_reg_s cn61xx;
	struct cvmx_dpi_int_reg_cn63xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_26_63:38;
		uint64_t sprt1_rst:1;
		uint64_t sprt0_rst:1;
		uint64_t reserved_23_23:1;
		uint64_t req_badfil:1;
		uint64_t req_inull:1;
		uint64_t req_anull:1;
		uint64_t req_undflw:1;
		uint64_t req_ovrflw:1;
		uint64_t req_badlen:1;
		uint64_t req_badadr:1;
		uint64_t dmadbo:8;
		uint64_t reserved_2_7:6;
		uint64_t nfovr:1;
		uint64_t nderr:1;
#else
		uint64_t nderr:1;
		uint64_t nfovr:1;
		uint64_t reserved_2_7:6;
		uint64_t dmadbo:8;
		uint64_t req_badadr:1;
		uint64_t req_badlen:1;
		uint64_t req_ovrflw:1;
		uint64_t req_undflw:1;
		uint64_t req_anull:1;
		uint64_t req_inull:1;
		uint64_t req_badfil:1;
		uint64_t reserved_23_23:1;
		uint64_t sprt0_rst:1;
		uint64_t sprt1_rst:1;
		uint64_t reserved_26_63:38;
#endif
	} cn63xx;
	struct cvmx_dpi_int_reg_cn63xx cn63xxp1;
	struct cvmx_dpi_int_reg_s cn66xx;
	struct cvmx_dpi_int_reg_cn63xx cn68xx;
	struct cvmx_dpi_int_reg_cn63xx cn68xxp1;
	struct cvmx_dpi_int_reg_s cnf71xx;
};

union cvmx_dpi_ncbx_cfg {
	uint64_t u64;
	struct cvmx_dpi_ncbx_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_6_63:58;
		uint64_t molr:6;
#else
		uint64_t molr:6;
		uint64_t reserved_6_63:58;
#endif
	} s;
	struct cvmx_dpi_ncbx_cfg_s cn61xx;
	struct cvmx_dpi_ncbx_cfg_s cn66xx;
	struct cvmx_dpi_ncbx_cfg_s cn68xx;
	struct cvmx_dpi_ncbx_cfg_s cnf71xx;
};

union cvmx_dpi_pint_info {
	uint64_t u64;
	struct cvmx_dpi_pint_info_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_14_63:50;
		uint64_t iinfo:6;
		uint64_t reserved_6_7:2;
		uint64_t sinfo:6;
#else
		uint64_t sinfo:6;
		uint64_t reserved_6_7:2;
		uint64_t iinfo:6;
		uint64_t reserved_14_63:50;
#endif
	} s;
	struct cvmx_dpi_pint_info_s cn61xx;
	struct cvmx_dpi_pint_info_s cn63xx;
	struct cvmx_dpi_pint_info_s cn63xxp1;
	struct cvmx_dpi_pint_info_s cn66xx;
	struct cvmx_dpi_pint_info_s cn68xx;
	struct cvmx_dpi_pint_info_s cn68xxp1;
	struct cvmx_dpi_pint_info_s cnf71xx;
};

union cvmx_dpi_pkt_err_rsp {
	uint64_t u64;
	struct cvmx_dpi_pkt_err_rsp_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_1_63:63;
		uint64_t pkterr:1;
#else
		uint64_t pkterr:1;
		uint64_t reserved_1_63:63;
#endif
	} s;
	struct cvmx_dpi_pkt_err_rsp_s cn61xx;
	struct cvmx_dpi_pkt_err_rsp_s cn63xx;
	struct cvmx_dpi_pkt_err_rsp_s cn63xxp1;
	struct cvmx_dpi_pkt_err_rsp_s cn66xx;
	struct cvmx_dpi_pkt_err_rsp_s cn68xx;
	struct cvmx_dpi_pkt_err_rsp_s cn68xxp1;
	struct cvmx_dpi_pkt_err_rsp_s cnf71xx;
};

union cvmx_dpi_req_err_rsp {
	uint64_t u64;
	struct cvmx_dpi_req_err_rsp_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t qerr:8;
#else
		uint64_t qerr:8;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_req_err_rsp_s cn61xx;
	struct cvmx_dpi_req_err_rsp_s cn63xx;
	struct cvmx_dpi_req_err_rsp_s cn63xxp1;
	struct cvmx_dpi_req_err_rsp_s cn66xx;
	struct cvmx_dpi_req_err_rsp_s cn68xx;
	struct cvmx_dpi_req_err_rsp_s cn68xxp1;
	struct cvmx_dpi_req_err_rsp_s cnf71xx;
};

union cvmx_dpi_req_err_rsp_en {
	uint64_t u64;
	struct cvmx_dpi_req_err_rsp_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t en:8;
#else
		uint64_t en:8;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_req_err_rsp_en_s cn61xx;
	struct cvmx_dpi_req_err_rsp_en_s cn63xx;
	struct cvmx_dpi_req_err_rsp_en_s cn63xxp1;
	struct cvmx_dpi_req_err_rsp_en_s cn66xx;
	struct cvmx_dpi_req_err_rsp_en_s cn68xx;
	struct cvmx_dpi_req_err_rsp_en_s cn68xxp1;
	struct cvmx_dpi_req_err_rsp_en_s cnf71xx;
};

union cvmx_dpi_req_err_rst {
	uint64_t u64;
	struct cvmx_dpi_req_err_rst_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t qerr:8;
#else
		uint64_t qerr:8;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_req_err_rst_s cn61xx;
	struct cvmx_dpi_req_err_rst_s cn63xx;
	struct cvmx_dpi_req_err_rst_s cn63xxp1;
	struct cvmx_dpi_req_err_rst_s cn66xx;
	struct cvmx_dpi_req_err_rst_s cn68xx;
	struct cvmx_dpi_req_err_rst_s cn68xxp1;
	struct cvmx_dpi_req_err_rst_s cnf71xx;
};

union cvmx_dpi_req_err_rst_en {
	uint64_t u64;
	struct cvmx_dpi_req_err_rst_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t en:8;
#else
		uint64_t en:8;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_req_err_rst_en_s cn61xx;
	struct cvmx_dpi_req_err_rst_en_s cn63xx;
	struct cvmx_dpi_req_err_rst_en_s cn63xxp1;
	struct cvmx_dpi_req_err_rst_en_s cn66xx;
	struct cvmx_dpi_req_err_rst_en_s cn68xx;
	struct cvmx_dpi_req_err_rst_en_s cn68xxp1;
	struct cvmx_dpi_req_err_rst_en_s cnf71xx;
};

union cvmx_dpi_req_err_skip_comp {
	uint64_t u64;
	struct cvmx_dpi_req_err_skip_comp_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_24_63:40;
		uint64_t en_rst:8;
		uint64_t reserved_8_15:8;
		uint64_t en_rsp:8;
#else
		uint64_t en_rsp:8;
		uint64_t reserved_8_15:8;
		uint64_t en_rst:8;
		uint64_t reserved_24_63:40;
#endif
	} s;
	struct cvmx_dpi_req_err_skip_comp_s cn61xx;
	struct cvmx_dpi_req_err_skip_comp_s cn66xx;
	struct cvmx_dpi_req_err_skip_comp_s cn68xx;
	struct cvmx_dpi_req_err_skip_comp_s cn68xxp1;
	struct cvmx_dpi_req_err_skip_comp_s cnf71xx;
};

union cvmx_dpi_req_gbl_en {
	uint64_t u64;
	struct cvmx_dpi_req_gbl_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t qen:8;
#else
		uint64_t qen:8;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_dpi_req_gbl_en_s cn61xx;
	struct cvmx_dpi_req_gbl_en_s cn63xx;
	struct cvmx_dpi_req_gbl_en_s cn63xxp1;
	struct cvmx_dpi_req_gbl_en_s cn66xx;
	struct cvmx_dpi_req_gbl_en_s cn68xx;
	struct cvmx_dpi_req_gbl_en_s cn68xxp1;
	struct cvmx_dpi_req_gbl_en_s cnf71xx;
};

union cvmx_dpi_sli_prtx_cfg {
	uint64_t u64;
	struct cvmx_dpi_sli_prtx_cfg_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_25_63:39;
		uint64_t halt:1;
		uint64_t qlm_cfg:4;
		uint64_t reserved_17_19:3;
		uint64_t rd_mode:1;
		uint64_t reserved_14_15:2;
		uint64_t molr:6;
		uint64_t mps_lim:1;
		uint64_t reserved_5_6:2;
		uint64_t mps:1;
		uint64_t mrrs_lim:1;
		uint64_t reserved_2_2:1;
		uint64_t mrrs:2;
#else
		uint64_t mrrs:2;
		uint64_t reserved_2_2:1;
		uint64_t mrrs_lim:1;
		uint64_t mps:1;
		uint64_t reserved_5_6:2;
		uint64_t mps_lim:1;
		uint64_t molr:6;
		uint64_t reserved_14_15:2;
		uint64_t rd_mode:1;
		uint64_t reserved_17_19:3;
		uint64_t qlm_cfg:4;
		uint64_t halt:1;
		uint64_t reserved_25_63:39;
#endif
	} s;
	struct cvmx_dpi_sli_prtx_cfg_s cn61xx;
	struct cvmx_dpi_sli_prtx_cfg_cn63xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_25_63:39;
		uint64_t halt:1;
		uint64_t reserved_21_23:3;
		uint64_t qlm_cfg:1;
		uint64_t reserved_17_19:3;
		uint64_t rd_mode:1;
		uint64_t reserved_14_15:2;
		uint64_t molr:6;
		uint64_t mps_lim:1;
		uint64_t reserved_5_6:2;
		uint64_t mps:1;
		uint64_t mrrs_lim:1;
		uint64_t reserved_2_2:1;
		uint64_t mrrs:2;
#else
		uint64_t mrrs:2;
		uint64_t reserved_2_2:1;
		uint64_t mrrs_lim:1;
		uint64_t mps:1;
		uint64_t reserved_5_6:2;
		uint64_t mps_lim:1;
		uint64_t molr:6;
		uint64_t reserved_14_15:2;
		uint64_t rd_mode:1;
		uint64_t reserved_17_19:3;
		uint64_t qlm_cfg:1;
		uint64_t reserved_21_23:3;
		uint64_t halt:1;
		uint64_t reserved_25_63:39;
#endif
	} cn63xx;
	struct cvmx_dpi_sli_prtx_cfg_cn63xx cn63xxp1;
	struct cvmx_dpi_sli_prtx_cfg_s cn66xx;
	struct cvmx_dpi_sli_prtx_cfg_cn63xx cn68xx;
	struct cvmx_dpi_sli_prtx_cfg_cn63xx cn68xxp1;
	struct cvmx_dpi_sli_prtx_cfg_s cnf71xx;
};

union cvmx_dpi_sli_prtx_err {
	uint64_t u64;
	struct cvmx_dpi_sli_prtx_err_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t addr:61;
		uint64_t reserved_0_2:3;
#else
		uint64_t reserved_0_2:3;
		uint64_t addr:61;
#endif
	} s;
	struct cvmx_dpi_sli_prtx_err_s cn61xx;
	struct cvmx_dpi_sli_prtx_err_s cn63xx;
	struct cvmx_dpi_sli_prtx_err_s cn63xxp1;
	struct cvmx_dpi_sli_prtx_err_s cn66xx;
	struct cvmx_dpi_sli_prtx_err_s cn68xx;
	struct cvmx_dpi_sli_prtx_err_s cn68xxp1;
	struct cvmx_dpi_sli_prtx_err_s cnf71xx;
};

union cvmx_dpi_sli_prtx_err_info {
	uint64_t u64;
	struct cvmx_dpi_sli_prtx_err_info_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_9_63:55;
		uint64_t lock:1;
		uint64_t reserved_5_7:3;
		uint64_t type:1;
		uint64_t reserved_3_3:1;
		uint64_t reqq:3;
#else
		uint64_t reqq:3;
		uint64_t reserved_3_3:1;
		uint64_t type:1;
		uint64_t reserved_5_7:3;
		uint64_t lock:1;
		uint64_t reserved_9_63:55;
#endif
	} s;
	struct cvmx_dpi_sli_prtx_err_info_s cn61xx;
	struct cvmx_dpi_sli_prtx_err_info_s cn63xx;
	struct cvmx_dpi_sli_prtx_err_info_s cn63xxp1;
	struct cvmx_dpi_sli_prtx_err_info_s cn66xx;
	struct cvmx_dpi_sli_prtx_err_info_s cn68xx;
	struct cvmx_dpi_sli_prtx_err_info_s cn68xxp1;
	struct cvmx_dpi_sli_prtx_err_info_s cnf71xx;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*
 * Copyright (c) 2003-2016 Cavium Inc.
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 */

#ifndef __CVMX_CIU3_DEFS_H__
#define __CVMX_CIU3_DEFS_H__

#define CVMX_CIU3_FUSE CVMX_ADD_IO_SEG(0x00010100000001A0ull)
#define CVMX_CIU3_BIST CVMX_ADD_IO_SEG(0x00010100000001C0ull)
#define CVMX_CIU3_CONST CVMX_ADD_IO_SEG(0x0001010000000220ull)
#define CVMX_CIU3_CTL CVMX_ADD_IO_SEG(0x00010100000000E0ull)
#define CVMX_CIU3_DESTX_IO_INT(offset) (CVMX_ADD_IO_SEG(0x0001010000210000ull) + ((offset) & 7) * 8)
#define CVMX_CIU3_DESTX_PP_INT(offset) (CVMX_ADD_IO_SEG(0x0001010000200000ull) + ((offset) & 255) * 8)
#define CVMX_CIU3_GSTOP CVMX_ADD_IO_SEG(0x0001010000000140ull)
#define CVMX_CIU3_IDTX_CTL(offset) (CVMX_ADD_IO_SEG(0x0001010000110000ull) + ((offset) & 255) * 8)
#define CVMX_CIU3_IDTX_IO(offset) (CVMX_ADD_IO_SEG(0x0001010000130000ull) + ((offset) & 255) * 8)
#define CVMX_CIU3_IDTX_PPX(offset, block_id) (CVMX_ADD_IO_SEG(0x0001010000120000ull) + ((block_id) & 255) * 0x20ull)
#define CVMX_CIU3_INTR_RAM_ECC_CTL CVMX_ADD_IO_SEG(0x0001010000000260ull)
#define CVMX_CIU3_INTR_RAM_ECC_ST CVMX_ADD_IO_SEG(0x0001010000000280ull)
#define CVMX_CIU3_INTR_READY CVMX_ADD_IO_SEG(0x00010100000002A0ull)
#define CVMX_CIU3_INTR_SLOWDOWN CVMX_ADD_IO_SEG(0x0001010000000240ull)
#define CVMX_CIU3_ISCX_CTL(offset) (CVMX_ADD_IO_SEG(0x0001010080000000ull) + ((offset) & 1048575) * 8)
#define CVMX_CIU3_ISCX_W1C(offset) (CVMX_ADD_IO_SEG(0x0001010090000000ull) + ((offset) & 1048575) * 8)
#define CVMX_CIU3_ISCX_W1S(offset) (CVMX_ADD_IO_SEG(0x00010100A0000000ull) + ((offset) & 1048575) * 8)
#define CVMX_CIU3_NMI CVMX_ADD_IO_SEG(0x0001010000000160ull)
#define CVMX_CIU3_SISCX(offset) (CVMX_ADD_IO_SEG(0x0001010000220000ull) + ((offset) & 255) * 8)
#define CVMX_CIU3_TIMX(offset) (CVMX_ADD_IO_SEG(0x0001010000010000ull) + ((offset) & 15) * 8)

union cvmx_ciu3_bist {
	uint64_t u64;
	struct cvmx_ciu3_bist_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_9_63                : 55;
	uint64_t bist                         : 9;
#else
	uint64_t bist                         : 9;
	uint64_t reserved_9_63                : 55;
#endif
	} s;
};

union cvmx_ciu3_const {
	uint64_t u64;
	struct cvmx_ciu3_const_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t dests_io                     : 16;
	uint64_t pintsn                       : 16;
	uint64_t dests_pp                     : 16;
	uint64_t idt                          : 16;
#else
	uint64_t idt                          : 16;
	uint64_t dests_pp                     : 16;
	uint64_t pintsn                       : 16;
	uint64_t dests_io                     : 16;
#endif
	} s;
};

union cvmx_ciu3_ctl {
	uint64_t u64;
	struct cvmx_ciu3_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_5_63                : 59;
	uint64_t mcd_sel                      : 2;
	uint64_t iscmem_le                    : 1;
	uint64_t seq_dis                      : 1;
	uint64_t cclk_dis                     : 1;
#else
	uint64_t cclk_dis                     : 1;
	uint64_t seq_dis                      : 1;
	uint64_t iscmem_le                    : 1;
	uint64_t mcd_sel                      : 2;
	uint64_t reserved_5_63                : 59;
#endif
	} s;
};

union cvmx_ciu3_destx_io_int {
	uint64_t u64;
	struct cvmx_ciu3_destx_io_int_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_52_63               : 12;
	uint64_t intsn                        : 20;
	uint64_t reserved_10_31               : 22;
	uint64_t intidt                       : 8;
	uint64_t newint                       : 1;
	uint64_t intr                         : 1;
#else
	uint64_t intr                         : 1;
	uint64_t newint                       : 1;
	uint64_t intidt                       : 8;
	uint64_t reserved_10_31               : 22;
	uint64_t intsn                        : 20;
	uint64_t reserved_52_63               : 12;
#endif
	} s;
};

union cvmx_ciu3_destx_pp_int {
	uint64_t u64;
	struct cvmx_ciu3_destx_pp_int_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_52_63               : 12;
	uint64_t intsn                        : 20;
	uint64_t reserved_10_31               : 22;
	uint64_t intidt                       : 8;
	uint64_t newint                       : 1;
	uint64_t intr                         : 1;
#else
	uint64_t intr                         : 1;
	uint64_t newint                       : 1;
	uint64_t intidt                       : 8;
	uint64_t reserved_10_31               : 22;
	uint64_t intsn                        : 20;
	uint64_t reserved_52_63               : 12;
#endif
	} s;
};

union cvmx_ciu3_gstop {
	uint64_t u64;
	struct cvmx_ciu3_gstop_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_1_63                : 63;
	uint64_t gstop                        : 1;
#else
	uint64_t gstop                        : 1;
	uint64_t reserved_1_63                : 63;
#endif
	} s;
};

union cvmx_ciu3_idtx_ctl {
	uint64_t u64;
	struct cvmx_ciu3_idtx_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_52_63               : 12;
	uint64_t intsn                        : 20;
	uint64_t reserved_4_31                : 28;
	uint64_t intr                         : 1;
	uint64_t newint                       : 1;
	uint64_t ip_num                       : 2;
#else
	uint64_t ip_num                       : 2;
	uint64_t newint                       : 1;
	uint64_t intr                         : 1;
	uint64_t reserved_4_31                : 28;
	uint64_t intsn                        : 20;
	uint64_t reserved_52_63               : 12;
#endif
	} s;
};

union cvmx_ciu3_idtx_io {
	uint64_t u64;
	struct cvmx_ciu3_idtx_io_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_5_63                : 59;
	uint64_t io                           : 5;
#else
	uint64_t io                           : 5;
	uint64_t reserved_5_63                : 59;
#endif
	} s;
};

union cvmx_ciu3_idtx_ppx {
	uint64_t u64;
	struct cvmx_ciu3_idtx_ppx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_48_63               : 16;
	uint64_t pp                           : 48;
#else
	uint64_t pp                           : 48;
	uint64_t reserved_48_63               : 16;
#endif
	} s;
};

union cvmx_ciu3_intr_ram_ecc_ctl {
	uint64_t u64;
	struct cvmx_ciu3_intr_ram_ecc_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_3_63                : 61;
	uint64_t flip_synd                    : 2;
	uint64_t ecc_ena                      : 1;
#else
	uint64_t ecc_ena                      : 1;
	uint64_t flip_synd                    : 2;
	uint64_t reserved_3_63                : 61;
#endif
	} s;
};

union cvmx_ciu3_intr_ram_ecc_st {
	uint64_t u64;
	struct cvmx_ciu3_intr_ram_ecc_st_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_52_63               : 12;
	uint64_t addr                         : 20;
	uint64_t reserved_6_31                : 26;
	uint64_t sisc_dbe                     : 1;
	uint64_t sisc_sbe                     : 1;
	uint64_t idt_dbe                      : 1;
	uint64_t idt_sbe                      : 1;
	uint64_t isc_dbe                      : 1;
	uint64_t isc_sbe                      : 1;
#else
	uint64_t isc_sbe                      : 1;
	uint64_t isc_dbe                      : 1;
	uint64_t idt_sbe                      : 1;
	uint64_t idt_dbe                      : 1;
	uint64_t sisc_sbe                     : 1;
	uint64_t sisc_dbe                     : 1;
	uint64_t reserved_6_31                : 26;
	uint64_t addr                         : 20;
	uint64_t reserved_52_63               : 12;
#endif
	} s;
};

union cvmx_ciu3_intr_ready {
	uint64_t u64;
	struct cvmx_ciu3_intr_ready_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_46_63               : 18;
	uint64_t index                        : 14;
	uint64_t reserved_1_31                : 31;
	uint64_t ready                        : 1;
#else
	uint64_t ready                        : 1;
	uint64_t reserved_1_31                : 31;
	uint64_t index                        : 14;
	uint64_t reserved_46_63               : 18;
#endif
	} s;
};

union cvmx_ciu3_intr_slowdown {
	uint64_t u64;
	struct cvmx_ciu3_intr_slowdown_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_3_63                : 61;
	uint64_t ctl                          : 3;
#else
	uint64_t ctl                          : 3;
	uint64_t reserved_3_63                : 61;
#endif
	} s;
};

union cvmx_ciu3_iscx_ctl {
	uint64_t u64;
	struct cvmx_ciu3_iscx_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_24_63               : 40;
	uint64_t idt                          : 8;
	uint64_t imp                          : 1;
	uint64_t reserved_2_14                : 13;
	uint64_t en                           : 1;
	uint64_t raw                          : 1;
#else
	uint64_t raw                          : 1;
	uint64_t en                           : 1;
	uint64_t reserved_2_14                : 13;
	uint64_t imp                          : 1;
	uint64_t idt                          : 8;
	uint64_t reserved_24_63               : 40;
#endif
	} s;
};

union cvmx_ciu3_iscx_w1c {
	uint64_t u64;
	struct cvmx_ciu3_iscx_w1c_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_2_63                : 62;
	uint64_t en                           : 1;
	uint64_t raw                          : 1;
#else
	uint64_t raw                          : 1;
	uint64_t en                           : 1;
	uint64_t reserved_2_63                : 62;
#endif
	} s;
};

union cvmx_ciu3_iscx_w1s {
	uint64_t u64;
	struct cvmx_ciu3_iscx_w1s_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_2_63                : 62;
	uint64_t en                           : 1;
	uint64_t raw                          : 1;
#else
	uint64_t raw                          : 1;
	uint64_t en                           : 1;
	uint64_t reserved_2_63                : 62;
#endif
	} s;
};

union cvmx_ciu3_nmi {
	uint64_t u64;
	struct cvmx_ciu3_nmi_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_48_63               : 16;
	uint64_t nmi                          : 48;
#else
	uint64_t nmi                          : 48;
	uint64_t reserved_48_63               : 16;
#endif
	} s;
};

union cvmx_ciu3_siscx {
	uint64_t u64;
	struct cvmx_ciu3_siscx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t en                           : 64;
#else
	uint64_t en                           : 64;
#endif
	} s;
};

union cvmx_ciu3_timx {
	uint64_t u64;
	struct cvmx_ciu3_timx_s {
#ifdef __BIG_ENDIAN_BITFIELD
	uint64_t reserved_37_63               : 27;
	uint64_t one_shot                     : 1;
	uint64_t len                          : 36;
#else
	uint64_t len                          : 36;
	uint64_t one_shot                     : 1;
	uint64_t reserved_37_63               : 27;
#endif
	} s;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2012 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

#ifndef __CVMX_UCTLX_DEFS_H__
#define __CVMX_UCTLX_DEFS_H__

#define CVMX_UCTLX_BIST_STATUS(block_id) (CVMX_ADD_IO_SEG(0x000118006F0000A0ull))
#define CVMX_UCTLX_CLK_RST_CTL(block_id) (CVMX_ADD_IO_SEG(0x000118006F000000ull))
#define CVMX_UCTLX_EHCI_CTL(block_id) (CVMX_ADD_IO_SEG(0x000118006F000080ull))
#define CVMX_UCTLX_EHCI_FLA(block_id) (CVMX_ADD_IO_SEG(0x000118006F0000A8ull))
#define CVMX_UCTLX_ERTO_CTL(block_id) (CVMX_ADD_IO_SEG(0x000118006F000090ull))
#define CVMX_UCTLX_IF_ENA(block_id) (CVMX_ADD_IO_SEG(0x000118006F000030ull))
#define CVMX_UCTLX_INT_ENA(block_id) (CVMX_ADD_IO_SEG(0x000118006F000028ull))
#define CVMX_UCTLX_INT_REG(block_id) (CVMX_ADD_IO_SEG(0x000118006F000020ull))
#define CVMX_UCTLX_OHCI_CTL(block_id) (CVMX_ADD_IO_SEG(0x000118006F000088ull))
#define CVMX_UCTLX_ORTO_CTL(block_id) (CVMX_ADD_IO_SEG(0x000118006F000098ull))
#define CVMX_UCTLX_PPAF_WM(block_id) (CVMX_ADD_IO_SEG(0x000118006F000038ull))
#define CVMX_UCTLX_UPHY_CTL_STATUS(block_id) (CVMX_ADD_IO_SEG(0x000118006F000008ull))
#define CVMX_UCTLX_UPHY_PORTX_CTL_STATUS(offset, block_id) (CVMX_ADD_IO_SEG(0x000118006F000010ull) + (((offset) & 1) + ((block_id) & 0) * 0x0ull) * 8)

union cvmx_uctlx_bist_status {
	uint64_t u64;
	struct cvmx_uctlx_bist_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_6_63:58;
		uint64_t data_bis:1;
		uint64_t desc_bis:1;
		uint64_t erbm_bis:1;
		uint64_t orbm_bis:1;
		uint64_t wrbm_bis:1;
		uint64_t ppaf_bis:1;
#else
		uint64_t ppaf_bis:1;
		uint64_t wrbm_bis:1;
		uint64_t orbm_bis:1;
		uint64_t erbm_bis:1;
		uint64_t desc_bis:1;
		uint64_t data_bis:1;
		uint64_t reserved_6_63:58;
#endif
	} s;
	struct cvmx_uctlx_bist_status_s cn61xx;
	struct cvmx_uctlx_bist_status_s cn63xx;
	struct cvmx_uctlx_bist_status_s cn63xxp1;
	struct cvmx_uctlx_bist_status_s cn66xx;
	struct cvmx_uctlx_bist_status_s cn68xx;
	struct cvmx_uctlx_bist_status_s cn68xxp1;
	struct cvmx_uctlx_bist_status_s cnf71xx;
};

union cvmx_uctlx_clk_rst_ctl {
	uint64_t u64;
	struct cvmx_uctlx_clk_rst_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_25_63:39;
		uint64_t clear_bist:1;
		uint64_t start_bist:1;
		uint64_t ehci_sm:1;
		uint64_t ohci_clkcktrst:1;
		uint64_t ohci_sm:1;
		uint64_t ohci_susp_lgcy:1;
		uint64_t app_start_clk:1;
		uint64_t o_clkdiv_rst:1;
		uint64_t h_clkdiv_byp:1;
		uint64_t h_clkdiv_rst:1;
		uint64_t h_clkdiv_en:1;
		uint64_t o_clkdiv_en:1;
		uint64_t h_div:4;
		uint64_t p_refclk_sel:2;
		uint64_t p_refclk_div:2;
		uint64_t reserved_4_4:1;
		uint64_t p_com_on:1;
		uint64_t p_por:1;
		uint64_t p_prst:1;
		uint64_t hrst:1;
#else
		uint64_t hrst:1;
		uint64_t p_prst:1;
		uint64_t p_por:1;
		uint64_t p_com_on:1;
		uint64_t reserved_4_4:1;
		uint64_t p_refclk_div:2;
		uint64_t p_refclk_sel:2;
		uint64_t h_div:4;
		uint64_t o_clkdiv_en:1;
		uint64_t h_clkdiv_en:1;
		uint64_t h_clkdiv_rst:1;
		uint64_t h_clkdiv_byp:1;
		uint64_t o_clkdiv_rst:1;
		uint64_t app_start_clk:1;
		uint64_t ohci_susp_lgcy:1;
		uint64_t ohci_sm:1;
		uint64_t ohci_clkcktrst:1;
		uint64_t ehci_sm:1;
		uint64_t start_bist:1;
		uint64_t clear_bist:1;
		uint64_t reserved_25_63:39;
#endif
	} s;
	struct cvmx_uctlx_clk_rst_ctl_s cn61xx;
	struct cvmx_uctlx_clk_rst_ctl_s cn63xx;
	struct cvmx_uctlx_clk_rst_ctl_s cn63xxp1;
	struct cvmx_uctlx_clk_rst_ctl_s cn66xx;
	struct cvmx_uctlx_clk_rst_ctl_s cn68xx;
	struct cvmx_uctlx_clk_rst_ctl_s cn68xxp1;
	struct cvmx_uctlx_clk_rst_ctl_s cnf71xx;
};

union cvmx_uctlx_ehci_ctl {
	uint64_t u64;
	struct cvmx_uctlx_ehci_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_20_63:44;
		uint64_t desc_rbm:1;
		uint64_t reg_nb:1;
		uint64_t l2c_dc:1;
		uint64_t l2c_bc:1;
		uint64_t l2c_0pag:1;
		uint64_t l2c_stt:1;
		uint64_t l2c_buff_emod:2;
		uint64_t l2c_desc_emod:2;
		uint64_t inv_reg_a2:1;
		uint64_t ehci_64b_addr_en:1;
		uint64_t l2c_addr_msb:8;
#else
		uint64_t l2c_addr_msb:8;
		uint64_t ehci_64b_addr_en:1;
		uint64_t inv_reg_a2:1;
		uint64_t l2c_desc_emod:2;
		uint64_t l2c_buff_emod:2;
		uint64_t l2c_stt:1;
		uint64_t l2c_0pag:1;
		uint64_t l2c_bc:1;
		uint64_t l2c_dc:1;
		uint64_t reg_nb:1;
		uint64_t desc_rbm:1;
		uint64_t reserved_20_63:44;
#endif
	} s;
	struct cvmx_uctlx_ehci_ctl_s cn61xx;
	struct cvmx_uctlx_ehci_ctl_s cn63xx;
	struct cvmx_uctlx_ehci_ctl_s cn63xxp1;
	struct cvmx_uctlx_ehci_ctl_s cn66xx;
	struct cvmx_uctlx_ehci_ctl_s cn68xx;
	struct cvmx_uctlx_ehci_ctl_s cn68xxp1;
	struct cvmx_uctlx_ehci_ctl_s cnf71xx;
};

union cvmx_uctlx_ehci_fla {
	uint64_t u64;
	struct cvmx_uctlx_ehci_fla_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_6_63:58;
		uint64_t fla:6;
#else
		uint64_t fla:6;
		uint64_t reserved_6_63:58;
#endif
	} s;
	struct cvmx_uctlx_ehci_fla_s cn61xx;
	struct cvmx_uctlx_ehci_fla_s cn63xx;
	struct cvmx_uctlx_ehci_fla_s cn63xxp1;
	struct cvmx_uctlx_ehci_fla_s cn66xx;
	struct cvmx_uctlx_ehci_fla_s cn68xx;
	struct cvmx_uctlx_ehci_fla_s cn68xxp1;
	struct cvmx_uctlx_ehci_fla_s cnf71xx;
};

union cvmx_uctlx_erto_ctl {
	uint64_t u64;
	struct cvmx_uctlx_erto_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_32_63:32;
		uint64_t to_val:27;
		uint64_t reserved_0_4:5;
#else
		uint64_t reserved_0_4:5;
		uint64_t to_val:27;
		uint64_t reserved_32_63:32;
#endif
	} s;
	struct cvmx_uctlx_erto_ctl_s cn61xx;
	struct cvmx_uctlx_erto_ctl_s cn63xx;
	struct cvmx_uctlx_erto_ctl_s cn63xxp1;
	struct cvmx_uctlx_erto_ctl_s cn66xx;
	struct cvmx_uctlx_erto_ctl_s cn68xx;
	struct cvmx_uctlx_erto_ctl_s cn68xxp1;
	struct cvmx_uctlx_erto_ctl_s cnf71xx;
};

union cvmx_uctlx_if_ena {
	uint64_t u64;
	struct cvmx_uctlx_if_ena_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_1_63:63;
		uint64_t en:1;
#else
		uint64_t en:1;
		uint64_t reserved_1_63:63;
#endif
	} s;
	struct cvmx_uctlx_if_ena_s cn61xx;
	struct cvmx_uctlx_if_ena_s cn63xx;
	struct cvmx_uctlx_if_ena_s cn63xxp1;
	struct cvmx_uctlx_if_ena_s cn66xx;
	struct cvmx_uctlx_if_ena_s cn68xx;
	struct cvmx_uctlx_if_ena_s cn68xxp1;
	struct cvmx_uctlx_if_ena_s cnf71xx;
};

union cvmx_uctlx_int_ena {
	uint64_t u64;
	struct cvmx_uctlx_int_ena_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t ec_ovf_e:1;
		uint64_t oc_ovf_e:1;
		uint64_t wb_pop_e:1;
		uint64_t wb_psh_f:1;
		uint64_t cf_psh_f:1;
		uint64_t or_psh_f:1;
		uint64_t er_psh_f:1;
		uint64_t pp_psh_f:1;
#else
		uint64_t pp_psh_f:1;
		uint64_t er_psh_f:1;
		uint64_t or_psh_f:1;
		uint64_t cf_psh_f:1;
		uint64_t wb_psh_f:1;
		uint64_t wb_pop_e:1;
		uint64_t oc_ovf_e:1;
		uint64_t ec_ovf_e:1;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_uctlx_int_ena_s cn61xx;
	struct cvmx_uctlx_int_ena_s cn63xx;
	struct cvmx_uctlx_int_ena_s cn63xxp1;
	struct cvmx_uctlx_int_ena_s cn66xx;
	struct cvmx_uctlx_int_ena_s cn68xx;
	struct cvmx_uctlx_int_ena_s cn68xxp1;
	struct cvmx_uctlx_int_ena_s cnf71xx;
};

union cvmx_uctlx_int_reg {
	uint64_t u64;
	struct cvmx_uctlx_int_reg_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t ec_ovf_e:1;
		uint64_t oc_ovf_e:1;
		uint64_t wb_pop_e:1;
		uint64_t wb_psh_f:1;
		uint64_t cf_psh_f:1;
		uint64_t or_psh_f:1;
		uint64_t er_psh_f:1;
		uint64_t pp_psh_f:1;
#else
		uint64_t pp_psh_f:1;
		uint64_t er_psh_f:1;
		uint64_t or_psh_f:1;
		uint64_t cf_psh_f:1;
		uint64_t wb_psh_f:1;
		uint64_t wb_pop_e:1;
		uint64_t oc_ovf_e:1;
		uint64_t ec_ovf_e:1;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_uctlx_int_reg_s cn61xx;
	struct cvmx_uctlx_int_reg_s cn63xx;
	struct cvmx_uctlx_int_reg_s cn63xxp1;
	struct cvmx_uctlx_int_reg_s cn66xx;
	struct cvmx_uctlx_int_reg_s cn68xx;
	struct cvmx_uctlx_int_reg_s cn68xxp1;
	struct cvmx_uctlx_int_reg_s cnf71xx;
};

union cvmx_uctlx_ohci_ctl {
	uint64_t u64;
	struct cvmx_uctlx_ohci_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_19_63:45;
		uint64_t reg_nb:1;
		uint64_t l2c_dc:1;
		uint64_t l2c_bc:1;
		uint64_t l2c_0pag:1;
		uint64_t l2c_stt:1;
		uint64_t l2c_buff_emod:2;
		uint64_t l2c_desc_emod:2;
		uint64_t inv_reg_a2:1;
		uint64_t reserved_8_8:1;
		uint64_t l2c_addr_msb:8;
#else
		uint64_t l2c_addr_msb:8;
		uint64_t reserved_8_8:1;
		uint64_t inv_reg_a2:1;
		uint64_t l2c_desc_emod:2;
		uint64_t l2c_buff_emod:2;
		uint64_t l2c_stt:1;
		uint64_t l2c_0pag:1;
		uint64_t l2c_bc:1;
		uint64_t l2c_dc:1;
		uint64_t reg_nb:1;
		uint64_t reserved_19_63:45;
#endif
	} s;
	struct cvmx_uctlx_ohci_ctl_s cn61xx;
	struct cvmx_uctlx_ohci_ctl_s cn63xx;
	struct cvmx_uctlx_ohci_ctl_s cn63xxp1;
	struct cvmx_uctlx_ohci_ctl_s cn66xx;
	struct cvmx_uctlx_ohci_ctl_s cn68xx;
	struct cvmx_uctlx_ohci_ctl_s cn68xxp1;
	struct cvmx_uctlx_ohci_ctl_s cnf71xx;
};

union cvmx_uctlx_orto_ctl {
	uint64_t u64;
	struct cvmx_uctlx_orto_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_32_63:32;
		uint64_t to_val:24;
		uint64_t reserved_0_7:8;
#else
		uint64_t reserved_0_7:8;
		uint64_t to_val:24;
		uint64_t reserved_32_63:32;
#endif
	} s;
	struct cvmx_uctlx_orto_ctl_s cn61xx;
	struct cvmx_uctlx_orto_ctl_s cn63xx;
	struct cvmx_uctlx_orto_ctl_s cn63xxp1;
	struct cvmx_uctlx_orto_ctl_s cn66xx;
	struct cvmx_uctlx_orto_ctl_s cn68xx;
	struct cvmx_uctlx_orto_ctl_s cn68xxp1;
	struct cvmx_uctlx_orto_ctl_s cnf71xx;
};

union cvmx_uctlx_ppaf_wm {
	uint64_t u64;
	struct cvmx_uctlx_ppaf_wm_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t wm:5;
#else
		uint64_t wm:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_uctlx_ppaf_wm_s cn61xx;
	struct cvmx_uctlx_ppaf_wm_s cn63xx;
	struct cvmx_uctlx_ppaf_wm_s cn63xxp1;
	struct cvmx_uctlx_ppaf_wm_s cn66xx;
	struct cvmx_uctlx_ppaf_wm_s cnf71xx;
};

union cvmx_uctlx_uphy_ctl_status {
	uint64_t u64;
	struct cvmx_uctlx_uphy_ctl_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_10_63:54;
		uint64_t bist_done:1;
		uint64_t bist_err:1;
		uint64_t hsbist:1;
		uint64_t fsbist:1;
		uint64_t lsbist:1;
		uint64_t siddq:1;
		uint64_t vtest_en:1;
		uint64_t uphy_bist:1;
		uint64_t bist_en:1;
		uint64_t ate_reset:1;
#else
		uint64_t ate_reset:1;
		uint64_t bist_en:1;
		uint64_t uphy_bist:1;
		uint64_t vtest_en:1;
		uint64_t siddq:1;
		uint64_t lsbist:1;
		uint64_t fsbist:1;
		uint64_t hsbist:1;
		uint64_t bist_err:1;
		uint64_t bist_done:1;
		uint64_t reserved_10_63:54;
#endif
	} s;
	struct cvmx_uctlx_uphy_ctl_status_s cn61xx;
	struct cvmx_uctlx_uphy_ctl_status_s cn63xx;
	struct cvmx_uctlx_uphy_ctl_status_s cn63xxp1;
	struct cvmx_uctlx_uphy_ctl_status_s cn66xx;
	struct cvmx_uctlx_uphy_ctl_status_s cn68xx;
	struct cvmx_uctlx_uphy_ctl_status_s cn68xxp1;
	struct cvmx_uctlx_uphy_ctl_status_s cnf71xx;
};

union cvmx_uctlx_uphy_portx_ctl_status {
	uint64_t u64;
	struct cvmx_uctlx_uphy_portx_ctl_status_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_43_63:21;
		uint64_t tdata_out:4;
		uint64_t txbiststuffenh:1;
		uint64_t txbiststuffen:1;
		uint64_t dmpulldown:1;
		uint64_t dppulldown:1;
		uint64_t vbusvldext:1;
		uint64_t portreset:1;
		uint64_t txhsvxtune:2;
		uint64_t txvreftune:4;
		uint64_t txrisetune:1;
		uint64_t txpreemphasistune:1;
		uint64_t txfslstune:4;
		uint64_t sqrxtune:3;
		uint64_t compdistune:3;
		uint64_t loop_en:1;
		uint64_t tclk:1;
		uint64_t tdata_sel:1;
		uint64_t taddr_in:4;
		uint64_t tdata_in:8;
#else
		uint64_t tdata_in:8;
		uint64_t taddr_in:4;
		uint64_t tdata_sel:1;
		uint64_t tclk:1;
		uint64_t loop_en:1;
		uint64_t compdistune:3;
		uint64_t sqrxtune:3;
		uint64_t txfslstune:4;
		uint64_t txpreemphasistune:1;
		uint64_t txrisetune:1;
		uint64_t txvreftune:4;
		uint64_t txhsvxtune:2;
		uint64_t portreset:1;
		uint64_t vbusvldext:1;
		uint64_t dppulldown:1;
		uint64_t dmpulldown:1;
		uint64_t txbiststuffen:1;
		uint64_t txbiststuffenh:1;
		uint64_t tdata_out:4;
		uint64_t reserved_43_63:21;
#endif
	} s;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cn61xx;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cn63xx;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cn63xxp1;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cn66xx;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cn68xx;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cn68xxp1;
	struct cvmx_uctlx_uphy_portx_ctl_status_s cnf71xx;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2008 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

/**
 *
 * This file provides support for the processor local scratch memory.
 * Scratch memory is byte addressable - all addresses are byte addresses.
 *
 */

#ifndef __CVMX_SCRATCH_H__
#define __CVMX_SCRATCH_H__

/*
 * Note: This define must be a long, not a long long in order to
 * compile without warnings for both 32bit and 64bit.
 */
#define CVMX_SCRATCH_BASE	(-32768l)	/* 0xffffffffffff8000 */

/**
 * Reads an 8 bit value from the processor local scratchpad memory.
 *
 * @address: byte address to read from
 *
 * Returns value read
 */
static inline uint8_t cvmx_scratch_read8(uint64_t address)
{
	return *CASTPTR(volatile uint8_t, CVMX_SCRATCH_BASE + address);
}

/**
 * Reads a 16 bit value from the processor local scratchpad memory.
 *
 * @address: byte address to read from
 *
 * Returns value read
 */
static inline uint16_t cvmx_scratch_read16(uint64_t address)
{
	return *CASTPTR(volatile uint16_t, CVMX_SCRATCH_BASE + address);
}

/**
 * Reads a 32 bit value from the processor local scratchpad memory.
 *
 * @address: byte address to read from
 *
 * Returns value read
 */
static inline uint32_t cvmx_scratch_read32(uint64_t address)
{
	return *CASTPTR(volatile uint32_t, CVMX_SCRATCH_BASE + address);
}

/**
 * Reads a 64 bit value from the processor local scratchpad memory.
 *
 * @address: byte address to read from
 *
 * Returns value read
 */
static inline uint64_t cvmx_scratch_read64(uint64_t address)
{
	return *CASTPTR(volatile uint64_t, CVMX_SCRATCH_BASE + address);
}

/**
 * Writes an 8 bit value to the processor local scratchpad memory.
 *
 * @address: byte address to write to
 * @value:   value to write
 */
static inline void cvmx_scratch_write8(uint64_t address, uint64_t value)
{
	*CASTPTR(volatile uint8_t, CVMX_SCRATCH_BASE + address) =
	    (uint8_t) value;
}

/**
 * Writes a 32 bit value to the processor local scratchpad memory.
 *
 * @address: byte address to write to
 * @value:   value to write
 */
static inline void cvmx_scratch_write16(uint64_t address, uint64_t value)
{
	*CASTPTR(volatile uint16_t, CVMX_SCRATCH_BASE + address) =
	    (uint16_t) value;
}

/**
 * Writes a 16 bit value to the processor local scratchpad memory.
 *
 * @address: byte address to write to
 * @value:   value to write
 */
static inline void cvmx_scratch_write32(uint64_t address, uint64_t value)
{
	*CASTPTR(volatile uint32_t, CVMX_SCRATCH_BASE + address) =
	    (uint32_t) value;
}

/**
 * Writes a 64 bit value to the processor local scratchpad memory.
 *
 * @address: byte address to write to
 * @value:   value to write
 */
static inline void cvmx_scratch_write64(uint64_t address, uint64_t value)
{
	*CASTPTR(volatile uint64_t, CVMX_SCRATCH_BASE + address) = value;
}

#endif /* __CVMX_SCRATCH_H__ */
                                                                                                                                                                                                                                   /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2012 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

#ifndef __CVMX_SRXX_DEFS_H__
#define __CVMX_SRXX_DEFS_H__

#define CVMX_SRXX_COM_CTL(block_id) (CVMX_ADD_IO_SEG(0x0001180090000200ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_SRXX_IGN_RX_FULL(block_id) (CVMX_ADD_IO_SEG(0x0001180090000218ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_SRXX_SPI4_CALX(offset, block_id) (CVMX_ADD_IO_SEG(0x0001180090000000ull) + (((offset) & 31) + ((block_id) & 1) * 0x1000000ull) * 8)
#define CVMX_SRXX_SPI4_STAT(block_id) (CVMX_ADD_IO_SEG(0x0001180090000208ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_SRXX_SW_TICK_CTL(block_id) (CVMX_ADD_IO_SEG(0x0001180090000220ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_SRXX_SW_TICK_DAT(block_id) (CVMX_ADD_IO_SEG(0x0001180090000228ull) + ((block_id) & 1) * 0x8000000ull)

union cvmx_srxx_com_ctl {
	uint64_t u64;
	struct cvmx_srxx_com_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t prts:4;
		uint64_t st_en:1;
		uint64_t reserved_1_2:2;
		uint64_t inf_en:1;
#else
		uint64_t inf_en:1;
		uint64_t reserved_1_2:2;
		uint64_t st_en:1;
		uint64_t prts:4;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_srxx_com_ctl_s cn38xx;
	struct cvmx_srxx_com_ctl_s cn38xxp2;
	struct cvmx_srxx_com_ctl_s cn58xx;
	struct cvmx_srxx_com_ctl_s cn58xxp1;
};

union cvmx_srxx_ign_rx_full {
	uint64_t u64;
	struct cvmx_srxx_ign_rx_full_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_16_63:48;
		uint64_t ignore:16;
#else
		uint64_t ignore:16;
		uint64_t reserved_16_63:48;
#endif
	} s;
	struct cvmx_srxx_ign_rx_full_s cn38xx;
	struct cvmx_srxx_ign_rx_full_s cn38xxp2;
	struct cvmx_srxx_ign_rx_full_s cn58xx;
	struct cvmx_srxx_ign_rx_full_s cn58xxp1;
};

union cvmx_srxx_spi4_calx {
	uint64_t u64;
	struct cvmx_srxx_spi4_calx_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_17_63:47;
		uint64_t oddpar:1;
		uint64_t prt3:4;
		uint64_t prt2:4;
		uint64_t prt1:4;
		uint64_t prt0:4;
#else
		uint64_t prt0:4;
		uint64_t prt1:4;
		uint64_t prt2:4;
		uint64_t prt3:4;
		uint64_t oddpar:1;
		uint64_t reserved_17_63:47;
#endif
	} s;
	struct cvmx_srxx_spi4_calx_s cn38xx;
	struct cvmx_srxx_spi4_calx_s cn38xxp2;
	struct cvmx_srxx_spi4_calx_s cn58xx;
	struct cvmx_srxx_spi4_calx_s cn58xxp1;
};

union cvmx_srxx_spi4_stat {
	uint64_t u64;
	struct cvmx_srxx_spi4_stat_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_16_63:48;
		uint64_t m:8;
		uint64_t reserved_7_7:1;
		uint64_t len:7;
#else
		uint64_t len:7;
		uint64_t reserved_7_7:1;
		uint64_t m:8;
		uint64_t reserved_16_63:48;
#endif
	} s;
	struct cvmx_srxx_spi4_stat_s cn38xx;
	struct cvmx_srxx_spi4_stat_s cn38xxp2;
	struct cvmx_srxx_spi4_stat_s cn58xx;
	struct cvmx_srxx_spi4_stat_s cn58xxp1;
};

union cvmx_srxx_sw_tick_ctl {
	uint64_t u64;
	struct cvmx_srxx_sw_tick_ctl_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_14_63:50;
		uint64_t eop:1;
		uint64_t sop:1;
		uint64_t mod:4;
		uint64_t opc:4;
		uint64_t adr:4;
#else
		uint64_t adr:4;
		uint64_t opc:4;
		uint64_t mod:4;
		uint64_t sop:1;
		uint64_t eop:1;
		uint64_t reserved_14_63:50;
#endif
	} s;
	struct cvmx_srxx_sw_tick_ctl_s cn38xx;
	struct cvmx_srxx_sw_tick_ctl_s cn58xx;
	struct cvmx_srxx_sw_tick_ctl_s cn58xxp1;
};

union cvmx_srxx_sw_tick_dat {
	uint64_t u64;
	struct cvmx_srxx_sw_tick_dat_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t dat:64;
#else
		uint64_t dat:64;
#endif
	} s;
	struct cvmx_srxx_sw_tick_dat_s cn38xx;
	struct cvmx_srxx_sw_tick_dat_s cn58xx;
	struct cvmx_srxx_sw_tick_dat_s cn58xxp1;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2008 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

/*
 *
 * Support functions for managing command queues used for
 * various hardware blocks.
 *
 * The common command queue infrastructure abstracts out the
 * software necessary for adding to Octeon's chained queue
 * structures. These structures are used for commands to the
 * PKO, ZIP, DFA, RAID, and DMA engine blocks. Although each
 * hardware unit takes commands and CSRs of different types,
 * they all use basic linked command buffers to store the
 * pending request. In general, users of the CVMX API don't
 * call cvmx-cmd-queue functions directly. Instead the hardware
 * unit specific wrapper should be used. The wrappers perform
 * unit specific validation and CSR writes to submit the
 * commands.
 *
 * Even though most software will never directly interact with
 * cvmx-cmd-queue, knowledge of its internal working can help
 * in diagnosing performance problems and help with debugging.
 *
 * Command queue pointers are stored in a global named block
 * called "cvmx_cmd_queues". Except for the PKO queues, each
 * hardware queue is stored in its own cache line to reduce SMP
 * contention on spin locks. The PKO queues are stored such that
 * every 16th queue is next to each other in memory. This scheme
 * allows for queues being in separate cache lines when there
 * are low number of queues per port. With 16 queues per port,
 * the first queue for each port is in the same cache area. The
 * second queues for each port are in another area, etc. This
 * allows software to implement very efficient lockless PKO with
 * 16 queues per port using a minimum of cache lines per core.
 * All queues for a given core will be isolated in the same
 * cache area.
 *
 * In addition to the memory pointer layout, cvmx-cmd-queue
 * provides an optimized fair ll/sc locking mechanism for the
 * queues. The lock uses a "ticket / now serving" model to
 * maintain fair order on contended locks. In addition, it uses
 * predicted locking time to limit cache contention. When a core
 * know it must wait in line for a lock, it spins on the
 * internal cycle counter to completely eliminate any causes of
 * bus traffic.
 *
 */

#ifndef __CVMX_CMD_QUEUE_H__
#define __CVMX_CMD_QUEUE_H__

#include <linux/prefetch.h>

#include <asm/compiler.h>

#include <asm/octeon/cvmx-fpa.h>
/**
 * By default we disable the max depth support. Most programs
 * don't use it and it slows down the command queue processing
 * significantly.
 */
#ifndef CVMX_CMD_QUEUE_ENABLE_MAX_DEPTH
#define CVMX_CMD_QUEUE_ENABLE_MAX_DEPTH 0
#endif

/**
 * Enumeration representing all hardware blocks that use command
 * queues. Each hardware block has up to 65536 sub identifiers for
 * multiple command queues. Not all chips support all hardware
 * units.
 */
typedef enum {
	CVMX_CMD_QUEUE_PKO_BASE = 0x00000,

#define CVMX_CMD_QUEUE_PKO(queue) \
	((cvmx_cmd_queue_id_t)(CVMX_CMD_QUEUE_PKO_BASE + (0xffff&(queue))))

	CVMX_CMD_QUEUE_ZIP = 0x10000,
	CVMX_CMD_QUEUE_DFA = 0x20000,
	CVMX_CMD_QUEUE_RAID = 0x30000,
	CVMX_CMD_QUEUE_DMA_BASE = 0x40000,

#define CVMX_CMD_QUEUE_DMA(queue) \
	((cvmx_cmd_queue_id_t)(CVMX_CMD_QUEUE_DMA_BASE + (0xffff&(queue))))

	CVMX_CMD_QUEUE_END = 0x50000,
} cvmx_cmd_queue_id_t;

/**
 * Command write operations can fail if the command queue needs
 * a new buffer and the associated FPA pool is empty. It can also
 * fail if the number of queued command words reaches the maximum
 * set at initialization.
 */
typedef enum {
	CVMX_CMD_QUEUE_SUCCESS = 0,
	CVMX_CMD_QUEUE_NO_MEMORY = -1,
	CVMX_CMD_QUEUE_FULL = -2,
	CVMX_CMD_QUEUE_INVALID_PARAM = -3,
	CVMX_CMD_QUEUE_ALREADY_SETUP = -4,
} cvmx_cmd_queue_result_t;

typedef struct {
	/* You have lock when this is your ticket */
	uint8_t now_serving;
	uint64_t unused1:24;
	/* Maximum outstanding command words */
	uint32_t max_depth;
	/* FPA pool buffers come from */
	uint64_t fpa_pool:3;
	/* Top of command buffer pointer shifted 7 */
	uint64_t base_ptr_div128:29;
	uint64_t unused2:6;
	/* FPA buffer size in 64bit words minus 1 */
	uint64_t pool_size_m1:13;
	/* Number of commands already used in buffer */
	uint64_t index:13;
} __cvmx_cmd_queue_state_t;

/**
 * This structure contains the global state of all command queues.
 * It is stored in a bootmem named block and shared by all
 * applications running on Octeon. Tickets are stored in a differnet
 * cache line that queue information to reduce the contention on the
 * ll/sc used to get a ticket. If this is not the case, the update
 * of queue state causes the ll/sc to fail quite often.
 */
typedef struct {
	uint64_t ticket[(CVMX_CMD_QUEUE_END >> 16) * 256];
	__cvmx_cmd_queue_state_t state[(CVMX_CMD_QUEUE_END >> 16) * 256];
} __cvmx_cmd_queue_all_state_t;

/**
 * Initialize a command queue for use. The initial FPA buffer is
 * allocated and the hardware unit is configured to point to the
 * new command queue.
 *
 * @queue_id:  Hardware command queue to initialize.
 * @max_depth: Maximum outstanding commands that can be queued.
 * @fpa_pool:  FPA pool the command queues should come from.
 * @pool_size: Size of each buffer in the FPA pool (bytes)
 *
 * Returns CVMX_CMD_QUEUE_SUCCESS or a failure code
 */
cvmx_cmd_queue_result_t cvmx_cmd_queue_initialize(cvmx_cmd_queue_id_t queue_id,
						  int max_depth, int fpa_pool,
						  int pool_size);

/**
 * Shutdown a queue a free it's command buffers to the FPA. The
 * hardware connected to the queue must be stopped before this
 * function is called.
 *
 * @queue_id: Queue to shutdown
 *
 * Returns CVMX_CMD_QUEUE_SUCCESS or a failure code
 */
cvmx_cmd_queue_result_t cvmx_cmd_queue_shutdown(cvmx_cmd_queue_id_t queue_id);

/**
 * Return the number of command words pending in the queue. This
 * function may be relatively slow for some hardware units.
 *
 * @queue_id: Hardware command queue to query
 *
 * Returns Number of outstanding commands
 */
int cvmx_cmd_queue_length(cvmx_cmd_queue_id_t queue_id);

/**
 * Return the command buffer to be written to. The purpose of this
 * function is to allow CVMX routine access t othe low level buffer
 * for initial hardware setup. User applications should not call this
 * function directly.
 *
 * @queue_id: Command queue to query
 *
 * Returns Command buffer or NULL on failure
 */
void *cvmx_cmd_queue_buffer(cvmx_cmd_queue_id_t queue_id);

/**
 * Get the index into the state arrays for the supplied queue id.
 *
 * @queue_id: Queue ID to get an index for
 *
 * Returns Index into the state arrays
 */
static inline int __cvmx_cmd_queue_get_index(cvmx_cmd_queue_id_t queue_id)
{
	/*
	 * Warning: This code currently only works with devices that
	 * have 256 queues or less. Devices with more than 16 queues
	 * are laid out in memory to allow cores quick access to
	 * every 16th queue. This reduces cache thrashing when you are
	 * running 16 queues per port to support lockless operation.
	 */
	int unit = queue_id >> 16;
	int q = (queue_id >> 4) & 0xf;
	int core = queue_id & 0xf;
	return unit * 256 + core * 16 + q;
}

/**
 * Lock the supplied queue so nobody else is updating it at the same
 * time as us.
 *
 * @queue_id: Queue ID to lock
 * @qptr:     Pointer to the queue's global state
 */
static inline void __cvmx_cmd_queue_lock(cvmx_cmd_queue_id_t queue_id,
					 __cvmx_cmd_queue_state_t *qptr)
{
	extern __cvmx_cmd_queue_all_state_t
	    *__cvmx_cmd_queue_state_ptr;
	int tmp;
	int my_ticket;
	prefetch(qptr);
	asm volatile (
		".set push\n"
		".set noreorder\n"
		"1:\n"
		/* Atomic add one to ticket_ptr */
		"ll	%[my_ticket], %[ticket_ptr]\n"
		/* and store the original value */
		"li	%[ticket], 1\n"
		/* in my_ticket */
		"baddu	%[ticket], %[my_ticket]\n"
		"sc	%[ticket], %[ticket_ptr]\n"
		"beqz	%[ticket], 1b\n"
		" nop\n"
		/* Load the current now_serving ticket */
		"lbu	%[ticket], %[now_serving]\n"
		"2:\n"
		/* Jump out if now_serving == my_ticket */
		"beq	%[ticket], %[my_ticket], 4f\n"
		/* Find out how many tickets are in front of me */
		" subu	 %[ticket], %[my_ticket], %[ticket]\n"
		/* Use tickets in front of me minus one to delay */
		"subu  %[ticket], 1\n"
		/* Delay will be ((tickets in front)-1)*32 loops */
		"cins	%[ticket], %[ticket], 5, 7\n"
		"3:\n"
		/* Loop here until our ticket might be up */
		"bnez	%[ticket], 3b\n"
		" subu	%[ticket], 1\n"
		/* Jump back up to check out ticket again */
		"b	2b\n"
		/* Load the current now_serving ticket */
		" lbu	%[ticket], %[now_serving]\n"
		"4:\n"
		".set pop\n" :
		[ticket_ptr] "=" GCC_OFF_SMALL_ASM()(__cvmx_cmd_queue_state_ptr->ticket[__cvmx_cmd_queue_get_index(queue_id)]),
		[now_serving] "=m"(qptr->now_serving), [ticket] "=r"(tmp),
		[my_ticket] "=r"(my_ticket)
	    );
}

/**
 * Unlock the queue, flushing all writes.
 *
 * @qptr:   Queue to unlock
 */
static inline void __cvmx_cmd_queue_unlock(__cvmx_cmd_queue_state_t *qptr)
{
	qptr->now_serving++;
	CVMX_SYNCWS;
}

/**
 * Get the queue state structure for the given queue id
 *
 * @queue_id: Queue id to get
 *
 * Returns Queue structure or NULL on failure
 */
static inline __cvmx_cmd_queue_state_t
    *__cvmx_cmd_queue_get_state(cvmx_cmd_queue_id_t queue_id)
{
	extern __cvmx_cmd_queue_all_state_t
	    *__cvmx_cmd_queue_state_ptr;
	return &__cvmx_cmd_queue_state_ptr->
	    state[__cvmx_cmd_queue_get_index(queue_id)];
}

/**
 * Write an arbitrary number of command words to a command queue.
 * This is a generic function; the fixed number of command word
 * functions yield higher performance.
 *
 * @queue_id:  Hardware command queue to write to
 * @use_locking:
 *		    Use internal locking to ensure exclusive access for queue
 *		    updates. If you don't use this locking you must ensure
 *		    exclusivity some other way. Locking is strongly recommended.
 * @cmd_count: Number of command words to write
 * @cmds:      Array of commands to write
 *
 * Returns CVMX_CMD_QUEUE_SUCCESS or a failure code
 */
static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write(cvmx_cmd_queue_id_t
							   queue_id,
							   int use_locking,
							   int cmd_count,
							   uint64_t *cmds)
{
	__cvmx_cmd_queue_state_t *qptr = __cvmx_cmd_queue_get_state(queue_id);

	/* Make sure nobody else is updating the same queue */
	if (likely(use_locking))
		__cvmx_cmd_queue_lock(queue_id, qptr);

	/*
	 * If a max queue length was specified then make sure we don't
	 * exceed it. If any part of the command would be below the
	 * limit we allow it.
	 */
	if (CVMX_CMD_QUEUE_ENABLE_MAX_DEPTH && unlikely(qptr->max_depth)) {
		if (unlikely
		    (cvmx_cmd_queue_length(queue_id) > (int)qptr->max_depth)) {
			if (likely(use_locking))
				__cvmx_cmd_queue_unlock(qptr);
			return CVMX_CMD_QUEUE_FULL;
		}
	}

	/*
	 * Normally there is plenty of room in the current buffer for
	 * the command.
	 */
	if (likely(qptr->index + cmd_count < qptr->pool_size_m1)) {
		uint64_t *ptr =
		    (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->
						  base_ptr_div128 << 7);
		ptr += qptr->index;
		qptr->index += cmd_count;
		while (cmd_count--)
			*ptr++ = *cmds++;
	} else {
		uint64_t *ptr;
		int count;
		/*
		 * We need a new command buffer. Fail if there isn't
		 * one available.
		 */
		uint64_t *new_buffer =
		    (uint64_t *) cvmx_fpa_alloc(qptr->fpa_pool);
		if (unlikely(new_buffer == NULL)) {
			if (likely(use_locking))
				__cvmx_cmd_queue_unlock(qptr);
			return CVMX_CMD_QUEUE_NO_MEMORY;
		}
		ptr =
		    (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->
						  base_ptr_div128 << 7);
		/*
		 * Figure out how many command words will fit in this
		 * buffer. One location will be needed for the next
		 * buffer pointer.
		 */
		count = qptr->pool_size_m1 - qptr->index;
		ptr += qptr->index;
		cmd_count -= count;
		while (count--)
			*ptr++ = *cmds++;
		*ptr = cvmx_ptr_to_phys(new_buffer);
		/*
		 * The current buffer is full and has a link to the
		 * next buffer. Time to write the rest of the commands
		 * into the new buffer.
		 */
		qptr->base_ptr_div128 = *ptr >> 7;
		qptr->index = cmd_count;
		ptr = new_buffer;
		while (cmd_count--)
			*ptr++ = *cmds++;
	}

	/* All updates are complete. Release the lock and return */
	if (likely(use_locking))
		__cvmx_cmd_queue_unlock(qptr);
	return CVMX_CMD_QUEUE_SUCCESS;
}

/**
 * Simple function to write two command words to a command
 * queue.
 *
 * @queue_id: Hardware command queue to write to
 * @use_locking:
 *		   Use internal locking to ensure exclusive access for queue
 *		   updates. If you don't use this locking you must ensure
 *		   exclusivity some other way. Locking is strongly recommended.
 * @cmd1:     Command
 * @cmd2:     Command
 *
 * Returns CVMX_CMD_QUEUE_SUCCESS or a failure code
 */
static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write2(cvmx_cmd_queue_id_t
							    queue_id,
							    int use_locking,
							    uint64_t cmd1,
							    uint64_t cmd2)
{
	__cvmx_cmd_queue_state_t *qptr = __cvmx_cmd_queue_get_state(queue_id);

	/* Make sure nobody else is updating the same queue */
	if (likely(use_locking))
		__cvmx_cmd_queue_lock(queue_id, qptr);

	/*
	 * If a max queue length was specified then make sure we don't
	 * exceed it. If any part of the command would be below the
	 * limit we allow it.
	 */
	if (CVMX_CMD_QUEUE_ENABLE_MAX_DEPTH && unlikely(qptr->max_depth)) {
		if (unlikely
		    (cvmx_cmd_queue_length(queue_id) > (int)qptr->max_depth)) {
			if (likely(use_locking))
				__cvmx_cmd_queue_unlock(qptr);
			return CVMX_CMD_QUEUE_FULL;
		}
	}

	/*
	 * Normally there is plenty of room in the current buffer for
	 * the command.
	 */
	if (likely(qptr->index + 2 < qptr->pool_size_m1)) {
		uint64_t *ptr =
		    (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->
						  base_ptr_div128 << 7);
		ptr += qptr->index;
		qptr->index += 2;
		ptr[0] = cmd1;
		ptr[1] = cmd2;
	} else {
		uint64_t *ptr;
		/*
		 * Figure out how many command words will fit in this
		 * buffer. One location will be needed for the next
		 * buffer pointer.
		 */
		int count = qptr->pool_size_m1 - qptr->index;
		/*
		 * We need a new command buffer. Fail if there isn't
		 * one available.
		 */
		uint64_t *new_buffer =
		    (uint64_t *) cvmx_fpa_alloc(qptr->fpa_pool);
		if (unlikely(new_buffer == NULL)) {
			if (likely(use_locking))
				__cvmx_cmd_queue_unlock(qptr);
			return CVMX_CMD_QUEUE_NO_MEMORY;
		}
		count--;
		ptr =
		    (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->
						  base_ptr_div128 << 7);
		ptr += qptr->index;
		*ptr++ = cmd1;
		if (likely(count))
			*ptr++ = cmd2;
		*ptr = cvmx_ptr_to_phys(new_buffer);
		/*
		 * The current buffer is full and has a link to the
		 * next buffer. Time to write the rest of the commands
		 * into the new buffer.
		 */
		qptr->base_ptr_div128 = *ptr >> 7;
		qptr->index = 0;
		if (unlikely(count == 0)) {
			qptr->index = 1;
			new_buffer[0] = cmd2;
		}
	}

	/* All updates are complete. Release the lock and return */
	if (likely(use_locking))
		__cvmx_cmd_queue_unlock(qptr);
	return CVMX_CMD_QUEUE_SUCCESS;
}

/**
 * Simple function to write three command words to a command
 * queue.
 *
 * @queue_id: Hardware command queue to write to
 * @use_locking:
 *		   Use internal locking to ensure exclusive access for queue
 *		   updates. If you don't use this locking you must ensure
 *		   exclusivity some other way. Locking is strongly recommended.
 * @cmd1:     Command
 * @cmd2:     Command
 * @cmd3:     Command
 *
 * Returns CVMX_CMD_QUEUE_SUCCESS or a failure code
 */
static inline cvmx_cmd_queue_result_t cvmx_cmd_queue_write3(cvmx_cmd_queue_id_t
							    queue_id,
							    int use_locking,
							    uint64_t cmd1,
							    uint64_t cmd2,
							    uint64_t cmd3)
{
	__cvmx_cmd_queue_state_t *qptr = __cvmx_cmd_queue_get_state(queue_id);

	/* Make sure nobody else is updating the same queue */
	if (likely(use_locking))
		__cvmx_cmd_queue_lock(queue_id, qptr);

	/*
	 * If a max queue length was specified then make sure we don't
	 * exceed it. If any part of the command would be below the
	 * limit we allow it.
	 */
	if (CVMX_CMD_QUEUE_ENABLE_MAX_DEPTH && unlikely(qptr->max_depth)) {
		if (unlikely
		    (cvmx_cmd_queue_length(queue_id) > (int)qptr->max_depth)) {
			if (likely(use_locking))
				__cvmx_cmd_queue_unlock(qptr);
			return CVMX_CMD_QUEUE_FULL;
		}
	}

	/*
	 * Normally there is plenty of room in the current buffer for
	 * the command.
	 */
	if (likely(qptr->index + 3 < qptr->pool_size_m1)) {
		uint64_t *ptr =
		    (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->
						  base_ptr_div128 << 7);
		ptr += qptr->index;
		qptr->index += 3;
		ptr[0] = cmd1;
		ptr[1] = cmd2;
		ptr[2] = cmd3;
	} else {
		uint64_t *ptr;
		/*
		 * Figure out how many command words will fit in this
		 * buffer. One location will be needed for the next
		 * buffer pointer
		 */
		int count = qptr->pool_size_m1 - qptr->index;
		/*
		 * We need a new command buffer. Fail if there isn't
		 * one available
		 */
		uint64_t *new_buffer =
		    (uint64_t *) cvmx_fpa_alloc(qptr->fpa_pool);
		if (unlikely(new_buffer == NULL)) {
			if (likely(use_locking))
				__cvmx_cmd_queue_unlock(qptr);
			return CVMX_CMD_QUEUE_NO_MEMORY;
		}
		count--;
		ptr =
		    (uint64_t *) cvmx_phys_to_ptr((uint64_t) qptr->
						  base_ptr_div128 << 7);
		ptr += qptr->index;
		*ptr++ = cmd1;
		if (count) {
			*ptr++ = cmd2;
			if (count > 1)
				*ptr++ = cmd3;
		}
		*ptr = cvmx_ptr_to_phys(new_buffer);
		/*
		 * The current buffer is full and has a link to the
		 * next buffer. Time to write the rest of the commands
		 * into the new buffer.
		 */
		qptr->base_ptr_div128 = *ptr >> 7;
		qptr->index = 0;
		ptr = new_buffer;
		if (count == 0) {
			*ptr++ = cmd2;
			qptr->index++;
		}
		if (count < 2) {
			*ptr++ = cmd3;
			qptr->index++;
		}
	}

	/* All updates are complete. Release the lock and return */
	if (likely(use_locking))
		__cvmx_cmd_queue_unlock(qptr);
	return CVMX_CMD_QUEUE_SUCCESS;
}

#endif /* __CVMX_CMD_QUEUE_H__ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2008 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

/**
 * @file
 *
 * Interface to the hardware Free Pool Allocator.
 *
 *
 */

#ifndef __CVMX_FPA_H__
#define __CVMX_FPA_H__

#include <asm/octeon/cvmx-address.h>
#include <asm/octeon/cvmx-fpa-defs.h>

#define CVMX_FPA_NUM_POOLS	8
#define CVMX_FPA_MIN_BLOCK_SIZE 128
#define CVMX_FPA_ALIGNMENT	128

/**
 * Structure describing the data format used for stores to the FPA.
 */
typedef union {
	uint64_t u64;
	struct {
#ifdef __BIG_ENDIAN_BITFIELD
		/*
		 * the (64-bit word) location in scratchpad to write
		 * to (if len != 0)
		 */
		uint64_t scraddr:8;
		/* the number of words in the response (0 => no response) */
		uint64_t len:8;
		/* the ID of the device on the non-coherent bus */
		uint64_t did:8;
		/*
		 * the address that will appear in the first tick on
		 * the NCB bus.
		 */
		uint64_t addr:40;
#else
		uint64_t addr:40;
		uint64_t did:8;
		uint64_t len:8;
		uint64_t scraddr:8;
#endif
	} s;
} cvmx_fpa_iobdma_data_t;

/**
 * Structure describing the current state of a FPA pool.
 */
typedef struct {
	/* Name it was created under */
	const char *name;
	/* Size of each block */
	uint64_t size;
	/* The base memory address of whole block */
	void *base;
	/* The number of elements in the pool at creation */
	uint64_t starting_element_count;
} cvmx_fpa_pool_info_t;

/**
 * Current state of all the pools. Use access functions
 * instead of using it directly.
 */
extern cvmx_fpa_pool_info_t cvmx_fpa_pool_info[CVMX_FPA_NUM_POOLS];

/* CSR typedefs have been moved to cvmx-csr-*.h */

/**
 * Return the name of the pool
 *
 * @pool:   Pool to get the name of
 * Returns The name
 */
static inline const char *cvmx_fpa_get_name(uint64_t pool)
{
	return cvmx_fpa_pool_info[pool].name;
}

/**
 * Return the base of the pool
 *
 * @pool:   Pool to get the base of
 * Returns The base
 */
static inline void *cvmx_fpa_get_base(uint64_t pool)
{
	return cvmx_fpa_pool_info[pool].base;
}

/**
 * Check if a pointer belongs to an FPA pool. Return non-zero
 * if the supplied pointer is inside the memory controlled by
 * an FPA pool.
 *
 * @pool:   Pool to check
 * @ptr:    Pointer to check
 * Returns Non-zero if pointer is in the pool. Zero if not
 */
static inline int cvmx_fpa_is_member(uint64_t pool, void *ptr)
{
	return ((ptr >= cvmx_fpa_pool_info[pool].base) &&
		((char *)ptr <
		 ((char *)(cvmx_fpa_pool_info[pool].base)) +
		 cvmx_fpa_pool_info[pool].size *
		 cvmx_fpa_pool_info[pool].starting_element_count));
}

/**
 * Enable the FPA for use. Must be performed after any CSR
 * configuration but before any other FPA functions.
 */
static inline void cvmx_fpa_enable(void)
{
	union cvmx_fpa_ctl_status status;

	status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
	if (status.s.enb) {
		cvmx_dprintf
		    ("Warning: Enabling FPA when FPA already enabled.\n");
	}

	/*
	 * Do runtime check as we allow pass1 compiled code to run on
	 * pass2 chips.
	 */
	if (cvmx_octeon_is_pass1()) {
		union cvmx_fpa_fpfx_marks marks;
		int i;
		for (i = 1; i < 8; i++) {
			marks.u64 =
			    cvmx_read_csr(CVMX_FPA_FPF1_MARKS + (i - 1) * 8ull);
			marks.s.fpf_wr = 0xe0;
			cvmx_write_csr(CVMX_FPA_FPF1_MARKS + (i - 1) * 8ull,
				       marks.u64);
		}

		/* Enforce a 10 cycle delay between config and enable */
		cvmx_wait(10);
	}

	/* FIXME: CVMX_FPA_CTL_STATUS read is unmodelled */
	status.u64 = 0;
	status.s.enb = 1;
	cvmx_write_csr(CVMX_FPA_CTL_STATUS, status.u64);
}

/**
 * Get a new block from the FPA
 *
 * @pool:   Pool to get the block from
 * Returns Pointer to the block or NULL on failure
 */
static inline void *cvmx_fpa_alloc(uint64_t pool)
{
	uint64_t address =
	    cvmx_read_csr(CVMX_ADDR_DID(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool)));
	if (address)
		return cvmx_phys_to_ptr(address);
	else
		return NULL;
}

/**
 * Asynchronously get a new block from the FPA
 *
 * @scr_addr: Local scratch address to put response in.	 This is a byte address,
 *		    but must be 8 byte aligned.
 * @pool:      Pool to get the block from
 */
static inline void cvmx_fpa_async_alloc(uint64_t scr_addr, uint64_t pool)
{
	cvmx_fpa_iobdma_data_t data;

	/*
	 * Hardware only uses 64 bit aligned locations, so convert
	 * from byte address to 64-bit index
	 */
	data.s.scraddr = scr_addr >> 3;
	data.s.len = 1;
	data.s.did = CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool);
	data.s.addr = 0;
	cvmx_send_single(data.u64);
}

/**
 * Free a block allocated with a FPA pool.  Does NOT provide memory
 * ordering in cases where the memory block was modified by the core.
 *
 * @ptr:    Block to free
 * @pool:   Pool to put it in
 * @num_cache_lines:
 *		 Cache lines to invalidate
 */
static inline void cvmx_fpa_free_nosync(void *ptr, uint64_t pool,
					uint64_t num_cache_lines)
{
	cvmx_addr_t newptr;
	newptr.u64 = cvmx_ptr_to_phys(ptr);
	newptr.sfilldidspace.didspace =
	    CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
	/* Prevent GCC from reordering around free */
	barrier();
	/* value written is number of cache lines not written back */
	cvmx_write_io(newptr.u64, num_cache_lines);
}

/**
 * Free a block allocated with a FPA pool.  Provides required memory
 * ordering in cases where memory block was modified by core.
 *
 * @ptr:    Block to free
 * @pool:   Pool to put it in
 * @num_cache_lines:
 *		 Cache lines to invalidate
 */
static inline void cvmx_fpa_free(void *ptr, uint64_t pool,
				 uint64_t num_cache_lines)
{
	cvmx_addr_t newptr;
	newptr.u64 = cvmx_ptr_to_phys(ptr);
	newptr.sfilldidspace.didspace =
	    CVMX_ADDR_DIDSPACE(CVMX_FULL_DID(CVMX_OCT_DID_FPA, pool));
	/*
	 * Make sure that any previous writes to memory go out before
	 * we free this buffer.	 This also serves as a barrier to
	 * prevent GCC from reordering operations to after the
	 * free.
	 */
	CVMX_SYNCWS;
	/* value written is number of cache lines not written back */
	cvmx_write_io(newptr.u64, num_cache_lines);
}

/**
 * Setup a FPA pool to control a new block of memory.
 * This can only be called once per pool. Make sure proper
 * locking enforces this.
 *
 * @pool:	Pool to initialize
 *		     0 <= pool < 8
 * @name:	Constant character string to name this pool.
 *		     String is not copied.
 * @buffer:	Pointer to the block of memory to use. This must be
 *		     accessible by all processors and external hardware.
 * @block_size: Size for each block controlled by the FPA
 * @num_blocks: Number of blocks
 *
 * Returns 0 on Success,
 *	   -1 on failure
 */
extern int cvmx_fpa_setup_pool(uint64_t pool, const char *name, void *buffer,
			       uint64_t block_size, uint64_t num_blocks);

/**
 * Shutdown a Memory pool and validate that it had all of
 * the buffers originally placed in it. This should only be
 * called by one processor after all hardware has finished
 * using the pool.
 *
 * @pool:   Pool to shutdown
 * Returns Zero on success
 *	   - Positive is count of missing buffers
 *	   - Negative is too many buffers or corrupted pointers
 */
extern uint64_t cvmx_fpa_shutdown_pool(uint64_t pool);

/**
 * Get the size of blocks controlled by the pool
 * This is resolved to a constant at compile time.
 *
 * @pool:   Pool to access
 * Returns Size of the block in bytes
 */
uint64_t cvmx_fpa_get_block_size(uint64_t pool);

#endif /*  __CVM_FPA_H__ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2008 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

#ifndef __CVMX_HELPER_ERRATA_H__
#define __CVMX_HELPER_ERRATA_H__

extern void __cvmx_helper_errata_qlm_disable_2nd_order_cdr(int qlm);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /***********************license start***************
 * Author: Cavium Networks
 *
 * Contact: support@caviumnetworks.com
 * This file is part of the OCTEON SDK
 *
 * Copyright (c) 2003-2012 Cavium Networks
 *
 * This file is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License, Version 2, as
 * published by the Free Software Foundation.
 *
 * This file is distributed in the hope that it will be useful, but
 * AS-IS and WITHOUT ANY WARRANTY; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE, TITLE, or
 * NONINFRINGEMENT.  See the GNU General Public License for more
 * details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this file; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
 * or visit http://www.gnu.org/licenses/.
 *
 * This file may also be available under a different license from Cavium.
 * Contact Cavium Networks for more information
 ***********************license end**************************************/

#ifndef __CVMX_ASXX_DEFS_H__
#define __CVMX_ASXX_DEFS_H__

#define CVMX_ASXX_GMII_RX_CLK_SET(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000180ull))
#define CVMX_ASXX_GMII_RX_DAT_SET(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000188ull))
#define CVMX_ASXX_INT_EN(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000018ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_INT_REG(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000010ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_MII_RX_DAT_SET(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000190ull))
#define CVMX_ASXX_PRT_LOOP(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000040ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_BYPASS(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000248ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_BYPASS_SETTING(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000250ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_COMP(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000220ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_DATA_DRV(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000218ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_FCRAM_MODE(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000210ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_NCTL_STRONG(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000230ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_NCTL_WEAK(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000240ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_PCTL_STRONG(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000228ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_PCTL_WEAK(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000238ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RLD_SETTING(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000258ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RX_CLK_SETX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800B0000020ull) + (((offset) & 3) + ((block_id) & 1) * 0x1000000ull) * 8)
#define CVMX_ASXX_RX_PRT_EN(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000000ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RX_WOL(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000100ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RX_WOL_MSK(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000108ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RX_WOL_POWOK(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000118ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_RX_WOL_SIG(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000110ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_TX_CLK_SETX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800B0000048ull) + (((offset) & 3) + ((block_id) & 1) * 0x1000000ull) * 8)
#define CVMX_ASXX_TX_COMP_BYP(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000068ull) + ((block_id) & 1) * 0x8000000ull)
#define CVMX_ASXX_TX_HI_WATERX(offset, block_id) (CVMX_ADD_IO_SEG(0x00011800B0000080ull) + (((offset) & 3) + ((block_id) & 1) * 0x1000000ull) * 8)
#define CVMX_ASXX_TX_PRT_EN(block_id) (CVMX_ADD_IO_SEG(0x00011800B0000008ull) + ((block_id) & 1) * 0x8000000ull)

union cvmx_asxx_gmii_rx_clk_set {
	uint64_t u64;
	struct cvmx_asxx_gmii_rx_clk_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_gmii_rx_clk_set_s cn30xx;
	struct cvmx_asxx_gmii_rx_clk_set_s cn31xx;
	struct cvmx_asxx_gmii_rx_clk_set_s cn50xx;
};

union cvmx_asxx_gmii_rx_dat_set {
	uint64_t u64;
	struct cvmx_asxx_gmii_rx_dat_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_gmii_rx_dat_set_s cn30xx;
	struct cvmx_asxx_gmii_rx_dat_set_s cn31xx;
	struct cvmx_asxx_gmii_rx_dat_set_s cn50xx;
};

union cvmx_asxx_int_en {
	uint64_t u64;
	struct cvmx_asxx_int_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_12_63:52;
		uint64_t txpsh:4;
		uint64_t txpop:4;
		uint64_t ovrflw:4;
#else
		uint64_t ovrflw:4;
		uint64_t txpop:4;
		uint64_t txpsh:4;
		uint64_t reserved_12_63:52;
#endif
	} s;
	struct cvmx_asxx_int_en_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_11_63:53;
		uint64_t txpsh:3;
		uint64_t reserved_7_7:1;
		uint64_t txpop:3;
		uint64_t reserved_3_3:1;
		uint64_t ovrflw:3;
#else
		uint64_t ovrflw:3;
		uint64_t reserved_3_3:1;
		uint64_t txpop:3;
		uint64_t reserved_7_7:1;
		uint64_t txpsh:3;
		uint64_t reserved_11_63:53;
#endif
	} cn30xx;
	struct cvmx_asxx_int_en_cn30xx cn31xx;
	struct cvmx_asxx_int_en_s cn38xx;
	struct cvmx_asxx_int_en_s cn38xxp2;
	struct cvmx_asxx_int_en_cn30xx cn50xx;
	struct cvmx_asxx_int_en_s cn58xx;
	struct cvmx_asxx_int_en_s cn58xxp1;
};

union cvmx_asxx_int_reg {
	uint64_t u64;
	struct cvmx_asxx_int_reg_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_12_63:52;
		uint64_t txpsh:4;
		uint64_t txpop:4;
		uint64_t ovrflw:4;
#else
		uint64_t ovrflw:4;
		uint64_t txpop:4;
		uint64_t txpsh:4;
		uint64_t reserved_12_63:52;
#endif
	} s;
	struct cvmx_asxx_int_reg_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_11_63:53;
		uint64_t txpsh:3;
		uint64_t reserved_7_7:1;
		uint64_t txpop:3;
		uint64_t reserved_3_3:1;
		uint64_t ovrflw:3;
#else
		uint64_t ovrflw:3;
		uint64_t reserved_3_3:1;
		uint64_t txpop:3;
		uint64_t reserved_7_7:1;
		uint64_t txpsh:3;
		uint64_t reserved_11_63:53;
#endif
	} cn30xx;
	struct cvmx_asxx_int_reg_cn30xx cn31xx;
	struct cvmx_asxx_int_reg_s cn38xx;
	struct cvmx_asxx_int_reg_s cn38xxp2;
	struct cvmx_asxx_int_reg_cn30xx cn50xx;
	struct cvmx_asxx_int_reg_s cn58xx;
	struct cvmx_asxx_int_reg_s cn58xxp1;
};

union cvmx_asxx_mii_rx_dat_set {
	uint64_t u64;
	struct cvmx_asxx_mii_rx_dat_set_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_mii_rx_dat_set_s cn30xx;
	struct cvmx_asxx_mii_rx_dat_set_s cn50xx;
};

union cvmx_asxx_prt_loop {
	uint64_t u64;
	struct cvmx_asxx_prt_loop_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t ext_loop:4;
		uint64_t int_loop:4;
#else
		uint64_t int_loop:4;
		uint64_t ext_loop:4;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_asxx_prt_loop_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_7_63:57;
		uint64_t ext_loop:3;
		uint64_t reserved_3_3:1;
		uint64_t int_loop:3;
#else
		uint64_t int_loop:3;
		uint64_t reserved_3_3:1;
		uint64_t ext_loop:3;
		uint64_t reserved_7_63:57;
#endif
	} cn30xx;
	struct cvmx_asxx_prt_loop_cn30xx cn31xx;
	struct cvmx_asxx_prt_loop_s cn38xx;
	struct cvmx_asxx_prt_loop_s cn38xxp2;
	struct cvmx_asxx_prt_loop_cn30xx cn50xx;
	struct cvmx_asxx_prt_loop_s cn58xx;
	struct cvmx_asxx_prt_loop_s cn58xxp1;
};

union cvmx_asxx_rld_bypass {
	uint64_t u64;
	struct cvmx_asxx_rld_bypass_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_1_63:63;
		uint64_t bypass:1;
#else
		uint64_t bypass:1;
		uint64_t reserved_1_63:63;
#endif
	} s;
	struct cvmx_asxx_rld_bypass_s cn38xx;
	struct cvmx_asxx_rld_bypass_s cn38xxp2;
	struct cvmx_asxx_rld_bypass_s cn58xx;
	struct cvmx_asxx_rld_bypass_s cn58xxp1;
};

union cvmx_asxx_rld_bypass_setting {
	uint64_t u64;
	struct cvmx_asxx_rld_bypass_setting_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_rld_bypass_setting_s cn38xx;
	struct cvmx_asxx_rld_bypass_setting_s cn38xxp2;
	struct cvmx_asxx_rld_bypass_setting_s cn58xx;
	struct cvmx_asxx_rld_bypass_setting_s cn58xxp1;
};

union cvmx_asxx_rld_comp {
	uint64_t u64;
	struct cvmx_asxx_rld_comp_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_9_63:55;
		uint64_t pctl:5;
		uint64_t nctl:4;
#else
		uint64_t nctl:4;
		uint64_t pctl:5;
		uint64_t reserved_9_63:55;
#endif
	} s;
	struct cvmx_asxx_rld_comp_cn38xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t pctl:4;
		uint64_t nctl:4;
#else
		uint64_t nctl:4;
		uint64_t pctl:4;
		uint64_t reserved_8_63:56;
#endif
	} cn38xx;
	struct cvmx_asxx_rld_comp_cn38xx cn38xxp2;
	struct cvmx_asxx_rld_comp_s cn58xx;
	struct cvmx_asxx_rld_comp_s cn58xxp1;
};

union cvmx_asxx_rld_data_drv {
	uint64_t u64;
	struct cvmx_asxx_rld_data_drv_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t pctl:4;
		uint64_t nctl:4;
#else
		uint64_t nctl:4;
		uint64_t pctl:4;
		uint64_t reserved_8_63:56;
#endif
	} s;
	struct cvmx_asxx_rld_data_drv_s cn38xx;
	struct cvmx_asxx_rld_data_drv_s cn38xxp2;
	struct cvmx_asxx_rld_data_drv_s cn58xx;
	struct cvmx_asxx_rld_data_drv_s cn58xxp1;
};

union cvmx_asxx_rld_fcram_mode {
	uint64_t u64;
	struct cvmx_asxx_rld_fcram_mode_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_1_63:63;
		uint64_t mode:1;
#else
		uint64_t mode:1;
		uint64_t reserved_1_63:63;
#endif
	} s;
	struct cvmx_asxx_rld_fcram_mode_s cn38xx;
	struct cvmx_asxx_rld_fcram_mode_s cn38xxp2;
};

union cvmx_asxx_rld_nctl_strong {
	uint64_t u64;
	struct cvmx_asxx_rld_nctl_strong_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t nctl:5;
#else
		uint64_t nctl:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_rld_nctl_strong_s cn38xx;
	struct cvmx_asxx_rld_nctl_strong_s cn38xxp2;
	struct cvmx_asxx_rld_nctl_strong_s cn58xx;
	struct cvmx_asxx_rld_nctl_strong_s cn58xxp1;
};

union cvmx_asxx_rld_nctl_weak {
	uint64_t u64;
	struct cvmx_asxx_rld_nctl_weak_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t nctl:5;
#else
		uint64_t nctl:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_rld_nctl_weak_s cn38xx;
	struct cvmx_asxx_rld_nctl_weak_s cn38xxp2;
	struct cvmx_asxx_rld_nctl_weak_s cn58xx;
	struct cvmx_asxx_rld_nctl_weak_s cn58xxp1;
};

union cvmx_asxx_rld_pctl_strong {
	uint64_t u64;
	struct cvmx_asxx_rld_pctl_strong_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t pctl:5;
#else
		uint64_t pctl:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_rld_pctl_strong_s cn38xx;
	struct cvmx_asxx_rld_pctl_strong_s cn38xxp2;
	struct cvmx_asxx_rld_pctl_strong_s cn58xx;
	struct cvmx_asxx_rld_pctl_strong_s cn58xxp1;
};

union cvmx_asxx_rld_pctl_weak {
	uint64_t u64;
	struct cvmx_asxx_rld_pctl_weak_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t pctl:5;
#else
		uint64_t pctl:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_rld_pctl_weak_s cn38xx;
	struct cvmx_asxx_rld_pctl_weak_s cn38xxp2;
	struct cvmx_asxx_rld_pctl_weak_s cn58xx;
	struct cvmx_asxx_rld_pctl_weak_s cn58xxp1;
};

union cvmx_asxx_rld_setting {
	uint64_t u64;
	struct cvmx_asxx_rld_setting_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_13_63:51;
		uint64_t dfaset:5;
		uint64_t dfalag:1;
		uint64_t dfalead:1;
		uint64_t dfalock:1;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t dfalock:1;
		uint64_t dfalead:1;
		uint64_t dfalag:1;
		uint64_t dfaset:5;
		uint64_t reserved_13_63:51;
#endif
	} s;
	struct cvmx_asxx_rld_setting_cn38xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} cn38xx;
	struct cvmx_asxx_rld_setting_cn38xx cn38xxp2;
	struct cvmx_asxx_rld_setting_s cn58xx;
	struct cvmx_asxx_rld_setting_s cn58xxp1;
};

union cvmx_asxx_rx_clk_setx {
	uint64_t u64;
	struct cvmx_asxx_rx_clk_setx_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_rx_clk_setx_s cn30xx;
	struct cvmx_asxx_rx_clk_setx_s cn31xx;
	struct cvmx_asxx_rx_clk_setx_s cn38xx;
	struct cvmx_asxx_rx_clk_setx_s cn38xxp2;
	struct cvmx_asxx_rx_clk_setx_s cn50xx;
	struct cvmx_asxx_rx_clk_setx_s cn58xx;
	struct cvmx_asxx_rx_clk_setx_s cn58xxp1;
};

union cvmx_asxx_rx_prt_en {
	uint64_t u64;
	struct cvmx_asxx_rx_prt_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_4_63:60;
		uint64_t prt_en:4;
#else
		uint64_t prt_en:4;
		uint64_t reserved_4_63:60;
#endif
	} s;
	struct cvmx_asxx_rx_prt_en_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_3_63:61;
		uint64_t prt_en:3;
#else
		uint64_t prt_en:3;
		uint64_t reserved_3_63:61;
#endif
	} cn30xx;
	struct cvmx_asxx_rx_prt_en_cn30xx cn31xx;
	struct cvmx_asxx_rx_prt_en_s cn38xx;
	struct cvmx_asxx_rx_prt_en_s cn38xxp2;
	struct cvmx_asxx_rx_prt_en_cn30xx cn50xx;
	struct cvmx_asxx_rx_prt_en_s cn58xx;
	struct cvmx_asxx_rx_prt_en_s cn58xxp1;
};

union cvmx_asxx_rx_wol {
	uint64_t u64;
	struct cvmx_asxx_rx_wol_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_2_63:62;
		uint64_t status:1;
		uint64_t enable:1;
#else
		uint64_t enable:1;
		uint64_t status:1;
		uint64_t reserved_2_63:62;
#endif
	} s;
	struct cvmx_asxx_rx_wol_s cn38xx;
	struct cvmx_asxx_rx_wol_s cn38xxp2;
};

union cvmx_asxx_rx_wol_msk {
	uint64_t u64;
	struct cvmx_asxx_rx_wol_msk_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t msk:64;
#else
		uint64_t msk:64;
#endif
	} s;
	struct cvmx_asxx_rx_wol_msk_s cn38xx;
	struct cvmx_asxx_rx_wol_msk_s cn38xxp2;
};

union cvmx_asxx_rx_wol_powok {
	uint64_t u64;
	struct cvmx_asxx_rx_wol_powok_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_1_63:63;
		uint64_t powerok:1;
#else
		uint64_t powerok:1;
		uint64_t reserved_1_63:63;
#endif
	} s;
	struct cvmx_asxx_rx_wol_powok_s cn38xx;
	struct cvmx_asxx_rx_wol_powok_s cn38xxp2;
};

union cvmx_asxx_rx_wol_sig {
	uint64_t u64;
	struct cvmx_asxx_rx_wol_sig_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_32_63:32;
		uint64_t sig:32;
#else
		uint64_t sig:32;
		uint64_t reserved_32_63:32;
#endif
	} s;
	struct cvmx_asxx_rx_wol_sig_s cn38xx;
	struct cvmx_asxx_rx_wol_sig_s cn38xxp2;
};

union cvmx_asxx_tx_clk_setx {
	uint64_t u64;
	struct cvmx_asxx_tx_clk_setx_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_5_63:59;
		uint64_t setting:5;
#else
		uint64_t setting:5;
		uint64_t reserved_5_63:59;
#endif
	} s;
	struct cvmx_asxx_tx_clk_setx_s cn30xx;
	struct cvmx_asxx_tx_clk_setx_s cn31xx;
	struct cvmx_asxx_tx_clk_setx_s cn38xx;
	struct cvmx_asxx_tx_clk_setx_s cn38xxp2;
	struct cvmx_asxx_tx_clk_setx_s cn50xx;
	struct cvmx_asxx_tx_clk_setx_s cn58xx;
	struct cvmx_asxx_tx_clk_setx_s cn58xxp1;
};

union cvmx_asxx_tx_comp_byp {
	uint64_t u64;
	struct cvmx_asxx_tx_comp_byp_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_0_63:64;
#else
		uint64_t reserved_0_63:64;
#endif
	} s;
	struct cvmx_asxx_tx_comp_byp_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_9_63:55;
		uint64_t bypass:1;
		uint64_t pctl:4;
		uint64_t nctl:4;
#else
		uint64_t nctl:4;
		uint64_t pctl:4;
		uint64_t bypass:1;
		uint64_t reserved_9_63:55;
#endif
	} cn30xx;
	struct cvmx_asxx_tx_comp_byp_cn30xx cn31xx;
	struct cvmx_asxx_tx_comp_byp_cn38xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_8_63:56;
		uint64_t pctl:4;
		uint64_t nctl:4;
#else
		uint64_t nctl:4;
		uint64_t pctl:4;
		uint64_t reserved_8_63:56;
#endif
	} cn38xx;
	struct cvmx_asxx_tx_comp_byp_cn38xx cn38xxp2;
	struct cvmx_asxx_tx_comp_byp_cn50xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_17_63:47;
		uint64_t bypass:1;
		uint64_t reserved_13_15:3;
		uint64_t pctl:5;
		uint64_t reserved_5_7:3;
		uint64_t nctl:5;
#else
		uint64_t nctl:5;
		uint64_t reserved_5_7:3;
		uint64_t pctl:5;
		uint64_t reserved_13_15:3;
		uint64_t bypass:1;
		uint64_t reserved_17_63:47;
#endif
	} cn50xx;
	struct cvmx_asxx_tx_comp_byp_cn58xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_13_63:51;
		uint64_t pctl:5;
		uint64_t reserved_5_7:3;
		uint64_t nctl:5;
#else
		uint64_t nctl:5;
		uint64_t reserved_5_7:3;
		uint64_t pctl:5;
		uint64_t reserved_13_63:51;
#endif
	} cn58xx;
	struct cvmx_asxx_tx_comp_byp_cn58xx cn58xxp1;
};

union cvmx_asxx_tx_hi_waterx {
	uint64_t u64;
	struct cvmx_asxx_tx_hi_waterx_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_4_63:60;
		uint64_t mark:4;
#else
		uint64_t mark:4;
		uint64_t reserved_4_63:60;
#endif
	} s;
	struct cvmx_asxx_tx_hi_waterx_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_3_63:61;
		uint64_t mark:3;
#else
		uint64_t mark:3;
		uint64_t reserved_3_63:61;
#endif
	} cn30xx;
	struct cvmx_asxx_tx_hi_waterx_cn30xx cn31xx;
	struct cvmx_asxx_tx_hi_waterx_s cn38xx;
	struct cvmx_asxx_tx_hi_waterx_s cn38xxp2;
	struct cvmx_asxx_tx_hi_waterx_cn30xx cn50xx;
	struct cvmx_asxx_tx_hi_waterx_s cn58xx;
	struct cvmx_asxx_tx_hi_waterx_s cn58xxp1;
};

union cvmx_asxx_tx_prt_en {
	uint64_t u64;
	struct cvmx_asxx_tx_prt_en_s {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_4_63:60;
		uint64_t prt_en:4;
#else
		uint64_t prt_en:4;
		uint64_t reserved_4_63:60;
#endif
	} s;
	struct cvmx_asxx_tx_prt_en_cn30xx {
#ifdef __BIG_ENDIAN_BITFIELD
		uint64_t reserved_3_63:61;
		uint64_t prt_en:3;
#else
		uint64_t prt_en:3;
		uint64_t reserved_3_63:61;
#endif
	} cn30xx;
	struct cvmx_asxx_tx_prt_en_cn30xx cn31xx;
	struct cvmx_asxx_tx_prt_en_s cn38xx;
	struct cvmx_asxx_tx_prt_en_s cn38xxp2;
	struct cvmx_asxx_tx_prt_en_cn30xx cn50xx;
	struct cvmx_asxx_tx_prt_en_s cn58xx;
	struct cvmx_asxx_tx_prt_en_s cn58xxp1;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ELF          (    $+  4   @J   4    (                  3 3          < < < x             < < < X  X                    $   $         Qtd                          Rtd< < < x  x                 GNU 7SO 9q82             `1 B          4|BEW=WqXvT<Yy                    |%       	     <       X             4	                                       9                                       <                                                                    a                                                      L                          i                          @                                       n                          *             /             F             u                                                                                               `             c             +             +                                       6             8                            i             u                                                      A                                                                                                        c             D                                                     N             *                          ;             	                                                    u                                                    ]	             '                                                    t	                                                     !	             K                                       Y                                                     u                          [                           	                                       G	             G             3                                       X             p                                                    P             n             z             u                                                                 I             \                                       P                          R           "                [                                                    
  I       
  I       o
   I           |    
  I       v
   I          |%       	    P        
   I       
  I        __gmon_start__ _init _fini _ITM_deregisterTMCloneTable _ITM_registerTMCloneTable __cxa_finalize _Jv_RegisterClasses _talloc_stackframe initialize_password_db _talloc_free lp_passdb_backend PyErr_Format _Py_NoneStruct get_global_sam_sid dom_sid_dup pytalloc_steal PyErr_NoMemory _PyArg_ParseTuple_SizeT secrets_init_path lp_load_global talloc_named_const _talloc_zero _pytalloc_get_ptr PyString_FromString PyInt_FromLong _Py_BuildValue_SizeT samu_new pdb_get_code_page pdb_get_country_code pdb_get_logon_count pdb_get_bad_password_count PyType_IsSubtype _pytalloc_get_mem_ctx _talloc_array PyInt_AsLong pdb_set_hours PyList_Type PyInt_Type PyExc_TypeError pdb_get_hours_len pdb_get_hours PyList_New PyList_SetItem pdb_get_logon_divs pdb_get_acct_ctrl PyString_AsString pdb_set_plaintext_passwd PyString_AsStringAndSize pdb_set_pw_history pdb_set_nt_passwd pdb_get_user_sid pdb_get_pass_must_change_time pdb_get_pass_can_change_time pdb_get_pass_last_set_time pdb_get_bad_password_time pdb_get_kickoff_time pdb_get_logoff_time pdb_get_logon_time make_pdb_method_name get_friendly_nt_error_msg memcpy PyList_Append PyDict_GetItemString PyDict_Type PyString_Type _pytalloc_get_type PyDict_SetItemString PyString_FromStringAndSize PyDict_New PyLong_FromUnsignedLongLong account_policy_names_list account_policy_name_to_typenum talloc_strdup dom_sid_add_rid _talloc_steal_loc strlcpy pdb_set_code_page pdb_set_country_code pdb_set_logon_count pdb_set_bad_password_count pdb_set_hours_len pdb_set_logon_divs pdb_set_acct_ctrl pdb_get_pw_history pdb_set_lanman_passwd pdb_set_group_sid pdb_set_user_sid pdb_set_munged_dial pdb_set_comment pdb_set_workstations pdb_set_acct_desc pdb_set_profile_path pdb_set_logon_script pdb_set_dir_drive pdb_set_homedir pdb_set_fullname pdb_set_nt_username pdb_set_domain pdb_set_username pdb_get_domain pdb_get_nt_username pdb_get_fullname pdb_get_homedir pdb_get_dir_drive pdb_get_logon_script pdb_get_profile_path pdb_get_acct_desc pdb_get_workstations pdb_get_comment pdb_get_munged_dial pdb_get_group_sid pdb_get_lanman_passwd pdb_get_nt_passwd pdb_get_plaintext_passwd pdb_get_backends pdb_get_username pdb_set_pass_can_change_time pdb_set_pass_last_set_time pdb_set_bad_password_time pdb_set_kickoff_time pdb_set_logoff_time pdb_set_logon_time initpassdb pytalloc_BaseObject_PyType_Ready Py_InitModule4 PyErr_NewException PyModule_AddObject PyImport_ImportModule PyObject_GetAttrString __stack_chk_fail __stack_chk_guard libsamba-util.so.0 libsamba-passdb.so.0 libsecrets3.so.0 libsamba-errors.so.1 libsamba-security.so.0 libsmbconf.so.0 libpython2.7.so.1.0 libtalloc.so.2 libbsd.so.0 libpytalloc-util.so.2 libc.so.6 ld-linux-armhf.so.3 _edata __bss_start __bss_start__ __bss_end__ __end__ _end samba/samba3/passdb.so /usr/lib/arm-linux-gnueabihf/samba LIBBSD_0.0 GLIBC_2.4 SAMBA_ERRORS_1 SMBCONF_0 SAMBA_UTIL_0.0.1 SAMBA_4.5.16_DEBIAN PYTALLOC_UTIL_2.0.6 PYTALLOC_UTIL_2.1.6 TALLOC_2.0.2 SAMBA_PASSDB_0.2.0                                                                                   	      
                  	                                                      	                   /
         p0}   
        [
         ii   
        	           
 
        Q
         ii  	 
        	         0t           	         T           	            "        ;
     0   Y   6     Y   J         
         "   ^        	            "        	            k      <    <     @    @    \@    @    @    @     A    DA    dA    A    A     B    (B    PB    TB    \B    `B    dB    lB    pB    tB    |B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B    B     C    C    C    C    C    C     C    $C    ,C    0C    4C    <C    @C    DC    LC    PC    TC    \C    `C    dC    lC    pC    tC    |C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C    C     D    D    D    D    D    D     D    $D    ,D    0D    4D    <D    @D    DD    LD    PD    TD    \D    `D    dD    lD    pD    tD    |D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D    D     E    E    E    E    E    E     E    $E    ,E    0E    4E    <E    @E    DE    LE    PE    TE    \E    `E    dE    lE    pE    tE    |E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    E    F    F    F    F     F    $F    0F    4F    8F    XF    \F    `F    lF    pF    tF    F    F    F    F    F    F    F    F    F    F    F    F    F    F    F    F    F    F    F    F     G    G    G    G     G    $G    (G    4G    8G    <G    HG    LG    PG    \G    `G    dG    pG    tG    xG    G    G    G    G    G    G    G    G    G    G    G    G    G    G    G    G    G    G    G     H    H    H    H    H    $H    (H    ,H    8H    <H    @H    LH    PH    TH    `H    dH    hH    tH    xH    |H    H    H    H    H    H    H    H    H    H    H    H    H    H    H    H    ?   ?   ?   ?   ?   ?   ? %  ? -  ? E  ? T  ? q  ? }  =   =    >   >   >   >   > 	  > 
  >   >    >   $>   (>   ,>   0>   4>   8>   <>   @>   D>   H>   L>   P>   T>   X>    \> !  `> "  d> #  h> $  l> &  p> '  t> (  x> )  |> *  > +  > ,  > .  > /  > 0  > 1  > 2  > 3  > 4  > 5  > 6  > 7  > 8  > 9  > :  > ;  > <  > =  > >  > ?  > @  > A  > B  > C  > D  > F  > G  > H  > I  > J  > K  > L   ? M  ? N  ? O  ? P  ? Q  ? R  ? S  ? U   ? V  $? W  (? X  ,? Y  0? Z  4? [  8? \  <? ]  @? ^  D? _  H? `  L? a  P? b  T? c  X? d  \? e  `? f  d? g  h? h  l? i  p? j  t? k  x? l  |? m  ? n  ? o  ? p  ? r  ? s  ? t  ? u  ? v  ? w  ? x  ? y  ? z  ? {  ? |  ? }  ? ~  ?   ?   ?   ?   @-g -T  !T !L !D !< !4 !, !$ ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !| !t !l !d !\ !T !L !D !< !4 !, !$ ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !| !t !l !d !\ !T !L !D !< !4 !, !$ ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !| !t !l !d !\ !T !L !D !< !4 !, !$ ! ! ! ! ! ! ! ! ! ! ! ! ! ! !0 0   R/   404 0  0 0C S 00/ 0  S//  |   88    A,0A0/ 0  S//\ X 4    L0L 0  0  S/80@-0  S  
(0 0 0        8 80    0  R     0  S
@-3/@4     p@-   |PP `  @P
  
d KX00      p@0P8   u( 8 p  4      p  |  l p@-   P  S @P  
D00 4 @  p,      T   p@-  M@_ PP `  @P  
 # @P  
 x00      p\  pD0D0   0  x  $            4   p@-  M@" PP `  @P  
 " @P  
 x00      p\  pD0D0   0  @  0   p           A- p       P  `P  
 X  @P  
 P @P  
 x t t @l\ fP bu< \0 X     4                 p@- P`    @ GL00T   P  
 P4 : p  0P     ,       p@- P`    @ 'L00P   P  
 P4  p  0P       p     p@- @   _ P     @ . `P  
( @P  
00 t @ d  pL @4 (         ,        @- p M  @  PP `  @P  
 03/ @P  
 t00      X  @0@0  0      
      |       A-  M  @`` 0 0000PP p  @P  
 x @ u  0 8/ @P  
| gp00      T [ <  0 P      	       $  <  p@- `PM  @  P G @P  
  0  3` 03/ @P  
 T @P  
00  @  Ppl  PpT0T0    C@ ,  @  P   x    4       p@- `PM  @F  P  @P  
   0`  03/ @P  
  @P  
00  @  Ppl  PpT0T0    @ ,     H    p   p  |    p@- @4    P L  @  p    0@- @| M   P 03/ @P  
P  04040  $ t 0     \  `  p@- @<    P f$    @ [ pt  |  t  @- p M  @PP0  ` U @P  
 D @ A0   3/ @P  
t 4h    aP ) 8  [,  d  , h            p@- `T   f P   @P  
8  p@  p$  H     p@- @4   J P f @  p   $  p@- @4   7 P S @  p     p@- @4   $ P k@ @  p    p@- @4    P v- @  p    O- @M  `	  1  P P  
(  PL  
 1 0 PP  
  X  `1
@pP    \   
  P  
     W 0
 O @
 i  T  
 c     0  00    K  h0  0   0\\00v  OD 6    p   (      T                p@- @4   x P   @  pp  t  A- @   e   @'00 PP  
  p- `P  
  WPE @   q@    WP  < 0`       l           p@- @4   + P G @  p    p@- @4    P )4 @  p    p@- P` `   @  P     P   
$  p  p      p@- P M  ` @   P o    R0  0"r  P   
(v  pp        p@- Pd `   @ d P S     P   
$U  pP  p    l  p@- @    P E'00 @P  
    h `P  
b @P  
00   @ ) % pt 0@      p/T @(< 0    |            (  <  p@- @4   R P Kn @  ph  l  p@- @4   ? P [ @  pd  h  p@- @4   , P H @  p`  d  p@- @4    P 35 @  p\  `  p@- @4    P " @  pX  \  p@- @4    P  @  pT  X  p@- @4    P  @  pP  T  A- p M  @  PP" ` { @P  
  P   4 @P  
 \  U h0p0@ PT 0   ~< AT( ;H        8       @- p M  @ PP ` 2 @P  
 !03/ @P   00      p 
 X0p0 PH 0   40        | \           @- p M  @< PP `  @P  
 03/ @P   00      d  L0PKD  0 0       d     t   p    O- P$M  @qp0    PA  
  @ 0 0 |P0  5/ @P9   PD  
0  S%  
$P
D`  }  :0D@ U  *
 	 P  9 Py _ $ X $| Q $ P\   0 ~D AT0 ;  x         x  x      A- M  @``0 0  0PP p * @P  
  @   x0   3/ @P   00      d   PD  0 (0        \     H  H  \  A- M  @0``0 0  0PP p  @P  
  @   t0   3/ @P   00      d   P2D  0 0   `  T d   x          A-  M  @``0 PP p  @P  
 | @ yh0  3/ @P   m00      d a  PD  0 0 R            |  |    @- ` M  @  P I @P  
 8 d03/ @P   , h $ P0p0 `@ 0   N(         H  t 8  H  @- p M  @X0 `` P  @P  
  `@4/ @P   00      d  L0`eD  0 0   T  `         `     @- p M  @0 `` P  @P  
  \@4/ @P   00      d  L0` D  0 0        H      L     G- `M  @p!p P0 PPP  z pP1  
 i @ f000 0	T`0   6/ @P'   pP4  
0  S
P  
 `vPD@    0 U:	 : 	 3 h0p0 PX  0 ^D	 !40	      @ x            A- `@M  @`qp<0 PP   @P!  
  `<  @          H@4/ @P   00      @d  @ P^D  0 0              t  t    @- p M  @   0PP `  @P  
  @ D0  3/ @P   00      h  P0PH  0 4 }            0   ,  D  @- p M  @   0PP ` n @P  
 ] @ Z@0  3/ @P   N00      h B P0PH  0 o4 2  D   H  l            @- p M  @v `` P & @P  
  <03/ @P   	00      p  X0p0 `H 0   '0        L D           @- ` M  @/  P  @P  
 0 8@4/ @P    9h  P0p0 `@@ 0   (         h   X  l  @- PM  @  `  @P  
    P     @P%  
40   3/ PP   y | r d0 @0 pT  0 @ `s, Zx           $  @    @- PM  @  ` R @P  
 A   P     @P%  
700   3/ PP   * | # d0 @0 pT  0 N@ $, 0  @   |    p       C- PDLM  @Q4a4`D0  p   P'  
  PD    @    N P.  
         	  ,@4/ @P    Lx  L PKX   0 @ ,         4  X  l     @- p M  @ 0 0 0PP `  @P  
  @ $0   3/ @P   ~00      h r P0PH  0 4 b  \  X \  0 d       Dw    @- p M  @ 0 PP ` T @P  
 C @ @ 0  3/ @P   400      h ( P0PH  0 U4     (        l   h  x  @- p M  @\ 0 PP ` 
 @P  
  @ 0  3/ @P   00      h  P0PeH  0 4   x             `      @- p M  @ 0 PP `  @P  
  @ 0 p 3/ @P   00      t  \0$p0 PL 0   4       (   T      0     @- p M  @ 0 `` P r @P  
 a @ ^0   3/ @P   Q00      h E P0`H  0 r4 5       |     D   @  H  @- ` M  @y0  P * @P  
  0 @4/ @P   
 h  P0p0 `@ 0   ,(   H  T    ~   ~  ~  A- P0M  @6     @P  
    P    @P0  
` p    6/ PP      0`>|  0  00C  S 0  0 03/D  @,      < L  ~   ~  ~  4~  A- P0M  @   `  @P  
 ~   P   a @P0  
u0   3/ PP   h  a 00 p0     00C  S 0  0 03/D E @W, >~  ~   ~  0~  h D~  <~  }  O- M  `R2PBp@0 0   0  * @PP  
\ P ` @ p 02   P  
 @P`  
  P  
 @Pg  
  P  
 @PA  
	 @   `0  00
 0 0  	 @4/ @P  \ P10      4  1`0 PI 0      0  0    000 0  0   000 l0  0   0dd00 (~     ,~   ~  $~  ~     ~    |   }  }    @}  4}  P|  <|  x|  d|  @- p M  @Q1P0   ` j @PX  
 $H@  A  \D    t  d$\0 h0 l<0 p0$t  x  |    0 0 03/ @P   00        x0Pp  0 )\    }  t   }  4}  ,}  $}  g  }  |  |  |  |  |  |    {   H|  d|  O- @tM  ' P  0 @4/ `Pw   pP  
0  Sj  
$2$0020
	0F  0A`      
    p   PL    ~XT    w\ h   p` P   id 8   btp    Z 20 V  * PPz 00C  S 0  0 03/ pW  P 0 p0 @|  0 {h > OL 6<|  z  z  z  z   z  Tz  Hz  8z  ,z  z  z  $ a  z  @z  @- p0M  @t b `0  P # @Pb  
  @  p0   7/ @P\  < @Pg  
0  q   0 i    t   0PL T   0XT 4   0\ L   0` D   0d <   0tp         `3x  @ 0 ` L (z  d ,z  w  w  w  w  w  |w  lw  Xw  Hw  \y  x  x  x  x  @- `$M  @  P  @P`  
 t0  @4/ `P^   @Pk  
0     K0    C10 $|   80PL |\   /0XT s<   &0\     0`    0d    0tp R       0 @0 px  0 :d P x  x  hu  Tu  P 8u  (u  u  u  t  t  t  w  0w    $v  w  w  G- @HM  5  
0 @4/ @P-   `P<  
 0  S   
p	p PP  
01  3	   0     w 0@ T:
  l0 `0 P.\  0 H
  ,
 v  s    P~  v   v  4v  \v  p@- `XM  @  P  @P4  
 v@0 00 `6/  P/  
  @P6  
(10 2 `P5  
 @P9  
    ?  :    3 D Xp = Xp00 @  l /Bl )<X @"5@ @v  Pv   v  t|  v  |v  pu   tu  u  u  u  u  O- `M  p]B"@0    P P#  l pPl  
  @  P P  
 P8"   $ `Po  
 0 3/  P\  
"   PPh  
   pPk  
1001
	000 3/  P,  
 @P'  
  0    *
    $	                Y 03/    00 p   t pmt pfy\ `u       u  u  u  v  u    u  u   v  $u  s   t  t  s  t  $t  O- @(M   P  B"   @ y `Pg  
0 3/  PU  
!  l PPa  
  U pPd  
1001
	000 3/  P,  
J @P'  
      
    z	    n    h    b     03/  00 p   x p` pH 4t  r  s  ts  <s    8s  @s  Xs  ls  ` r  r  tr  r  r  O- PdM  @T    pPf  
 0"   @  `Po  
0  3/  P\  
!   PPh  
   pPk  
1001
	000 3/  P,  
 @P'  
     O 
   I 	   C    =    7    1 	V 03/ 9  2 00 p  a $7 p0h p)P r  r  Hp  p  p  p  |  p  p  p  q  q   8q  8q  p  (q  0q  A- PM  @M|q|p0  `  @P2  
  @ D!    PP:  
l0  3/ @P%   @P7  
  D    =    <        P<  @ 0 h T @< q   q  q  |q  lq    Dq  @p  xp  p   p  xp  G- @   p A@03/ PP>  
  PA  
X!   `PA  
P0   @PB  
       J    C    <	     4    , = 00@      Gp 	@-@X @&9@  p   p  |e   p  pp  \p  Dp  4p    Xo  lo  to  A- `8M  @a  P  @PN  
 q!p ` @  6   `PU  
00 000000 0 (0  8/ @P3   @PG  
,( X   @   40 $          8  8 `p60  @     @ 00C  S 0  0 03/D o  o   o  (a  o  `  o  `  o  Xn  n  n  8n  tn  O- tM  dad1``AP@0 0 p 	  n @P?  
 ]  P n0  S  0	 @000  P  
0     ;/ 0P  0@ S 100       0 

 0   W4  n     n  < n  m    tm  G- @ M  ^   P: `P'  
 	 0  S @p  0s0   3/  P   
 
   0@ S4	  	 m  <  8m  l  C- p$M  @0  00a` P  @P0  
  p \  }    P @ 3  
, q    P @ 1  
	p0  3/ @P   00      $  $ `  0  t  t  h j T  H ` m   m    i  h  <m    4l  l  l  l  l  k  l  A- XM  @HQHP0  p N `P,  
 = @ :0 0P`0   6/ @P$  Y `P/  
0  S   
0 !@    0 T:  t   PT  ` 0 9< ( Hl   Ll  Dl  k  k  k  k  O- p,,M  =R2P  @ @ @"   `(0  `#   PN  
 p P  P  
 0  000$0 0 L@ 04/ @P>   PK  
$0  S&  
HaHH`
p`    P  
 0X  P 0  1P 0 
 1T	 P$0@ T:   ~ , w ,|0 0 Pl  0 X exD _k  p   l pk   k  k  j  j  8j   ,j  @j  j   @-  M`@0@P p  P  
  P  
\ 9  D0  0   0,,00c  j     j    Tj  @8  A- @ M  Pp p @0@`   P  
  P  
00 U  
 T0 P  
 ,9   hT ,-TL0  0   04400  j  0     tj  V   V    i   7  A- @ M  P& p @0@`   P  
R  P  
00 U  
 P0 P  
 ,   hP ,TL0  0   04400  i       i  T  T    8i  5  A- @ M  P p @0@`   P  
  P	  
 \L  o  @0  0   0((00  `i     i    h  5  A- @ M  P p O@0@`   P  
  P	  
 \  :  @0  0   0((00d  $i     Di    h  D4  A- P M  @r`` p PP   P  
  P  
| D   `    H0  0    0,,00)  h  ` 0 >  h    `h  X3  A- @ M  P6 p @0@`   P  
b  P  
 X p E  P   
h  T  D0  0   0,,00  h  H   h  |h    g  X2  A- @ M  P p @0@`   P  
"  P  
  p   P   
h  T~  D0  0   0,,00  Lh  H   th  8h    g  X1  A- @ M  P p ^@0@`   P  
  P  
  p   P   
hD  T>  D0  0   0,,00i  h  H   ,h  g    pg  X0  A- @ M  Pv p @0@`   P  
  P  
  p '  P   
h  T  D0  0   0,,00)  g  H   g  g    (g  X/  A- @ M  P6 p @0@`   P  
b  P  
 X     P   
h  T  D0  0   0,,00  xg  H   g  `g    f  X.  A- @ M  P p @0@`   P  
"  P  
  p >  P   
h  T~  D0  0   0,,00  0g  H   Tg  g    f  X-  A- @ M  P p ^@0@`   P  
  P  
      P   
hD  T>  D0  0   0,,00i  f  H   g  f    Pf  X,  0@- @| M  w P <\00  P
  
GD @  0( 0@      0f  H f    A- @ M  PO p @0@`   P  
{  P  
      P   
h  T  D0  0   0,,00  Lf     pf  4f    e  *  A- P M  @`` p PP   P  
;  P  
      P   
l  X  H0  0    0,,00  f    (f  e    he  )  A- P M  @`` p tPP   P  
  P  
 h     P   
l\  XV  H0  0    0,,00  e    e  e    e  (  A- @ M  P p 5@0@`   P  
  P  
      P   
h  T  D0  0   0,,00@  le     e  Te    d  '  A- @ M  PM p @0@`   P  
y  P  
      P   
h  T  D0  0   0,,00   $e     He  e    d  &  A- @ M  P p @0@`   P  
9  P  
      P   
h  T  D0  0   0,,00  d      e  d    Dd  %  A- @ M  P p u@0@`   P  
  P  
 Y      P   
h[  TU  D0  0   0,,00  d     d  |d    c  $  A- @ M  P p 5@0@`   P  
  P  
      P   
h  T  D0  0   0,,00@  Ld     pd  4d    c  #  A- @ M  PM p @0@`   P  
y  P  
      P   
h  T  D0  0   0,,00   d     (d  c    lc  "  A- @ M  P p @0@`   P  
9  P  
    (  P   
h  T  D0  0   0,,00  c     c  c    $c  !  A- @ M  P p u@0@`   P  
  P  
 Y   9  P   
h[  TU  D0  0   0,,00  tc     c  \c    b     A- @ M  P p 5@0@`   P  
  P  
      P   
h  T  D0  0   0,,00@  ,c     Pc  c    b    A- @ M  PM p @0@`   P  
y  P  
    2  P   
h  T  D0  0   0,,00   b     c  b    Lb    A- @ M  P p @0@`   P  
9  P  
    X  P   
h  T  D0  0   0,,00  b     b  b    b    A- @ M  P p u@0@`   P  
  P  
 Y     P   
h[  TU  D0  0   0,,00  Tb     xb  <b    a    0 00      /   p@- @D    P ,m  P  
  @ ! pp@a  a  p@- @D   m P   P  
  @ 
 pp@a  a  p@- @D   V P   P  
j  @  pp@a  a  p@- @D   ? P   P  
S  @  pp@a  a  p@- @D   ( P   P  
<  @  pp@a  a  p@- @D    P   P  
%  @  pp@la  |a  p@- @D    P   P  
  @  pp@Ula  ha  p@- @D    P   P  
  @  pp@>Xa  Ta  p@- @D    P t  P  
  @ i pp@'Da  @a  p@- @D    P ]  P  
  @ R pp@0a  ,a  p@- @D    P F  P  
  @ ; pp@a  a  p@- @x    P / P  
  U @P  
H "<00p@ p@.  pa  a  x `  p@- @H   a P 	  P  
5  @  pp@`  `  p@- @H   I P   P  
  @  pp@`  `  p@- @D   1 P   P  
E  @  pp@`  `   p@-   ` @P  
   PP  
  ,  }@  T4  pp@n `  `  L`  p@- @D    P   P  
	  @  pp@Pp`  l`  A- @ M  P p @0@`   P  
  P  
    o  P   
hj  Td  D0  0   0,,00  X`     |`  @`    _    A- @ M  P p D@0@`   P  
  P  
      P   
h*  T$  D0  0   0,,00O  `     4`  _    x_    A- @ M  P\ p @0@`   P  
  P  
 ~     P   
h  T  D0  0   0,,00  _     _  _    0_    A- @ M  P p @0@`   P  
H  P  
 >     P   
h  T  D0  0   0,,00  _     _  h_    ^    A- @ M  P p @0@`   P  
  P  
      P   
hj  Td  D0  0   0,,00  8_     \_   _    ^    A- @ M  P p D@0@`   P  
  P  
    Y  P   
h*  T$  D0  0   0,,00O  ^     _  ^    X^     3 #0G- M`B 0  0W2P0@b     0c  Pi   _  Pz  
 Z  Pj  "  " 0    Po  
   XRP  0 D  	  01,01 	  00  0	 000
 	    @PR  
Y  P Q  
 R 00C  S 0 '  
  PN  
   @P6  
||QA 0P0C  S 0 %  
  P 7  
L  @   0 R4    z0 03/  o j0 03/  _ Z UQ L   ^   `    ^  ^  \ ^  ^  l^  T^  P^  9  l:  x^  ^  L ^  \  \  \  \  ]  ]  ]  ]  ]  @-../source3/passdb/py_passdb.c:3653  Cannot re-open passdb backend %s    ../source3/passdb/py_passdb.c:3658  ../source3/passdb/py_passdb.c:3662  ../source3/passdb/py_passdb.c:3668  ../source3/passdb/py_passdb.c:3677  ../source3/passdb/py_passdb.c:3683  ../source3/passdb/py_passdb.c:3631  ../source3/passdb/py_passdb.c:3635  Cannot open secrets file database in '%s'   ../source3/passdb/py_passdb.c:3643  ../source3/passdb/py_passdb.c:3647  ../source3/passdb/py_passdb.c:3609  ../source3/passdb/py_passdb.c:3613  Cannot open '%s'    ../source3/passdb/py_passdb.c:3620  ../source3/passdb/py_passdb.c:3624  ../source3/passdb/py_passdb.c:1276  talloc_new: ../source3/passdb/py_passdb.c:1281  ../source3/passdb/py_passdb.c:1284  GROUP_MAP   ../source3/passdb/py_passdb.c:1291  ../source3/passdb/py_passdb.c:1292  ../source3/passdb/py_passdb.c:1299  ../source3/passdb/py_passdb.c:1300  ../source3/passdb/py_passdb.c:1304  ../source3/passdb/py_passdb.c:1306  ../source3/passdb/py_passdb.c:1237  ../source3/passdb/py_passdb.c:1246  ../source3/passdb/py_passdb.c:1207  ../source3/passdb/py_passdb.c:1216  ../source3/passdb/py_passdb.c:1143  talloc_new: ../source3/passdb/py_passdb.c:1149  ../source3/passdb/py_passdb.c:1152  ../source3/passdb/py_passdb.c:1159  ../source3/passdb/py_passdb.c:1160  ../source3/passdb/py_passdb.c:1166  ../source3/passdb/py_passdb.c:1168  ../source3/passdb/py_passdb.c:2880  s:del_trusteddom_pw ../source3/passdb/py_passdb.c:2885  Unable to delete trusted domain password    ../source3/passdb/py_passdb.c:2893  ../source3/passdb/py_passdb.c:2897  ../source3/passdb/py_passdb.c:2850  ssO!:set_trusteddom_pw  ../source3/passdb/py_passdb.c:2859  Unable to set trusted domain password   ../source3/passdb/py_passdb.c:2869  ../source3/passdb/py_passdb.c:2873  ../source3/passdb/py_passdb.c:2710  I:gid_to_sid    ../source3/passdb/py_passdb.c:2718  Unable to get sid for gid=%d    ../source3/passdb/py_passdb.c:2729  ../source3/passdb/py_passdb.c:2736  ../source3/passdb/py_passdb.c:2742  ../source3/passdb/py_passdb.c:2671  I:uid_to_sid    ../source3/passdb/py_passdb.c:2679  Unable to get sid for uid=%d    ../source3/passdb/py_passdb.c:2690  ../source3/passdb/py_passdb.c:2697  ../source3/passdb/py_passdb.c:2703  ../source3/passdb/py_passdb.c:1185  ../source3/passdb/py_passdb.c:1190  ../source3/passdb/py_passdb.c:2777  Unable to get new rid   ../source3/passdb/py_passdb.c:2785  ../source3/passdb/py_passdb.c:2789  ../source3/passdb/py_passdb.c:1121  i   ../source3/passdb/py_passdb.c:1126  ../source3/passdb/py_passdb.c:2749  O!:sid_to_id    ../source3/passdb/py_passdb.c:2756  Unable to get id for sid    ../source3/passdb/py_passdb.c:2766  ../source3/passdb/py_passdb.c:2770  (II)    ../source3/passdb/py_passdb.c:1095  ../source3/passdb/py_passdb.c:1101  ../source3/passdb/py_passdb.c:1105  ../source3/passdb/py_passdb.c:1030  ../source3/passdb/py_passdb.c:1035  ../source3/passdb/py_passdb.c:1005  ../source3/passdb/py_passdb.c:1010  ../source3/passdb/py_passdb.c:980   ../source3/passdb/py_passdb.c:985   ../source3/passdb/py_passdb.c:955   ../source3/passdb/py_passdb.c:960   ../source3/passdb/py_passdb.c:919   value   ../source3/passdb/py_passdb.c:926: Expected type '%s' for '%s' of type '%s' uint8_t ../source3/passdb/py_passdb.c:943   ../source3/passdb/py_passdb.c:933   PyList_GET_ITEM(value,i)    ../source3/passdb/py_passdb.c:938: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:946   ../source3/passdb/py_passdb.c:949   ../source3/passdb/py_passdb.c:867   ../source3/passdb/py_passdb.c:872   ../source3/passdb/py_passdb.c:892   ../source3/passdb/py_passdb.c:913   ../source3/passdb/py_passdb.c:906   ../source3/passdb/py_passdb.c:842   ../source3/passdb/py_passdb.c:847   ../source3/passdb/py_passdb.c:817   ../source3/passdb/py_passdb.c:822   ../source3/passdb/py_passdb.c:804   ../source3/passdb/py_passdb.c:808   ../source3/passdb/py_passdb.c:811   ../source3/passdb/py_passdb.c:769   ../source3/passdb/py_passdb.c:778   ../source3/passdb/py_passdb.c:781   ../source3/passdb/py_passdb.c:738   ../source3/passdb/py_passdb.c:742   ../source3/passdb/py_passdb.c:745   ../source3/passdb/py_passdb.c:603   talloc_new: ../source3/passdb/py_passdb.c:615   ../source3/passdb/py_passdb.c:618   ../source3/passdb/py_passdb.c:624   ../source3/passdb/py_passdb.c:625   ../source3/passdb/py_passdb.c:631   ../source3/passdb/py_passdb.c:633   ../source3/passdb/py_passdb.c:210   ../source3/passdb/py_passdb.c:215   ../source3/passdb/py_passdb.c:185   ../source3/passdb/py_passdb.c:190   ../source3/passdb/py_passdb.c:160   ../source3/passdb/py_passdb.c:165   ../source3/passdb/py_passdb.c:135   ../source3/passdb/py_passdb.c:140   ../source3/passdb/py_passdb.c:110   ../source3/passdb/py_passdb.c:115   ../source3/passdb/py_passdb.c:85    ../source3/passdb/py_passdb.c:90    ../source3/passdb/py_passdb.c:60    ../source3/passdb/py_passdb.c:65    ../source3/passdb/py_passdb.c:3535  ../source3/passdb/py_passdb.c:3542  Cannot load backend methods for '%s' backend (%d,%s)    ../source3/passdb/py_passdb.c:3553  ../source3/passdb/py_passdb.c:3559  ../source3/passdb/py_passdb.c:3563  ../source3/passdb/py_passdb.c:3342  s:delete_secret ../source3/passdb/py_passdb.c:3348  Unable to delete secret (%s), (%d,%s)   ../source3/passdb/py_passdb.c:3360  ../source3/passdb/py_passdb.c:3364  ../source3/passdb/py_passdb.c:3132  s:del_trusted_domain    ../source3/passdb/py_passdb.c:3138  Unable to delete trusted domain, (%d,%s)    ../source3/passdb/py_passdb.c:3149  ../source3/passdb/py_passdb.c:3153  ../source3/passdb/py_passdb.c:2355  O!:enum_aliasmem    ../source3/passdb/py_passdb.c:2365  Unable to enumerate members for alias, (%d,%s)  ../source3/passdb/py_passdb.c:2378  ../source3/passdb/py_passdb.c:2401  ../source3/passdb/py_passdb.c:2385  struct dom_sid  ../source3/passdb/py_passdb.c:2393  ../source3/passdb/py_passdb.c:2322  O!O!:del_aliasmem   ../source3/passdb/py_passdb.c:2330  Unable to delete member from alias, (%d,%s) ../source3/passdb/py_passdb.c:2344  ../source3/passdb/py_passdb.c:2348  ../source3/passdb/py_passdb.c:2289  O!O!:add_aliasmem   ../source3/passdb/py_passdb.c:2297  Unable to add member to alias, (%d,%s)  ../source3/passdb/py_passdb.c:2311  ../source3/passdb/py_passdb.c:2315  ../source3/passdb/py_passdb.c:2158  O!:delete_alias ../source3/passdb/py_passdb.c:2165  Unable to delete alias, (%d,%s) ../source3/passdb/py_passdb.c:2178  ../source3/passdb/py_passdb.c:2182  ../source3/passdb/py_passdb.c:2128  s:create_alias  ../source3/passdb/py_passdb.c:2135  Unable to create alias (%s), (%d,%s)    ../source3/passdb/py_passdb.c:2147  ../source3/passdb/py_passdb.c:2151  ../source3/passdb/py_passdb.c:2100  II:del_groupmem ../source3/passdb/py_passdb.c:2106  Unable to rename sam account, (%d,%s)   ../source3/passdb/py_passdb.c:2117  ../source3/passdb/py_passdb.c:2121  ../source3/passdb/py_passdb.c:2072  II:add_groupmem ../source3/passdb/py_passdb.c:2078  Unable to add group member, (%d,%s) ../source3/passdb/py_passdb.c:2089  ../source3/passdb/py_passdb.c:2093  ../source3/passdb/py_passdb.c:2023  O!:enum_group_memberships   ../source3/passdb/py_passdb.c:2036  Unable to enumerate group memberships, (%d,%s)  ../source3/passdb/py_passdb.c:2050  ../source3/passdb/py_passdb.c:2065  ../source3/passdb/py_passdb.c:2057  ../source3/passdb/py_passdb.c:1872  O!:delete_group_mapping_entry   ../source3/passdb/py_passdb.c:1879  Unable to delete group mapping entry, (%d,%s)   ../source3/passdb/py_passdb.c:1892  ../source3/passdb/py_passdb.c:1896  ../source3/passdb/py_passdb.c:1841  O!:update_group_mapping_entry   ../source3/passdb/py_passdb.c:1848  Unable to update group mapping entry, (%d,%s)   ../source3/passdb/py_passdb.c:1861  ../source3/passdb/py_passdb.c:1865  ../source3/passdb/py_passdb.c:1810  O!:add_group_mapping_entry  ../source3/passdb/py_passdb.c:1817  Unable to add group mapping entry, (%d,%s)  ../source3/passdb/py_passdb.c:1830  ../source3/passdb/py_passdb.c:1834  ../source3/passdb/py_passdb.c:1781  I:delete_dom_group  ../source3/passdb/py_passdb.c:1787  Unable to delete domain group (rid=%d), (%d,%s) ../source3/passdb/py_passdb.c:1799  ../source3/passdb/py_passdb.c:1803  ../source3/passdb/py_passdb.c:1751  s:create_dom_group  ../source3/passdb/py_passdb.c:1758  Unable to create domain group (%s), (%d,%s) ../source3/passdb/py_passdb.c:1770  ../source3/passdb/py_passdb.c:1774  ../source3/passdb/py_passdb.c:1712  s:getgrnam  ../source3/passdb/py_passdb.c:1720  ../source3/passdb/py_passdb.c:1729  Unable to get group information by name, (%d,%s)    ../source3/passdb/py_passdb.c:1740  ../source3/passdb/py_passdb.c:1744  ../source3/passdb/py_passdb.c:1673  I:getgrgid  ../source3/passdb/py_passdb.c:1681  ../source3/passdb/py_passdb.c:1690  Unable to get group information by gid, (%d,%s) ../source3/passdb/py_passdb.c:1701  ../source3/passdb/py_passdb.c:1705  ../source3/passdb/py_passdb.c:1632  O!:getgrsid ../source3/passdb/py_passdb.c:1640  ../source3/passdb/py_passdb.c:1651  Unable to get group information by sid, (%d,%s) ../source3/passdb/py_passdb.c:1662  ../source3/passdb/py_passdb.c:1666  ../source3/passdb/py_passdb.c:1599  O!s:rename_sam_account  ../source3/passdb/py_passdb.c:1608  ../source3/passdb/py_passdb.c:1621  ../source3/passdb/py_passdb.c:1625  ../source3/passdb/py_passdb.c:1569  O!:delete_sam_account   ../source3/passdb/py_passdb.c:1576  Unable to delete sam account, (%d,%s)   ../source3/passdb/py_passdb.c:1589  ../source3/passdb/py_passdb.c:1593  ../source3/passdb/py_passdb.c:1539  O!:update_sam_account   ../source3/passdb/py_passdb.c:1546  Unable to update sam account, (%d,%s)   ../source3/passdb/py_passdb.c:1559  ../source3/passdb/py_passdb.c:1563  ../source3/passdb/py_passdb.c:1508  O!:add_sam_account  ../source3/passdb/py_passdb.c:1515  Unable to add sam account '%s', (%d,%s) ../source3/passdb/py_passdb.c:1529  ../source3/passdb/py_passdb.c:1533  ../source3/passdb/py_passdb.c:1478  O!:delete_user  ../source3/passdb/py_passdb.c:1485  Unable to delete user, (%d,%s)  ../source3/passdb/py_passdb.c:1498  ../source3/passdb/py_passdb.c:1502  ../source3/passdb/py_passdb.c:1448  sI:create_user  ../source3/passdb/py_passdb.c:1456  Unable to create user (%s), (%d,%s) ../source3/passdb/py_passdb.c:1468  ../source3/passdb/py_passdb.c:1472  ../source3/passdb/py_passdb.c:1410  O:getsampwsid   ../source3/passdb/py_passdb.c:1418  ../source3/passdb/py_passdb.c:1427  Unable to get user information from SID, (%d,%s)    ../source3/passdb/py_passdb.c:1438  ../source3/passdb/py_passdb.c:1442  ../source3/passdb/py_passdb.c:1371  s:getsampwnam   ../source3/passdb/py_passdb.c:1379  ../source3/passdb/py_passdb.c:1388  Unable to get user information for '%s', (%d,%s)    ../source3/passdb/py_passdb.c:1400  ../source3/passdb/py_passdb.c:1404  ../source3/passdb/py_passdb.c:3294  sO!:set_secret_name ../source3/passdb/py_passdb.c:3305  secret_current  secret_old  sd  py_secret_cur   ../source3/passdb/py_passdb.c:3313: Expected type '%s' for '%s' of type '%s'    py_secret_old   ../source3/passdb/py_passdb.c:3314: Expected type '%s' for '%s' of type '%s'    py_sd   ../source3/passdb/py_passdb.c:3315: Expected type '%s' for '%s' of type '%s'    Unable to set information for secret (%s), (%d,%s)  ../source3/passdb/py_passdb.c:3331  ../source3/passdb/py_passdb.c:3335  ../source3/passdb/py_passdb.c:3070  sO!:set_trusted_domain  ../source3/passdb/py_passdb.c:3080  domain_name netbios_name    security_identifier trust_auth_incoming trust_auth_outgoing trust_direction trust_type  trust_attributes    trust_forest_trust_info Unable to set trusted domain information, (%d,%s)   ../source3/passdb/py_passdb.c:3121  ../source3/passdb/py_passdb.c:3125  ../source3/passdb/py_passdb.c:3160  ../source3/passdb/py_passdb.c:3175  ../source3/passdb/py_passdb.c:3222  ../source3/passdb/py_passdb.c:3182  ../source3/passdb/py_passdb.c:3192  ../source3/passdb/py_passdb.c:3008  O!:get_trusted_domain_by_sid    ../source3/passdb/py_passdb.c:3017  Unable to get trusted domain information, (%d,%s)   ../source3/passdb/py_passdb.c:3030  ../source3/passdb/py_passdb.c:3037  ../source3/passdb/py_passdb.c:3063  ../source3/passdb/py_passdb.c:2949  s:get_trusted_domain    ../source3/passdb/py_passdb.c:2957  ../source3/passdb/py_passdb.c:2968  ../source3/passdb/py_passdb.c:2975  ../source3/passdb/py_passdb.c:3001  ../source3/passdb/py_passdb.c:2904  Unable to enumerate trusted domains, (%d,%s)    ../source3/passdb/py_passdb.c:2919  ../source3/passdb/py_passdb.c:2942  ../source3/passdb/py_passdb.c:2926  ../source3/passdb/py_passdb.c:2796  s:get_trusteddom_pw ../source3/passdb/py_passdb.c:2806  Unable to get trusted domain password   ../source3/passdb/py_passdb.c:2814  ../source3/passdb/py_passdb.c:2821  ../source3/passdb/py_passdb.c:2828  ../source3/passdb/py_passdb.c:2835  pwd last_set_tim    ../source3/passdb/py_passdb.c:2843  ../source3/passdb/py_passdb.c:2599  |O!:search_aliases  ../source3/passdb/py_passdb.c:2611  struct pdb_search   ../source3/passdb/py_passdb.c:2624  Unable to search aliases    ../source3/passdb/py_passdb.c:2630  struct samr_displayentry    ../source3/passdb/py_passdb.c:2637  ../source3/passdb/py_passdb.c:2644  idx acct_flags  account_name    fullname    description ../source3/passdb/py_passdb.c:2664  ../source3/passdb/py_passdb.c:2541  ../source3/passdb/py_passdb.c:2552  Unable to search groups ../source3/passdb/py_passdb.c:2558  ../source3/passdb/py_passdb.c:2565  ../source3/passdb/py_passdb.c:2572  ../source3/passdb/py_passdb.c:2592  ../source3/passdb/py_passdb.c:2477  I:search_users  ../source3/passdb/py_passdb.c:2485  ../source3/passdb/py_passdb.c:2494  Unable to search users  ../source3/passdb/py_passdb.c:2500  ../source3/passdb/py_passdb.c:2507  ../source3/passdb/py_passdb.c:2514  ../source3/passdb/py_passdb.c:2534  ../source3/passdb/py_passdb.c:2189  O!:get_aliasinfo    ../source3/passdb/py_passdb.c:2198  struct acct_info    ../source3/passdb/py_passdb.c:2209  Unable to get alias information, (%d,%s)    ../source3/passdb/py_passdb.c:2218  ../source3/passdb/py_passdb.c:2225  acct_name   acct_desc   ../source3/passdb/py_passdb.c:2236  ../source3/passdb/py_passdb.c:1323  ../source3/passdb/py_passdb.c:1340  struct GUID ../source3/passdb/py_passdb.c:1347  ../source3/passdb/py_passdb.c:1354  dns_domain  dns_forest  dom_sid guid    ../source3/passdb/py_passdb.c:1364  ../source3/passdb/py_passdb.c:3229  s:get_secret_name   ../source3/passdb/py_passdb.c:3240  struct security_descriptor  ../source3/passdb/py_passdb.c:3249  Unable to get information for secret (%s), (%d,%s)  ../source3/passdb/py_passdb.c:3265  ../source3/passdb/py_passdb.c:3273  secret_current_lastchange   secret_old_lastchange   ../source3/passdb/py_passdb.c:3287  ../source3/passdb/py_passdb.c:2442  O!:set_account_policy   ../source3/passdb/py_passdb.c:2451  ../source3/passdb/py_passdb.c:2471  Error setting account policy (%s), (%d,%s)  ../source3/passdb/py_passdb.c:2408  ../source3/passdb/py_passdb.c:2422  ../source3/passdb/py_passdb.c:2435  ../source3/passdb/py_passdb.c:2243  O!O:set_alias_info  ../source3/passdb/py_passdb.c:2252  Unable to allocate memory   ../source3/passdb/py_passdb.c:2263  ../source3/passdb/py_passdb.c:2269  Unable to set alias information, (%d,%s)    ../source3/passdb/py_passdb.c:2278  ../source3/passdb/py_passdb.c:2282  ../source3/passdb/py_passdb.c:1972  O!:enum_group_members   ../source3/passdb/py_passdb.c:1984  Unable to enumerate group members, (%d,%s)  ../source3/passdb/py_passdb.c:1998  ../source3/passdb/py_passdb.c:2005  ../source3/passdb/py_passdb.c:2016  ../source3/passdb/py_passdb.c:1903  |O!ii:enum_group_mapping    ../source3/passdb/py_passdb.c:1922  Unable to enumerate group mappings, (%d,%s) ../source3/passdb/py_passdb.c:1940  ../source3/passdb/py_passdb.c:1963  ../source3/passdb/py_passdb.c:1965  ../source3/passdb/py_passdb.c:1947  ../source3/passdb/py_passdb.c:1956  ../source3/passdb/py_passdb.c:1957  ../source3/passdb/py_passdb.c:221   ../source3/passdb/py_passdb.c:222: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:225   ../source3/passdb/py_passdb.c:1252  ../source3/passdb/py_passdb.c:1255: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1261  ../source3/passdb/py_passdb.c:1222  ../source3/passdb/py_passdb.c:1225: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1231  ../source3/passdb/py_passdb.c:1196  ../source3/passdb/py_passdb.c:1199: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1201  ../source3/passdb/py_passdb.c:1132  ../source3/passdb/py_passdb.c:1135: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1137  ../source3/passdb/py_passdb.c:1174  ../source3/passdb/py_passdb.c:1177: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1179  ../source3/passdb/py_passdb.c:1041  ../source3/passdb/py_passdb.c:1044: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1046  ../source3/passdb/py_passdb.c:1049  ../source3/passdb/py_passdb.c:1016  ../source3/passdb/py_passdb.c:1019: Expected type '%s' for '%s' of type '%s'    ../source3/passdb/py_passdb.c:1021  ../source3/passdb/py_passdb.c:1024  ../source3/passdb/py_passdb.c:991   ../source3/passdb/py_passdb.c:994: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:996   ../source3/passdb/py_passdb.c:999   ../source3/passdb/py_passdb.c:966   ../source3/passdb/py_passdb.c:969: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:971   ../source3/passdb/py_passdb.c:974   ../source3/passdb/py_passdb.c:878   ../source3/passdb/py_passdb.c:881: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:883   ../source3/passdb/py_passdb.c:886   ../source3/passdb/py_passdb.c:853   ../source3/passdb/py_passdb.c:856: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:858   ../source3/passdb/py_passdb.c:861   ../source3/passdb/py_passdb.c:828   ../source3/passdb/py_passdb.c:831: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:833   ../source3/passdb/py_passdb.c:836   ../source3/passdb/py_passdb.c:751   ../source3/passdb/py_passdb.c:763   ../source3/passdb/py_passdb.c:707   ../source3/passdb/py_passdb.c:710: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:712   ../source3/passdb/py_passdb.c:715   ../source3/passdb/py_passdb.c:676   ../source3/passdb/py_passdb.c:679: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:681   ../source3/passdb/py_passdb.c:684   ../source3/passdb/py_passdb.c:639   ../source3/passdb/py_passdb.c:642: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:644   ../source3/passdb/py_passdb.c:647   ../source3/passdb/py_passdb.c:589   ../source3/passdb/py_passdb.c:592: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:594   ../source3/passdb/py_passdb.c:597   ../source3/passdb/py_passdb.c:558   ../source3/passdb/py_passdb.c:561: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:563   ../source3/passdb/py_passdb.c:566   ../source3/passdb/py_passdb.c:527   ../source3/passdb/py_passdb.c:530: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:532   ../source3/passdb/py_passdb.c:535   ../source3/passdb/py_passdb.c:496   ../source3/passdb/py_passdb.c:499: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:501   ../source3/passdb/py_passdb.c:504   ../source3/passdb/py_passdb.c:465   ../source3/passdb/py_passdb.c:468: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:470   ../source3/passdb/py_passdb.c:473   ../source3/passdb/py_passdb.c:434   ../source3/passdb/py_passdb.c:437: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:439   ../source3/passdb/py_passdb.c:442   ../source3/passdb/py_passdb.c:403   ../source3/passdb/py_passdb.c:406: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:408   ../source3/passdb/py_passdb.c:411   ../source3/passdb/py_passdb.c:372   ../source3/passdb/py_passdb.c:375: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:377   ../source3/passdb/py_passdb.c:380   ../source3/passdb/py_passdb.c:341   ../source3/passdb/py_passdb.c:344: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:346   ../source3/passdb/py_passdb.c:349   ../source3/passdb/py_passdb.c:310   ../source3/passdb/py_passdb.c:313: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:315   ../source3/passdb/py_passdb.c:318   ../source3/passdb/py_passdb.c:279   ../source3/passdb/py_passdb.c:282: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:284   ../source3/passdb/py_passdb.c:287   ../source3/passdb/py_passdb.c:248   ../source3/passdb/py_passdb.c:251: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:253   ../source3/passdb/py_passdb.c:256   ../source3/passdb/py_passdb.c:262   ../source3/passdb/py_passdb.c:273   ../source3/passdb/py_passdb.c:293   ../source3/passdb/py_passdb.c:304   ../source3/passdb/py_passdb.c:324   ../source3/passdb/py_passdb.c:335   ../source3/passdb/py_passdb.c:355   ../source3/passdb/py_passdb.c:366   ../source3/passdb/py_passdb.c:386   ../source3/passdb/py_passdb.c:397   ../source3/passdb/py_passdb.c:417   ../source3/passdb/py_passdb.c:428   ../source3/passdb/py_passdb.c:448   ../source3/passdb/py_passdb.c:459   ../source3/passdb/py_passdb.c:479   ../source3/passdb/py_passdb.c:490   ../source3/passdb/py_passdb.c:510   ../source3/passdb/py_passdb.c:521   ../source3/passdb/py_passdb.c:541   ../source3/passdb/py_passdb.c:552   ../source3/passdb/py_passdb.c:572   ../source3/passdb/py_passdb.c:583   ../source3/passdb/py_passdb.c:653   ../source3/passdb/py_passdb.c:666   ../source3/passdb/py_passdb.c:670   ../source3/passdb/py_passdb.c:690   ../source3/passdb/py_passdb.c:701   ../source3/passdb/py_passdb.c:721   ../source3/passdb/py_passdb.c:732   ../source3/passdb/py_passdb.c:787   ../source3/passdb/py_passdb.c:798   ../source3/passdb/py_passdb.c:3582  ../source3/passdb/py_passdb.c:3593  ../source3/passdb/py_passdb.c:3602  ../source3/passdb/py_passdb.c:231   ../source3/passdb/py_passdb.c:242   ../source3/passdb/py_passdb.c:196   ../source3/passdb/py_passdb.c:199: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:201   ../source3/passdb/py_passdb.c:204   ../source3/passdb/py_passdb.c:171   ../source3/passdb/py_passdb.c:174: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:176   ../source3/passdb/py_passdb.c:179   ../source3/passdb/py_passdb.c:146   ../source3/passdb/py_passdb.c:149: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:151   ../source3/passdb/py_passdb.c:154   ../source3/passdb/py_passdb.c:121   ../source3/passdb/py_passdb.c:124: Expected type '%s' for '%s' of type '%s' ../source3/passdb/py_passdb.c:126   ../source3/passdb/py_passdb.c:129   ../source3/passdb/py_passdb.c:96    ../source3/passdb/py_passdb.c:99: Expected type '%s' for '%s' of type '%s'  ../source3/passdb/py_passdb.c:101   ../source3/passdb/py_passdb.c:104   ../source3/passdb/py_passdb.c:71    ../source3/passdb/py_passdb.c:74: Expected type '%s' for '%s' of type '%s'  ../source3/passdb/py_passdb.c:76    ../source3/passdb/py_passdb.c:79    ../source3/passdb/py_passdb.c:3709  ../source3/passdb/py_passdb.c:3714  ../source3/passdb/py_passdb.c:3719  ../source3/passdb/py_passdb.c:3724  SAMBA Password Database passdb  ../source3/passdb/py_passdb.c:3730  error   PDB Samu    Groupmap    samba.dcerpc.security   ../source3/passdb/py_passdb.c:3751  ../source3/passdb/py_passdb.c:3757  ../source3/passdb/py_passdb.c:3765  samba.dcerpc.misc   ../source3/passdb/py_passdb.c:3772  GUID    ../source3/passdb/py_passdb.c:3779  ../source3/passdb/py_passdb.c:3782  passdb.error    get_backends    get_backends() -> list

 		Get a list of password database backends supported.  set_smb_config  set_smb_config(path) -> None

 		Set path to smb.conf file to load configuration parameters.    set_secrets_dir set_secrets_dir(private_dir) -> None

 		Set path to private directory to load secrets database from non-default location.  get_global_sam_sid  get_global_sam_sid() -> dom_sid

 		Return domain SID.  reload_static_pdb   reload_static_pdb() -> None

 		Re-initalise the static pdb used internally.  Needed if 'passdb backend' is changed.    domain_info domain_info() -> str

 		Get domain information for the database.   getsampwnam getsampwnam(username) -> samu object

 		Get user information by name.  getsampwsid getsampwsid(user_sid) -> samu object

 		Get user information by sid (dcerpc.security.dom_sid object).  create_user create_user(username, acct_flags) -> rid

 		Create user. acct_flags are samr account control flags.    delete_user delete_user(samu object) -> None

 		Delete user.   add_sam_account add_sam_account(samu object) -> None

 		Add SAM account.   update_sam_account  update_sam_account(samu object) -> None

 		Update SAM account. delete_sam_account  delete_sam_account(samu object) -> None

 		Delete SAM account. rename_sam_account(samu object1, new_username) -> None

 		Rename SAM account.  getgrsid    getgrsid(group_sid) -> groupmap object

 		Get group information by sid (dcerpc.security.dom_sid object).   getgrgid    getgrsid(gid) -> groupmap object

 		Get group information by gid.  getgrnam    getgrsid(groupname) -> groupmap object

 		Get group information by name.   create_dom_group    create_dom_group(groupname) -> group_rid

 		Create new domain group by name.   delete_dom_group    delete_dom_group(group_rid) -> None

 		Delete domain group identified by rid   add_group_mapping_entry add_group_mapping_entry(groupmap) -> None
 		Add group mapping entry for groupmap object.   update_group_mapping_entry  update_group_mapping_entry(groupmap) -> None

 		Update group mapping entry for groupmap object.    delete_group_mapping_entry  delete_group_mapping_entry(groupmap) -> None

 		Delete group mapping entry for groupmap object.    enum_group_mapping  enum_group_mapping([domain_sid, [type, [unix_only]]]) -> List

 		Return list of group mappings as groupmap objects. Optional arguments are domain_sid object, type of group, unix only flag.   enum_group_members  enum_group_members(group_sid) -> List

 		Return list of users (dom_sid object) in group.   enum_group_memberships  enum_group_memberships(samu object) -> List

 		Return list of groups (dom_sid object) this user is part of.    add_groupmem    add_groupmem(group_rid, member_rid) -> None

 		Add user to group.  del_groupmem    del_groupmem(group_rid, member_rid) -> None

 		Remove user from from group.    create_alias    create_alias(alias_name) -> alias_rid

 		Create alias entry.   delete_alias    delete_alias(alias_sid) -> None

 		Delete alias entry. get_aliasinfo   get_aliasinfo(alias_sid) -> Mapping

 		Get alias information as a dictionary with keys - acct_name, acct_desc, rid.    set_aliasinfo   set_alias_info(alias_sid, Mapping) -> None

 		Set alias information from a dictionary with keys - acct_name, acct_desc.    add_aliasmem    add_aliasmem(alias_sid, member_sid) -> None

 		Add user to alias entry.    del_aliasmem    del_aliasmem(alias_sid, member_sid) -> None

 		Remove a user from alias entry. enum_aliasmem   enum_aliasmem(alias_sid) -> List

 		Return a list of members (dom_sid object) for alias entry. get_account_policy  get_account_policy() -> Mapping

 		Get account policy information as a dictionary. set_account_policy  get_account_policy(Mapping) -> None

 		Set account policy settings from a dicionary.   search_users    search_users(acct_flags) -> List

 		Search users. acct_flags are samr account control flags.
 		Each list entry is dictionary with keys - idx, rid, acct_flags, account_name, fullname, description.   search_groups   search_groups() -> List

 		Search unix only groups. 
 		Each list entry is dictionary with keys - idx, rid, acct_flags, account_name, fullname, description.   search_aliases([domain_sid]) -> List

 		Search aliases. domain_sid is dcerpc.security.dom_sid object.
 		Each list entry is dictionary with keys - idx, rid, acct_flags, account_name, fullname, description.  uid_to_sid  uid_to_sid(uid) -> sid

 		Return sid for given user id.    gid_to_sid  gid_to_sid(gid) -> sid

 		Return sid for given group id.   sid_to_id   sid_to_id(sid) -> Tuple

 		Return id and type for given sid.   new_rid new_rid() -> rid

 		Get a new rid. get_trusteddom_pw   get_trusteddom_pw(domain) -> Mapping

 		Get trusted domain password, sid and last set time in a dictionary.    set_trusteddom_pw   set_trusteddom_pw(domain, pwd, sid) -> None

 		Set trusted domain password.    del_trusteddom_pw   del_trusteddom_pw(domain) -> None

 		Delete trusted domain password.   enum_trusteddoms    enum_trusteddoms() -> List

 		Get list of trusted domains. Each item is a dictionary with name and sid keys    get_trusted_domain  get_trusted_domain(domain) -> Mapping

 		Get trusted domain information by name. Information is a dictionary with keys - domain_name, netbios_name, security_identifier, trust_auth_incoming, trust_auth_outgoing, trust_direction, trust_type, trust_attributes, trust_forest_trust_info. get_trusted_domain_by_sid   get_trusted_domain_by_sid(domain_sid) -> Mapping

 		Get trusted domain information by sid. Information is a dictionary with keys - domain_name, netbios_name, security_identifier, trust_auth_incoming, trust_auth_outgoing, trust_direction, trust_type, trust_attributes, trust_forest_trust_info    set_trusted_domain(domain, Mapping) -> None

 		Set trusted domain information for domain. Mapping is a dictionary with keys - domain_name, netbios_name, security_identifier, trust_auth_incoming, trust_auth_outgoing, trust_direction, trust_type, trust_attributes, trust_forest_trust_info.    del_trusted_domain  del_trusted_domain(domain) -> None

 		Delete trusted domain.   enum_trusted_domains    enum_trusted_domains() -> List

 		Get list of trusted domains. Each entry is a dictionary with keys - domain_name, netbios_name, security_identifier, trust_auth_incoming, trust_auth_outgoing, trust_direction, trust_type, trust_attributes, trust_forest_trust_info.    get_secret  get_secret(secret_name) -> Mapping

 		Get secret information for secret_name. Information is a dictionary with keys - secret_current, secret_current_lastchange, secret_old, secret_old_lastchange, sd.    set_secret  set_secret(secret_name, Mapping) -> None

 		Set secret information for secret_name using dictionary with keys - secret_current, sd.    delete_secret   delete_secret(secret_name) -> None

 		Delete secret information for secret_name.   gid sid_name_use    nt_name comment logon_time  logoff_time kickoff_time    bad_password_time   pass_last_set_time  pass_can_change_time    pass_must_change_time   username    nt_username full_name   home_dir    dir_drive   logon_script    profile_path    workstations    munged_dial user_sid    group_sid   lanman_passwd   nt_passwd   pw_history  plaintext_passwd    acct_ctrl   logon_divs  hours_len   hours   bad_password_count  logon_count country_code    code_page   passdb.PDB  PDB(url[, read_write_flags]) -> Password DB object
 passdb.Groupmap Groupmap() -> group map object
 passdb.Samu Samu() -> samu object
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      L,  +         	     	     	     	     	     	     
      
     /
     ;
     Q
     [
     
     
     |%     P     <          <       o     4
     d  
   ~           =               !     <     	               o   o  o   o  o&                                          <         %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %  %                                                   @             3                                                                      3                                 XF                             9                                                  3                                                                      3                                 E                             /                                                  P3                                                                      \3                         B                                     D                                              .      t -        H-      L ,     `                        ( c     4 | lb       `a      d 4`     p  ^       ]      D \     X   x[        Z      ` X     l  W       V      l lU       @T      D S     `  Q      D P     X        ,    P       ! N      ! d! M     t! ! L     ! " K     $" \" ~     l" "      " p# J     # # DI     # ,$ `G     <$ $      $ % (     % p% T{     % H& x     X&   u     & ' ,6     ' ( 4     ( X( 8     d( ( 7     ( ( s     ( T) 3     h) ) 2     ) * tr     (* * o     * + tm     +   Lh     - 0. TF     D. . j     . /      / 0 4e     0 1 <E     $1                 x1 T8            8  1  |          |1 h7            1 P1            1 0                                1 C            1 C            1 4C            1 B            1 B            1 PB            2 B            2 x            <. <            (2             42             @2 P            L2             X2             h2 d            P              x2             1 x            2             2 @            2 0            2             2 (  X@          2 l  ?          2   8?          2 >  l          2 >  l           3 l=  l          3 =  T;          3 ;  l          (3 :  l          43 p:  l          D3 $:  l                              A,   aeabi "   6 	
"e037a053f54ff900fce2397138a732a9a7e4f6.debug    Y .shstrtab .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rel.dyn .rel.plt .init .text .fini .rodata .eh_frame .init_array .fini_array .jcr .dynamic .got .data .bss .ARM.attributes .gnu_debuglink                                                        $                     o       L                (         d  d                0         4
  4
  ~                 8   o                      E   o       p               T   	      <  <  	               ]   	   B   !  !                f         |%  |%                    a         %  %                  l         $+  $+  ,                 r         P  P                    x      2   X  X  z                         3 3                            < <                           < <                           < <                            < < X                        = =                           @  @  	                           I  I                        p         I -                                -I 4                                aI                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           /*
 * This is <linux/capability.h>
 *
 * Andrew G. Morgan <morgan@kernel.org>
 * Alexander Kjeldaas <astor@guardian.no>
 * with help from Aleph1, Roland Buresund and Andrew Main.
 *
 * See here for the libcap library ("POSIX draft" compliance):
 *
 * ftp://www.kernel.org/pub/linux/libs/security/linux-privs/kernel-2.6/
 */
#ifndef _LINUX_CAPABILITY_H
#define _LINUX_CAPABILITY_H

#include <uapi/linux/capability.h>


#define _KERNEL_CAPABILITY_VERSION _LINUX_CAPABILITY_VERSION_3
#define _KERNEL_CAPABILITY_U32S    _LINUX_CAPABILITY_U32S_3

extern int file_caps_enabled;

typedef struct kernel_cap_struct {
	__u32 cap[_KERNEL_CAPABILITY_U32S];
} kernel_cap_t;

/* exact same as vfs_cap_data but in cpu endian and always filled completely */
struct cpu_vfs_cap_data {
	__u32 magic_etc;
	kernel_cap_t permitted;
	kernel_cap_t inheritable;
};

#define _USER_CAP_HEADER_SIZE  (sizeof(struct __user_cap_header_struct))
#define _KERNEL_CAP_T_SIZE     (sizeof(kernel_cap_t))


struct file;
struct inode;
struct dentry;
struct task_struct;
struct user_namespace;

extern const kernel_cap_t __cap_empty_set;
extern const kernel_cap_t __cap_init_eff_set;

/*
 * Internal kernel functions only
 */

#define CAP_FOR_EACH_U32(__capi)  \
	for (__capi = 0; __capi < _KERNEL_CAPABILITY_U32S; ++__capi)

/*
 * CAP_FS_MASK and CAP_NFSD_MASKS:
 *
 * The fs mask is all the privileges that fsuid==0 historically meant.
 * At one time in the past, that included CAP_MKNOD and CAP_LINUX_IMMUTABLE.
 *
 * It has never meant setting security.* and trusted.* xattrs.
 *
 * We could also define fsmask as follows:
 *   1. CAP_FS_MASK is the privilege to bypass all fs-related DAC permissions
 *   2. The security.* and trusted.* xattrs are fs-related MAC permissions
 */

# define CAP_FS_MASK_B0     (CAP_TO_MASK(CAP_CHOWN)		\
			    | CAP_TO_MASK(CAP_MKNOD)		\
			    | CAP_TO_MASK(CAP_DAC_OVERRIDE)	\
			    | CAP_TO_MASK(CAP_DAC_READ_SEARCH)	\
			    | CAP_TO_MASK(CAP_FOWNER)		\
			    | CAP_TO_MASK(CAP_FSETID))

# define CAP_FS_MASK_B1     (CAP_TO_MASK(CAP_MAC_OVERRIDE))

#if _KERNEL_CAPABILITY_U32S != 2
# error Fix up hand-coded capability macro initializers
#else /* HAND-CODED capability initializers */

#define CAP_LAST_U32			((_KERNEL_CAPABILITY_U32S) - 1)
#define CAP_LAST_U32_VALID_MASK		(CAP_TO_MASK(CAP_LAST_CAP + 1) -1)

# define CAP_EMPTY_SET    ((kernel_cap_t){{ 0, 0 }})
# define CAP_FULL_SET     ((kernel_cap_t){{ ~0, CAP_LAST_U32_VALID_MASK }})
# define CAP_FS_SET       ((kernel_cap_t){{ CAP_FS_MASK_B0 \
				    | CAP_TO_MASK(CAP_LINUX_IMMUTABLE), \
				    CAP_FS_MASK_B1 } })
# define CAP_NFSD_SET     ((kernel_cap_t){{ CAP_FS_MASK_B0 \
				    | CAP_TO_MASK(CAP_SYS_RESOURCE), \
				    CAP_FS_MASK_B1 } })

#endif /* _KERNEL_CAPABILITY_U32S != 2 */

# define cap_clear(c)         do { (c) = __cap_empty_set; } while (0)

#define cap_raise(c, flag)  ((c).cap[CAP_TO_INDEX(flag)] |= CAP_TO_MASK(flag))
#define cap_lower(c, flag)  ((c).cap[CAP_TO_INDEX(flag)] &= ~CAP_TO_MASK(flag))
#define cap_raised(c, flag) ((c).cap[CAP_TO_INDEX(flag)] & CAP_TO_MASK(flag))

#define CAP_BOP_ALL(c, a, b, OP)                                    \
do {                                                                \
	unsigned __capi;                                            \
	CAP_FOR_EACH_U32(__capi) {                                  \
		c.cap[__capi] = a.cap[__capi] OP b.cap[__capi];     \
	}                                                           \
} while (0)

#define CAP_UOP_ALL(c, a, OP)                                       \
do {                                                                \
	unsigned __capi;                                            \
	CAP_FOR_EACH_U32(__capi) {                                  \
		c.cap[__capi] = OP a.cap[__capi];                   \
	}                                                           \
} while (0)

static inline kernel_cap_t cap_combine(const kernel_cap_t a,
				       const kernel_cap_t b)
{
	kernel_cap_t dest;
	CAP_BOP_ALL(dest, a, b, |);
	return dest;
}

static inline kernel_cap_t cap_intersect(const kernel_cap_t a,
					 const kernel_cap_t b)
{
	kernel_cap_t dest;
	CAP_BOP_ALL(dest, a, b, &);
	return dest;
}

static inline kernel_cap_t cap_drop(const kernel_cap_t a,
				    const kernel_cap_t drop)
{
	kernel_cap_t dest;
	CAP_BOP_ALL(dest, a, drop, &~);
	return dest;
}

static inline kernel_cap_t cap_invert(const kernel_cap_t c)
{
	kernel_cap_t dest;
	CAP_UOP_ALL(dest, c, ~);
	return dest;
}

static inline bool cap_isclear(const kernel_cap_t a)
{
	unsigned __capi;
	CAP_FOR_EACH_U32(__capi) {
		if (a.cap[__capi] != 0)
			return false;
	}
	return true;
}

/*
 * Check if "a" is a subset of "set".
 * return true if ALL of the capabilities in "a" are also in "set"
 *	cap_issubset(0101, 1111) will return true
 * return false if ANY of the capabilities in "a" are not in "set"
 *	cap_issubset(1111, 0101) will return false
 */
static inline bool cap_issubset(const kernel_cap_t a, const kernel_cap_t set)
{
	kernel_cap_t dest;
	dest = cap_drop(a, set);
	return cap_isclear(dest);
}

/* Used to decide between falling back on the old suser() or fsuser(). */

static inline kernel_cap_t cap_drop_fs_set(const kernel_cap_t a)
{
	const kernel_cap_t __cap_fs_set = CAP_FS_SET;
	return cap_drop(a, __cap_fs_set);
}

static inline kernel_cap_t cap_raise_fs_set(const kernel_cap_t a,
					    const kernel_cap_t permitted)
{
	const kernel_cap_t __cap_fs_set = CAP_FS_SET;
	return cap_combine(a,
			   cap_intersect(permitted, __cap_fs_set));
}

static inline kernel_cap_t cap_drop_nfsd_set(const kernel_cap_t a)
{
	const kernel_cap_t __cap_fs_set = CAP_NFSD_SET;
	return cap_drop(a, __cap_fs_set);
}

static inline kernel_cap_t cap_raise_nfsd_set(const kernel_cap_t a,
					      const kernel_cap_t permitted)
{
	const kernel_cap_t __cap_nfsd_set = CAP_NFSD_SET;
	return cap_combine(a,
			   cap_intersect(permitted, __cap_nfsd_set));
}

#ifdef CONFIG_MULTIUSER
extern bool has_capability(struct task_struct *t, int cap);
extern bool has_ns_capability(struct task_struct *t,
			      struct user_namespace *ns, int cap);
extern bool has_capability_noaudit(struct task_struct *t, int cap);
extern bool has_ns_capability_noaudit(struct task_struct *t,
				      struct user_namespace *ns, int cap);
extern bool capable(int cap);
extern bool ns_capable(struct user_namespace *ns, int cap);
extern bool ns_capable_noaudit(struct user_namespace *ns, int cap);
#else
static inline bool has_capability(struct task_struct *t, int cap)
{
	return true;
}
static inline bool has_ns_capability(struct task_struct *t,
			      struct user_namespace *ns, int cap)
{
	return true;
}
static inline bool has_capability_noaudit(struct task_struct *t, int cap)
{
	return true;
}
static inline bool has_ns_capability_noaudit(struct task_struct *t,
				      struct user_namespace *ns, int cap)
{
	return true;
}
static inline bool capable(int cap)
{
	return true;
}
static inline bool ns_capable(struct user_namespace *ns, int cap)
{
	return true;
}
static inline bool ns_capable_noaudit(struct user_namespace *ns, int cap)
{
	return true;
}
#endif /* CONFIG_MULTIUSER */
extern bool privileged_wrt_inode_uidgid(struct user_namespace *ns, const struct inode *inode);
extern bool capable_wrt_inode_uidgid(const struct inode *inode, int cap);
extern bool file_ns_capable(const struct file *file, struct user_namespace *ns, int cap);
extern bool ptracer_capable(struct task_struct *tsk, struct user_namespace *ns);

/* audit system wants to get cap info from files as well */
extern int get_vfs_caps_from_disk(const struct dentry *dentry, struct cpu_vfs_cap_data *cpu_caps);

#endif /* !_LINUX_CAPABILITY_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         /*
 * IEEE 802.2 User Interface SAPs for Linux, data structures and indicators.
 *
 * Copyright (c) 2001 by Jay Schulist <jschlst@samba.org>
 *
 * This program can be redistributed or modified under the terms of the
 * GNU General Public License as published by the Free Software Foundation.
 * This program is distributed without any warranty or implied warranty
 * of merchantability or fitness for a particular purpose.
 *
 * See the GNU General Public License for more details.
 */
#ifndef __LINUX_LLC_H
#define __LINUX_LLC_H

#include <uapi/linux/llc.h>

#define LLC_SAP_DYN_START	0xC0
#define LLC_SAP_DYN_STOP	0xDE
#define LLC_SAP_DYN_TRIES	4

#define llc_ui_skb_cb(__skb) ((struct sockaddr_llc *)&((__skb)->cb[0]))
#endif /* __LINUX_LLC_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /*
 * INET		An implementation of the TCP/IP protocol suite for the LINUX
 *		operating system.  INET is implemented using the  BSD Socket
 *		interface as the means of communication with the user level.
 *
 *		Definitions for the ICMP protocol.
 *
 * Version:	@(#)icmp.h	1.0.3	04/28/93
 *
 * Author:	Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
 *
 *		This program is free software; you can redistribute it and/or
 *		modify it under the terms of the GNU General Public License
 *		as published by the Free Software Foundation; either version
 *		2 of the License, or (at your option) any later version.
 */
#ifndef _LINUX_ICMP_H
#define	_LINUX_ICMP_H

#include <linux/skbuff.h>
#include <uapi/linux/icmp.h>

static inline struct icmphdr *icmp_hdr(const struct sk_buff *skb)
{
	return (struct icmphdr *)skb_transport_header(skb);
}
#endif	/* _LINUX_ICMP_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /*
 * mv643xx.h - MV-643XX Internal registers definition file.
 *
 * Copyright 2002 Momentum Computer, Inc.
 * 	Author: Matthew Dharm <mdharm@momenco.com>
 * Copyright 2002 GALILEO TECHNOLOGY, LTD. 
 *
 * This program is free software; you can redistribute  it and/or modify it
 * under  the terms of  the GNU General  Public License as published by the
 * Free Software Foundation;  either version 2 of the  License, or (at your
 * option) any later version.
 */
#ifndef __ASM_MV643XX_H
#define __ASM_MV643XX_H

#include <asm/types.h>
#include <linux/mv643xx_eth.h>
#include <linux/mv643xx_i2c.h>

/****************************************/
/* Processor Address Space              */
/****************************************/

/* DDR SDRAM BAR and size registers */

#define MV64340_CS_0_BASE_ADDR                                      0x008
#define MV64340_CS_0_SIZE                                           0x010
#define MV64340_CS_1_BASE_ADDR                                      0x208
#define MV64340_CS_1_SIZE                                           0x210
#define MV64340_CS_2_BASE_ADDR                                      0x018
#define MV64340_CS_2_SIZE                                           0x020
#define MV64340_CS_3_BASE_ADDR                                      0x218
#define MV64340_CS_3_SIZE                                           0x220

/* Devices BAR and size registers */

#define MV64340_DEV_CS0_BASE_ADDR                                   0x028
#define MV64340_DEV_CS0_SIZE                                        0x030
#define MV64340_DEV_CS1_BASE_ADDR                                   0x228
#define MV64340_DEV_CS1_SIZE                                        0x230
#define MV64340_DEV_CS2_BASE_ADDR                                   0x248
#define MV64340_DEV_CS2_SIZE                                        0x250
#define MV64340_DEV_CS3_BASE_ADDR                                   0x038
#define MV64340_DEV_CS3_SIZE                                        0x040
#define MV64340_BOOTCS_BASE_ADDR                                    0x238
#define MV64340_BOOTCS_SIZE                                         0x240

/* PCI 0 BAR and size registers */

#define MV64340_PCI_0_IO_BASE_ADDR                                  0x048
#define MV64340_PCI_0_IO_SIZE                                       0x050
#define MV64340_PCI_0_MEMORY0_BASE_ADDR                             0x058
#define MV64340_PCI_0_MEMORY0_SIZE                                  0x060
#define MV64340_PCI_0_MEMORY1_BASE_ADDR                             0x080
#define MV64340_PCI_0_MEMORY1_SIZE                                  0x088
#define MV64340_PCI_0_MEMORY2_BASE_ADDR                             0x258
#define MV64340_PCI_0_MEMORY2_SIZE                                  0x260
#define MV64340_PCI_0_MEMORY3_BASE_ADDR                             0x280
#define MV64340_PCI_0_MEMORY3_SIZE                                  0x288

/* PCI 1 BAR and size registers */
#define MV64340_PCI_1_IO_BASE_ADDR                                  0x090
#define MV64340_PCI_1_IO_SIZE                                       0x098
#define MV64340_PCI_1_MEMORY0_BASE_ADDR                             0x0a0
#define MV64340_PCI_1_MEMORY0_SIZE                                  0x0a8
#define MV64340_PCI_1_MEMORY1_BASE_ADDR                             0x0b0
#define MV64340_PCI_1_MEMORY1_SIZE                                  0x0b8
#define MV64340_PCI_1_MEMORY2_BASE_ADDR                             0x2a0
#define MV64340_PCI_1_MEMORY2_SIZE                                  0x2a8
#define MV64340_PCI_1_MEMORY3_BASE_ADDR                             0x2b0
#define MV64340_PCI_1_MEMORY3_SIZE                                  0x2b8

/* SRAM base address */
#define MV64340_INTEGRATED_SRAM_BASE_ADDR                           0x268

/* internal registers space base address */
#define MV64340_INTERNAL_SPACE_BASE_ADDR                            0x068

/* Enables the CS , DEV_CS , PCI 0 and PCI 1 
   windows above */
#define MV64340_BASE_ADDR_ENABLE                                    0x278

/****************************************/
/* PCI remap registers                  */
/****************************************/
      /* PCI 0 */
#define MV64340_PCI_0_IO_ADDR_REMAP                                 0x0f0
#define MV64340_PCI_0_MEMORY0_LOW_ADDR_REMAP                        0x0f8
#define MV64340_PCI_0_MEMORY0_HIGH_ADDR_REMAP                       0x320
#define MV64340_PCI_0_MEMORY1_LOW_ADDR_REMAP                        0x100
#define MV64340_PCI_0_MEMORY1_HIGH_ADDR_REMAP                       0x328
#define MV64340_PCI_0_MEMORY2_LOW_ADDR_REMAP                        0x2f8
#define MV64340_PCI_0_MEMORY2_HIGH_ADDR_REMAP                       0x330
#define MV64340_PCI_0_MEMORY3_LOW_ADDR_REMAP                        0x300
#define MV64340_PCI_0_MEMORY3_HIGH_ADDR_REMAP                       0x338
      /* PCI 1 */
#define MV64340_PCI_1_IO_ADDR_REMAP                                 0x108
#define MV64340_PCI_1_MEMORY0_LOW_ADDR_REMAP                        0x110
#define MV64340_PCI_1_MEMORY0_HIGH_ADDR_REMAP                       0x340
#define MV64340_PCI_1_MEMORY1_LOW_ADDR_REMAP                        0x118
#define MV64340_PCI_1_MEMORY1_HIGH_ADDR_REMAP                       0x348
#define MV64340_PCI_1_MEMORY2_LOW_ADDR_REMAP                        0x310
#define MV64340_PCI_1_MEMORY2_HIGH_ADDR_REMAP                       0x350
#define MV64340_PCI_1_MEMORY3_LOW_ADDR_REMAP                        0x318
#define MV64340_PCI_1_MEMORY3_HIGH_ADDR_REMAP                       0x358
 
#define MV64340_CPU_PCI_0_HEADERS_RETARGET_CONTROL                  0x3b0
#define MV64340_CPU_PCI_0_HEADERS_RETARGET_BASE                     0x3b8
#define MV64340_CPU_PCI_1_HEADERS_RETARGET_CONTROL                  0x3c0
#define MV64340_CPU_PCI_1_HEADERS_RETARGET_BASE                     0x3c8
#define MV64340_CPU_GE_HEADERS_RETARGET_CONTROL                     0x3d0
#define MV64340_CPU_GE_HEADERS_RETARGET_BASE                        0x3d8
#define MV64340_CPU_IDMA_HEADERS_RETARGET_CONTROL                   0x3e0
#define MV64340_CPU_IDMA_HEADERS_RETARGET_BASE                      0x3e8

/****************************************/
/*         CPU Control Registers        */
/****************************************/

#define MV64340_CPU_CONFIG                                          0x000
#define MV64340_CPU_MODE                                            0x120
#define MV64340_CPU_MASTER_CONTROL                                  0x160
#define MV64340_CPU_CROSS_BAR_CONTROL_LOW                           0x150
#define MV64340_CPU_CROSS_BAR_CONTROL_HIGH                          0x158
#define MV64340_CPU_CROSS_BAR_TIMEOUT                               0x168

/****************************************/
/* SMP RegisterS                        */
/****************************************/

#define MV64340_SMP_WHO_AM_I                                        0x200
#define MV64340_SMP_CPU0_DOORBELL                                   0x214
#define MV64340_SMP_CPU0_DOORBELL_CLEAR                             0x21C
#define MV64340_SMP_CPU1_DOORBELL                                   0x224
#define MV64340_SMP_CPU1_DOORBELL_CLEAR                             0x22C
#define MV64340_SMP_CPU0_DOORBELL_MASK                              0x234
#define MV64340_SMP_CPU1_DOORBELL_MASK                              0x23C
#define MV64340_SMP_SEMAPHOR0                                       0x244
#define MV64340_SMP_SEMAPHOR1                                       0x24c
#define MV64340_SMP_SEMAPHOR2                                       0x254
#define MV64340_SMP_SEMAPHOR3                                       0x25c
#define MV64340_SMP_SEMAPHOR4                                       0x264
#define MV64340_SMP_SEMAPHOR5                                       0x26c
#define MV64340_SMP_SEMAPHOR6                                       0x274
#define MV64340_SMP_SEMAPHOR7                                       0x27c

/****************************************/
/*  CPU Sync Barrier Register           */
/****************************************/

#define MV64340_CPU_0_SYNC_BARRIER_TRIGGER                          0x0c0
#define MV64340_CPU_0_SYNC_BARRIER_VIRTUAL                          0x0c8
#define MV64340_CPU_1_SYNC_BARRIER_TRIGGER                          0x0d0
#define MV64340_CPU_1_SYNC_BARRIER_VIRTUAL                          0x0d8

/****************************************/
/* CPU Access Protect                   */
/****************************************/

#define MV64340_CPU_PROTECT_WINDOW_0_BASE_ADDR                      0x180
#define MV64340_CPU_PROTECT_WINDOW_0_SIZE                           0x188
#define MV64340_CPU_PROTECT_WINDOW_1_BASE_ADDR                      0x190
#define MV64340_CPU_PROTECT_WINDOW_1_SIZE                           0x198
#define MV64340_CPU_PROTECT_WINDOW_2_BASE_ADDR                      0x1a0
#define MV64340_CPU_PROTECT_WINDOW_2_SIZE                           0x1a8
#define MV64340_CPU_PROTECT_WINDOW_3_BASE_ADDR                      0x1b0
#define MV64340_CPU_PROTECT_WINDOW_3_SIZE                           0x1b8


/****************************************/
/*          CPU Error Report            */
/****************************************/

#define MV64340_CPU_ERROR_ADDR_LOW                                  0x070
#define MV64340_CPU_ERROR_ADDR_HIGH                                 0x078
#define MV64340_CPU_ERROR_DATA_LOW                                  0x128
#define MV64340_CPU_ERROR_DATA_HIGH                                 0x130
#define MV64340_CPU_ERROR_PARITY                                    0x138
#define MV64340_CPU_ERROR_CAUSE                                     0x140
#define MV64340_CPU_ERROR_MASK                                      0x148

/****************************************/
/*      CPU Interface Debug Registers 	*/
/****************************************/

#define MV64340_PUNIT_SLAVE_DEBUG_LOW                               0x360
#define MV64340_PUNIT_SLAVE_DEBUG_HIGH                              0x368
#define MV64340_PUNIT_MASTER_DEBUG_LOW                              0x370
#define MV64340_PUNIT_MASTER_DEBUG_HIGH                             0x378
#define MV64340_PUNIT_MMASK                                         0x3e4

/****************************************/
/*  Integrated SRAM Registers           */
/****************************************/

#define MV64340_SRAM_CONFIG                                         0x380
#define MV64340_SRAM_TEST_MODE                                      0X3F4
#define MV64340_SRAM_ERROR_CAUSE                                    0x388
#define MV64340_SRAM_ERROR_ADDR                                     0x390
#define MV64340_SRAM_ERROR_ADDR_HIGH                                0X3F8
#define MV64340_SRAM_ERROR_DATA_LOW                                 0x398
#define MV64340_SRAM_ERROR_DATA_HIGH                                0x3a0
#define MV64340_SRAM_ERROR_DATA_PARITY                              0x3a8

/****************************************/
/* SDRAM Configuration                  */
/****************************************/

#define MV64340_SDRAM_CONFIG                                        0x1400
#define MV64340_D_UNIT_CONTROL_LOW                                  0x1404
#define MV64340_D_UNIT_CONTROL_HIGH                                 0x1424
#define MV64340_SDRAM_TIMING_CONTROL_LOW                            0x1408
#define MV64340_SDRAM_TIMING_CONTROL_HIGH                           0x140c
#define MV64340_SDRAM_ADDR_CONTROL                                  0x1410
#define MV64340_SDRAM_OPEN_PAGES_CONTROL                            0x1414
#define MV64340_SDRAM_OPERATION                                     0x1418
#define MV64340_SDRAM_MODE                                          0x141c
#define MV64340_EXTENDED_DRAM_MODE                                  0x1420
#define MV64340_SDRAM_CROSS_BAR_CONTROL_LOW                         0x1430
#define MV64340_SDRAM_CROSS_BAR_CONTROL_HIGH                        0x1434
#define MV64340_SDRAM_CROSS_BAR_TIMEOUT                             0x1438
#define MV64340_SDRAM_ADDR_CTRL_PADS_CALIBRATION                    0x14c0
#define MV64340_SDRAM_DATA_PADS_CALIBRATION                         0x14c4

/****************************************/
/* SDRAM Error Report                   */
/****************************************/

#define MV64340_SDRAM_ERROR_DATA_LOW                                0x1444
#define MV64340_SDRAM_ERROR_DATA_HIGH                               0x1440
#define MV64340_SDRAM_ERROR_ADDR                                    0x1450
#define MV64340_SDRAM_RECEIVED_ECC                                  0x1448
#define MV64340_SDRAM_CALCULATED_ECC                                0x144c
#define MV64340_SDRAM_ECC_CONTROL                                   0x1454
#define MV64340_SDRAM_ECC_ERROR_COUNTER                             0x1458

/******************************************/
/*  Controlled Delay Line (CDL) Registers */
/******************************************/

#define MV64340_DFCDL_CONFIG0                                       0x1480
#define MV64340_DFCDL_CONFIG1                                       0x1484
#define MV64340_DLL_WRITE                                           0x1488
#define MV64340_DLL_READ                                            0x148c
#define MV64340_SRAM_ADDR                                           0x1490
#define MV64340_SRAM_DATA0                                          0x1494
#define MV64340_SRAM_DATA1                                          0x1498
#define MV64340_SRAM_DATA2                                          0x149c
#define MV64340_DFCL_PROBE                                          0x14a0

/******************************************/
/*   Debug Registers                      */
/******************************************/

#define MV64340_DUNIT_DEBUG_LOW                                     0x1460
#define MV64340_DUNIT_DEBUG_HIGH                                    0x1464
#define MV64340_DUNIT_MMASK                                         0X1b40

/****************************************/
/* Device Parameters			*/
/****************************************/

#define MV64340_DEVICE_BANK0_PARAMETERS				    0x45c
#define MV64340_DEVICE_BANK1_PARAMETERS				    0x460
#define MV64340_DEVICE_BANK2_PARAMETERS				    0x464
#define MV64340_DEVICE_BANK3_PARAMETERS				    0x468
#define MV64340_DEVICE_BOOT_BANK_PARAMETERS			    0x46c
#define MV64340_DEVICE_INTERFACE_CONTROL                            0x4c0
#define MV64340_DEVICE_INTERFACE_CROSS_BAR_CONTROL_LOW              0x4c8
#define MV64340_DEVICE_INTERFACE_CROSS_BAR_CONTROL_HIGH             0x4cc
#define MV64340_DEVICE_INTERFACE_CROSS_BAR_TIMEOUT                  0x4c4

/****************************************/
/* Device interrupt registers		*/
/****************************************/

#define MV64340_DEVICE_INTERRUPT_CAUSE				    0x4d0
#define MV64340_DEVICE_INTERRUPT_MASK				    0x4d4
#define MV64340_DEVICE_ERROR_ADDR				    0x4d8
#define MV64340_DEVICE_ERROR_DATA   				    0x4dc
#define MV64340_DEVICE_ERROR_PARITY     			    0x4e0

/****************************************/
/* Device debug registers   		*/
/****************************************/

#define MV64340_DEVICE_DEBUG_LOW     				    0x4e4
#define MV64340_DEVICE_DEBUG_HIGH     				    0x4e8
#define MV64340_RUNIT_MMASK                                         0x4f0

/****************************************/
/* PCI Slave Address Decoding registers */
/****************************************/

#define MV64340_PCI_0_CS_0_BANK_SIZE                                0xc08
#define MV64340_PCI_1_CS_0_BANK_SIZE                                0xc88
#define MV64340_PCI_0_CS_1_BANK_SIZE                                0xd08
#define MV64340_PCI_1_CS_1_BANK_SIZE                                0xd88
#define MV64340_PCI_0_CS_2_BANK_SIZE                                0xc0c
#define MV64340_PCI_1_CS_2_BANK_SIZE                                0xc8c
#define MV64340_PCI_0_CS_3_BANK_SIZE                                0xd0c
#define MV64340_PCI_1_CS_3_BANK_SIZE                                0xd8c
#define MV64340_PCI_0_DEVCS_0_BANK_SIZE                             0xc10
#define MV64340_PCI_1_DEVCS_0_BANK_SIZE                             0xc90
#define MV64340_PCI_0_DEVCS_1_BANK_SIZE                             0xd10
#define MV64340_PCI_1_DEVCS_1_BANK_SIZE                             0xd90
#define MV64340_PCI_0_DEVCS_2_BANK_SIZE                             0xd18
#define MV64340_PCI_1_DEVCS_2_BANK_SIZE                             0xd98
#define MV64340_PCI_0_DEVCS_3_BANK_SIZE                             0xc14
#define MV64340_PCI_1_DEVCS_3_BANK_SIZE                             0xc94
#define MV64340_PCI_0_DEVCS_BOOT_BANK_SIZE                          0xd14
#define MV64340_PCI_1_DEVCS_BOOT_BANK_SIZE                          0xd94
#define MV64340_PCI_0_P2P_MEM0_BAR_SIZE                             0xd1c
#define MV64340_PCI_1_P2P_MEM0_BAR_SIZE                             0xd9c
#define MV64340_PCI_0_P2P_MEM1_BAR_SIZE                             0xd20
#define MV64340_PCI_1_P2P_MEM1_BAR_SIZE                             0xda0
#define MV64340_PCI_0_P2P_I_O_BAR_SIZE                              0xd24
#define MV64340_PCI_1_P2P_I_O_BAR_SIZE                              0xda4
#define MV64340_PCI_0_CPU_BAR_SIZE                                  0xd28
#define MV64340_PCI_1_CPU_BAR_SIZE                                  0xda8
#define MV64340_PCI_0_INTERNAL_SRAM_BAR_SIZE                        0xe00
#define MV64340_PCI_1_INTERNAL_SRAM_BAR_SIZE                        0xe80
#define MV64340_PCI_0_EXPANSION_ROM_BAR_SIZE                        0xd2c
#define MV64340_PCI_1_EXPANSION_ROM_BAR_SIZE                        0xd9c
#define MV64340_PCI_0_BASE_ADDR_REG_ENABLE                          0xc3c
#define MV64340_PCI_1_BASE_ADDR_REG_ENABLE                          0xcbc
#define MV64340_PCI_0_CS_0_BASE_ADDR_REMAP			    0xc48
#define MV64340_PCI_1_CS_0_BASE_ADDR_REMAP			    0xcc8
#define MV64340_PCI_0_CS_1_BASE_ADDR_REMAP			    0xd48
#define MV64340_PCI_1_CS_1_BASE_ADDR_REMAP			    0xdc8
#define MV64340_PCI_0_CS_2_BASE_ADDR_REMAP			    0xc4c
#define MV64340_PCI_1_CS_2_BASE_ADDR_REMAP			    0xccc
#define MV64340_PCI_0_CS_3_BASE_ADDR_REMAP			    0xd4c
#define MV64340_PCI_1_CS_3_BASE_ADDR_REMAP			    0xdcc
#define MV64340_PCI_0_CS_0_BASE_HIGH_ADDR_REMAP			    0xF04
#define MV64340_PCI_1_CS_0_BASE_HIGH_ADDR_REMAP			    0xF84
#define MV64340_PCI_0_CS_1_BASE_HIGH_ADDR_REMAP			    0xF08
#define MV64340_PCI_1_CS_1_BASE_HIGH_ADDR_REMAP			    0xF88
#define MV64340_PCI_0_CS_2_BASE_HIGH_ADDR_REMAP			    0xF0C
#define MV64340_PCI_1_CS_2_BASE_HIGH_ADDR_REMAP			    0xF8C
#define MV64340_PCI_0_CS_3_BASE_HIGH_ADDR_REMAP			    0xF10
#define MV64340_PCI_1_CS_3_BASE_HIGH_ADDR_REMAP			    0xF90
#define MV64340_PCI_0_DEVCS_0_BASE_ADDR_REMAP			    0xc50
#define MV64340_PCI_1_DEVCS_0_BASE_ADDR_REMAP			    0xcd0
#define MV64340_PCI_0_DEVCS_1_BASE_ADDR_REMAP			    0xd50
#define MV64340_PCI_1_DEVCS_1_BASE_ADDR_REMAP			    0xdd0
#define MV64340_PCI_0_DEVCS_2_BASE_ADDR_REMAP			    0xd58
#define MV64340_PCI_1_DEVCS_2_BASE_ADDR_REMAP			    0xdd8
#define MV64340_PCI_0_DEVCS_3_BASE_ADDR_REMAP           	    0xc54
#define MV64340_PCI_1_DEVCS_3_BASE_ADDR_REMAP           	    0xcd4
#define MV64340_PCI_0_DEVCS_BOOTCS_BASE_ADDR_REMAP      	    0xd54
#define MV64340_PCI_1_DEVCS_BOOTCS_BASE_ADDR_REMAP      	    0xdd4
#define MV64340_PCI_0_P2P_MEM0_BASE_ADDR_REMAP_LOW                  0xd5c
#define MV64340_PCI_1_P2P_MEM0_BASE_ADDR_REMAP_LOW                  0xddc
#define MV64340_PCI_0_P2P_MEM0_BASE_ADDR_REMAP_HIGH                 0xd60
#define MV64340_PCI_1_P2P_MEM0_BASE_ADDR_REMAP_HIGH                 0xde0
#define MV64340_PCI_0_P2P_MEM1_BASE_ADDR_REMAP_LOW                  0xd64
#define MV64340_PCI_1_P2P_MEM1_BASE_ADDR_REMAP_LOW                  0xde4
#define MV64340_PCI_0_P2P_MEM1_BASE_ADDR_REMAP_HIGH                 0xd68
#define MV64340_PCI_1_P2P_MEM1_BASE_ADDR_REMAP_HIGH                 0xde8
#define MV64340_PCI_0_P2P_I_O_BASE_ADDR_REMAP                       0xd6c
#define MV64340_PCI_1_P2P_I_O_BASE_ADDR_REMAP                       0xdec 
#define MV64340_PCI_0_CPU_BASE_ADDR_REMAP_LOW                       0xd70
#define MV64340_PCI_1_CPU_BASE_ADDR_REMAP_LOW                       0xdf0
#define MV64340_PCI_0_CPU_BASE_ADDR_REMAP_HIGH                      0xd74
#define MV64340_PCI_1_CPU_BASE_ADDR_REMAP_HIGH                      0xdf4
#define MV64340_PCI_0_INTEGRATED_SRAM_BASE_ADDR_REMAP               0xf00
#define MV64340_PCI_1_INTEGRATED_SRAM_BASE_ADDR_REMAP               0xf80
#define MV64340_PCI_0_EXPANSION_ROM_BASE_ADDR_REMAP                 0xf38
#define MV64340_PCI_1_EXPANSION_ROM_BASE_ADDR_REMAP                 0xfb8
#define MV64340_PCI_0_ADDR_DECODE_CONTROL                           0xd3c
#define MV64340_PCI_1_ADDR_DECODE_CONTROL                           0xdbc
#define MV64340_PCI_0_HEADERS_RETARGET_CONTROL                      0xF40
#define MV64340_PCI_1_HEADERS_RETARGET_CONTROL                      0xFc0
#define MV64340_PCI_0_HEADERS_RETARGET_BASE                         0xF44
#define MV64340_PCI_1_HEADERS_RETARGET_BASE                         0xFc4
#define MV64340_PCI_0_HEADERS_RETARGET_HIGH                         0xF48
#define MV64340_PCI_1_HEADERS_RETARGET_HIGH                         0xFc8

/***********************************/
/*   PCI Control Register Map      */
/***********************************/

#define MV64340_PCI_0_DLL_STATUS_AND_COMMAND                        0x1d20
#define MV64340_PCI_1_DLL_STATUS_AND_COMMAND                        0x1da0
#define MV64340_PCI_0_MPP_PADS_DRIVE_CONTROL                        0x1d1C
#define MV64340_PCI_1_MPP_PADS_DRIVE_CONTROL                        0x1d9C
#define MV64340_PCI_0_COMMAND			         	    0xc00
#define MV64340_PCI_1_COMMAND					    0xc80
#define MV64340_PCI_0_MODE                                          0xd00
#define MV64340_PCI_1_MODE                                          0xd80
#define MV64340_PCI_0_RETRY	        	 		    0xc04
#define MV64340_PCI_1_RETRY				            0xc84
#define MV64340_PCI_0_READ_BUFFER_DISCARD_TIMER                     0xd04
#define MV64340_PCI_1_READ_BUFFER_DISCARD_TIMER                     0xd84
#define MV64340_PCI_0_MSI_TRIGGER_TIMER                             0xc38
#define MV64340_PCI_1_MSI_TRIGGER_TIMER                             0xcb8
#define MV64340_PCI_0_ARBITER_CONTROL                               0x1d00
#define MV64340_PCI_1_ARBITER_CONTROL                               0x1d80
#define MV64340_PCI_0_CROSS_BAR_CONTROL_LOW                         0x1d08
#define MV64340_PCI_1_CROSS_BAR_CONTROL_LOW                         0x1d88
#define MV64340_PCI_0_CROSS_BAR_CONTROL_HIGH                        0x1d0c
#define MV64340_PCI_1_CROSS_BAR_CONTROL_HIGH                        0x1d8c
#define MV64340_PCI_0_CROSS_BAR_TIMEOUT                             0x1d04
#define MV64340_PCI_1_CROSS_BAR_TIMEOUT                             0x1d84
#define MV64340_PCI_0_SYNC_BARRIER_TRIGGER_REG                      0x1D18
#define MV64340_PCI_1_SYNC_BARRIER_TRIGGER_REG                      0x1D98
#define MV64340_PCI_0_SYNC_BARRIER_VIRTUAL_REG                      0x1d10
#define MV64340_PCI_1_SYNC_BARRIER_VIRTUAL_REG                      0x1d90
#define MV64340_PCI_0_P2P_CONFIG                                    0x1d14
#define MV64340_PCI_1_P2P_CONFIG                                    0x1d94

#define MV64340_PCI_0_ACCESS_CONTROL_BASE_0_LOW                     0x1e00
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_0_HIGH                    0x1e04
#define MV64340_PCI_0_ACCESS_CONTROL_SIZE_0                         0x1e08
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_1_LOW                     0x1e10
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_1_HIGH                    0x1e14
#define MV64340_PCI_0_ACCESS_CONTROL_SIZE_1                         0x1e18
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_2_LOW                     0x1e20
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_2_HIGH                    0x1e24
#define MV64340_PCI_0_ACCESS_CONTROL_SIZE_2                         0x1e28
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_3_LOW                     0x1e30
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_3_HIGH                    0x1e34
#define MV64340_PCI_0_ACCESS_CONTROL_SIZE_3                         0x1e38
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_4_LOW                     0x1e40
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_4_HIGH                    0x1e44
#define MV64340_PCI_0_ACCESS_CONTROL_SIZE_4                         0x1e48
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_5_LOW                     0x1e50
#define MV64340_PCI_0_ACCESS_CONTROL_BASE_5_HIGH                    0x1e54
#define MV64340_PCI_0_ACCESS_CONTROL_SIZE_5                         0x1e58

#define MV64340_PCI_1_ACCESS_CONTROL_BASE_0_LOW                     0x1e80
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_0_HIGH                    0x1e84
#define MV64340_PCI_1_ACCESS_CONTROL_SIZE_0                         0x1e88
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_1_LOW                     0x1e90
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_1_HIGH                    0x1e94
#define MV64340_PCI_1_ACCESS_CONTROL_SIZE_1                         0x1e98
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_2_LOW                     0x1ea0
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_2_HIGH                    0x1ea4
#define MV64340_PCI_1_ACCESS_CONTROL_SIZE_2                         0x1ea8
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_3_LOW                     0x1eb0
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_3_HIGH                    0x1eb4
#define MV64340_PCI_1_ACCESS_CONTROL_SIZE_3                         0x1eb8
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_4_LOW                     0x1ec0
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_4_HIGH                    0x1ec4
#define MV64340_PCI_1_ACCESS_CONTROL_SIZE_4                         0x1ec8
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_5_LOW                     0x1ed0
#define MV64340_PCI_1_ACCESS_CONTROL_BASE_5_HIGH                    0x1ed4
#define MV64340_PCI_1_ACCESS_CONTROL_SIZE_5                         0x1ed8

/****************************************/
/*   PCI Configuration Access Registers */
/****************************************/

#define MV64340_PCI_0_CONFIG_ADDR 				    0xcf8
#define MV64340_PCI_0_CONFIG_DATA_VIRTUAL_REG                       0xcfc
#define MV64340_PCI_1_CONFIG_ADDR 				    0xc78
#define MV64340_PCI_1_CONFIG_DATA_VIRTUAL_REG                       0xc7c
#define MV64340_PCI_0_INTERRUPT_ACKNOWLEDGE_VIRTUAL_REG	            0xc34
#define MV64340_PCI_1_INTERRUPT_ACKNOWLEDGE_VIRTUAL_REG	            0xcb4

/****************************************/
/*   PCI Error Report Registers         */
/****************************************/

#define MV64340_PCI_0_SERR_MASK					    0xc28
#define MV64340_PCI_1_SERR_MASK					    0xca8
#define MV64340_PCI_0_ERROR_ADDR_LOW                                0x1d40
#define MV64340_PCI_1_ERROR_ADDR_LOW                                0x1dc0
#define MV64340_PCI_0_ERROR_ADDR_HIGH                               0x1d44
#define MV64340_PCI_1_ERROR_ADDR_HIGH                               0x1dc4
#define MV64340_PCI_0_ERROR_ATTRIBUTE                               0x1d48
#define MV64340_PCI_1_ERROR_ATTRIBUTE                               0x1dc8
#define MV64340_PCI_0_ERROR_COMMAND                                 0x1d50
#define MV64340_PCI_1_ERROR_COMMAND                                 0x1dd0
#define MV64340_PCI_0_ERROR_CAUSE                                   0x1d58
#define MV64340_PCI_1_ERROR_CAUSE                                   0x1dd8
#define MV64340_PCI_0_ERROR_MASK                                    0x1d5c
#define MV64340_PCI_1_ERROR_MASK                                    0x1ddc

/****************************************/
/*   PCI Debug Registers                */
/****************************************/

#define MV64340_PCI_0_MMASK                                         0X1D24
#define MV64340_PCI_1_MMASK                                         0X1DA4

/*********************************************/
/* PCI Configuration, Function 0, Registers  */
/*********************************************/

#define MV64340_PCI_DEVICE_AND_VENDOR_ID 			    0x000
#define MV64340_PCI_STATUS_AND_COMMAND				    0x004
#define MV64340_PCI_CLASS_CODE_AND_REVISION_ID			    0x008
#define MV64340_PCI_BIST_HEADER_TYPE_LATENCY_TIMER_CACHE_LINE 	    0x00C

#define MV64340_PCI_SCS_0_BASE_ADDR_LOW   	      		    0x010
#define MV64340_PCI_SCS_0_BASE_ADDR_HIGH   		            0x014
#define MV64340_PCI_SCS_1_BASE_ADDR_LOW  	     	            0x018
#define MV64340_PCI_SCS_1_BASE_ADDR_HIGH 		            0x01C
#define MV64340_PCI_INTERNAL_REG_MEM_MAPPED_BASE_ADDR_LOW      	    0x020
#define MV64340_PCI_INTERNAL_REG_MEM_MAPPED_BASE_ADDR_HIGH     	    0x024
#define MV64340_PCI_SUBSYSTEM_ID_AND_SUBSYSTEM_VENDOR_ID	    0x02c
#define MV64340_PCI_EXPANSION_ROM_BASE_ADDR_REG	                    0x030
#define MV64340_PCI_CAPABILTY_LIST_POINTER                          0x034
#define MV64340_PCI_INTERRUPT_PIN_AND_LINE 			    0x03C
       /* capability list */
#define MV64340_PCI_POWER_MANAGEMENT_CAPABILITY                     0x040
#define MV64340_PCI_POWER_MANAGEMENT_STATUS_AND_CONTROL             0x044
#define MV64340_PCI_VPD_ADDR                                        0x048
#define MV64340_PCI_VPD_DATA                                        0x04c
#define MV64340_PCI_MSI_MESSAGE_CONTROL                             0x050
#define MV64340_PCI_MSI_MESSAGE_ADDR                                0x054
#define MV64340_PCI_MSI_MESSAGE_UPPER_ADDR                          0x058
#define MV64340_PCI_MSI_MESSAGE_DATA                                0x05c
#define MV64340_PCI_X_COMMAND                                       0x060
#define MV64340_PCI_X_STATUS                                        0x064
#define MV64340_PCI_COMPACT_PCI_HOT_SWAP                            0x068

/***********************************************/
/*   PCI Configuration, Function 1, Registers  */
/***********************************************/

#define MV64340_PCI_SCS_2_BASE_ADDR_LOW   			    0x110
#define MV64340_PCI_SCS_2_BASE_ADDR_HIGH			    0x114
#define MV64340_PCI_SCS_3_BASE_ADDR_LOW 			    0x118
#define MV64340_PCI_SCS_3_BASE_ADDR_HIGH			    0x11c
#define MV64340_PCI_INTERNAL_SRAM_BASE_ADDR_LOW          	    0x120
#define MV64340_PCI_INTERNAL_SRAM_BASE_ADDR_HIGH         	    0x124

/***********************************************/
/*  PCI Configuration, Function 2, Registers   */
/***********************************************/

#define MV64340_PCI_DEVCS_0_BASE_ADDR_LOW	    		    0x210
#define MV64340_PCI_DEVCS_0_BASE_ADDR_HIGH 			    0x214
#define MV64340_PCI_DEVCS_1_BASE_ADDR_LOW 			    0x218
#define MV64340_PCI_DEVCS_1_BASE_ADDR_HIGH      		    0x21c
#define MV64340_PCI_DEVCS_2_BASE_ADDR_LOW 			    0x220
#define MV64340_PCI_DEVCS_2_BASE_ADDR_HIGH      		    0x224

/***********************************************/
/*  PCI Configuration, Function 3, Registers   */
/***********************************************/

#define MV64340_PCI_DEVCS_3_BASE_ADDR_LOW	    		    0x310
#define MV64340_PCI_DEVCS_3_BASE_ADDR_HIGH 			    0x314
#define MV64340_PCI_BOOT_CS_BASE_ADDR_LOW			    0x318
#define MV64340_PCI_BOOT_CS_BASE_ADDR_HIGH      		    0x31c
#define MV64340_PCI_CPU_BASE_ADDR_LOW 				    0x220
#define MV64340_PCI_CPU_BASE_ADDR_HIGH      			    0x224

/***********************************************/
/*  PCI Configuration, Function 4, Registers   */
/***********************************************/

#define MV64340_PCI_P2P_MEM0_BASE_ADDR_LOW  			    0x410
#define MV64340_PCI_P2P_MEM0_BASE_ADDR_HIGH 			    0x414
#define MV64340_PCI_P2P_MEM1_BASE_ADDR_LOW   			    0x418
#define MV64340_PCI_P2P_MEM1_BASE_ADDR_HIGH 			    0x41c
#define MV64340_PCI_P2P_I_O_BASE_ADDR                 	            0x420
#define MV64340_PCI_INTERNAL_REGS_I_O_MAPPED_BASE_ADDR              0x424

/****************************************/
/* Messaging Unit Registers (I20)   	*/
/****************************************/

#define MV64340_I2O_INBOUND_MESSAGE_REG0_PCI_0_SIDE		    0x010
#define MV64340_I2O_INBOUND_MESSAGE_REG1_PCI_0_SIDE  		    0x014
#define MV64340_I2O_OUTBOUND_MESSAGE_REG0_PCI_0_SIDE 		    0x018
#define MV64340_I2O_OUTBOUND_MESSAGE_REG1_PCI_0_SIDE  		    0x01C
#define MV64340_I2O_INBOUND_DOORBELL_REG_PCI_0_SIDE  		    0x020
#define MV64340_I2O_INBOUND_INTERRUPT_CAUSE_REG_PCI_0_SIDE          0x024
#define MV64340_I2O_INBOUND_INTERRUPT_MASK_REG_PCI_0_SIDE	    0x028
#define MV64340_I2O_OUTBOUND_DOORBELL_REG_PCI_0_SIDE 		    0x02C
#define MV64340_I2O_OUTBOUND_INTERRUPT_CAUSE_REG_PCI_0_SIDE         0x030
#define MV64340_I2O_OUTBOUND_INTERRUPT_MASK_REG_PCI_0_SIDE          0x034
#define MV64340_I2O_INBOUND_QUEUE_PORT_VIRTUAL_REG_PCI_0_SIDE       0x040
#define MV64340_I2O_OUTBOUND_QUEUE_PORT_VIRTUAL_REG_PCI_0_SIDE      0x044
#define MV64340_I2O_QUEUE_CONTROL_REG_PCI_0_SIDE 		    0x050
#define MV64340_I2O_QUEUE_BASE_ADDR_REG_PCI_0_SIDE 		    0x054
#define MV64340_I2O_INBOUND_FREE_HEAD_POINTER_REG_PCI_0_SIDE        0x060
#define MV64340_I2O_INBOUND_FREE_TAIL_POINTER_REG_PCI_0_SIDE        0x064
#define MV64340_I2O_INBOUND_POST_HEAD_POINTER_REG_PCI_0_SIDE        0x068
#define MV64340_I2O_INBOUND_POST_TAIL_POINTER_REG_PCI_0_SIDE        0x06C
#define MV64340_I2O_OUTBOUND_FREE_HEAD_POINTER_REG_PCI_0_SIDE       0x070
#define MV64340_I2O_OUTBOUND_FREE_TAIL_POINTER_REG_PCI_0_SIDE       0x074
#define MV64340_I2O_OUTBOUND_POST_HEAD_POINTER_REG_PCI_0_SIDE       0x0F8
#define MV64340_I2O_OUTBOUND_POST_TAIL_POINTER_REG_PCI_0_SIDE       0x0FC

#define MV64340_I2O_INBOUND_MESSAGE_REG0_PCI_1_SIDE		    0x090
#define MV64340_I2O_INBOUND_MESSAGE_REG1_PCI_1_SIDE  		    0x094
#define MV64340_I2O_OUTBOUND_MESSAGE_REG0_PCI_1_SIDE 		    0x098
#define MV64340_I2O_OUTBOUND_MESSAGE_REG1_PCI_1_SIDE  		    0x09C
#define MV64340_I2O_INBOUND_DOORBELL_REG_PCI_1_SIDE  		    0x0A0
#define MV64340_I2O_INBOUND_INTERRUPT_CAUSE_REG_PCI_1_SIDE          0x0A4
#define MV64340_I2O_INBOUND_INTERRUPT_MASK_REG_PCI_1_SIDE	    0x0A8
#define MV64340_I2O_OUTBOUND_DOORBELL_REG_PCI_1_SIDE 		    0x0AC
#define MV64340_I2O_OUTBOUND_INTERRUPT_CAUSE_REG_PCI_1_SIDE         0x0B0
#define MV64340_I2O_OUTBOUND_INTERRUPT_MASK_REG_PCI_1_SIDE          0x0B4
#define MV64340_I2O_INBOUND_QUEUE_PORT_VIRTUAL_REG_PCI_1_SIDE       0x0C0
#define MV64340_I2O_OUTBOUND_QUEUE_PORT_VIRTUAL_REG_PCI_1_SIDE      0x0C4
#define MV64340_I2O_QUEUE_CONTROL_REG_PCI_1_SIDE 		    0x0D0
#define MV64340_I2O_QUEUE_BASE_ADDR_REG_PCI_1_SIDE 		    0x0D4
#define MV64340_I2O_INBOUND_FREE_HEAD_POINTER_REG_PCI_1_SIDE        0x0E0
#define MV64340_I2O_INBOUND_FREE_TAIL_POINTER_REG_PCI_1_SIDE        0x0E4
#define MV64340_I2O_INBOUND_POST_HEAD_POINTER_REG_PCI_1_SIDE        0x0E8
#define MV64340_I2O_INBOUND_POST_TAIL_POINTER_REG_PCI_1_SIDE        0x0EC
#define MV64340_I2O_OUTBOUND_FREE_HEAD_POINTER_REG_PCI_1_SIDE       0x0F0
#define MV64340_I2O_OUTBOUND_FREE_TAIL_POINTER_REG_PCI_1_SIDE       0x0F4
#define MV64340_I2O_OUTBOUND_POST_HEAD_POINTER_REG_PCI_1_SIDE       0x078
#define MV64340_I2O_OUTBOUND_POST_TAIL_POINTER_REG_PCI_1_SIDE       0x07C

#define MV64340_I2O_INBOUND_MESSAGE_REG0_CPU0_SIDE		    0x1C10
#define MV64340_I2O_INBOUND_MESSAGE_REG1_CPU0_SIDE  		    0x1C14
#define MV64340_I2O_OUTBOUND_MESSAGE_REG0_CPU0_SIDE 		    0x1C18
#define MV64340_I2O_OUTBOUND_MESSAGE_REG1_CPU0_SIDE  		    0x1C1C
#define MV64340_I2O_INBOUND_DOORBELL_REG_CPU0_SIDE  		    0x1C20
#define MV64340_I2O_INBOUND_INTERRUPT_CAUSE_REG_CPU0_SIDE  	    0x1C24
#define MV64340_I2O_INBOUND_INTERRUPT_MASK_REG_CPU0_SIDE	    0x1C28
#define MV64340_I2O_OUTBOUND_DOORBELL_REG_CPU0_SIDE 		    0x1C2C
#define MV64340_I2O_OUTBOUND_INTERRUPT_CAUSE_REG_CPU0_SIDE          0x1C30
#define MV64340_I2O_OUTBOUND_INTERRUPT_MASK_REG_CPU0_SIDE           0x1C34
#define MV64340_I2O_INBOUND_QUEUE_PORT_VIRTUAL_REG_CPU0_SIDE        0x1C40
#define MV64340_I2O_OUTBOUND_QUEUE_PORT_VIRTUAL_REG_CPU0_SIDE       0x1C44
#define MV64340_I2O_QUEUE_CONTROL_REG_CPU0_SIDE 		    0x1C50
#define MV64340_I2O_QUEUE_BASE_ADDR_REG_CPU0_SIDE 		    0x1C54
#define MV64340_I2O_INBOUND_FREE_HEAD_POINTER_REG_CPU0_SIDE         0x1C60
#define MV64340_I2O_INBOUND_FREE_TAIL_POINTER_REG_CPU0_SIDE         0x1C64
#define MV64340_I2O_INBOUND_POST_HEAD_POINTER_REG_CPU0_SIDE         0x1C68
#define MV64340_I2O_INBOUND_POST_TAIL_POINTER_REG_CPU0_SIDE         0x1C6C
#define MV64340_I2O_OUTBOUND_FREE_HEAD_POINTER_REG_CPU0_SIDE        0x1C70
#define MV64340_I2O_OUTBOUND_FREE_TAIL_POINTER_REG_CPU0_SIDE        0x1C74
#define MV64340_I2O_OUTBOUND_POST_HEAD_POINTER_REG_CPU0_SIDE        0x1CF8
#define MV64340_I2O_OUTBOUND_POST_TAIL_POINTER_REG_CPU0_SIDE        0x1CFC
#define MV64340_I2O_INBOUND_MESSAGE_REG0_CPU1_SIDE		    0x1C90
#define MV64340_I2O_INBOUND_MESSAGE_REG1_CPU1_SIDE  		    0x1C94
#define MV64340_I2O_OUTBOUND_MESSAGE_REG0_CPU1_SIDE 		    0x1C98
#define MV64340_I2O_OUTBOUND_MESSAGE_REG1_CPU1_SIDE  		    0x1C9C
#define MV64340_I2O_INBOUND_DOORBELL_REG_CPU1_SIDE  		    0x1CA0
#define MV64340_I2O_INBOUND_INTERRUPT_CAUSE_REG_CPU1_SIDE  	    0x1CA4
#define MV64340_I2O_INBOUND_INTERRUPT_MASK_REG_CPU1_SIDE	    0x1CA8
#define MV64340_I2O_OUTBOUND_DOORBELL_REG_CPU1_SIDE 		    0x1CAC
#define MV64340_I2O_OUTBOUND_INTERRUPT_CAUSE_REG_CPU1_SIDE          0x1CB0
#define MV64340_I2O_OUTBOUND_INTERRUPT_MASK_REG_CPU1_SIDE           0x1CB4
#define MV64340_I2O_INBOUND_QUEUE_PORT_VIRTUAL_REG_CPU1_SIDE        0x1CC0
#define MV64340_I2O_OUTBOUND_QUEUE_PORT_VIRTUAL_REG_CPU1_SIDE       0x1CC4
#define MV64340_I2O_QUEUE_CONTROL_REG_CPU1_SIDE 		    0x1CD0
#define MV64340_I2O_QUEUE_BASE_ADDR_REG_CPU1_SIDE 		    0x1CD4
#define MV64340_I2O_INBOUND_FREE_HEAD_POINTER_REG_CPU1_SIDE         0x1CE0
#define MV64340_I2O_INBOUND_FREE_TAIL_POINTER_REG_CPU1_SIDE         0x1CE4
#define MV64340_I2O_INBOUND_POST_HEAD_POINTER_REG_CPU1_SIDE         0x1CE8
#define MV64340_I2O_INBOUND_POST_TAIL_POINTER_REG_CPU1_SIDE         0x1CEC
#define MV64340_I2O_OUTBOUND_FREE_HEAD_POINTER_REG_CPU1_SIDE        0x1CF0
#define MV64340_I2O_OUTBOUND_FREE_TAIL_POINTER_REG_CPU1_SIDE        0x1CF4
#define MV64340_I2O_OUTBOUND_POST_HEAD_POINTER_REG_CPU1_SIDE        0x1C78
#define MV64340_I2O_OUTBOUND_POST_TAIL_POINTER_REG_CPU1_SIDE        0x1C7C

/****************************************/
/*        Ethernet Unit Registers  		*/
/****************************************/

/*******************************************/
/*          CUNIT  Registers               */
/*******************************************/

         /* Address Decoding Register Map */
           
#define MV64340_CUNIT_BASE_ADDR_REG0                                0xf200
#define MV64340_CUNIT_BASE_ADDR_REG1                                0xf208
#define MV64340_CUNIT_BASE_ADDR_REG2                                0xf210
#define MV64340_CUNIT_BASE_ADDR_REG3                                0xf218
#define MV64340_CUNIT_SIZE0                                         0xf204
#define MV64340_CUNIT_SIZE1                                         0xf20c
#define MV64340_CUNIT_SIZE2                                         0xf214
#define MV64340_CUNIT_SIZE3                                         0xf21c
#define MV64340_CUNIT_HIGH_ADDR_REMAP_REG0                          0xf240
#define MV64340_CUNIT_HIGH_ADDR_REMAP_REG1                          0xf244
#define MV64340_CUNIT_BASE_ADDR_ENABLE_REG                          0xf250
#define MV64340_MPSC0_ACCESS_PROTECTION_REG                         0xf254
#define MV64340_MPSC1_ACCESS_PROTECTION_REG                         0xf258
#define MV64340_CUNIT_INTERNAL_SPACE_BASE_ADDR_REG                  0xf25C

        /*  Error Report Registers  */

#define MV64340_CUNIT_INTERRUPT_CAUSE_REG                           0xf310
#define MV64340_CUNIT_INTERRUPT_MASK_REG                            0xf314
#define MV64340_CUNIT_ERROR_ADDR                                    0xf318

        /*  Cunit Control Registers */

#define MV64340_CUNIT_ARBITER_CONTROL_REG                           0xf300
#define MV64340_CUNIT_CONFIG_REG                                    0xb40c
#define MV64340_CUNIT_CRROSBAR_TIMEOUT_REG                          0xf304

        /*  Cunit Debug Registers   */

#define MV64340_CUNIT_DEBUG_LOW                                     0xf340
#define MV64340_CUNIT_DEBUG_HIGH                                    0xf344
#define MV64340_CUNIT_MMASK                                         0xf380

        /*  MPSCs Clocks Routing Registers  */

#define MV64340_MPSC_ROUTING_REG                                    0xb400
#define MV64340_MPSC_RX_CLOCK_ROUTING_REG                           0xb404
#define MV64340_MPSC_TX_CLOCK_ROUTING_REG                           0xb408

        /*  MPSCs Interrupts Registers    */

#define MV64340_MPSC_CAUSE_REG(port)                               (0xb804 + (port<<3))
#define MV64340_MPSC_MASK_REG(port)                                (0xb884 + (port<<3))
 
#define MV64340_MPSC_MAIN_CONFIG_LOW(port)                         (0x8000 + (port<<12))
#define MV64340_MPSC_MAIN_CONFIG_HIGH(port)                        (0x8004 + (port<<12))    
#define MV64340_MPSC_PROTOCOL_CONFIG(port)                         (0x8008 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG1(port)                            (0x800c + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG2(port)                            (0x8010 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG3(port)                            (0x8014 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG4(port)                            (0x8018 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG5(port)                            (0x801c + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG6(port)                            (0x8020 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG7(port)                            (0x8024 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG8(port)                            (0x8028 + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG9(port)                            (0x802c + (port<<12))    
#define MV64340_MPSC_CHANNEL_REG10(port)                           (0x8030 + (port<<12))    
        
        /*  MPSC0 Registers      */


/***************************************/
/*          SDMA Registers             */
/***************************************/

#define MV64340_SDMA_CONFIG_REG(channel)                        (0x4000 + (channel<<13))        
#define MV64340_SDMA_COMMAND_REG(channel)                       (0x4008 + (channel<<13))        
#define MV64340_SDMA_CURRENT_RX_DESCRIPTOR_POINTER(channel)     (0x4810 + (channel<<13))        
#define MV64340_SDMA_CURRENT_TX_DESCRIPTOR_POINTER(channel)     (0x4c10 + (channel<<13))        
#define MV64340_SDMA_FIRST_TX_DESCRIPTOR_POINTER(channel)       (0x4c14 + (channel<<13)) 

#define MV64340_SDMA_CAUSE_REG                                      0xb800
#define MV64340_SDMA_MASK_REG                                       0xb880
         
/* BRG Interrupts */

#define MV64340_BRG_CONFIG_REG(brg)                              (0xb200 + (brg<<3))
#define MV64340_BRG_BAUDE_TUNING_REG(brg)                        (0xb208 + (brg<<3))
#define MV64340_BRG_CAUSE_REG                                       0xb834
#define MV64340_BRG_MASK_REG                                        0xb8b4

/****************************************/
/* DMA Channel Control			*/
/****************************************/

#define MV64340_DMA_CHANNEL0_CONTROL 				    0x840
#define MV64340_DMA_CHANNEL0_CONTROL_HIGH			    0x880
#define MV64340_DMA_CHANNEL1_CONTROL 				    0x844
#define MV64340_DMA_CHANNEL1_CONTROL_HIGH			    0x884
#define MV64340_DMA_CHANNEL2_CONTROL 				    0x848
#define MV64340_DMA_CHANNEL2_CONTROL_HIGH			    0x888
#define MV64340_DMA_CHANNEL3_CONTROL 				    0x84C
#define MV64340_DMA_CHANNEL3_CONTROL_HIGH			    0x88C


/****************************************/
/*           IDMA Registers             */
/****************************************/

#define MV64340_DMA_CHANNEL0_BYTE_COUNT                             0x800
#define MV64340_DMA_CHANNEL1_BYTE_COUNT                             0x804
#define MV64340_DMA_CHANNEL2_BYTE_COUNT                             0x808
#define MV64340_DMA_CHANNEL3_BYTE_COUNT                             0x80C
#define MV64340_DMA_CHANNEL0_SOURCE_ADDR                            0x810
#define MV64340_DMA_CHANNEL1_SOURCE_ADDR                            0x814
#define MV64340_DMA_CHANNEL2_SOURCE_ADDR                            0x818
#define MV64340_DMA_CHANNEL3_SOURCE_ADDR                            0x81c
#define MV64340_DMA_CHANNEL0_DESTINATION_ADDR                       0x820
#define MV64340_DMA_CHANNEL1_DESTINATION_ADDR                       0x824
#define MV64340_DMA_CHANNEL2_DESTINATION_ADDR                       0x828
#define MV64340_DMA_CHANNEL3_DESTINATION_ADDR                       0x82C
#define MV64340_DMA_CHANNEL0_NEXT_DESCRIPTOR_POINTER                0x830
#define MV64340_DMA_CHANNEL1_NEXT_DESCRIPTOR_POINTER                0x834
#define MV64340_DMA_CHANNEL2_NEXT_DESCRIPTOR_POINTER                0x838
#define MV64340_DMA_CHANNEL3_NEXT_DESCRIPTOR_POINTER                0x83C
#define MV64340_DMA_CHANNEL0_CURRENT_DESCRIPTOR_POINTER             0x870
#define MV64340_DMA_CHANNEL1_CURRENT_DESCRIPTOR_POINTER             0x874
#define MV64340_DMA_CHANNEL2_CURRENT_DESCRIPTOR_POINTER             0x878
#define MV64340_DMA_CHANNEL3_CURRENT_DESCRIPTOR_POINTER             0x87C

 /*  IDMA Address Decoding Base Address Registers  */
 
#define MV64340_DMA_BASE_ADDR_REG0                                  0xa00
#define MV64340_DMA_BASE_ADDR_REG1                                  0xa08
#define MV64340_DMA_BASE_ADDR_REG2                                  0xa10
#define MV64340_DMA_BASE_ADDR_REG3                                  0xa18
#define MV64340_DMA_BASE_ADDR_REG4                                  0xa20
#define MV64340_DMA_BASE_ADDR_REG5                                  0xa28
#define MV64340_DMA_BASE_ADDR_REG6                                  0xa30
#define MV64340_DMA_BASE_ADDR_REG7                                  0xa38
 
 /*  IDMA Address Decoding Size Address Register   */
 
#define MV64340_DMA_SIZE_REG0                                       0xa04
#define MV64340_DMA_SIZE_REG1                                       0xa0c
#define MV64340_DMA_SIZE_REG2                                       0xa14
#define MV64340_DMA_SIZE_REG3                                       0xa1c
#define MV64340_DMA_SIZE_REG4                                       0xa24
#define MV64340_DMA_SIZE_REG5                                       0xa2c
#define MV64340_DMA_SIZE_REG6                                       0xa34
#define MV64340_DMA_SIZE_REG7                                       0xa3C

 /* IDMA Address Decoding High Address Remap and Access 
                  Protection Registers                    */
                  
#define MV64340_DMA_HIGH_ADDR_REMAP_REG0                            0xa60
#define MV64340_DMA_HIGH_ADDR_REMAP_REG1                            0xa64
#define MV64340_DMA_HIGH_ADDR_REMAP_REG2                            0xa68
#define MV64340_DMA_HIGH_ADDR_REMAP_REG3                            0xa6C
#define MV64340_DMA_BASE_ADDR_ENABLE_REG                            0xa80
#define MV64340_DMA_CHANNEL0_ACCESS_PROTECTION_REG                  0xa70
#define MV64340_DMA_CHANNEL1_ACCESS_PROTECTION_REG                  0xa74
#define MV64340_DMA_CHANNEL2_ACCESS_PROTECTION_REG                  0xa78
#define MV64340_DMA_CHANNEL3_ACCESS_PROTECTION_REG                  0xa7c
#define MV64340_DMA_ARBITER_CONTROL                                 0x860
#define MV64340_DMA_CROSS_BAR_TIMEOUT                               0x8d0

 /*  IDMA Headers Retarget Registers   */

#define MV64340_DMA_HEADERS_RETARGET_CONTROL                        0xa84
#define MV64340_DMA_HEADERS_RETARGET_BASE                           0xa88

 /*  IDMA Interrupt Register  */

#define MV64340_DMA_INTERRUPT_CAUSE_REG                             0x8c0
#define MV64340_DMA_INTERRUPT_CAUSE_MASK                            0x8c4
#define MV64340_DMA_ERROR_ADDR                                      0x8c8
#define MV64340_DMA_ERROR_SELECT                                    0x8cc

 /*  IDMA Debug Register ( for internal use )    */

#define MV64340_DMA_DEBUG_LOW                                       0x8e0
#define MV64340_DMA_DEBUG_HIGH                                      0x8e4
#define MV64340_DMA_SPARE                                           0xA8C

/****************************************/
/* Timer_Counter 			*/
/****************************************/

#define MV64340_TIMER_COUNTER0					    0x850
#define MV64340_TIMER_COUNTER1					    0x854
#define MV64340_TIMER_COUNTER2					    0x858
#define MV64340_TIMER_COUNTER3					    0x85C
#define MV64340_TIMER_COUNTER_0_3_CONTROL			    0x864
#define MV64340_TIMER_COUNTER_0_3_INTERRUPT_CAUSE		    0x868
#define MV64340_TIMER_COUNTER_0_3_INTERRUPT_MASK      		    0x86c

/****************************************/
/*         Watchdog registers  	        */
/****************************************/

#define MV64340_WATCHDOG_CONFIG_REG                                 0xb410
#define MV64340_WATCHDOG_VALUE_REG                                  0xb414

/****************************************/
/* I2C Registers                        */
/****************************************/

#define MV64XXX_I2C_OFFSET                                          0xc000
#define MV64XXX_I2C_REG_BLOCK_SIZE                                  0x0020

/****************************************/
/* GPP Interface Registers              */
/****************************************/

#define MV64340_GPP_IO_CONTROL                                      0xf100
#define MV64340_GPP_LEVEL_CONTROL                                   0xf110
#define MV64340_GPP_VALUE                                           0xf104
#define MV64340_GPP_INTERRUPT_CAUSE                                 0xf108
#define MV64340_GPP_INTERRUPT_MASK0                                 0xf10c
#define MV64340_GPP_INTERRUPT_MASK1                                 0xf114
#define MV64340_GPP_VALUE_SET                                       0xf118
#define MV64340_GPP_VALUE_CLEAR                                     0xf11c

/****************************************/
/* Interrupt Controller Registers       */
/****************************************/

/****************************************/
/* Interrupts	  			*/
/****************************************/

#define MV64340_MAIN_INTERRUPT_CAUSE_LOW                            0x004
#define MV64340_MAIN_INTERRUPT_CAUSE_HIGH                           0x00c
#define MV64340_CPU_INTERRUPT0_MASK_LOW                             0x014
#define MV64340_CPU_INTERRUPT0_MASK_HIGH                            0x01c
#define MV64340_CPU_INTERRUPT0_SELECT_CAUSE                         0x024
#define MV64340_CPU_INTERRUPT1_MASK_LOW                             0x034
#define MV64340_CPU_INTERRUPT1_MASK_HIGH                            0x03c
#define MV64340_CPU_INTERRUPT1_SELECT_CAUSE                         0x044
#define MV64340_INTERRUPT0_MASK_0_LOW                               0x054
#define MV64340_INTERRUPT0_MASK_0_HIGH                              0x05c
#define MV64340_INTERRUPT0_SELECT_CAUSE                             0x064
#define MV64340_INTERRUPT1_MASK_0_LOW                               0x074
#define MV64340_INTERRUPT1_MASK_0_HIGH                              0x07c
#define MV64340_INTERRUPT1_SELECT_CAUSE                             0x084

/****************************************/
/*      MPP Interface Registers         */
/****************************************/

#define MV64340_MPP_CONTROL0                                        0xf000
#define MV64340_MPP_CONTROL1                                        0xf004
#define MV64340_MPP_CONTROL2                                        0xf008
#define MV64340_MPP_CONTROL3                                        0xf00c

/****************************************/
/*    Serial Initialization registers   */
/****************************************/

#define MV64340_SERIAL_INIT_LAST_DATA                               0xf324
#define MV64340_SERIAL_INIT_CONTROL                                 0xf328
#define MV64340_SERIAL_INIT_STATUS                                  0xf32c

extern void mv64340_irq_init(unsigned int base);

/* MPSC Platform Device, Driver Data (Shared register regions) */
#define	MPSC_SHARED_NAME		"mpsc_shared"

#define	MPSC_ROUTING_BASE_ORDER		0
#define	MPSC_SDMA_INTR_BASE_ORDER	1

#define MPSC_ROUTING_REG_BLOCK_SIZE	0x000c
#define MPSC_SDMA_INTR_REG_BLOCK_SIZE	0x0084

struct mpsc_shared_pdata {
	u32	mrr_val;
	u32	rcrr_val;
	u32	tcrr_val;
	u32	intr_cause_val;
	u32	intr_mask_val;
};

/* MPSC Platform Device, Driver Data */
#define	MPSC_CTLR_NAME			"mpsc"

#define	MPSC_BASE_ORDER			0
#define	MPSC_SDMA_BASE_ORDER		1
#define	MPSC_BRG_BASE_ORDER		2

#define MPSC_REG_BLOCK_SIZE		0x0038
#define MPSC_SDMA_REG_BLOCK_SIZE	0x0c18
#define MPSC_BRG_REG_BLOCK_SIZE		0x0008

struct mpsc_pdata {
	u8	mirror_regs;
	u8	cache_mgmt;
	u8	max_idle;
	int	default_baud;
	int	default_bits;
	int	default_parity;
	int	default_flow;
	u32	chr_1_val;
	u32	chr_2_val;
	u32	chr_10_val;
	u32	mpcr_val;
	u32	bcr_val;
	u8	brg_can_tune;
	u8	brg_clk_src;
	u32	brg_clk_freq;
};

/* Watchdog Platform Device, Driver Data */
#define	MV64x60_WDT_NAME			"mv64x60_wdt"

struct mv64x60_wdt_pdata {
	int	timeout;	/* watchdog expiry in seconds, default 10 */
	int	bus_clk;	/* bus clock in MHz, default 133 */
};

#endif /* __ASM_MV643XX_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       #ifndef _INET_DIAG_H_
#define _INET_DIAG_H_ 1

#include <uapi/linux/inet_diag.h>

struct net;
struct sock;
struct inet_hashinfo;
struct nlattr;
struct nlmsghdr;
struct sk_buff;
struct netlink_callback;

struct inet_diag_handler {
	void		(*dump)(struct sk_buff *skb,
				struct netlink_callback *cb,
				const struct inet_diag_req_v2 *r,
				struct nlattr *bc);

	int		(*dump_one)(struct sk_buff *in_skb,
				    const struct nlmsghdr *nlh,
				    const struct inet_diag_req_v2 *req);

	void		(*idiag_get_info)(struct sock *sk,
					  struct inet_diag_msg *r,
					  void *info);

	int		(*destroy)(struct sk_buff *in_skb,
				   const struct inet_diag_req_v2 *req);

	__u16		idiag_type;
	__u16		idiag_info_size;
};

struct inet_connection_sock;
int inet_sk_diag_fill(struct sock *sk, struct inet_connection_sock *icsk,
		      struct sk_buff *skb, const struct inet_diag_req_v2 *req,
		      struct user_namespace *user_ns,
		      u32 pid, u32 seq, u16 nlmsg_flags,
		      const struct nlmsghdr *unlh, bool net_admin);
void inet_diag_dump_icsk(struct inet_hashinfo *h, struct sk_buff *skb,
			 struct netlink_callback *cb,
			 const struct inet_diag_req_v2 *r,
			 struct nlattr *bc);
int inet_diag_dump_one_icsk(struct inet_hashinfo *hashinfo,
			    struct sk_buff *in_skb, const struct nlmsghdr *nlh,
			    const struct inet_diag_req_v2 *req);

struct sock *inet_diag_find_one_icsk(struct net *net,
				     struct inet_hashinfo *hashinfo,
				     const struct inet_diag_req_v2 *req);

int inet_diag_bc_sk(const struct nlattr *_bc, struct sock *sk);

void inet_diag_msg_common_fill(struct inet_diag_msg *r, struct sock *sk);

int inet_diag_msg_attrs_fill(struct sock *sk, struct sk_buff *skb,
			     struct inet_diag_msg *r, int ext,
			     struct user_namespace *user_ns, bool net_admin);

extern int  inet_diag_register(const struct inet_diag_handler *handler);
extern void inet_diag_unregister(const struct inet_diag_handler *handler);
#endif /* _INET_DIAG_H_ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         /*
 * include/linux/journal-head.h
 *
 * buffer_head fields for JBD
 *
 * 27 May 2001 Andrew Morton
 *	Created - pulled out of fs.h
 */

#ifndef JOURNAL_HEAD_H_INCLUDED
#define JOURNAL_HEAD_H_INCLUDED

typedef unsigned int		tid_t;		/* Unique transaction ID */
typedef struct transaction_s	transaction_t;	/* Compound transaction type */


struct buffer_head;

struct journal_head {
	/*
	 * Points back to our buffer_head. [jbd_lock_bh_journal_head()]
	 */
	struct buffer_head *b_bh;

	/*
	 * Reference count - see description in journal.c
	 * [jbd_lock_bh_journal_head()]
	 */
	int b_jcount;

	/*
	 * Journalling list for this buffer [jbd_lock_bh_state()]
	 * NOTE: We *cannot* combine this with b_modified into a bitfield
	 * as gcc would then (which the C standard allows but which is
	 * very unuseful) make 64-bit accesses to the bitfield and clobber
	 * b_jcount if its update races with bitfield modification.
	 */
	unsigned b_jlist;

	/*
	 * This flag signals the buffer has been modified by
	 * the currently running transaction
	 * [jbd_lock_bh_state()]
	 */
	unsigned b_modified;

	/*
	 * Copy of the buffer data frozen for writing to the log.
	 * [jbd_lock_bh_state()]
	 */
	char *b_frozen_data;

	/*
	 * Pointer to a saved copy of the buffer containing no uncommitted
	 * deallocation references, so that allocations can avoid overwriting
	 * uncommitted deletes. [jbd_lock_bh_state()]
	 */
	char *b_committed_data;

	/*
	 * Pointer to the compound transaction which owns this buffer's
	 * metadata: either the running transaction or the committing
	 * transaction (if there is one).  Only applies to buffers on a
	 * transaction's data or metadata journaling list.
	 * [j_list_lock] [jbd_lock_bh_state()]
	 * Either of these locks is enough for reading, both are needed for
	 * changes.
	 */
	transaction_t *b_transaction;

	/*
	 * Pointer to the running compound transaction which is currently
	 * modifying the buffer's metadata, if there was already a transaction
	 * committing it when the new transaction touched it.
	 * [t_list_lock] [jbd_lock_bh_state()]
	 */
	transaction_t *b_next_transaction;

	/*
	 * Doubly-linked list of buffers on a transaction's data, metadata or
	 * forget queue. [t_list_lock] [jbd_lock_bh_state()]
	 */
	struct journal_head *b_tnext, *b_tprev;

	/*
	 * Pointer to the compound transaction against which this buffer
	 * is checkpointed.  Only dirty buffers can be checkpointed.
	 * [j_list_lock]
	 */
	transaction_t *b_cp_transaction;

	/*
	 * Doubly-linked list of buffers still remaining to be flushed
	 * before an old transaction can be checkpointed.
	 * [j_list_lock]
	 */
	struct journal_head *b_cpnext, *b_cpprev;

	/* Trigger type */
	struct jbd2_buffer_trigger_type *b_triggers;

	/* Trigger type for the committing transaction's frozen data */
	struct jbd2_buffer_trigger_type *b_frozen_triggers;
};

#endif		/* JOURNAL_HEAD_H_INCLUDED */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /*
 * Sony Programmable I/O Control Device driver for VAIO
 *
 * Copyright (C) 2001-2005 Stelian Pop <stelian@popies.net>
 *
 * Copyright (C) 2005 Narayanan R S <nars@kadamba.org>

 * Copyright (C) 2001-2002 Alcve <www.alcove.com>
 *
 * Copyright (C) 2001 Michael Ashley <m.ashley@unsw.edu.au>
 *
 * Copyright (C) 2001 Junichi Morita <jun1m@mars.dti.ne.jp>
 *
 * Copyright (C) 2000 Takaya Kinjo <t-kinjo@tc4.so-net.ne.jp>
 *
 * Copyright (C) 2000 Andrew Tridgell <tridge@valinux.com>
 *
 * Earlier work by Werner Almesberger, Paul `Rusty' Russell and Paul Mackerras.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
 *
 */
#ifndef _SONYPI_H_
#define _SONYPI_H_

#include <uapi/linux/sonypi.h>


/* used only for communication between v4l and sonypi */

#define SONYPI_COMMAND_GETCAMERA		 1	/* obsolete */
#define SONYPI_COMMAND_SETCAMERA		 2
#define SONYPI_COMMAND_GETCAMERABRIGHTNESS	 3	/* obsolete */
#define SONYPI_COMMAND_SETCAMERABRIGHTNESS	 4
#define SONYPI_COMMAND_GETCAMERACONTRAST	 5	/* obsolete */
#define SONYPI_COMMAND_SETCAMERACONTRAST	 6
#define SONYPI_COMMAND_GETCAMERAHUE		 7	/* obsolete */
#define SONYPI_COMMAND_SETCAMERAHUE		 8
#define SONYPI_COMMAND_GETCAMERACOLOR		 9	/* obsolete */
#define SONYPI_COMMAND_SETCAMERACOLOR		10
#define SONYPI_COMMAND_GETCAMERASHARPNESS	11	/* obsolete */
#define SONYPI_COMMAND_SETCAMERASHARPNESS	12
#define SONYPI_COMMAND_GETCAMERAPICTURE		13	/* obsolete */
#define SONYPI_COMMAND_SETCAMERAPICTURE		14
#define SONYPI_COMMAND_GETCAMERAAGC		15	/* obsolete */
#define SONYPI_COMMAND_SETCAMERAAGC		16
#define SONYPI_COMMAND_GETCAMERADIRECTION	17	/* obsolete */
#define SONYPI_COMMAND_GETCAMERAROMVERSION	18	/* obsolete */
#define SONYPI_COMMAND_GETCAMERAREVISION	19	/* obsolete */

#endif				/* _SONYPI_H_ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /*****************************************************************************
* Copyright 2012 Broadcom Corporation.  All rights reserved.
*
* Unless you and Broadcom execute a separate written software license
* agreement governing use of this software, this software is licensed to you
* under the terms of the GNU General Public License version 2, available at
* http://www.broadcom.com/licenses/GPLv2.php (the "GPL").
*
* Notwithstanding the above, under no circumstances may you combine this
* software in any way with any other Broadcom software provided under a
* license other than the GPL, without Broadcom's express prior written
* consent.
*****************************************************************************/

#if !defined( VC_CMA_H )
#define VC_CMA_H

#include <linux/ioctl.h>

#define VC_CMA_IOC_MAGIC 0xc5

#define VC_CMA_IOC_RESERVE _IO(VC_CMA_IOC_MAGIC, 0)

#ifdef __KERNEL__

#ifdef CONFIG_BCM_VC_CMA
void vc_cma_early_init(void);
void vc_cma_reserve(void);
#else
static inline void vc_cma_early_init(void) { }
static inline void vc_cma_reserve(void) { }
#endif

#endif

#endif /* VC_CMA_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*****************************************************************************
*  Copyright 2011 Broadcom Corporation.  All rights reserved.
*
*  Unless you and Broadcom execute a separate written software license
*  agreement governing use of this software, this software is licensed to you
*  under the terms of the GNU General Public License version 2, available at
*  http://www.broadcom.com/licenses/GPLv2.php (the "GPL").
*
*  Notwithstanding the above, under no circumstances may you combine this
*  software in any way with any other Broadcom software provided under a
*  license other than the GPL, without Broadcom's express prior written
*  consent.
*
*****************************************************************************/

#if !defined(__VMCS_SM_IOCTL_H__INCLUDED__)
#define __VMCS_SM_IOCTL_H__INCLUDED__

/* ---- Include Files ---------------------------------------------------- */

#if defined(__KERNEL__)
#include <linux/types.h>	/* Needed for standard types */
#else
#include <stdint.h>
#endif

#include <linux/ioctl.h>

/* ---- Constants and Types ---------------------------------------------- */

#define VMCS_SM_RESOURCE_NAME               32
#define VMCS_SM_RESOURCE_NAME_DEFAULT       "sm-host-resource"

/* Type define used to create unique IOCTL number */
#define VMCS_SM_MAGIC_TYPE                  'I'

/* IOCTL commands */
enum vmcs_sm_cmd_e {
	VMCS_SM_CMD_ALLOC = 0x5A,	/* Start at 0x5A arbitrarily */
	VMCS_SM_CMD_ALLOC_SHARE,
	VMCS_SM_CMD_LOCK,
	VMCS_SM_CMD_LOCK_CACHE,
	VMCS_SM_CMD_UNLOCK,
	VMCS_SM_CMD_RESIZE,
	VMCS_SM_CMD_UNMAP,
	VMCS_SM_CMD_FREE,
	VMCS_SM_CMD_FLUSH,
	VMCS_SM_CMD_INVALID,

	VMCS_SM_CMD_SIZE_USR_HANDLE,
	VMCS_SM_CMD_CHK_USR_HANDLE,

	VMCS_SM_CMD_MAPPED_USR_HANDLE,
	VMCS_SM_CMD_MAPPED_USR_ADDRESS,
	VMCS_SM_CMD_MAPPED_VC_HDL_FROM_ADDR,
	VMCS_SM_CMD_MAPPED_VC_HDL_FROM_HDL,
	VMCS_SM_CMD_MAPPED_VC_ADDR_FROM_HDL,

	VMCS_SM_CMD_VC_WALK_ALLOC,
	VMCS_SM_CMD_HOST_WALK_MAP,
	VMCS_SM_CMD_HOST_WALK_PID_ALLOC,
	VMCS_SM_CMD_HOST_WALK_PID_MAP,

	VMCS_SM_CMD_CLEAN_INVALID,
	VMCS_SM_CMD_CLEAN_INVALID2,

	VMCS_SM_CMD_IMPORT_DMABUF,

	VMCS_SM_CMD_LAST	/* Do not delete */
};

/* Cache type supported, conveniently matches the user space definition in
** user-vcsm.h.
*/
enum vmcs_sm_cache_e {
	VMCS_SM_CACHE_NONE,
	VMCS_SM_CACHE_HOST,
	VMCS_SM_CACHE_VC,
	VMCS_SM_CACHE_BOTH,
};

/* IOCTL Data structures */
struct vmcs_sm_ioctl_alloc {
	/* user -> kernel */
	unsigned int size;
	unsigned int num;
	enum vmcs_sm_cache_e cached;
	char name[VMCS_SM_RESOURCE_NAME];

	/* kernel -> user */
	unsigned int handle;
	/* unsigned int base_addr; */
};

struct vmcs_sm_ioctl_alloc_share {
	/* user -> kernel */
	unsigned int handle;
	unsigned int size;
};

struct vmcs_sm_ioctl_free {
	/* user -> kernel */
	unsigned int handle;
	/* unsigned int base_addr; */
};

struct vmcs_sm_ioctl_lock_unlock {
	/* user -> kernel */
	unsigned int handle;

	/* kernel -> user */
	unsigned int addr;
};

struct vmcs_sm_ioctl_lock_cache {
	/* user -> kernel */
	unsigned int handle;
	enum vmcs_sm_cache_e cached;
};

struct vmcs_sm_ioctl_resize {
	/* user -> kernel */
	unsigned int handle;
	unsigned int new_size;

	/* kernel -> user */
	unsigned int old_size;
};

struct vmcs_sm_ioctl_map {
	/* user -> kernel */
	/* and kernel -> user */
	unsigned int pid;
	unsigned int handle;
	unsigned int addr;

	/* kernel -> user */
	unsigned int size;
};

struct vmcs_sm_ioctl_walk {
	/* user -> kernel */
	unsigned int pid;
};

struct vmcs_sm_ioctl_chk {
	/* user -> kernel */
	unsigned int handle;

	/* kernel -> user */
	unsigned int addr;
	unsigned int size;
	enum vmcs_sm_cache_e cache;
};

struct vmcs_sm_ioctl_size {
	/* user -> kernel */
	unsigned int handle;

	/* kernel -> user */
	unsigned int size;
};

struct vmcs_sm_ioctl_cache {
	/* user -> kernel */
	unsigned int handle;
	unsigned int addr;
	unsigned int size;
};

struct vmcs_sm_ioctl_clean_invalid {
	/* user -> kernel */
	struct {
		unsigned int cmd;
		unsigned int handle;
		unsigned int addr;
		unsigned int size;
	} s[8];
};

struct vmcs_sm_ioctl_clean_invalid2 {
	uint8_t op_count;
	uint8_t zero[3];
	struct vmcs_sm_ioctl_clean_invalid_block {
		uint16_t invalidate_mode;
		uint16_t block_count;
		void *   start_address;
		uint32_t block_size;
		uint32_t inter_block_stride;
	} s[0];
};

struct vmcs_sm_ioctl_import_dmabuf {
	/* user -> kernel */
	int dmabuf_fd;
	enum vmcs_sm_cache_e cached;
	char name[VMCS_SM_RESOURCE_NAME];

	/* kernel -> user */
	unsigned int handle;
};

/* IOCTL numbers */
#define VMCS_SM_IOCTL_MEM_ALLOC\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_ALLOC,\
	 struct vmcs_sm_ioctl_alloc)
#define VMCS_SM_IOCTL_MEM_ALLOC_SHARE\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_ALLOC_SHARE,\
	 struct vmcs_sm_ioctl_alloc_share)
#define VMCS_SM_IOCTL_MEM_LOCK\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_LOCK,\
	 struct vmcs_sm_ioctl_lock_unlock)
#define VMCS_SM_IOCTL_MEM_LOCK_CACHE\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_LOCK_CACHE,\
	 struct vmcs_sm_ioctl_lock_cache)
#define VMCS_SM_IOCTL_MEM_UNLOCK\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_UNLOCK,\
	 struct vmcs_sm_ioctl_lock_unlock)
#define VMCS_SM_IOCTL_MEM_RESIZE\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_RESIZE,\
	 struct vmcs_sm_ioctl_resize)
#define VMCS_SM_IOCTL_MEM_FREE\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_FREE,\
	 struct vmcs_sm_ioctl_free)
#define VMCS_SM_IOCTL_MEM_FLUSH\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_FLUSH,\
	 struct vmcs_sm_ioctl_cache)
#define VMCS_SM_IOCTL_MEM_INVALID\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_INVALID,\
	 struct vmcs_sm_ioctl_cache)
#define VMCS_SM_IOCTL_MEM_CLEAN_INVALID\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_CLEAN_INVALID,\
	 struct vmcs_sm_ioctl_clean_invalid)
#define VMCS_SM_IOCTL_MEM_CLEAN_INVALID2\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_CLEAN_INVALID2,\
	 struct vmcs_sm_ioctl_clean_invalid2)

#define VMCS_SM_IOCTL_SIZE_USR_HDL\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_SIZE_USR_HANDLE,\
	 struct vmcs_sm_ioctl_size)
#define VMCS_SM_IOCTL_CHK_USR_HDL\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_CHK_USR_HANDLE,\
	 struct vmcs_sm_ioctl_chk)

#define VMCS_SM_IOCTL_MAP_USR_HDL\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_MAPPED_USR_HANDLE,\
	 struct vmcs_sm_ioctl_map)
#define VMCS_SM_IOCTL_MAP_USR_ADDRESS\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_MAPPED_USR_ADDRESS,\
	 struct vmcs_sm_ioctl_map)
#define VMCS_SM_IOCTL_MAP_VC_HDL_FR_ADDR\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_MAPPED_VC_HDL_FROM_ADDR,\
	 struct vmcs_sm_ioctl_map)
#define VMCS_SM_IOCTL_MAP_VC_HDL_FR_HDL\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_MAPPED_VC_HDL_FROM_HDL,\
	 struct vmcs_sm_ioctl_map)
#define VMCS_SM_IOCTL_MAP_VC_ADDR_FR_HDL\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_MAPPED_VC_ADDR_FROM_HDL,\
	 struct vmcs_sm_ioctl_map)

#define VMCS_SM_IOCTL_VC_WALK_ALLOC\
	_IO(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_VC_WALK_ALLOC)
#define VMCS_SM_IOCTL_HOST_WALK_MAP\
	_IO(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_HOST_WALK_MAP)
#define VMCS_SM_IOCTL_HOST_WALK_PID_ALLOC\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_HOST_WALK_PID_ALLOC,\
	 struct vmcs_sm_ioctl_walk)
#define VMCS_SM_IOCTL_HOST_WALK_PID_MAP\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_HOST_WALK_PID_MAP,\
	 struct vmcs_sm_ioctl_walk)

#define VMCS_SM_IOCTL_MEM_IMPORT_DMABUF\
	_IOR(VMCS_SM_MAGIC_TYPE, VMCS_SM_CMD_IMPORT_DMABUF,\
	 struct vmcs_sm_ioctl_import_dmabuf)

/* ---- Variable Externs ------------------------------------------------- */

/* ---- Function Prototypes ---------------------------------------------- */

#endif /* __VMCS_SM_IOCTL_H__INCLUDED__ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        /**
 * Declarations and definitions for Broadcom's Secondary Memory Interface
 *
 * Written by Luke Wren <luke@raspberrypi.org>
 * Copyright (c) 2015, Raspberry Pi (Trading) Ltd.
 * Copyright (c) 2010-2012 Broadcom. All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions, and the following disclaimer,
 *    without modification.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. The names of the above-listed copyright holders may not be used
 *    to endorse or promote products derived from this software without
 *    specific prior written permission.
 *
 * ALTERNATIVELY, this software may be distributed under the terms of the
 * GNU General Public License ("GPL") version 2, as published by the Free
 * Software Foundation.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef BCM2835_SMI_H
#define BCM2835_SMI_H

#include <linux/ioctl.h>

#ifndef __KERNEL__
#include <stdint.h>
#include <stdbool.h>
#endif

#define BCM2835_SMI_IOC_MAGIC 0x1
#define BCM2835_SMI_INVALID_HANDLE (~0)

/* IOCTLs 0x100...0x1ff are not device-specific - we can use them */
#define BCM2835_SMI_IOC_GET_SETTINGS    _IO(BCM2835_SMI_IOC_MAGIC, 0)
#define BCM2835_SMI_IOC_WRITE_SETTINGS  _IO(BCM2835_SMI_IOC_MAGIC, 1)
#define BCM2835_SMI_IOC_ADDRESS	 _IO(BCM2835_SMI_IOC_MAGIC, 2)
#define BCM2835_SMI_IOC_MAX	     2

#define SMI_WIDTH_8BIT 0
#define SMI_WIDTH_16BIT 1
#define SMI_WIDTH_9BIT 2
#define SMI_WIDTH_18BIT 3

/* max number of bytes where DMA will not be used */
#define DMA_THRESHOLD_BYTES 128
#define DMA_BOUNCE_BUFFER_SIZE (1024 * 1024 / 2)
#define DMA_BOUNCE_BUFFER_COUNT 3


struct smi_settings {
	int data_width;
	/* Whether or not to pack multiple SMI transfers into a
	   single 32 bit FIFO word */
	bool pack_data;

	/* Timing for reads (writes the same but for WE)
	 *
	 * OE ----------+	   +--------------------
	 *		|	   |
	 *		+----------+
	 * SD -<==============================>-----------
	 * SA -<=========================================>-
	 *    <-setup->  <-strobe ->  <-hold ->  <- pace ->
	 */

	int read_setup_time;
	int read_hold_time;
	int read_pace_time;
	int read_strobe_time;

	int write_setup_time;
	int write_hold_time;
	int write_pace_time;
	int write_strobe_time;

	bool dma_enable;		/* DREQs */
	bool dma_passthrough_enable;	/* External DREQs */
	int dma_read_thresh;
	int dma_write_thresh;
	int dma_panic_read_thresh;
	int dma_panic_write_thresh;
};

/****************************************************************************
*
*   Declare exported SMI functions
*
***************************************************************************/

#ifdef __KERNEL__

#include <linux/dmaengine.h> /* for enum dma_transfer_direction */
#include <linux/of.h>
#include <linux/semaphore.h>

struct bcm2835_smi_instance;

struct bcm2835_smi_bounce_info {
	struct semaphore callback_sem;
	void *buffer[DMA_BOUNCE_BUFFER_COUNT];
	dma_addr_t phys[DMA_BOUNCE_BUFFER_COUNT];
	struct scatterlist sgl[DMA_BOUNCE_BUFFER_COUNT];
};


void bcm2835_smi_set_regs_from_settings(struct bcm2835_smi_instance *);

struct smi_settings *bcm2835_smi_get_settings_from_regs(
	struct bcm2835_smi_instance *inst);

void bcm2835_smi_write_buf(
	struct bcm2835_smi_instance *inst,
	const void *buf,
	size_t n_bytes);

void bcm2835_smi_read_buf(
	struct bcm2835_smi_instance *inst,
	void *buf,
	size_t n_bytes);

void bcm2835_smi_set_address(struct bcm2835_smi_instance *inst,
	unsigned int address);

ssize_t bcm2835_smi_user_dma(
	struct bcm2835_smi_instance *inst,
	enum dma_transfer_direction dma_dir,
	char __user *user_ptr,
	size_t count,
	struct bcm2835_smi_bounce_info **bounce);

struct bcm2835_smi_instance *bcm2835_smi_get(struct device_node *node);

#endif /* __KERNEL__ */

/****************************************************************
*
*	Implementation-only declarations
*
****************************************************************/

#ifdef BCM2835_SMI_IMPLEMENTATION

/* Clock manager registers for SMI clock: */
#define CM_SMI_BASE_ADDRESS ((BCM2708_PERI_BASE) + 0x1010b0)
/* Clock manager "password" to protect registers from spurious writes */
#define CM_PWD (0x5a << 24)

#define CM_SMI_CTL	0x00
#define CM_SMI_DIV	0x04

#define CM_SMI_CTL_FLIP (1 << 8)
#define CM_SMI_CTL_BUSY (1 << 7)
#define CM_SMI_CTL_KILL (1 << 5)
#define CM_SMI_CTL_ENAB (1 << 4)
#define CM_SMI_CTL_SRC_MASK (0xf)
#define CM_SMI_CTL_SRC_OFFS (0)

#define CM_SMI_DIV_DIVI_MASK (0xf <<  12)
#define CM_SMI_DIV_DIVI_OFFS (12)
#define CM_SMI_DIV_DIVF_MASK (0xff << 4)
#define CM_SMI_DIV_DIVF_OFFS (4)

/* SMI register mapping:*/
#define SMI_BASE_ADDRESS ((BCM2708_PERI_BASE) + 0x600000)

#define SMICS	0x00	/* control + status register		*/
#define SMIL	0x04	/* length/count (n external txfers)	*/
#define SMIA	0x08	/* address register			*/
#define SMID	0x0c	/* data register			*/
#define SMIDSR0	0x10	/* device 0 read settings		*/
#define SMIDSW0	0x14	/* device 0 write settings		*/
#define SMIDSR1	0x18	/* device 1 read settings		*/
#define SMIDSW1	0x1c	/* device 1 write settings		*/
#define SMIDSR2	0x20	/* device 2 read settings		*/
#define SMIDSW2	0x24	/* device 2 write settings		*/
#define SMIDSR3	0x28	/* device 3 read settings		*/
#define SMIDSW3	0x2c	/* device 3 write settings		*/
#define SMIDC	0x30	/* DMA control registers		*/
#define SMIDCS	0x34	/* direct control/status register	*/
#define SMIDA	0x38	/* direct address register		*/
#define SMIDD	0x3c	/* direct data registers		*/
#define SMIFD	0x40	/* FIFO debug register			*/



/* Control and Status register bits:
 * SMICS_RXF	: RX fifo full: 1 when RX fifo is full
 * SMICS_TXE	: TX fifo empty: 1 when empty.
 * SMICS_RXD	: RX fifo contains data: 1 when there is data.
 * SMICS_TXD	: TX fifo can accept data: 1 when true.
 * SMICS_RXR	: RX fifo needs reading: 1 when fifo more than 3/4 full, or
 *		  when "DONE" and fifo not emptied.
 * SMICS_TXW	: TX fifo needs writing: 1 when less than 1/4 full.
 * SMICS_AFERR	: AXI FIFO error: 1 when fifo read when empty or written
 *		  when full. Write 1 to clear.
 * SMICS_EDREQ	: 1 when external DREQ received.
 * SMICS_PXLDAT	:  Pixel data:	write 1 to enable pixel transfer modes.
 * SMICS_SETERR	: 1 if there was an error writing to setup regs (e.g.
 *		  tx was in progress). Write 1 to clear.
 * SMICS_PVMODE	: Set to 1 to enable pixel valve mode.
 * SMICS_INTR	: Set to 1 to enable interrupt on RX.
 * SMICS_INTT	: Set to 1 to enable interrupt on TX.
 * SMICS_INTD	: Set to 1 to enable interrupt on DONE condition.
 * SMICS_TEEN	: Tear effect mode enabled: Programmed transfers will wait
 *		  for a TE trigger before writing.
 * SMICS_PAD1	: Padding settings for external transfers. For writes: the
 *		  number of bytes initially written to  the TX fifo that
 * SMICS_PAD0	: should be ignored. For reads: the number of bytes that will
 *		  be read before the data, and should be dropped.
 * SMICS_WRITE	: Transfer direction: 1 = write to external device, 0 = read
 * SMICS_CLEAR	: Write 1 to clear the FIFOs.
 * SMICS_START	: Write 1 to start the programmed transfer.
 * SMICS_ACTIVE	: Reads as 1 when a programmed transfer is underway.
 * SMICS_DONE	: Reads as 1 when transfer finished. For RX, not set until
 *		  FIFO emptied.
 * SMICS_ENABLE	: Set to 1 to enable the SMI peripheral, 0 to disable.
 */

#define SMICS_RXF	(1 << 31)
#define SMICS_TXE	(1 << 30)
#define SMICS_RXD	(1 << 29)
#define SMICS_TXD	(1 << 28)
#define SMICS_RXR	(1 << 27)
#define SMICS_TXW	(1 << 26)
#define SMICS_AFERR	(1 << 25)
#define SMICS_EDREQ	(1 << 15)
#define SMICS_PXLDAT	(1 << 14)
#define SMICS_SETERR	(1 << 13)
#define SMICS_PVMODE	(1 << 12)
#define SMICS_INTR	(1 << 11)
#define SMICS_INTT	(1 << 10)
#define SMICS_INTD	(1 << 9)
#define SMICS_TEEN	(1 << 8)
#define SMICS_PAD1	(1 << 7)
#define SMICS_PAD0	(1 << 6)
#define SMICS_WRITE	(1 << 5)
#define SMICS_CLEAR	(1 << 4)
#define SMICS_START	(1 << 3)
#define SMICS_ACTIVE	(1 << 2)
#define SMICS_DONE	(1 << 1)
#define SMICS_ENABLE	(1 << 0)

/* Address register bits: */

#define SMIA_DEVICE_MASK ((1 << 9) | (1 << 8))
#define SMIA_DEVICE_OFFS (8)
#define SMIA_ADDR_MASK (0x3f)	/* bits 5 -> 0 */
#define SMIA_ADDR_OFFS (0)

/* DMA control register bits:
 * SMIDC_DMAEN	: DMA enable: set 1: DMA requests will be issued.
 * SMIDC_DMAP	: DMA passthrough: when set to 0, top two data pins are used by
 *		  SMI as usual. When set to 1, the top two pins are used for
 *		  external DREQs: pin 16 read request, 17 write.
 * SMIDC_PANIC*	: Threshold at which DMA will panic during read/write.
 * SMIDC_REQ*	: Threshold at which DMA will generate a DREQ.
 */

#define SMIDC_DMAEN		(1 << 28)
#define SMIDC_DMAP		(1 << 24)
#define SMIDC_PANICR_MASK	(0x3f << 18)
#define SMIDC_PANICR_OFFS	(18)
#define SMIDC_PANICW_MASK	(0x3f << 12)
#define SMIDC_PANICW_OFFS	(12)
#define SMIDC_REQR_MASK		(0x3f << 6)
#define SMIDC_REQR_OFFS		(6)
#define SMIDC_REQW_MASK		(0x3f)
#define SMIDC_REQW_OFFS		(0)

/* Device settings register bits: same for all 4 (or 3?) device register sets.
 * Device read settings:
 * SMIDSR_RWIDTH	: Read transfer width. 00 = 8bit, 01 = 16bit,
 *			  10 = 18bit, 11 = 9bit.
 * SMIDSR_RSETUP	: Read setup time: number of core cycles between chip
 *			  select/address and read strobe. Min 1, max 64.
 * SMIDSR_MODE68	: 1 for System 68 mode (i.e. enable + direction pins,
 *			  rather than OE + WE pin)
 * SMIDSR_FSETUP	: If set to 1, setup time only applies to first
 *			  transfer after address change.
 * SMIDSR_RHOLD		: Number of core cycles between read strobe going
 *			  inactive and CS/address going inactive. Min 1, max 64
 * SMIDSR_RPACEALL	: When set to 1, this device's RPACE value will always
 *			  be used for the next transaction, even if it is not
 *			  to this device.
 * SMIDSR_RPACE		: Number of core cycles spent waiting between CS
 *			  deassert and start of next transfer. Min 1, max 128
 * SMIDSR_RDREQ		: 1 = use external DMA request on SD16 to pace reads
 *			  from device. Must also set DMAP in SMICS.
 * SMIDSR_RSTROBE	: Number of cycles to assert the read strobe.
 *			  min 1, max 128.
 */
#define SMIDSR_RWIDTH_MASK	((1<<31)|(1<<30))
#define SMIDSR_RWIDTH_OFFS	(30)
#define SMIDSR_RSETUP_MASK	(0x3f << 24)
#define SMIDSR_RSETUP_OFFS	(24)
#define SMIDSR_MODE68		(1 << 23)
#define SMIDSR_FSETUP		(1 << 22)
#define SMIDSR_RHOLD_MASK	(0x3f << 16)
#define SMIDSR_RHOLD_OFFS	(16)
#define SMIDSR_RPACEALL		(1 << 15)
#define SMIDSR_RPACE_MASK	(0x7f << 8)
#define SMIDSR_RPACE_OFFS	(8)
#define SMIDSR_RDREQ		(1 << 7)
#define SMIDSR_RSTROBE_MASK	(0x7f)
#define SMIDSR_RSTROBE_OFFS	(0)

/* Device write settings:
 * SMIDSW_WWIDTH	: Write transfer width. 00 = 8bit, 01 = 16bit,
 *			  10= 18bit, 11 = 9bit.
 * SMIDSW_WSETUP	: Number of cycles between CS assert and write strobe.
 *			  Min 1, max 64.
 * SMIDSW_WFORMAT	: Pixel format of input. 0 = 16bit RGB 565,
 *			  1 = 32bit RGBA 8888
 * SMIDSW_WSWAP		: 1 = swap pixel data bits. (Use with SMICS_PXLDAT)
 * SMIDSW_WHOLD		: Time between WE deassert and CS deassert. 1 to 64
 * SMIDSW_WPACEALL	: 1: this device's WPACE will be used for the next
 *			  transfer, regardless of that transfer's device.
 * SMIDSW_WPACE		: Cycles between CS deassert and next CS assert.
 *			  Min 1, max 128
 * SMIDSW_WDREQ		: Use external DREQ on pin 17 to pace writes. DMAP must
 *			  be set in SMICS.
 * SMIDSW_WSTROBE	: Number of cycles to assert the write strobe.
 *			  Min 1, max 128
 */
#define SMIDSW_WWIDTH_MASK	 ((1<<31)|(1<<30))
#define SMIDSW_WWIDTH_OFFS	(30)
#define SMIDSW_WSETUP_MASK	(0x3f << 24)
#define SMIDSW_WSETUP_OFFS	(24)
#define SMIDSW_WFORMAT		(1 << 23)
#define SMIDSW_WSWAP		(1 << 22)
#define SMIDSW_WHOLD_MASK	(0x3f << 16)
#define SMIDSW_WHOLD_OFFS	(16)
#define SMIDSW_WPACEALL		(1 << 15)
#define SMIDSW_WPACE_MASK	(0x7f << 8)
#define SMIDSW_WPACE_OFFS	(8)
#define SMIDSW_WDREQ		(1 << 7)
#define SMIDSW_WSTROBE_MASK	 (0x7f)
#define SMIDSW_WSTROBE_OFFS	 (0)

/* Direct transfer control + status register
 * SMIDCS_WRITE	: Direction of transfer: 1 -> write, 0 -> read
 * SMIDCS_DONE	: 1 when a transfer has finished. Write 1 to clear.
 * SMIDCS_START	: Write 1 to start a transfer, if one is not already underway.
 * SMIDCE_ENABLE: Write 1 to enable SMI in direct mode.
 */

#define SMIDCS_WRITE		(1 << 3)
#define SMIDCS_DONE		(1 << 2)
#define SMIDCS_START		(1 << 1)
#define SMIDCS_ENABLE		(1 << 0)

/* Direct transfer address register
 * SMIDA_DEVICE	: Indicates which of the device settings banks should be used.
 * SMIDA_ADDR	: The value to be asserted on the address pins.
 */

#define SMIDA_DEVICE_MASK	((1<<9)|(1<<8))
#define SMIDA_DEVICE_OFFS	(8)
#define SMIDA_ADDR_MASK		(0x3f)
#define SMIDA_ADDR_OFFS		(0)

/* FIFO debug register
 * SMIFD_FLVL	: The high-tide mark of FIFO count during the most recent txfer
 * SMIFD_FCNT	: The current FIFO count.
 */
#define SMIFD_FLVL_MASK		(0x3f << 8)
#define SMIFD_FLVL_OFFS		(8)
#define SMIFD_FCNT_MASK		(0x3f)
#define SMIFD_FCNT_OFFS		(0)

#endif /* BCM2835_SMI_IMPLEMENTATION */

#endif /* BCM2835_SMI_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /*****************************************************************************
* Copyright 2010 - 2011 Broadcom Corporation.  All rights reserved.
*
* Unless you and Broadcom execute a separate written software license
* agreement governing use of this software, this software is licensed to you
* under the terms of the GNU General Public License version 2, available at
* http://www.broadcom.com/licenses/GPLv2.php (the "GPL").
*
* Notwithstanding the above, under no circumstances may you combine this
* software in any way with any other Broadcom software provided under a
* license other than the GPL, without Broadcom's express prior written
* consent.
*****************************************************************************/

#ifndef _VC_MEM_H
#define _VC_MEM_H

#include <linux/ioctl.h>

#define VC_MEM_IOC_MAGIC  'v'

#define VC_MEM_IOC_MEM_PHYS_ADDR    _IOR( VC_MEM_IOC_MAGIC, 0, unsigned long )
#define VC_MEM_IOC_MEM_SIZE         _IOR( VC_MEM_IOC_MAGIC, 1, unsigned int )
#define VC_MEM_IOC_MEM_BASE         _IOR( VC_MEM_IOC_MAGIC, 2, unsigned int )
#define VC_MEM_IOC_MEM_LOAD         _IOR( VC_MEM_IOC_MAGIC, 3, unsigned int )

#if defined( __KERNEL__ )
#define VC_MEM_TO_ARM_ADDR_MASK 0x3FFFFFFF

extern unsigned long mm_vc_mem_phys_addr;
extern unsigned int  mm_vc_mem_size;
extern int vc_mem_get_current_size( void );
#endif

#endif  /* _VC_MEM_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /* Integer base 2 logarithm calculation
 *
 * Copyright (C) 2006 Red Hat, Inc. All Rights Reserved.
 * Written by David Howells (dhowells@redhat.com)
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version
 * 2 of the License, or (at your option) any later version.
 */

#ifndef _LINUX_LOG2_H
#define _LINUX_LOG2_H

#include <linux/types.h>
#include <linux/bitops.h>

/*
 * non-constant log of base 2 calculators
 * - the arch may override these in asm/bitops.h if they can be implemented
 *   more efficiently than using fls() and fls64()
 * - the arch is not required to handle n==0 if implementing the fallback
 */
#ifndef CONFIG_ARCH_HAS_ILOG2_U32
static inline __attribute__((const))
int __ilog2_u32(u32 n)
{
	return fls(n) - 1;
}
#endif

#ifndef CONFIG_ARCH_HAS_ILOG2_U64
static inline __attribute__((const))
int __ilog2_u64(u64 n)
{
	return fls64(n) - 1;
}
#endif

/*
 *  Determine whether some value is a power of two, where zero is
 * *not* considered a power of two.
 */

static inline __attribute__((const))
bool is_power_of_2(unsigned long n)
{
	return (n != 0 && ((n & (n - 1)) == 0));
}

/*
 * round up to nearest power of two
 */
static inline __attribute__((const))
unsigned long __roundup_pow_of_two(unsigned long n)
{
	return 1UL << fls_long(n - 1);
}

/*
 * round down to nearest power of two
 */
static inline __attribute__((const))
unsigned long __rounddown_pow_of_two(unsigned long n)
{
	return 1UL << (fls_long(n) - 1);
}

/**
 * ilog2 - log of base 2 of 32-bit or a 64-bit unsigned value
 * @n - parameter
 *
 * constant-capable log of base 2 calculation
 * - this can be used to initialise global variables from constant data, hence
 *   the massive ternary operator construction
 *
 * selects the appropriately-sized optimised version depending on sizeof(n)
 */
#define ilog2(n)				\
(						\
	__builtin_constant_p(n) ? (		\
		(n) < 2 ? 0 :			\
		(n) & (1ULL << 63) ? 63 :	\
		(n) & (1ULL << 62) ? 62 :	\
		(n) & (1ULL << 61) ? 61 :	\
		(n) & (1ULL << 60) ? 60 :	\
		(n) & (1ULL << 59) ? 59 :	\
		(n) & (1ULL << 58) ? 58 :	\
		(n) & (1ULL << 57) ? 57 :	\
		(n) & (1ULL << 56) ? 56 :	\
		(n) & (1ULL << 55) ? 55 :	\
		(n) & (1ULL << 54) ? 54 :	\
		(n) & (1ULL << 53) ? 53 :	\
		(n) & (1ULL << 52) ? 52 :	\
		(n) & (1ULL << 51) ? 51 :	\
		(n) & (1ULL << 50) ? 50 :	\
		(n) & (1ULL << 49) ? 49 :	\
		(n) & (1ULL << 48) ? 48 :	\
		(n) & (1ULL << 47) ? 47 :	\
		(n) & (1ULL << 46) ? 46 :	\
		(n) & (1ULL << 45) ? 45 :	\
		(n) & (1ULL << 44) ? 44 :	\
		(n) & (1ULL << 43) ? 43 :	\
		(n) & (1ULL << 42) ? 42 :	\
		(n) & (1ULL << 41) ? 41 :	\
		(n) & (1ULL << 40) ? 40 :	\
		(n) & (1ULL << 39) ? 39 :	\
		(n) & (1ULL << 38) ? 38 :	\
		(n) & (1ULL << 37) ? 37 :	\
		(n) & (1ULL << 36) ? 36 :	\
		(n) & (1ULL << 35) ? 35 :	\
		(n) & (1ULL << 34) ? 34 :	\
		(n) & (1ULL << 33) ? 33 :	\
		(n) & (1ULL << 32) ? 32 :	\
		(n) & (1ULL << 31) ? 31 :	\
		(n) & (1ULL << 30) ? 30 :	\
		(n) & (1ULL << 29) ? 29 :	\
		(n) & (1ULL << 28) ? 28 :	\
		(n) & (1ULL << 27) ? 27 :	\
		(n) & (1ULL << 26) ? 26 :	\
		(n) & (1ULL << 25) ? 25 :	\
		(n) & (1ULL << 24) ? 24 :	\
		(n) & (1ULL << 23) ? 23 :	\
		(n) & (1ULL << 22) ? 22 :	\
		(n) & (1ULL << 21) ? 21 :	\
		(n) & (1ULL << 20) ? 20 :	\
		(n) & (1ULL << 19) ? 19 :	\
		(n) & (1ULL << 18) ? 18 :	\
		(n) & (1ULL << 17) ? 17 :	\
		(n) & (1ULL << 16) ? 16 :	\
		(n) & (1ULL << 15) ? 15 :	\
		(n) & (1ULL << 14) ? 14 :	\
		(n) & (1ULL << 13) ? 13 :	\
		(n) & (1ULL << 12) ? 12 :	\
		(n) & (1ULL << 11) ? 11 :	\
		(n) & (1ULL << 10) ? 10 :	\
		(n) & (1ULL <<  9) ?  9 :	\
		(n) & (1ULL <<  8) ?  8 :	\
		(n) & (1ULL <<  7) ?  7 :	\
		(n) & (1ULL <<  6) ?  6 :	\
		(n) & (1ULL <<  5) ?  5 :	\
		(n) & (1ULL <<  4) ?  4 :	\
		(n) & (1ULL <<  3) ?  3 :	\
		(n) & (1ULL <<  2) ?  2 :	\
		1 ) :				\
	(sizeof(n) <= 4) ?			\
	__ilog2_u32(n) :			\
	__ilog2_u64(n)				\
 )

/**
 * roundup_pow_of_two - round the given value up to nearest power of two
 * @n - parameter
 *
 * round the given value up to the nearest power of two
 * - the result is undefined when n == 0
 * - this can be used to initialise global variables from constant data
 */
#define roundup_pow_of_two(n)			\
(						\
	__builtin_constant_p(n) ? (		\
		(n == 1) ? 1 :			\
		(1UL << (ilog2((n) - 1) + 1))	\
				   ) :		\
	__roundup_pow_of_two(n)			\
 )

/**
 * rounddown_pow_of_two - round the given value down to nearest power of two
 * @n - parameter
 *
 * round the given value down to the nearest power of two
 * - the result is undefined when n == 0
 * - this can be used to initialise global variables from constant data
 */
#define rounddown_pow_of_two(n)			\
(						\
	__builtin_constant_p(n) ? (		\
		(1UL << ilog2(n))) :		\
	__rounddown_pow_of_two(n)		\
 )

/**
 * order_base_2 - calculate the (rounded up) base 2 order of the argument
 * @n: parameter
 *
 * The first few values calculated by this routine:
 *  ob2(0) = 0
 *  ob2(1) = 0
 *  ob2(2) = 1
 *  ob2(3) = 2
 *  ob2(4) = 2
 *  ob2(5) = 3
 *  ... and so on.
 */

static inline __attribute_const__
int __order_base_2(unsigned long n)
{
	return n > 1 ? ilog2(n - 1) + 1 : 0;
}

#define order_base_2(n)				\
(						\
	__builtin_constant_p(n) ? (		\
		((n) == 0 || (n) == 1) ? 0 :	\
		ilog2((n) - 1) + 1) :		\
	__order_base_2(n)			\
)
#endif /* _LINUX_LOG2_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /***************************************************************************
 * Linux PPP over X - Generic PPP transport layer sockets
 * Linux PPP over Ethernet (PPPoE) Socket Implementation (RFC 2516) 
 *
 * This file supplies definitions required by the PPP over Ethernet driver
 * (pppox.c).  All version information wrt this file is located in pppox.c
 *
 * License:
 *		This program is free software; you can redistribute it and/or
 *		modify it under the terms of the GNU General Public License
 *		as published by the Free Software Foundation; either version
 *		2 of the License, or (at your option) any later version.
 *
 */
#ifndef __LINUX_IF_PPPOX_H
#define __LINUX_IF_PPPOX_H

#include <linux/if.h>
#include <linux/netdevice.h>
#include <linux/ppp_channel.h>
#include <linux/skbuff.h>
#include <linux/workqueue.h>
#include <uapi/linux/if_pppox.h>

static inline struct pppoe_hdr *pppoe_hdr(const struct sk_buff *skb)
{
	return (struct pppoe_hdr *)skb_network_header(skb);
}

struct pppoe_opt {
	struct net_device      *dev;	  /* device associated with socket*/
	int			ifindex;  /* ifindex of device associated with socket */
	struct pppoe_addr	pa;	  /* what this socket is bound to*/
	struct sockaddr_pppox	relay;	  /* what socket data will be
					     relayed to (PPPoE relaying) */
	struct work_struct      padt_work;/* Work item for handling PADT */
};

struct pptp_opt {
	struct pptp_addr src_addr;
	struct pptp_addr dst_addr;
	u32 ack_sent, ack_recv;
	u32 seq_sent, seq_recv;
	int ppp_flags;
};
#include <net/sock.h>

struct pppox_sock {
	/* struct sock must be the first member of pppox_sock */
	struct sock sk;
	struct ppp_channel chan;
	struct pppox_sock	*next;	  /* for hash table */
	union {
		struct pppoe_opt pppoe;
		struct pptp_opt  pptp;
	} proto;
	__be16			num;
};
#define pppoe_dev	proto.pppoe.dev
#define pppoe_ifindex	proto.pppoe.ifindex
#define pppoe_pa	proto.pppoe.pa
#define pppoe_relay	proto.pppoe.relay

static inline struct pppox_sock *pppox_sk(struct sock *sk)
{
	return (struct pppox_sock *)sk;
}

static inline struct sock *sk_pppox(struct pppox_sock *po)
{
	return (struct sock *)po;
}

struct module;

struct pppox_proto {
	int		(*create)(struct net *net, struct socket *sock, int kern);
	int		(*ioctl)(struct socket *sock, unsigned int cmd,
				 unsigned long arg);
	struct module	*owner;
};

extern int register_pppox_proto(int proto_num, const struct pppox_proto *pp);
extern void unregister_pppox_proto(int proto_num);
extern void pppox_unbind_sock(struct sock *sk);/* delete ppp-channel binding */
extern int pppox_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg);

/* PPPoX socket states */
enum {
    PPPOX_NONE		= 0,  /* initial state */
    PPPOX_CONNECTED	= 1,  /* connection established ==TCP_ESTABLISHED */
    PPPOX_BOUND		= 2,  /* bound to ppp device */
    PPPOX_RELAY		= 4,  /* forwarding is enabled */
    PPPOX_DEAD		= 16  /* dead, useless, please clean me up!*/
};

#endif /* !(__LINUX_IF_PPPOX_H) */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             /*
 * Copyright (c) 2011 Broadcom Corporation
 *
 * Permission to use, copy, modify, and/or distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY
 * SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION
 * OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN
 * CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */
#ifndef __CORDIC_H_
#define __CORDIC_H_

#include <linux/types.h>

/**
 * struct cordic_iq - i/q coordinate.
 *
 * @i: real part of coordinate (in phase).
 * @q: imaginary part of coordinate (quadrature).
 */
struct cordic_iq {
	s32 i;
	s32 q;
};

/**
 * cordic_calc_iq() - calculates the i/q coordinate for given angle.
 *
 * @theta: angle in degrees for which i/q coordinate is to be calculated.
 * @coord: function output parameter holding the i/q coordinate.
 *
 * The function calculates the i/q coordinate for a given angle using the
 * CORDIC algorithm. The coordinate consists of a real (i) and an
 * imaginary (q) part. The real part is essentially the cosine of the
 * angle and the imaginary part is the sine of the angle. The returned
 * values are scaled by 2^16 for precision. The range for theta is
 * for -180 degrees to +180 degrees. Passed values outside this range are
 * converted before doing the actual calculation.
 */
struct cordic_iq cordic_calc_iq(s32 theta);

#endif /* __CORDIC_H_ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /* Authentication token and access key management
 *
 * Copyright (C) 2004, 2007 Red Hat, Inc. All Rights Reserved.
 * Written by David Howells (dhowells@redhat.com)
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version
 * 2 of the License, or (at your option) any later version.
 *
 *
 * See Documentation/security/keys.txt for information on keys/keyrings.
 */

#ifndef _LINUX_KEY_H
#define _LINUX_KEY_H

#include <linux/types.h>
#include <linux/list.h>
#include <linux/rbtree.h>
#include <linux/rcupdate.h>
#include <linux/sysctl.h>
#include <linux/rwsem.h>
#include <linux/atomic.h>
#include <linux/assoc_array.h>

#ifdef __KERNEL__
#include <linux/uidgid.h>

/* key handle serial number */
typedef int32_t key_serial_t;

/* key handle permissions mask */
typedef uint32_t key_perm_t;

struct key;

#ifdef CONFIG_KEYS

#undef KEY_DEBUGGING

#define KEY_POS_VIEW	0x01000000	/* possessor can view a key's attributes */
#define KEY_POS_READ	0x02000000	/* possessor can read key payload / view keyring */
#define KEY_POS_WRITE	0x04000000	/* possessor can update key payload / add link to keyring */
#define KEY_POS_SEARCH	0x08000000	/* possessor can find a key in search / search a keyring */
#define KEY_POS_LINK	0x10000000	/* possessor can create a link to a key/keyring */
#define KEY_POS_SETATTR	0x20000000	/* possessor can set key attributes */
#define KEY_POS_ALL	0x3f000000

#define KEY_USR_VIEW	0x00010000	/* user permissions... */
#define KEY_USR_READ	0x00020000
#define KEY_USR_WRITE	0x00040000
#define KEY_USR_SEARCH	0x00080000
#define KEY_USR_LINK	0x00100000
#define KEY_USR_SETATTR	0x00200000
#define KEY_USR_ALL	0x003f0000

#define KEY_GRP_VIEW	0x00000100	/* group permissions... */
#define KEY_GRP_READ	0x00000200
#define KEY_GRP_WRITE	0x00000400
#define KEY_GRP_SEARCH	0x00000800
#define KEY_GRP_LINK	0x00001000
#define KEY_GRP_SETATTR	0x00002000
#define KEY_GRP_ALL	0x00003f00

#define KEY_OTH_VIEW	0x00000001	/* third party permissions... */
#define KEY_OTH_READ	0x00000002
#define KEY_OTH_WRITE	0x00000004
#define KEY_OTH_SEARCH	0x00000008
#define KEY_OTH_LINK	0x00000010
#define KEY_OTH_SETATTR	0x00000020
#define KEY_OTH_ALL	0x0000003f

#define KEY_PERM_UNDEF	0xffffffff

struct seq_file;
struct user_struct;
struct signal_struct;
struct cred;

struct key_type;
struct key_owner;
struct keyring_list;
struct keyring_name;

struct keyring_index_key {
	struct key_type		*type;
	const char		*description;
	size_t			desc_len;
};

union key_payload {
	void __rcu		*rcu_data0;
	void			*data[4];
};

/*****************************************************************************/
/*
 * key reference with possession attribute handling
 *
 * NOTE! key_ref_t is a typedef'd pointer to a type that is not actually
 * defined. This is because we abuse the bottom bit of the reference to carry a
 * flag to indicate whether the calling process possesses that key in one of
 * its keyrings.
 *
 * the key_ref_t has been made a separate type so that the compiler can reject
 * attempts to dereference it without proper conversion.
 *
 * the three functions are used to assemble and disassemble references
 */
typedef struct __key_reference_with_attributes *key_ref_t;

static inline key_ref_t make_key_ref(const struct key *key,
				     bool possession)
{
	return (key_ref_t) ((unsigned long) key | possession);
}

static inline struct key *key_ref_to_ptr(const key_ref_t key_ref)
{
	return (struct key *) ((unsigned long) key_ref & ~1UL);
}

static inline bool is_key_possessed(const key_ref_t key_ref)
{
	return (unsigned long) key_ref & 1UL;
}

enum key_state {
	KEY_IS_UNINSTANTIATED,
	KEY_IS_POSITIVE,		/* Positively instantiated */
};

/*****************************************************************************/
/*
 * authentication token / access credential / keyring
 * - types of key include:
 *   - keyrings
 *   - disk encryption IDs
 *   - Kerberos TGTs and tickets
 */
struct key {
	atomic_t		usage;		/* number of references */
	key_serial_t		serial;		/* key serial number */
	union {
		struct list_head graveyard_link;
		struct rb_node	serial_node;
	};
	struct rw_semaphore	sem;		/* change vs change sem */
	struct key_user		*user;		/* owner of this key */
	void			*security;	/* security data for this key */
	union {
		time_t		expiry;		/* time at which key expires (or 0) */
		time_t		revoked_at;	/* time at which key was revoked */
	};
	time_t			last_used_at;	/* last time used for LRU keyring discard */
	kuid_t			uid;
	kgid_t			gid;
	key_perm_t		perm;		/* access permissions */
	unsigned short		quotalen;	/* length added to quota */
	unsigned short		datalen;	/* payload data length
						 * - may not match RCU dereferenced payload
						 * - payload should contain own length
						 */
	short			state;		/* Key state (+) or rejection error (-) */

#ifdef KEY_DEBUGGING
	unsigned		magic;
#define KEY_DEBUG_MAGIC		0x18273645u
#define KEY_DEBUG_MAGIC_X	0xf8e9dacbu
#endif

	unsigned long		flags;		/* status flags (change with bitops) */
#define KEY_FLAG_DEAD		0	/* set if key type has been deleted */
#define KEY_FLAG_REVOKED	1	/* set if key had been revoked */
#define KEY_FLAG_IN_QUOTA	2	/* set if key consumes quota */
#define KEY_FLAG_USER_CONSTRUCT	3	/* set if key is being constructed in userspace */
#define KEY_FLAG_ROOT_CAN_CLEAR	4	/* set if key can be cleared by root without permission */
#define KEY_FLAG_INVALIDATED	5	/* set if key has been invalidated */
#define KEY_FLAG_BUILTIN	6	/* set if key is built in to the kernel */
#define KEY_FLAG_ROOT_CAN_INVAL	7	/* set if key can be invalidated by root without permission */
#define KEY_FLAG_KEEP		8	/* set if key should not be removed */
#define KEY_FLAG_UID_KEYRING	9	/* set if key is a user or user session keyring */

	/* the key type and key description string
	 * - the desc is used to match a key against search criteria
	 * - it should be a printable string
	 * - eg: for krb5 AFS, this might be "afs@REDHAT.COM"
	 */
	union {
		struct keyring_index_key index_key;
		struct {
			struct key_type	*type;		/* type of key */
			char		*description;
		};
	};

	/* key data
	 * - this is used to hold the data actually used in cryptography or
	 *   whatever
	 */
	union {
		union key_payload payload;
		struct {
			/* Keyring bits */
			struct list_head name_link;
			struct assoc_array keys;
		};
	};

	/* This is set on a keyring to restrict the addition of a link to a key
	 * to it.  If this method isn't provided then it is assumed that the
	 * keyring is open to any addition.  It is ignored for non-keyring
	 * keys.
	 *
	 * This is intended for use with rings of trusted keys whereby addition
	 * to the keyring needs to be controlled.  KEY_ALLOC_BYPASS_RESTRICTION
	 * overrides this, allowing the kernel to add extra keys without
	 * restriction.
	 */
	int (*restrict_link)(struct key *keyring,
			     const struct key_type *type,
			     const union key_payload *payload);
};

extern struct key *key_alloc(struct key_type *type,
			     const char *desc,
			     kuid_t uid, kgid_t gid,
			     const struct cred *cred,
			     key_perm_t perm,
			     unsigned long flags,
			     int (*restrict_link)(struct key *,
						  const struct key_type *,
						  const union key_payload *));


#define KEY_ALLOC_IN_QUOTA		0x0000	/* add to quota, reject if would overrun */
#define KEY_ALLOC_QUOTA_OVERRUN		0x0001	/* add to quota, permit even if overrun */
#define KEY_ALLOC_NOT_IN_QUOTA		0x0002	/* not in quota */
#define KEY_ALLOC_BUILT_IN		0x0004	/* Key is built into kernel */
#define KEY_ALLOC_BYPASS_RESTRICTION	0x0008	/* Override the check on restricted keyrings */
#define KEY_ALLOC_UID_KEYRING		0x0010	/* allocating a user or user session keyring */

extern void key_revoke(struct key *key);
extern void key_invalidate(struct key *key);
extern void key_put(struct key *key);

static inline struct key *__key_get(struct key *key)
{
	atomic_inc(&key->usage);
	return key;
}

static inline struct key *key_get(struct key *key)
{
	return key ? __key_get(key) : key;
}

static inline void key_ref_put(key_ref_t key_ref)
{
	key_put(key_ref_to_ptr(key_ref));
}

extern struct key *request_key(struct key_type *type,
			       const char *description,
			       const char *callout_info);

extern struct key *request_key_with_auxdata(struct key_type *type,
					    const char *description,
					    const void *callout_info,
					    size_t callout_len,
					    void *aux);

extern struct key *request_key_async(struct key_type *type,
				     const char *description,
				     const void *callout_info,
				     size_t callout_len);

extern struct key *request_key_async_with_auxdata(struct key_type *type,
						  const char *description,
						  const void *callout_info,
						  size_t callout_len,
						  void *aux);

extern int wait_for_key_construction(struct key *key, bool intr);

extern int key_validate(const struct key *key);

extern key_ref_t key_create_or_update(key_ref_t keyring,
				      const char *type,
				      const char *description,
				      const void *payload,
				      size_t plen,
				      key_perm_t perm,
				      unsigned long flags);

extern int key_update(key_ref_t key,
		      const void *payload,
		      size_t plen);

extern int key_link(struct key *keyring,
		    struct key *key);

extern int key_unlink(struct key *keyring,
		      struct key *key);

extern struct key *keyring_alloc(const char *description, kuid_t uid, kgid_t gid,
				 const struct cred *cred,
				 key_perm_t perm,
				 unsigned long flags,
				 int (*restrict_link)(struct key *,
						      const struct key_type *,
						      const union key_payload *),
				 struct key *dest);

extern int restrict_link_reject(struct key *keyring,
				const struct key_type *type,
				const union key_payload *payload);

extern int keyring_clear(struct key *keyring);

extern key_ref_t keyring_search(key_ref_t keyring,
				struct key_type *type,
				const char *description);

extern int keyring_add_key(struct key *keyring,
			   struct key *key);

extern struct key *key_lookup(key_serial_t id);

static inline key_serial_t key_serial(const struct key *key)
{
	return key ? key->serial : 0;
}

extern void key_set_timeout(struct key *, unsigned);

/*
 * The permissions required on a key that we're looking up.
 */
#define	KEY_NEED_VIEW	0x01	/* Require permission to view attributes */
#define	KEY_NEED_READ	0x02	/* Require permission to read content */
#define	KEY_NEED_WRITE	0x04	/* Require permission to update / modify */
#define	KEY_NEED_SEARCH	0x08	/* Require permission to search (keyring) or find (key) */
#define	KEY_NEED_LINK	0x10	/* Require permission to link */
#define	KEY_NEED_SETATTR 0x20	/* Require permission to change attributes */
#define	KEY_NEED_ALL	0x3f	/* All the above permissions */

static inline short key_read_state(const struct key *key)
{
	/* Barrier versus mark_key_instantiated(). */
	return smp_load_acquire(&key->state);
}

/**
 * key_is_positive - Determine if a key has been positively instantiated
 * @key: The key to check.
 *
 * Return true if the specified key has been positively instantiated, false
 * otherwise.
 */
static inline bool key_is_positive(const struct key *key)
{
	return key_read_state(key) == KEY_IS_POSITIVE;
}

static inline bool key_is_negative(const struct key *key)
{
	return key_read_state(key) < 0;
}

#define rcu_dereference_key(KEY)					\
	(rcu_dereference_protected((KEY)->payload.rcu_data0,		\
				   rwsem_is_locked(&((struct key *)(KEY))->sem)))

#define rcu_assign_keypointer(KEY, PAYLOAD)				\
do {									\
	rcu_assign_pointer((KEY)->payload.rcu_data0, (PAYLOAD));	\
} while (0)

#ifdef CONFIG_SYSCTL
extern struct ctl_table key_sysctls[];
#endif
/*
 * the userspace interface
 */
extern int install_thread_keyring_to_cred(struct cred *cred);
extern void key_fsuid_changed(struct task_struct *tsk);
extern void key_fsgid_changed(struct task_struct *tsk);
extern void key_init(void);

#else /* CONFIG_KEYS */

#define key_validate(k)			0
#define key_serial(k)			0
#define key_get(k) 			({ NULL; })
#define key_revoke(k)			do { } while(0)
#define key_invalidate(k)		do { } while(0)
#define key_put(k)			do { } while(0)
#define key_ref_put(k)			do { } while(0)
#define make_key_ref(k, p)		NULL
#define key_ref_to_ptr(k)		NULL
#define is_key_possessed(k)		0
#define key_fsuid_changed(t)		do { } while(0)
#define key_fsgid_changed(t)		do { } while(0)
#define key_init()			do { } while(0)

#endif /* CONFIG_KEYS */
#endif /* __KERNEL__ */
#endif /* _LINUX_KEY_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #ifndef _LINUX_SEM_H
#define _LINUX_SEM_H

#include <linux/atomic.h>
#include <linux/rcupdate.h>
#include <linux/cache.h>
#include <uapi/linux/sem.h>

struct task_struct;

/* One sem_array data structure for each set of semaphores in the system. */
struct sem_array {
	struct kern_ipc_perm	____cacheline_aligned_in_smp
				sem_perm;	/* permissions .. see ipc.h */
	time_t			sem_ctime;	/* last change time */
	struct sem		*sem_base;	/* ptr to first semaphore in array */
	struct list_head	pending_alter;	/* pending operations */
						/* that alter the array */
	struct list_head	pending_const;	/* pending complex operations */
						/* that do not alter semvals */
	struct list_head	list_id;	/* undo requests on this array */
	int			sem_nsems;	/* no. of semaphores in array */
	int			complex_count;	/* pending complex operations */
	bool			complex_mode;	/* no parallel simple ops */
};

#ifdef CONFIG_SYSVIPC

struct sysv_sem {
	struct sem_undo_list *undo_list;
};

extern int copy_semundo(unsigned long clone_flags, struct task_struct *tsk);
extern void exit_sem(struct task_struct *tsk);

#else

struct sysv_sem {
	/* empty */
};

static inline int copy_semundo(unsigned long clone_flags, struct task_struct *tsk)
{
	return 0;
}

static inline void exit_sem(struct task_struct *tsk)
{
	return;
}
#endif

#endif /* _LINUX_SEM_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /*
 * Common functions for in-kernel torture tests.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, you can access it online at
 * http://www.gnu.org/licenses/gpl-2.0.html.
 *
 * Copyright IBM Corporation, 2014
 *
 * Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
 */

#ifndef __LINUX_TORTURE_H
#define __LINUX_TORTURE_H

#include <linux/types.h>
#include <linux/cache.h>
#include <linux/spinlock.h>
#include <linux/threads.h>
#include <linux/cpumask.h>
#include <linux/seqlock.h>
#include <linux/lockdep.h>
#include <linux/completion.h>
#include <linux/debugobjects.h>
#include <linux/bug.h>
#include <linux/compiler.h>

/* Definitions for a non-string torture-test module parameter. */
#define torture_param(type, name, init, msg) \
	static type name = init; \
	module_param(name, type, 0444); \
	MODULE_PARM_DESC(name, msg);

#define TORTURE_FLAG "-torture:"
#define TOROUT_STRING(s) \
	pr_alert("%s" TORTURE_FLAG " %s\n", torture_type, s)
#define VERBOSE_TOROUT_STRING(s) \
	do { if (verbose) pr_alert("%s" TORTURE_FLAG " %s\n", torture_type, s); } while (0)
#define VERBOSE_TOROUT_ERRSTRING(s) \
	do { if (verbose) pr_alert("%s" TORTURE_FLAG "!!! %s\n", torture_type, s); } while (0)

/* Definitions for online/offline exerciser. */
bool torture_offline(int cpu, long *n_onl_attempts, long *n_onl_successes,
		     unsigned long *sum_offl, int *min_onl, int *max_onl);
bool torture_online(int cpu, long *n_onl_attempts, long *n_onl_successes,
		    unsigned long *sum_onl, int *min_onl, int *max_onl);
int torture_onoff_init(long ooholdoff, long oointerval);
void torture_onoff_stats(void);
bool torture_onoff_failures(void);

/* Low-rider random number generator. */
struct torture_random_state {
	unsigned long trs_state;
	long trs_count;
};
#define DEFINE_TORTURE_RANDOM(name) struct torture_random_state name = { 0, 0 }
unsigned long torture_random(struct torture_random_state *trsp);

/* Task shuffler, which causes CPUs to occasionally go idle. */
void torture_shuffle_task_register(struct task_struct *tp);
int torture_shuffle_init(long shuffint);

/* Test auto-shutdown handling. */
void torture_shutdown_absorb(const char *title);
int torture_shutdown_init(int ssecs, void (*cleanup)(void));

/* Task stuttering, which forces load/no-load transitions. */
void stutter_wait(const char *title);
int torture_stutter_init(int s);

/* Initialization and cleanup. */
bool torture_init_begin(char *ttype, bool v, int *runnable);
void torture_init_end(void);
bool torture_cleanup_begin(void);
void torture_cleanup_end(void);
bool torture_must_stop(void);
bool torture_must_stop_irq(void);
void torture_kthread_stopping(char *title);
int _torture_create_kthread(int (*fn)(void *arg), void *arg, char *s, char *m,
			     char *f, struct task_struct **tp);
void _torture_stop_kthread(char *m, struct task_struct **tp);

#define torture_create_kthread(n, arg, tp) \
	_torture_create_kthread(n, (arg), #n, "Creating " #n " task", \
				"Failed to create " #n, &(tp))
#define torture_stop_kthread(n, tp) \
	_torture_stop_kthread("Stopping " #n " task", &(tp))

#endif /* __LINUX_TORTURE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                #ifndef __LINUX_SOC_RENESAS_RCAR_SYSC_H__
#define __LINUX_SOC_RENESAS_RCAR_SYSC_H__

#include <linux/types.h>

struct rcar_sysc_ch {
	u16 chan_offs;
	u8 chan_bit;
	u8 isr_bit;
};

int rcar_sysc_power_down(const struct rcar_sysc_ch *sysc_ch);
int rcar_sysc_power_up(const struct rcar_sysc_ch *sysc_ch);
void rcar_sysc_init(phys_addr_t base, u32 syscier);

#endif /* __LINUX_SOC_RENESAS_RCAR_SYSC_H__ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              #ifndef LINUX_SOC_DOVE_PMU_H
#define LINUX_SOC_DOVE_PMU_H

#include <linux/types.h>

struct dove_pmu_domain_initdata {
	u32 pwr_mask;
	u32 rst_mask;
	u32 iso_mask;
	const char *name;
};

struct dove_pmu_initdata {
	void __iomem *pmc_base;
	void __iomem *pmu_base;
	int irq;
	int irq_domain_start;
	const struct dove_pmu_domain_initdata *domains;
};

int dove_init_pmu_legacy(const struct dove_pmu_initdata *);

int dove_init_pmu(void);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    #ifndef __BRCMSTB_SOC_H
#define __BRCMSTB_SOC_H

/*
 * Bus Interface Unit control register setup, must happen early during boot,
 * before SMP is brought up, called by machine entry point.
 */
void brcmstb_biuctrl_init(void);

#endif /* __BRCMSTB_SOC_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                /*
 * Copyright (C) 2014 Texas Instruments Incorporated
 * Authors:	Sandeep Nair <sandeep_n@ti.com
 *		Cyril Chemparathy <cyril@ti.com
		Santosh Shilimkar <santosh.shilimkar@ti.com>
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License as
 * published by the Free Software Foundation version 2.
 *
 * This program is distributed "as is" WITHOUT ANY WARRANTY of any
 * kind, whether express or implied; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

#ifndef __SOC_TI_KEYSTONE_NAVIGATOR_DMA_H__
#define __SOC_TI_KEYSTONE_NAVIGATOR_DMA_H__

/*
 * PKTDMA descriptor manipulation macros for host packet descriptor
 */
#define MASK(x)					(BIT(x) - 1)
#define KNAV_DMA_DESC_PKT_LEN_MASK		MASK(22)
#define KNAV_DMA_DESC_PKT_LEN_SHIFT		0
#define KNAV_DMA_DESC_PS_INFO_IN_SOP		BIT(22)
#define KNAV_DMA_DESC_PS_INFO_IN_DESC		0
#define KNAV_DMA_DESC_TAG_MASK			MASK(8)
#define KNAV_DMA_DESC_SAG_HI_SHIFT		24
#define KNAV_DMA_DESC_STAG_LO_SHIFT		16
#define KNAV_DMA_DESC_DTAG_HI_SHIFT		8
#define KNAV_DMA_DESC_DTAG_LO_SHIFT		0
#define KNAV_DMA_DESC_HAS_EPIB			BIT(31)
#define KNAV_DMA_DESC_NO_EPIB			0
#define KNAV_DMA_DESC_PSLEN_SHIFT		24
#define KNAV_DMA_DESC_PSLEN_MASK		MASK(6)
#define KNAV_DMA_DESC_ERR_FLAG_SHIFT		20
#define KNAV_DMA_DESC_ERR_FLAG_MASK		MASK(4)
#define KNAV_DMA_DESC_PSFLAG_SHIFT		16
#define KNAV_DMA_DESC_PSFLAG_MASK		MASK(4)
#define KNAV_DMA_DESC_RETQ_SHIFT		0
#define KNAV_DMA_DESC_RETQ_MASK			MASK(14)
#define KNAV_DMA_DESC_BUF_LEN_MASK		MASK(22)

#define KNAV_DMA_NUM_EPIB_WORDS			4
#define KNAV_DMA_NUM_PS_WORDS			16
#define KNAV_DMA_NUM_SW_DATA_WORDS		4
#define KNAV_DMA_FDQ_PER_CHAN			4

/* Tx channel scheduling priority */
enum knav_dma_tx_priority {
	DMA_PRIO_HIGH	= 0,
	DMA_PRIO_MED_H,
	DMA_PRIO_MED_L,
	DMA_PRIO_LOW
};

/* Rx channel error handling mode during buffer starvation */
enum knav_dma_rx_err_mode {
	DMA_DROP = 0,
	DMA_RETRY
};

/* Rx flow size threshold configuration */
enum knav_dma_rx_thresholds {
	DMA_THRESH_NONE		= 0,
	DMA_THRESH_0		= 1,
	DMA_THRESH_0_1		= 3,
	DMA_THRESH_0_1_2	= 7
};

/* Descriptor type */
enum knav_dma_desc_type {
	DMA_DESC_HOST = 0,
	DMA_DESC_MONOLITHIC = 2
};

/**
 * struct knav_dma_tx_cfg:	Tx channel configuration
 * @filt_einfo:			Filter extended packet info
 * @filt_pswords:		Filter PS words present
 * @knav_dma_tx_priority:	Tx channel scheduling priority
 */
struct knav_dma_tx_cfg {
	bool				filt_einfo;
	bool				filt_pswords;
	enum knav_dma_tx_priority	priority;
};

/**
 * struct knav_dma_rx_cfg:	Rx flow configuration
 * @einfo_present:		Extended packet info present
 * @psinfo_present:		PS words present
 * @knav_dma_rx_err_mode:	Error during buffer starvation
 * @knav_dma_desc_type:	Host or Monolithic desc
 * @psinfo_at_sop:		PS word located at start of packet
 * @sop_offset:			Start of packet offset
 * @dst_q:			Destination queue for a given flow
 * @thresh:			Rx flow size threshold
 * @fdq[]:			Free desc Queue array
 * @sz_thresh0:			RX packet size threshold 0
 * @sz_thresh1:			RX packet size threshold 1
 * @sz_thresh2:			RX packet size threshold 2
 */
struct knav_dma_rx_cfg {
	bool				einfo_present;
	bool				psinfo_present;
	enum knav_dma_rx_err_mode	err_mode;
	enum knav_dma_desc_type		desc_type;
	bool				psinfo_at_sop;
	unsigned int			sop_offset;
	unsigned int			dst_q;
	enum knav_dma_rx_thresholds	thresh;
	unsigned int			fdq[KNAV_DMA_FDQ_PER_CHAN];
	unsigned int			sz_thresh0;
	unsigned int			sz_thresh1;
	unsigned int			sz_thresh2;
};

/**
 * struct knav_dma_cfg:	Pktdma channel configuration
 * @sl_cfg:			Slave configuration
 * @tx:				Tx channel configuration
 * @rx:				Rx flow configuration
 */
struct knav_dma_cfg {
	enum dma_transfer_direction direction;
	union {
		struct knav_dma_tx_cfg	tx;
		struct knav_dma_rx_cfg	rx;
	} u;
};

/**
 * struct knav_dma_desc:	Host packet descriptor layout
 * @desc_info:			Descriptor information like id, type, length
 * @tag_info:			Flow tag info written in during RX
 * @packet_info:		Queue Manager, policy, flags etc
 * @buff_len:			Buffer length in bytes
 * @buff:			Buffer pointer
 * @next_desc:			For chaining the descriptors
 * @orig_len:			length since 'buff_len' can be overwritten
 * @orig_buff:			buff pointer since 'buff' can be overwritten
 * @epib:			Extended packet info block
 * @psdata:			Protocol specific
 * @sw_data:			Software private data not touched by h/w
 */
struct knav_dma_desc {
	__le32	desc_info;
	__le32	tag_info;
	__le32	packet_info;
	__le32	buff_len;
	__le32	buff;
	__le32	next_desc;
	__le32	orig_len;
	__le32	orig_buff;
	__le32	epib[KNAV_DMA_NUM_EPIB_WORDS];
	__le32	psdata[KNAV_DMA_NUM_PS_WORDS];
	u32	sw_data[KNAV_DMA_NUM_SW_DATA_WORDS];
} ____cacheline_aligned;

#if IS_ENABLED(CONFIG_KEYSTONE_NAVIGATOR_DMA)
void *knav_dma_open_channel(struct device *dev, const char *name,
				struct knav_dma_cfg *config);
void knav_dma_close_channel(void *channel);
#else
static inline void *knav_dma_open_channel(struct device *dev, const char *name,
				struct knav_dma_cfg *config)
{
	return (void *) NULL;
}
static inline void knav_dma_close_channel(void *channel)
{}

#endif

#endif /* __SOC_TI_KEYSTONE_NAVIGATOR_DMA_H__ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /*
 * Texas Instruments' Message Manager
 *
 * Copyright (C) 2015-2016 Texas Instruments Incorporated - http://www.ti.com/
 *	Nishanth Menon
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 *
 * This program is distributed "as is" WITHOUT ANY WARRANTY of any
 * kind, whether express or implied; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

#ifndef TI_MSGMGR_H
#define TI_MSGMGR_H

/**
 * struct ti_msgmgr_message - Message Manager structure
 * @len: Length of data in the Buffer
 * @buf: Buffer pointer
 *
 * This is the structure for data used in mbox_send_message
 * the length of data buffer used depends on the SoC integration
 * parameters - each message may be 64, 128 bytes long depending
 * on SoC. Client is supposed to be aware of this.
 */
struct ti_msgmgr_message {
	size_t len;
	u8 *buf;
};

#endif /* TI_MSGMGR_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /*
 * Keystone Navigator Queue Management Sub-System header
 *
 * Copyright (C) 2014 Texas Instruments Incorporated - http://www.ti.com
 * Author:	Sandeep Nair <sandeep_n@ti.com>
 *		Cyril Chemparathy <cyril@ti.com>
 *		Santosh Shilimkar <santosh.shilimkar@ti.com>
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License as
 * published by the Free Software Foundation version 2.
 *
 * This program is distributed "as is" WITHOUT ANY WARRANTY of any
 * kind, whether express or implied; without even the implied warranty
 * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 */

#ifndef __SOC_TI_KNAV_QMSS_H__
#define __SOC_TI_KNAV_QMSS_H__

#include <linux/err.h>
#include <linux/time.h>
#include <linux/atomic.h>
#include <linux/device.h>
#include <linux/fcntl.h>
#include <linux/dma-mapping.h>

/* queue types */
#define KNAV_QUEUE_QPEND	((unsigned)-2) /* interruptible qpend queue */
#define KNAV_QUEUE_ACC		((unsigned)-3) /* Accumulated queue */
#define KNAV_QUEUE_GP		((unsigned)-4) /* General purpose queue */

/* queue flags */
#define KNAV_QUEUE_SHARED	0x0001		/* Queue can be shared */

/**
 * enum knav_queue_ctrl_cmd -	queue operations.
 * @KNAV_QUEUE_GET_ID:		Get the ID number for an open queue
 * @KNAV_QUEUE_FLUSH:		forcibly empty a queue if possible
 * @KNAV_QUEUE_SET_NOTIFIER:	Set a notifier callback to a queue handle.
 * @KNAV_QUEUE_ENABLE_NOTIFY:	Enable notifier callback for a queue handle.
 * @KNAV_QUEUE_DISABLE_NOTIFY:	Disable notifier callback for a queue handle.
 * @KNAV_QUEUE_GET_COUNT:	Get number of queues.
 */
enum knav_queue_ctrl_cmd {
	KNAV_QUEUE_GET_ID,
	KNAV_QUEUE_FLUSH,
	KNAV_QUEUE_SET_NOTIFIER,
	KNAV_QUEUE_ENABLE_NOTIFY,
	KNAV_QUEUE_DISABLE_NOTIFY,
	KNAV_QUEUE_GET_COUNT
};

/* Queue notifier callback prototype */
typedef void (*knav_queue_notify_fn)(void *arg);

/**
 * struct knav_queue_notify_config:	Notifier configuration
 * @fn:					Notifier function
 * @fn_arg:				Notifier function arguments
 */
struct knav_queue_notify_config {
	knav_queue_notify_fn fn;
	void *fn_arg;
};

void *knav_queue_open(const char *name, unsigned id,
					unsigned flags);
void knav_queue_close(void *qhandle);
int knav_queue_device_control(void *qhandle,
				enum knav_queue_ctrl_cmd cmd,
				unsigned long arg);
dma_addr_t knav_queue_pop(void *qhandle, unsigned *size);
int knav_queue_push(void *qhandle, dma_addr_t dma,
				unsigned size, unsigned flags);

void *knav_pool_create(const char *name,
				int num_desc, int region_id);
void knav_pool_destroy(void *ph);
int knav_pool_count(void *ph);
void *knav_pool_desc_get(void *ph);
void knav_pool_desc_put(void *ph, void *desc);
int knav_pool_desc_map(void *ph, void *desc, unsigned size,
					dma_addr_t *dma, unsigned *dma_sz);
void *knav_pool_desc_unmap(void *ph, dma_addr_t dma, unsigned dma_sz);
dma_addr_t knav_pool_desc_virt_to_dma(void *ph, void *virt);
void *knav_pool_desc_dma_to_virt(void *ph, dma_addr_t dma);

#endif /* __SOC_TI_KNAV_QMSS_H__ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          /*
 * Copyright (c) 2014 Samsung Electronics Co., Ltd.
 *		http://www.samsung.com
 *
 * Header for EXYNOS PMU Driver support
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */

#ifndef __LINUX_SOC_EXYNOS_PMU_H
#define __LINUX_SOC_EXYNOS_PMU_H

enum sys_powerdown {
	SYS_AFTR,
	SYS_LPA,
	SYS_SLEEP,
	NUM_SYS_POWERDOWN,
};

extern void exynos_sys_powerdown_conf(enum sys_powerdown mode);

#endif /* __LINUX_SOC_EXYNOS_PMU_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        /*
 * Copyright (c) 2010-2012 Samsung Electronics Co., Ltd.
 *		http://www.samsung.com
 *
 * EXYNOS - Power management unit definition
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
*/

#ifndef __LINUX_SOC_EXYNOS_REGS_PMU_H
#define __LINUX_SOC_EXYNOS_REGS_PMU_H __FILE__

#define S5P_CENTRAL_SEQ_CONFIGURATION		0x0200

#define S5P_CENTRAL_LOWPWR_CFG			(1 << 16)

#define S5P_CENTRAL_SEQ_OPTION			0x0208

#define S5P_USE_STANDBY_WFI0			(1 << 16)
#define S5P_USE_STANDBY_WFI1			(1 << 17)
#define S5P_USE_STANDBY_WFI2			(1 << 19)
#define S5P_USE_STANDBY_WFI3			(1 << 20)
#define S5P_USE_STANDBY_WFE0			(1 << 24)
#define S5P_USE_STANDBY_WFE1			(1 << 25)
#define S5P_USE_STANDBY_WFE2			(1 << 27)
#define S5P_USE_STANDBY_WFE3			(1 << 28)

#define S5P_USE_STANDBY_WFI_ALL \
	(S5P_USE_STANDBY_WFI0 | S5P_USE_STANDBY_WFI1 | \
	 S5P_USE_STANDBY_WFI2 | S5P_USE_STANDBY_WFI3 | \
	 S5P_USE_STANDBY_WFE0 | S5P_USE_STANDBY_WFE1 | \
	 S5P_USE_STANDBY_WFE2 | S5P_USE_STANDBY_WFE3)

#define S5P_USE_DELAYED_RESET_ASSERTION		BIT(12)

#define EXYNOS_CORE_PO_RESET(n)			((1 << 4) << n)
#define EXYNOS_WAKEUP_FROM_LOWPWR		(1 << 28)
#define EXYNOS_SWRESET				0x0400
#define EXYNOS5440_SWRESET			0x00C4

#define S5P_WAKEUP_STAT				0x0600
#define S5P_EINT_WAKEUP_MASK			0x0604
#define S5P_WAKEUP_MASK				0x0608
#define S5P_WAKEUP_MASK2				0x0614

#define S5P_INFORM0				0x0800
#define S5P_INFORM1				0x0804
#define S5P_INFORM5				0x0814
#define S5P_INFORM6				0x0818
#define S5P_INFORM7				0x081C
#define S5P_PMU_SPARE2				0x0908
#define S5P_PMU_SPARE3				0x090C

#define EXYNOS_IROM_DATA2			0x0988
#define S5P_ARM_CORE0_LOWPWR			0x1000
#define S5P_DIS_IRQ_CORE0			0x1004
#define S5P_DIS_IRQ_CENTRAL0			0x1008
#define S5P_ARM_CORE1_LOWPWR			0x1010
#define S5P_DIS_IRQ_CORE1			0x1014
#define S5P_DIS_IRQ_CENTRAL1			0x1018
#define S5P_ARM_COMMON_LOWPWR			0x1080
#define S5P_L2_0_LOWPWR				0x10C0
#define S5P_L2_1_LOWPWR				0x10C4
#define S5P_CMU_ACLKSTOP_LOWPWR			0x1100
#define S5P_CMU_SCLKSTOP_LOWPWR			0x1104
#define S5P_CMU_RESET_LOWPWR			0x110C
#define S5P_APLL_SYSCLK_LOWPWR			0x1120
#define S5P_MPLL_SYSCLK_LOWPWR			0x1124
#define S5P_VPLL_SYSCLK_LOWPWR			0x1128
#define S5P_EPLL_SYSCLK_LOWPWR			0x112C
#define S5P_CMU_CLKSTOP_GPS_ALIVE_LOWPWR	0x1138
#define S5P_CMU_RESET_GPSALIVE_LOWPWR		0x113C
#define S5P_CMU_CLKSTOP_CAM_LOWPWR		0x1140
#define S5P_CMU_CLKSTOP_TV_LOWPWR		0x1144
#define S5P_CMU_CLKSTOP_MFC_LOWPWR		0x1148
#define S5P_CMU_CLKSTOP_G3D_LOWPWR		0x114C
#define S5P_CMU_CLKSTOP_LCD0_LOWPWR		0x1150
#define S5P_CMU_CLKSTOP_MAUDIO_LOWPWR		0x1158
#define S5P_CMU_CLKSTOP_GPS_LOWPWR		0x115C
#define S5P_CMU_RESET_CAM_LOWPWR		0x1160
#define S5P_CMU_RESET_TV_LOWPWR			0x1164
#define S5P_CMU_RESET_MFC_LOWPWR		0x1168
#define S5P_CMU_RESET_G3D_LOWPWR		0x116C
#define S5P_CMU_RESET_LCD0_LOWPWR		0x1170
#define S5P_CMU_RESET_MAUDIO_LOWPWR		0x1178
#define S5P_CMU_RESET_GPS_LOWPWR		0x117C
#define S5P_TOP_BUS_LOWPWR			0x1180
#define S5P_TOP_RETENTION_LOWPWR		0x1184
#define S5P_TOP_PWR_LOWPWR			0x1188
#define S5P_LOGIC_RESET_LOWPWR			0x11A0
#define S5P_ONENAND_MEM_LOWPWR			0x11C0
#define S5P_G2D_ACP_MEM_LOWPWR			0x11C8
#define S5P_USBOTG_MEM_LOWPWR			0x11CC
#define S5P_HSMMC_MEM_LOWPWR			0x11D0
#define S5P_CSSYS_MEM_LOWPWR			0x11D4
#define S5P_SECSS_MEM_LOWPWR			0x11D8
#define S5P_PAD_RETENTION_DRAM_LOWPWR		0x1200
#define S5P_PAD_RETENTION_MAUDIO_LOWPWR		0x1204
#define S5P_PAD_RETENTION_GPIO_LOWPWR		0x1220
#define S5P_PAD_RETENTION_UART_LOWPWR		0x1224
#define S5P_PAD_RETENTION_MMCA_LOWPWR		0x1228
#define S5P_PAD_RETENTION_MMCB_LOWPWR		0x122C
#define S5P_PAD_RETENTION_EBIA_LOWPWR		0x1230
#define S5P_PAD_RETENTION_EBIB_LOWPWR		0x1234
#define S5P_PAD_RETENTION_ISOLATION_LOWPWR	0x1240
#define S5P_PAD_RETENTION_ALV_SEL_LOWPWR	0x1260
#define S5P_XUSBXTI_LOWPWR			0x1280
#define S5P_XXTI_LOWPWR				0x1284
#define S5P_EXT_REGULATOR_LOWPWR		0x12C0
#define S5P_GPIO_MODE_LOWPWR			0x1300
#define S5P_GPIO_MODE_MAUDIO_LOWPWR		0x1340
#define S5P_CAM_LOWPWR				0x1380
#define S5P_TV_LOWPWR				0x1384
#define S5P_MFC_LOWPWR				0x1388
#define S5P_G3D_LOWPWR				0x138C
#define S5P_LCD0_LOWPWR				0x1390
#define S5P_MAUDIO_LOWPWR			0x1398
#define S5P_GPS_LOWPWR				0x139C
#define S5P_GPS_ALIVE_LOWPWR			0x13A0

#define EXYNOS_ARM_CORE0_CONFIGURATION		0x2000
#define EXYNOS_ARM_CORE_CONFIGURATION(_nr)	\
			(EXYNOS_ARM_CORE0_CONFIGURATION + (0x80 * (_nr)))
#define EXYNOS_ARM_CORE_STATUS(_nr)		\
			(EXYNOS_ARM_CORE_CONFIGURATION(_nr) + 0x4)
#define EXYNOS_ARM_CORE_OPTION(_nr)		\
			(EXYNOS_ARM_CORE_CONFIGURATION(_nr) + 0x8)

#define EXYNOS_ARM_COMMON_CONFIGURATION		0x2500
#define EXYNOS_COMMON_CONFIGURATION(_nr)	\
			(EXYNOS_ARM_COMMON_CONFIGURATION + (0x80 * (_nr)))
#define EXYNOS_COMMON_STATUS(_nr)		\
			(EXYNOS_COMMON_CONFIGURATION(_nr) + 0x4)
#define EXYNOS_COMMON_OPTION(_nr)		\
			(EXYNOS_COMMON_CONFIGURATION(_nr) + 0x8)

#define EXYNOS_CORE_LOCAL_PWR_EN		0x3

#define EXYNOS_ARM_COMMON_STATUS		0x2504
#define EXYNOS_COMMON_OPTION(_nr)		\
			(EXYNOS_COMMON_CONFIGURATION(_nr) + 0x8)

#define EXYNOS_ARM_L2_CONFIGURATION		0x2600
#define EXYNOS_L2_CONFIGURATION(_nr)		\
			(EXYNOS_ARM_L2_CONFIGURATION + ((_nr) * 0x80))
#define EXYNOS_L2_STATUS(_nr)			\
			(EXYNOS_L2_CONFIGURATION(_nr) + 0x4)
#define EXYNOS_L2_OPTION(_nr)			\
			(EXYNOS_L2_CONFIGURATION(_nr) + 0x8)
#define EXYNOS_L2_COMMON_PWR_EN			0x3

#define EXYNOS_ARM_CORE_X_STATUS_OFFSET		0x4

#define EXYNOS5_APLL_SYSCLK_CONFIGURATION	0x2A00
#define EXYNOS5_APLL_SYSCLK_STATUS		0x2A04

#define EXYNOS5_ARM_L2_OPTION			0x2608
#define EXYNOS5_USE_RETENTION			BIT(4)

#define EXYNOS5_L2RSTDISABLE_VALUE		BIT(3)

#define S5P_PAD_RET_MAUDIO_OPTION		0x3028
#define S5P_PAD_RET_MMC2_OPTION			0x30c8
#define S5P_PAD_RET_GPIO_OPTION			0x3108
#define S5P_PAD_RET_UART_OPTION			0x3128
#define S5P_PAD_RET_MMCA_OPTION			0x3148
#define S5P_PAD_RET_MMCB_OPTION			0x3168
#define S5P_PAD_RET_EBIA_OPTION			0x3188
#define S5P_PAD_RET_EBIB_OPTION			0x31A8
#define S5P_PAD_RET_SPI_OPTION			0x31c8

#define S5P_PS_HOLD_CONTROL			0x330C
#define S5P_PS_HOLD_EN				(1 << 31)
#define S5P_PS_HOLD_OUTPUT_HIGH			(3 << 8)

#define S5P_CAM_OPTION				0x3C08
#define S5P_MFC_OPTION				0x3C48
#define S5P_G3D_OPTION				0x3C68
#define S5P_LCD0_OPTION				0x3C88
#define S5P_LCD1_OPTION				0x3CA8
#define S5P_ISP_OPTION				S5P_LCD1_OPTION

#define S5P_CORE_LOCAL_PWR_EN			0x3
#define S5P_CORE_WAKEUP_FROM_LOCAL_CFG		(0x3 << 8)
#define S5P_CORE_AUTOWAKEUP_EN			(1 << 31)

/* Only for EXYNOS4210 */
#define S5P_CMU_CLKSTOP_LCD1_LOWPWR	0x1154
#define S5P_CMU_RESET_LCD1_LOWPWR	0x1174
#define S5P_MODIMIF_MEM_LOWPWR		0x11C4
#define S5P_PCIE_MEM_LOWPWR		0x11E0
#define S5P_SATA_MEM_LOWPWR		0x11E4
#define S5P_LCD1_LOWPWR			0x1394

/* Only for EXYNOS4x12 */
#define S5P_ISP_ARM_LOWPWR			0x1050
#define S5P_DIS_IRQ_ISP_ARM_LOCAL_LOWPWR	0x1054
#define S5P_DIS_IRQ_ISP_ARM_CENTRAL_LOWPWR	0x1058
#define S5P_CMU_ACLKSTOP_COREBLK_LOWPWR		0x1110
#define S5P_CMU_SCLKSTOP_COREBLK_LOWPWR		0x1114
#define S5P_CMU_RESET_COREBLK_LOWPWR		0x111C
#define S5P_MPLLUSER_SYSCLK_LOWPWR		0x1130
#define S5P_CMU_CLKSTOP_ISP_LOWPWR		0x1154
#define S5P_CMU_RESET_ISP_LOWPWR		0x1174
#define S5P_TOP_BUS_COREBLK_LOWPWR		0x1190
#define S5P_TOP_RETENTION_COREBLK_LOWPWR	0x1194
#define S5P_TOP_PWR_COREBLK_LOWPWR		0x1198
#define S5P_OSCCLK_GATE_LOWPWR			0x11A4
#define S5P_LOGIC_RESET_COREBLK_LOWPWR		0x11B0
#define S5P_OSCCLK_GATE_COREBLK_LOWPWR		0x11B4
#define S5P_HSI_MEM_LOWPWR			0x11C4
#define S5P_ROTATOR_MEM_LOWPWR			0x11DC
#define S5P_PAD_RETENTION_GPIO_COREBLK_LOWPWR	0x123C
#define S5P_PAD_ISOLATION_COREBLK_LOWPWR	0x1250
#define S5P_GPIO_MODE_COREBLK_LOWPWR		0x1320
#define S5P_TOP_ASB_RESET_LOWPWR		0x1344
#define S5P_TOP_ASB_ISOLATION_LOWPWR		0x1348
#define S5P_ISP_LOWPWR				0x1394
#define S5P_DRAM_FREQ_DOWN_LOWPWR		0x13B0
#define S5P_DDRPHY_DLLOFF_LOWPWR		0x13B4
#define S5P_CMU_SYSCLK_ISP_LOWPWR		0x13B8
#define S5P_CMU_SYSCLK_GPS_LOWPWR		0x13BC
#define S5P_LPDDR_PHY_DLL_LOCK_LOWPWR		0x13C0

#define S5P_ARM_L2_0_OPTION			0x2608
#define S5P_ARM_L2_1_OPTION			0x2628
#define S5P_ONENAND_MEM_OPTION			0x2E08
#define S5P_HSI_MEM_OPTION			0x2E28
#define S5P_G2D_ACP_MEM_OPTION			0x2E48
#define S5P_USBOTG_MEM_OPTION			0x2E68
#define S5P_HSMMC_MEM_OPTION			0x2E88
#define S5P_CSSYS_MEM_OPTION			0x2EA8
#define S5P_SECSS_MEM_OPTION			0x2EC8
#define S5P_ROTATOR_MEM_OPTION			0x2F48

/* Only for EXYNOS4412 */
#define S5P_ARM_CORE2_LOWPWR			0x1020
#define S5P_DIS_IRQ_CORE2			0x1024
#define S5P_DIS_IRQ_CENTRAL2			0x1028
#define S5P_ARM_CORE3_LOWPWR			0x1030
#define S5P_DIS_IRQ_CORE3			0x1034
#define S5P_DIS_IRQ_CENTRAL3			0x1038

/* Only for EXYNOS3XXX */
#define EXYNOS3_ARM_CORE0_SYS_PWR_REG			0x1000
#define EXYNOS3_DIS_IRQ_ARM_CORE0_LOCAL_SYS_PWR_REG	0x1004
#define EXYNOS3_DIS_IRQ_ARM_CORE0_CENTRAL_SYS_PWR_REG	0x1008
#define EXYNOS3_ARM_CORE1_SYS_PWR_REG			0x1010
#define EXYNOS3_DIS_IRQ_ARM_CORE1_LOCAL_SYS_PWR_REG	0x1014
#define EXYNOS3_DIS_IRQ_ARM_CORE1_CENTRAL_SYS_PWR_REG	0x1018
#define EXYNOS3_ISP_ARM_SYS_PWR_REG			0x1050
#define EXYNOS3_DIS_IRQ_ISP_ARM_LOCAL_SYS_PWR_REG	0x1054
#define EXYNOS3_DIS_IRQ_ISP_ARM_CENTRAL_SYS_PWR_REG	0x1058
#define EXYNOS3_ARM_COMMON_SYS_PWR_REG			0x1080
#define EXYNOS3_ARM_L2_SYS_PWR_REG			0x10C0
#define EXYNOS3_CMU_ACLKSTOP_SYS_PWR_REG		0x1100
#define EXYNOS3_CMU_SCLKSTOP_SYS_PWR_REG		0x1104
#define EXYNOS3_CMU_RESET_SYS_PWR_REG			0x110C
#define EXYNOS3_CMU_ACLKSTOP_COREBLK_SYS_PWR_REG	0x1110
#define EXYNOS3_CMU_SCLKSTOP_COREBLK_SYS_PWR_REG	0x1114
#define EXYNOS3_CMU_RESET_COREBLK_SYS_PWR_REG		0x111C
#define EXYNOS3_APLL_SYSCLK_SYS_PWR_REG			0x1120
#define EXYNOS3_MPLL_SYSCLK_SYS_PWR_REG			0x1124
#define EXYNOS3_VPLL_SYSCLK_SYS_PWR_REG			0x1128
#define EXYNOS3_EPLL_SYSCLK_SYS_PWR_REG			0x112C
#define EXYNOS3_MPLLUSER_SYSCLK_SYS_PWR_REG		0x1130
#define EXYNOS3_BPLLUSER_SYSCLK_SYS_PWR_REG		0x1134
#define EXYNOS3_EPLLUSER_SYSCLK_SYS_PWR_REG		0x1138
#define EXYNOS3_CMU_CLKSTOP_CAM_SYS_PWR_REG		0x1140
#define EXYNOS3_CMU_CLKSTOP_MFC_SYS_PWR_REG		0x1148
#define EXYNOS3_CMU_CLKSTOP_G3D_SYS_PWR_REG		0x114C
#define EXYNOS3_CMU_CLKSTOP_LCD0_SYS_PWR_REG		0x1150
#define EXYNOS3_CMU_CLKSTOP_ISP_SYS_PWR_REG		0x1154
#define EXYNOS3_CMU_CLKSTOP_MAUDIO_SYS_PWR_REG		0x1158
#define EXYNOS3_CMU_RESET_CAM_SYS_PWR_REG		0x1160
#define EXYNOS3_CMU_RESET_MFC_SYS_PWR_REG		0x1168
#define EXYNOS3_CMU_RESET_G3D_SYS_PWR_REG		0x116C
#define EXYNOS3_CMU_RESET_LCD0_SYS_PWR_REG		0x1170
#define EXYNOS3_CMU_RESET_ISP_SYS_PWR_REG		0x1174
#define EXYNOS3_CMU_RESET_MAUDIO_SYS_PWR_REG		0x1178
#define EXYNOS3_TOP_BUS_SYS_PWR_REG			0x1180
#define EXYNOS3_TOP_RETENTION_SYS_PWR_REG		0x1184
#define EXYNOS3_TOP_PWR_SYS_PWR_REG			0x1188
#define EXYNOS3_TOP_BUS_COREBLK_SYS_PWR_REG		0x1190
#define EXYNOS3_TOP_RETENTION_COREBLK_SYS_PWR_REG	0x1194
#define EXYNOS3_TOP_PWR_COREBLK_SYS_PWR_REG		0x1198
#define EXYNOS3_LOGIC_RESET_SYS_PWR_REG			0x11A0
#define EXYNOS3_OSCCLK_GATE_SYS_PWR_REG			0x11A4
#define EXYNOS3_LOGIC_RESET_COREBLK_SYS_PWR_REG		0x11B0
#define EXYNOS3_OSCCLK_GATE_COREBLK_SYS_PWR_REG		0x11B4
#define EXYNOS3_PAD_RETENTION_DRAM_SYS_PWR_REG		0x1200
#define EXYNOS3_PAD_RETENTION_MAUDIO_SYS_PWR_REG	0x1204
#define EXYNOS3_PAD_RETENTION_SPI_SYS_PWR_REG		0x1208
#define EXYNOS3_PAD_RETENTION_MMC2_SYS_PWR_REG		0x1218
#define EXYNOS3_PAD_RETENTION_GPIO_SYS_PWR_REG		0x1220
#define EXYNOS3_PAD_RETENTION_UART_SYS_PWR_REG		0x1224
#define EXYNOS3_PAD_RETENTION_MMC0_SYS_PWR_REG		0x1228
#define EXYNOS3_PAD_RETENTION_MMC1_SYS_PWR_REG		0x122C
#define EXYNOS3_PAD_RETENTION_EBIA_SYS_PWR_REG		0x1230
#define EXYNOS3_PAD_RETENTION_EBIB_SYS_PWR_REG		0x1234
#define EXYNOS3_PAD_RETENTION_JTAG_SYS_PWR_REG		0x1238
#define EXYNOS3_PAD_ISOLATION_SYS_PWR_REG		0x1240
#define EXYNOS3_PAD_ALV_SEL_SYS_PWR_REG			0x1260
#define EXYNOS3_XUSBXTI_SYS_PWR_REG			0x1280
#define EXYNOS3_XXTI_SYS_PWR_REG			0x1284
#define EXYNOS3_EXT_REGULATOR_SYS_PWR_REG		0x12C0
#define EXYNOS3_EXT_REGULATOR_COREBLK_SYS_PWR_REG	0x12C4
#define EXYNOS3_GPIO_MODE_SYS_PWR_REG			0x1300
#define EXYNOS3_GPIO_MODE_MAUDIO_SYS_PWR_REG		0x1340
#define EXYNOS3_TOP_ASB_RESET_SYS_PWR_REG		0x1344
#define EXYNOS3_TOP_ASB_ISOLATION_SYS_PWR_REG		0x1348
#define EXYNOS3_TOP_ASB_RESET_COREBLK_SYS_PWR_REG	0x1350
#define EXYNOS3_TOP_ASB_ISOLATION_COREBLK_SYS_PWR_REG	0x1354
#define EXYNOS3_CAM_SYS_PWR_REG				0x1380
#define EXYNOS3_MFC_SYS_PWR_REG				0x1388
#define EXYNOS3_G3D_SYS_PWR_REG				0x138C
#define EXYNOS3_LCD0_SYS_PWR_REG			0x1390
#define EXYNOS3_ISP_SYS_PWR_REG				0x1394
#define EXYNOS3_MAUDIO_SYS_PWR_REG			0x1398
#define EXYNOS3_DRAM_FREQ_DOWN_SYS_PWR_REG		0x13B0
#define EXYNOS3_DDRPHY_DLLOFF_SYS_PWR_REG		0x13B4
#define EXYNOS3_CMU_SYSCLK_ISP_SYS_PWR_REG		0x13B8
#define EXYNOS3_LPDDR_PHY_DLL_LOCK_SYS_PWR_REG		0x13C0
#define EXYNOS3_BPLL_SYSCLK_SYS_PWR_REG			0x13C4
#define EXYNOS3_UPLL_SYSCLK_SYS_PWR_REG			0x13C8

#define EXYNOS3_ARM_CORE0_OPTION			0x2008
#define EXYNOS3_ARM_CORE_OPTION(_nr)	\
			(EXYNOS3_ARM_CORE0_OPTION + ((_nr) * 0x80))

#define EXYNOS3_ARM_COMMON_OPTION			0x2408
#define EXYNOS3_ARM_L2_OPTION				0x2608
#define EXYNOS3_TOP_PWR_OPTION				0x2C48
#define EXYNOS3_CORE_TOP_PWR_OPTION			0x2CA8
#define EXYNOS3_XUSBXTI_DURATION			0x341C
#define EXYNOS3_XXTI_DURATION				0x343C
#define EXYNOS3_EXT_REGULATOR_DURATION			0x361C
#define EXYNOS3_EXT_REGULATOR_COREBLK_DURATION		0x363C
#define XUSBXTI_DURATION				0x00000BB8
#define XXTI_DURATION					XUSBXTI_DURATION
#define EXT_REGULATOR_DURATION				0x00001D4C
#define EXT_REGULATOR_COREBLK_DURATION			EXT_REGULATOR_DURATION

/* for XXX_OPTION */
#define EXYNOS3_OPTION_USE_SC_COUNTER			(1 << 0)
#define EXYNOS3_OPTION_USE_SC_FEEDBACK			(1 << 1)
#define EXYNOS3_OPTION_SKIP_DEACTIVATE_ACEACP_IN_PWDN	(1 << 7)

/* For EXYNOS5 */

#define EXYNOS5_AUTO_WDTRESET_DISABLE				0x0408
#define EXYNOS5_MASK_WDTRESET_REQUEST				0x040C

#define EXYNOS5_USE_RETENTION			BIT(4)
#define EXYNOS5_SYS_WDTRESET					(1 << 20)

#define EXYNOS5_ARM_CORE0_SYS_PWR_REG				0x1000
#define EXYNOS5_DIS_IRQ_ARM_CORE0_LOCAL_SYS_PWR_REG		0x1004
#define EXYNOS5_DIS_IRQ_ARM_CORE0_CENTRAL_SYS_PWR_REG		0x1008
#define EXYNOS5_ARM_CORE1_SYS_PWR_REG				0x1010
#define EXYNOS5_DIS_IRQ_ARM_CORE1_LOCAL_SYS_PWR_REG		0x1014
#define EXYNOS5_DIS_IRQ_ARM_CORE1_CENTRAL_SYS_PWR_REG		0x1018
#define EXYNOS5_FSYS_ARM_SYS_PWR_REG				0x1040
#define EXYNOS5_DIS_IRQ_FSYS_ARM_CENTRAL_SYS_PWR_REG		0x1048
#define EXYNOS5_ISP_ARM_SYS_PWR_REG				0x1050
#define EXYNOS5_DIS_IRQ_ISP_ARM_LOCAL_SYS_PWR_REG		0x1054
#define EXYNOS5_DIS_IRQ_ISP_ARM_CENTRAL_SYS_PWR_REG		0x1058
#define EXYNOS5_ARM_COMMON_SYS_PWR_REG				0x1080
#define EXYNOS5_ARM_L2_SYS_PWR_REG				0x10C0
#define EXYNOS5_CMU_ACLKSTOP_SYS_PWR_REG			0x1100
#define EXYNOS5_CMU_SCLKSTOP_SYS_PWR_REG			0x1104
#define EXYNOS5_CMU_RESET_SYS_PWR_REG				0x110C
#define EXYNOS5_CMU_ACLKSTOP_SYSMEM_SYS_PWR_REG			0x1120
#define EXYNOS5_CMU_SCLKSTOP_SYSMEM_SYS_PWR_REG			0x1124
#define EXYNOS5_CMU_RESET_SYSMEM_SYS_PWR_REG			0x112C
#define EXYNOS5_DRAM_FREQ_DOWN_SYS_PWR_REG			0x1130
#define EXYNOS5_DDRPHY_DLLOFF_SYS_PWR_REG			0x1134
#define EXYNOS5_DDRPHY_DLLLOCK_SYS_PWR_REG			0x1138
#define EXYNOS5_APLL_SYSCLK_SYS_PWR_REG				0x1140
#define EXYNOS5_MPLL_SYSCLK_SYS_PWR_REG				0x1144
#define EXYNOS5_VPLL_SYSCLK_SYS_PWR_REG				0x1148
#define EXYNOS5_EPLL_SYSCLK_SYS_PWR_REG				0x114C
#define EXYNOS5_BPLL_SYSCLK_SYS_PWR_REG				0x1150
#define EXYNOS5_CPLL_SYSCLK_SYS_PWR_REG				0x1154
#define EXYNOS5_MPLLUSER_SYSCLK_SYS_PWR_REG			0x1164
#define EXYNOS5_BPLLUSER_SYSCLK_SYS_PWR_REG			0x1170
#define EXYNOS5_TOP_BUS_SYS_PWR_REG				0x1180
#define EXYNOS5_TOP_RETENTION_SYS_PWR_REG			0x1184
#define EXYNOS5_TOP_PWR_SYS_PWR_REG				0x1188
#define EXYNOS5_TOP_BUS_SYSMEM_SYS_PWR_REG			0x1190
#define EXYNOS5_TOP_RETENTION_SYSMEM_SYS_PWR_REG		0x1194
#define EXYNOS5_TOP_PWR_SYSMEM_SYS_PWR_REG			0x1198
#define EXYNOS5_LOGIC_RESET_SYS_PWR_REG				0x11A0
#define EXYNOS5_OSCCLK_GATE_SYS_PWR_REG				0x11A4
#define EXYNOS5_LOGIC_RESET_SYSMEM_SYS_PWR_REG			0x11B0
#define EXYNOS5_OSCCLK_GATE_SYSMEM_SYS_PWR_REG			0x11B4
#define EXYNOS5_USBOTG_MEM_SYS_PWR_REG				0x11C0
#define EXYNOS5_G2D_MEM_SYS_PWR_REG				0x11C8
#define EXYNOS5_USBDRD_MEM_SYS_PWR_REG				0x11CC
#define EXYNOS5_SDMMC_MEM_SYS_PWR_REG				0x11D0
#define EXYNOS5_CSSYS_MEM_SYS_PWR_REG				0x11D4
#define EXYNOS5_SECSS_MEM_SYS_PWR_REG				0x11D8
#define EXYNOS5_ROTATOR_MEM_SYS_PWR_REG				0x11DC
#define EXYNOS5_INTRAM_MEM_SYS_PWR_REG				0x11E0
#define EXYNOS5_INTROM_MEM_SYS_PWR_REG				0x11E4
#define EXYNOS5_JPEG_MEM_SYS_PWR_REG				0x11E8
#define EXYNOS5_HSI_MEM_SYS_PWR_REG				0x11EC
#define EXYNOS5_MCUIOP_MEM_SYS_PWR_REG				0x11F4
#define EXYNOS5_SATA_MEM_SYS_PWR_REG				0x11FC
#define EXYNOS5_PAD_RETENTION_DRAM_SYS_PWR_REG			0x1200
#define EXYNOS5_PAD_RETENTION_MAU_SYS_PWR_REG			0x1204
#define EXYNOS5_PAD_RETENTION_EFNAND_SYS_PWR_REG		0x1208
#define EXYNOS5_PAD_RETENTION_GPIO_SYS_PWR_REG			0x1220
#define EXYNOS5_PAD_RETENTION_UART_SYS_PWR_REG			0x1224
#define EXYNOS5_PAD_RETENTION_MMCA_SYS_PWR_REG			0x1228
#define EXYNOS5_PAD_RETENTION_MMCB_SYS_PWR_REG			0x122C
#define EXYNOS5_PAD_RETENTION_EBIA_SYS_PWR_REG			0x1230
#define EXYNOS5_PAD_RETENTION_EBIB_SYS_PWR_REG			0x1234
#define EXYNOS5_PAD_RETENTION_SPI_SYS_PWR_REG			0x1238
#define EXYNOS5_PAD_RETENTION_GPIO_SYSMEM_SYS_PWR_REG		0x123C
#define EXYNOS5_PAD_ISOLATION_SYS_PWR_REG			0x1240
#define EXYNOS5_PAD_ISOLATION_SYSMEM_SYS_PWR_REG		0x1250
#define EXYNOS5_PAD_ALV_SEL_SYS_PWR_REG				0x1260
#define EXYNOS5_XUSBXTI_SYS_PWR_REG				0x1280
#define EXYNOS5_XXTI_SYS_PWR_REG				0x1284
#define EXYNOS5_EXT_REGULATOR_SYS_PWR_REG			0x12C0
#define EXYNOS5_GPIO_MODE_SYS_PWR_REG				0x1300
#define EXYNOS5_GPIO_MODE_SYSMEM_SYS_PWR_REG			0x1320
#define EXYNOS5_GPIO_MODE_MAU_SYS_PWR_REG			0x1340
#define EXYNOS5_TOP_ASB_RESET_SYS_PWR_REG			0x1344
#define EXYNOS5_TOP_ASB_ISOLATION_SYS_PWR_REG			0x1348
#define EXYNOS5_GSCL_SYS_PWR_REG				0x1400
#define EXYNOS5_ISP_SYS_PWR_REG					0x1404
#define EXYNOS5_MFC_SYS_PWR_REG					0x1408
#define EXYNOS5_G3D_SYS_PWR_REG					0x140C
#define EXYNOS5_DISP1_SYS_PWR_REG				0x1414
#define EXYNOS5_MAU_SYS_PWR_REG					0x1418
#define EXYNOS5_CMU_CLKSTOP_GSCL_SYS_PWR_REG			0x1480
#define EXYNOS5_CMU_CLKSTOP_ISP_SYS_PWR_REG			0x1484
#define EXYNOS5_CMU_CLKSTOP_MFC_SYS_PWR_REG			0x1488
#define EXYNOS5_CMU_CLKSTOP_G3D_SYS_PWR_REG			0x148C
#define EXYNOS5_CMU_CLKSTOP_DISP1_SYS_PWR_REG			0x1494
#define EXYNOS5_CMU_CLKSTOP_MAU_SYS_PWR_REG			0x1498
#define EXYNOS5_CMU_SYSCLK_GSCL_SYS_PWR_REG			0x14C0
#define EXYNOS5_CMU_SYSCLK_ISP_SYS_PWR_REG			0x14C4
#define EXYNOS5_CMU_SYSCLK_MFC_SYS_PWR_REG			0x14C8
#define EXYNOS5_CMU_SYSCLK_G3D_SYS_PWR_REG			0x14CC
#define EXYNOS5_CMU_SYSCLK_DISP1_SYS_PWR_REG			0x14D4
#define EXYNOS5_CMU_SYSCLK_MAU_SYS_PWR_REG			0x14D8
#define EXYNOS5_CMU_RESET_GSCL_SYS_PWR_REG			0x1580
#define EXYNOS5_CMU_RESET_ISP_SYS_PWR_REG			0x1584
#define EXYNOS5_CMU_RESET_MFC_SYS_PWR_REG			0x1588
#define EXYNOS5_CMU_RESET_G3D_SYS_PWR_REG			0x158C
#define EXYNOS5_CMU_RESET_DISP1_SYS_PWR_REG			0x1594
#define EXYNOS5_CMU_RESET_MAU_SYS_PWR_REG			0x1598

#define EXYNOS5_ARM_CORE0_OPTION				0x2008
#define EXYNOS5_ARM_CORE1_OPTION				0x2088
#define EXYNOS5_FSYS_ARM_OPTION					0x2208
#define EXYNOS5_ISP_ARM_OPTION					0x2288
#define EXYNOS5_ARM_COMMON_OPTION				0x2408
#define EXYNOS5_ARM_L2_OPTION					0x2608
#define EXYNOS5_TOP_PWR_OPTION					0x2C48
#define EXYNOS5_TOP_PWR_SYSMEM_OPTION				0x2CC8
#define EXYNOS5_JPEG_MEM_OPTION					0x2F48
#define EXYNOS5_GSCL_OPTION					0x4008
#define EXYNOS5_ISP_OPTION					0x4028
#define EXYNOS5_MFC_OPTION					0x4048
#define EXYNOS5_G3D_OPTION					0x4068
#define EXYNOS5_DISP1_OPTION					0x40A8
#define EXYNOS5_MAU_OPTION					0x40C8

#define EXYNOS5_USE_SC_FEEDBACK					(1 << 1)
#define EXYNOS5_USE_SC_COUNTER					(1 << 0)

#define EXYNOS5_SKIP_DEACTIVATE_ACEACP_IN_PWDN			(1 << 7)

#define EXYNOS5_OPTION_USE_STANDBYWFE				(1 << 24)
#define EXYNOS5_OPTION_USE_STANDBYWFI				(1 << 16)

#define EXYNOS5_OPTION_USE_RETENTION				(1 << 4)

#define EXYNOS5420_SWRESET_KFC_SEL				0x3

/* Only for EXYNOS5420 */
#define EXYNOS5420_ISP_ARM_OPTION				0x2488
#define EXYNOS5420_L2RSTDISABLE_VALUE				BIT(3)

#define EXYNOS5420_LPI_MASK					0x0004
#define EXYNOS5420_LPI_MASK1					0x0008
#define EXYNOS5420_UFS						BIT(8)
#define EXYNOS5420_ATB_KFC					BIT(13)
#define EXYNOS5420_ATB_ISP_ARM					BIT(19)
#define EXYNOS5420_EMULATION					BIT(31)
#define ATB_ISP_ARM						BIT(12)
#define ATB_KFC							BIT(13)
#define ATB_NOC							BIT(14)

#define EXYNOS5420_ARM_INTR_SPREAD_ENABLE			0x0100
#define EXYNOS5420_ARM_INTR_SPREAD_USE_STANDBYWFI		0x0104
#define EXYNOS5420_UP_SCHEDULER					0x0120
#define SPREAD_ENABLE						0xF
#define SPREAD_USE_STANDWFI					0xF

#define EXYNOS5420_KFC_CORE_RESET0				BIT(8)
#define EXYNOS5420_KFC_ETM_RESET0				BIT(20)

#define EXYNOS5420_KFC_CORE_RESET(_nr)				\
	((EXYNOS5420_KFC_CORE_RESET0 | EXYNOS5420_KFC_ETM_RESET0) << (_nr))

#define EXYNOS5420_BB_CON1					0x0784
#define EXYNOS5420_BB_SEL_EN					BIT(31)
#define EXYNOS5420_BB_PMOS_EN					BIT(7)
#define EXYNOS5420_BB_1300X					0XF

#define EXYNOS5420_ARM_CORE2_SYS_PWR_REG			0x1020
#define EXYNOS5420_DIS_IRQ_ARM_CORE2_LOCAL_SYS_PWR_REG		0x1024
#define EXYNOS5420_DIS_IRQ_ARM_CORE2_CENTRAL_SYS_PWR_REG	0x1028
#define EXYNOS5420_ARM_CORE3_SYS_PWR_REG			0x1030
#define EXYNOS5420_DIS_IRQ_ARM_CORE3_LOCAL_SYS_PWR_REG		0x1034
#define EXYNOS5420_DIS_IRQ_ARM_CORE3_CENTRAL_SYS_PWR_REG	0x1038
#define EXYNOS5420_KFC_CORE0_SYS_PWR_REG			0x1040
#define EXYNOS5420_DIS_IRQ_KFC_CORE0_LOCAL_SYS_PWR_REG		0x1044
#define EXYNOS5420_DIS_IRQ_KFC_CORE0_CENTRAL_SYS_PWR_REG	0x1048
#define EXYNOS5420_KFC_CORE1_SYS_PWR_REG			0x1050
#define EXYNOS5420_DIS_IRQ_KFC_CORE1_LOCAL_SYS_PWR_REG		0x1054
#define EXYNOS5420_DIS_IRQ_KFC_CORE1_CENTRAL_SYS_PWR_REG	0x1058
#define EXYNOS5420_KFC_CORE2_SYS_PWR_REG			0x1060
#define EXYNOS5420_DIS_IRQ_KFC_CORE2_LOCAL_SYS_PWR_REG		0x1064
#define EXYNOS5420_DIS_IRQ_KFC_CORE2_CENTRAL_SYS_PWR_REG	0x1068
#define EXYNOS5420_KFC_CORE3_SYS_PWR_REG			0x1070
#define EXYNOS5420_DIS_IRQ_KFC_CORE3_LOCAL_SYS_PWR_REG		0x1074
#define EXYNOS5420_DIS_IRQ_KFC_CORE3_CENTRAL_SYS_PWR_REG	0x1078
#define EXYNOS5420_ISP_ARM_SYS_PWR_REG				0x1090
#define EXYNOS5420_DIS_IRQ_ISP_ARM_LOCAL_SYS_PWR_REG		0x1094
#define EXYNOS5420_DIS_IRQ_ISP_ARM_CENTRAL_SYS_PWR_REG		0x1098
#define EXYNOS5420_ARM_COMMON_SYS_PWR_REG			0x10A0
#define EXYNOS5420_KFC_COMMON_SYS_PWR_REG			0x10B0
#define EXYNOS5420_KFC_L2_SYS_PWR_REG				0x10D0
#define EXYNOS5420_DPLL_SYSCLK_SYS_PWR_REG			0x1158
#define EXYNOS5420_IPLL_SYSCLK_SYS_PWR_REG			0x115C
#define EXYNOS5420_KPLL_SYSCLK_SYS_PWR_REG			0x1160
#define EXYNOS5420_RPLL_SYSCLK_SYS_PWR_REG                      0x1174
#define EXYNOS5420_SPLL_SYSCLK_SYS_PWR_REG                      0x1178
#define EXYNOS5420_INTRAM_MEM_SYS_PWR_REG                       0x11B8
#define EXYNOS5420_INTROM_MEM_SYS_PWR_REG                       0x11BC
#define EXYNOS5420_ONENANDXL_MEM_SYS_PWR			0x11C0
#define EXYNOS5420_USBDEV_MEM_SYS_PWR				0x11CC
#define EXYNOS5420_USBDEV1_MEM_SYS_PWR				0x11D0
#define EXYNOS5420_SDMMC_MEM_SYS_PWR				0x11D4
#define EXYNOS5420_CSSYS_MEM_SYS_PWR				0x11D8
#define EXYNOS5420_SECSS_MEM_SYS_PWR				0x11DC
#define EXYNOS5420_ROTATOR_MEM_SYS_PWR				0x11E0
#define EXYNOS5420_INTRAM_MEM_SYS_PWR				0x11E4
#define EXYNOS5420_INTROM_MEM_SYS_PWR				0x11E8
#define EXYNOS5420_PAD_RETENTION_JTAG_SYS_PWR_REG		0x1208
#define EXYNOS5420_PAD_RETENTION_DRAM_SYS_PWR_REG		0x1210
#define EXYNOS5420_PAD_RETENTION_UART_SYS_PWR_REG		0x1214
#define EXYNOS5420_PAD_RETENTION_MMC0_SYS_PWR_REG		0x1218
#define EXYNOS5420_PAD_RETENTION_MMC1_SYS_PWR_REG		0x121C
#define EXYNOS5420_PAD_RETENTION_MMC2_SYS_PWR_REG		0x1220
#define EXYNOS5420_PAD_RETENTION_HSI_SYS_PWR_REG		0x1224
#define EXYNOS5420_PAD_RETENTION_EBIA_SYS_PWR_REG		0x1228
#define EXYNOS5420_PAD_RETENTION_EBIB_SYS_PWR_REG		0x122C
#define EXYNOS5420_PAD_RETENTION_SPI_SYS_PWR_REG		0x1230
#define EXYNOS5420_PAD_RETENTION_DRAM_COREBLK_SYS_PWR_REG	0x1234
#define EXYNOS5420_DISP1_SYS_PWR_REG				0x1410
#define EXYNOS5420_MAU_SYS_PWR_REG				0x1414
#define EXYNOS5420_G2D_SYS_PWR_REG				0x1418
#define EXYNOS5420_MSC_SYS_PWR_REG				0x141C
#define EXYNOS5420_FSYS_SYS_PWR_REG				0x1420
#define EXYNOS5420_FSYS2_SYS_PWR_REG				0x1424
#define EXYNOS5420_PSGEN_SYS_PWR_REG				0x1428
#define EXYNOS5420_PERIC_SYS_PWR_REG				0x142C
#define EXYNOS5420_WCORE_SYS_PWR_REG				0x1430
#define EXYNOS5420_CMU_CLKSTOP_DISP1_SYS_PWR_REG		0x1490
#define EXYNOS5420_CMU_CLKSTOP_MAU_SYS_PWR_REG			0x1494
#define EXYNOS5420_CMU_CLKSTOP_G2D_SYS_PWR_REG			0x1498
#define EXYNOS5420_CMU_CLKSTOP_MSC_SYS_PWR_REG			0x149C
#define EXYNOS5420_CMU_CLKSTOP_FSYS_SYS_PWR_REG			0x14A0
#define EXYNOS5420_CMU_CLKSTOP_FSYS2_SYS_PWR_REG		0x14A4
#define EXYNOS5420_CMU_CLKSTOP_PSGEN_SYS_PWR_REG		0x14A8
#define EXYNOS5420_CMU_CLKSTOP_PERIC_SYS_PWR_REG		0x14AC
#define EXYNOS5420_CMU_CLKSTOP_WCORE_SYS_PWR_REG		0x14B0
#define EXYNOS5420_CMU_SYSCLK_TOPPWR_SYS_PWR_REG		0x14BC
#define EXYNOS5420_CMU_SYSCLK_DISP1_SYS_PWR_REG			0x14D0
#define EXYNOS5420_CMU_SYSCLK_MAU_SYS_PWR_REG			0x14D4
#define EXYNOS5420_CMU_SYSCLK_G2D_SYS_PWR_REG			0x14D8
#define EXYNOS5420_CMU_SYSCLK_MSC_SYS_PWR_REG			0x14DC
#define EXYNOS5420_CMU_SYSCLK_FSYS_SYS_PWR_REG			0x14E0
#define EXYNOS5420_CMU_SYSCLK_FSYS2_SYS_PWR_REG			0x14E4
#define EXYNOS5420_CMU_SYSCLK_PSGEN_SYS_PWR_REG			0x14E8
#define EXYNOS5420_CMU_SYSCLK_PERIC_SYS_PWR_REG			0x14EC
#define EXYNOS5420_CMU_SYSCLK_WCORE_SYS_PWR_REG			0x14F0
#define EXYNOS5420_CMU_SYSCLK_SYSMEM_TOPPWR_SYS_PWR_REG		0x14F4
#define EXYNOS5420_CMU_RESET_FSYS2_SYS_PWR_REG			0x1570
#define EXYNOS5420_CMU_RESET_PSGEN_SYS_PWR_REG			0x1574
#define EXYNOS5420_CMU_RESET_PERIC_SYS_PWR_REG			0x1578
#define EXYNOS5420_CMU_RESET_WCORE_SYS_PWR_REG			0x157C
#define EXYNOS5420_CMU_RESET_DISP1_SYS_PWR_REG			0x1590
#define EXYNOS5420_CMU_RESET_MAU_SYS_PWR_REG			0x1594
#define EXYNOS5420_CMU_RESET_G2D_SYS_PWR_REG			0x1598
#define EXYNOS5420_CMU_RESET_MSC_SYS_PWR_REG			0x159C
#define EXYNOS5420_CMU_RESET_FSYS_SYS_PWR_REG			0x15A0
#define EXYNOS5420_SFR_AXI_CGDIS1				0x15E4
#define EXYNOS_ARM_CORE2_CONFIGURATION				0x2100
#define EXYNOS5420_ARM_CORE2_OPTION				0x2108
#define EXYNOS_ARM_CORE3_CONFIGURATION				0x2180
#define EXYNOS5420_ARM_CORE3_OPTION				0x2188
#define EXYNOS5420_ARM_COMMON_STATUS				0x2504
#define EXYNOS5420_ARM_COMMON_OPTION				0x2508
#define EXYNOS5420_KFC_COMMON_STATUS				0x2584
#define EXYNOS5420_KFC_COMMON_OPTION				0x2588
#define EXYNOS5420_LOGIC_RESET_DURATION3			0x2D1C

#define EXYNOS5420_PAD_RET_GPIO_OPTION				0x30C8
#define EXYNOS5420_PAD_RET_UART_OPTION				0x30E8
#define EXYNOS5420_PAD_RET_MMCA_OPTION				0x3108
#define EXYNOS5420_PAD_RET_MMCB_OPTION				0x3128
#define EXYNOS5420_PAD_RET_MMCC_OPTION				0x3148
#define EXYNOS5420_PAD_RET_HSI_OPTION				0x3168
#define EXYNOS5420_PAD_RET_SPI_OPTION				0x31C8
#define EXYNOS5420_PAD_RET_DRAM_COREBLK_OPTION			0x31E8
#define EXYNOS_PAD_RET_DRAM_OPTION				0x3008
#define EXYNOS_PAD_RET_MAUDIO_OPTION				0x3028
#define EXYNOS_PAD_RET_JTAG_OPTION				0x3048
#define EXYNOS_PAD_RET_GPIO_OPTION				0x3108
#define EXYNOS_PAD_RET_UART_OPTION				0x3128
#define EXYNOS_PAD_RET_MMCA_OPTION				0x3148
#define EXYNOS_PAD_RET_MMCB_OPTION				0x3168
#define EXYNOS_PAD_RET_EBIA_OPTION				0x3188
#define EXYNOS_PAD_RET_EBIB_OPTION				0x31A8

#define EXYNOS_PS_HOLD_CONTROL					0x330C

/* For SYS_PWR_REG */
#define EXYNOS_SYS_PWR_CFG					BIT(0)

#define EXYNOS5420_MFC_CONFIGURATION				0x4060
#define EXYNOS5420_MFC_STATUS					0x4064
#define EXYNOS5420_MFC_OPTION					0x4068
#define EXYNOS5420_G3D_CONFIGURATION				0x4080
#define EXYNOS5420_G3D_STATUS					0x4084
#define EXYNOS5420_G3D_OPTION					0x4088
#define EXYNOS5420_DISP0_CONFIGURATION				0x40A0
#define EXYNOS5420_DISP0_STATUS					0x40A4
#define EXYNOS5420_DISP0_OPTION					0x40A8
#define EXYNOS5420_DISP1_CONFIGURATION				0x40C0
#define EXYNOS5420_DISP1_STATUS					0x40C4
#define EXYNOS5420_DISP1_OPTION					0x40C8
#define EXYNOS5420_MAU_CONFIGURATION				0x40E0
#define EXYNOS5420_MAU_STATUS					0x40E4
#define EXYNOS5420_MAU_OPTION					0x40E8
#define EXYNOS5420_FSYS2_OPTION					0x4168
#define EXYNOS5420_PSGEN_OPTION					0x4188

/* For EXYNOS_CENTRAL_SEQ_OPTION */
#define EXYNOS5_USE_STANDBYWFI_ARM_CORE0			BIT(16)
#define EXYNOS5_USE_STANDBYWFI_ARM_CORE1			BUT(17)
#define EXYNOS5_USE_STANDBYWFE_ARM_CORE0			BIT(24)
#define EXYNOS5_USE_STANDBYWFE_ARM_CORE1			BIT(25)

#define EXYNOS5420_ARM_USE_STANDBY_WFI0				BIT(4)
#define EXYNOS5420_ARM_USE_STANDBY_WFI1				BIT(5)
#define EXYNOS5420_ARM_USE_STANDBY_WFI2				BIT(6)
#define EXYNOS5420_ARM_USE_STANDBY_WFI3				BIT(7)
#define EXYNOS5420_KFC_USE_STANDBY_WFI0				BIT(8)
#define EXYNOS5420_KFC_USE_STANDBY_WFI1				BIT(9)
#define EXYNOS5420_KFC_USE_STANDBY_WFI2				BIT(10)
#define EXYNOS5420_KFC_USE_STANDBY_WFI3				BIT(11)
#define EXYNOS5420_ARM_USE_STANDBY_WFE0				BIT(16)
#define EXYNOS5420_ARM_USE_STANDBY_WFE1				BIT(17)
#define EXYNOS5420_ARM_USE_STANDBY_WFE2				BIT(18)
#define EXYNOS5420_ARM_USE_STANDBY_WFE3				BIT(19)
#define EXYNOS5420_KFC_USE_STANDBY_WFE0				BIT(20)
#define EXYNOS5420_KFC_USE_STANDBY_WFE1				BIT(21)
#define EXYNOS5420_KFC_USE_STANDBY_WFE2				BIT(22)
#define EXYNOS5420_KFC_USE_STANDBY_WFE3				BIT(23)

#define DUR_WAIT_RESET				0xF

#define EXYNOS5420_USE_STANDBY_WFI_ALL	(EXYNOS5420_ARM_USE_STANDBY_WFI0    \
					 | EXYNOS5420_ARM_USE_STANDBY_WFI1  \
					 | EXYNOS5420_ARM_USE_STANDBY_WFI2  \
					 | EXYNOS5420_ARM_USE_STANDBY_WFI3  \
					 | EXYNOS5420_KFC_USE_STANDBY_WFI0  \
					 | EXYNOS5420_KFC_USE_STANDBY_WFI1  \
					 | EXYNOS5420_KFC_USE_STANDBY_WFI2  \
					 | EXYNOS5420_KFC_USE_STANDBY_WFI3)

#endif /* __LINUX_SOC_EXYNOS_REGS_PMU_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                #ifndef __WCNSS_CTRL_H__
#define __WCNSS_CTRL_H__

#include <linux/soc/qcom/smd.h>

struct qcom_smd_channel *qcom_wcnss_open_channel(void *wcnss, const char *name, qcom_smd_cb_t cb);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #ifndef __QCOM_SMEM_H__
#define __QCOM_SMEM_H__

#define QCOM_SMEM_HOST_ANY -1

int qcom_smem_alloc(unsigned host, unsigned item, size_t size);
void *qcom_smem_get(unsigned host, unsigned item, size_t *size);

int qcom_smem_get_free_space(unsigned host);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         #ifndef __QCOM_SMD_H__
#define __QCOM_SMD_H__

#include <linux/device.h>
#include <linux/mod_devicetable.h>

struct qcom_smd;
struct qcom_smd_channel;
struct qcom_smd_lookup;

/**
 * struct qcom_smd_id - struct used for matching a smd device
 * @name:	name of the channel
 */
struct qcom_smd_id {
	char name[20];
};

/**
 * struct qcom_smd_device - smd device struct
 * @dev:	the device struct
 * @channel:	handle to the smd channel for this device
 */
struct qcom_smd_device {
	struct device dev;
	struct qcom_smd_channel *channel;
};

typedef int (*qcom_smd_cb_t)(struct qcom_smd_channel *, const void *, size_t);

/**
 * struct qcom_smd_driver - smd driver struct
 * @driver:	underlying device driver
 * @smd_match_table: static channel match table
 * @probe:	invoked when the smd channel is found
 * @remove:	invoked when the smd channel is closed
 * @callback:	invoked when an inbound message is received on the channel,
 *		should return 0 on success or -EBUSY if the data cannot be
 *		consumed at this time
 */
struct qcom_smd_driver {
	struct device_driver driver;
	const struct qcom_smd_id *smd_match_table;

	int (*probe)(struct qcom_smd_device *dev);
	void (*remove)(struct qcom_smd_device *dev);
	qcom_smd_cb_t callback;
};

#if IS_ENABLED(CONFIG_QCOM_SMD)

int qcom_smd_driver_register(struct qcom_smd_driver *drv);
void qcom_smd_driver_unregister(struct qcom_smd_driver *drv);

struct qcom_smd_channel *qcom_smd_open_channel(struct qcom_smd_channel *channel,
					       const char *name,
					       qcom_smd_cb_t cb);
void qcom_smd_close_channel(struct qcom_smd_channel *channel);
void *qcom_smd_get_drvdata(struct qcom_smd_channel *channel);
void qcom_smd_set_drvdata(struct qcom_smd_channel *channel, void *data);
int qcom_smd_send(struct qcom_smd_channel *channel, const void *data, int len);


struct qcom_smd_edge *qcom_smd_register_edge(struct device *parent,
					     struct device_node *node);
int qcom_smd_unregister_edge(struct qcom_smd_edge *edge);

#else

static inline int qcom_smd_driver_register(struct qcom_smd_driver *drv)
{
	return -ENXIO;
}

static inline void qcom_smd_driver_unregister(struct qcom_smd_driver *drv)
{
	/* This shouldn't be possible */
	WARN_ON(1);
}

static inline struct qcom_smd_channel *
qcom_smd_open_channel(struct qcom_smd_channel *channel,
		      const char *name,
		      qcom_smd_cb_t cb)
{
	/* This shouldn't be possible */
	WARN_ON(1);
	return NULL;
}

static inline void qcom_smd_close_channel(struct qcom_smd_channel *channel)
{
	/* This shouldn't be possible */
	WARN_ON(1);
}

static inline void *qcom_smd_get_drvdata(struct qcom_smd_channel *channel)
{
	/* This shouldn't be possible */
	WARN_ON(1);
	return NULL;
}

static inline void qcom_smd_set_drvdata(struct qcom_smd_channel *channel, void *data)
{
	/* This shouldn't be possible */
	WARN_ON(1);
}

static inline int qcom_smd_send(struct qcom_smd_channel *channel,
				const void *data, int len)
{
	/* This shouldn't be possible */
	WARN_ON(1);
	return -ENXIO;
}

static inline struct qcom_smd_edge *
qcom_smd_register_edge(struct device *parent,
		       struct device_node *node)
{
	return ERR_PTR(-ENXIO);
}

static inline int qcom_smd_unregister_edge(struct qcom_smd_edge *edge)
{
	/* This shouldn't be possible */
	WARN_ON(1);
	return -ENXIO;
}

#endif

#define module_qcom_smd_driver(__smd_driver) \
	module_driver(__smd_driver, qcom_smd_driver_register, \
		      qcom_smd_driver_unregister)


#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    #ifndef __QCOM_SMEM_STATE__
#define __QCOM_SMEM_STATE__

#include <linux/errno.h>

struct device_node;
struct qcom_smem_state;

struct qcom_smem_state_ops {
	int (*update_bits)(void *, u32, u32);
};

#ifdef CONFIG_QCOM_SMEM_STATE

struct qcom_smem_state *qcom_smem_state_get(struct device *dev, const char *con_id, unsigned *bit);
void qcom_smem_state_put(struct qcom_smem_state *);

int qcom_smem_state_update_bits(struct qcom_smem_state *state, u32 mask, u32 value);

struct qcom_smem_state *qcom_smem_state_register(struct device_node *of_node, const struct qcom_smem_state_ops *ops, void *data);
void qcom_smem_state_unregister(struct qcom_smem_state *state);

#else

static inline struct qcom_smem_state *qcom_smem_state_get(struct device *dev,
	const char *con_id, unsigned *bit)
{
	return ERR_PTR(-EINVAL);
}

static inline void qcom_smem_state_put(struct qcom_smem_state *state)
{
}

static inline int qcom_smem_state_update_bits(struct qcom_smem_state *state,
	u32 mask, u32 value)
{
	return -EINVAL;
}

static inline struct qcom_smem_state *qcom_smem_state_register(struct device_node *of_node,
	const struct qcom_smem_state_ops *ops, void *data)
{
	return ERR_PTR(-EINVAL);
}

static inline void qcom_smem_state_unregister(struct qcom_smem_state *state)
{
}

#endif

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #ifndef __QCOM_SMD_RPM_H__
#define __QCOM_SMD_RPM_H__

struct qcom_smd_rpm;

#define QCOM_SMD_RPM_ACTIVE_STATE        0
#define QCOM_SMD_RPM_SLEEP_STATE         1

/*
 * Constants used for addressing resources in the RPM.
 */
#define QCOM_SMD_RPM_BOOST	0x61747362
#define QCOM_SMD_RPM_BUS_CLK	0x316b6c63
#define QCOM_SMD_RPM_BUS_MASTER	0x73616d62
#define QCOM_SMD_RPM_BUS_SLAVE	0x766c7362
#define QCOM_SMD_RPM_CLK_BUF_A	0x616B6C63
#define QCOM_SMD_RPM_LDOA	0x616f646c
#define QCOM_SMD_RPM_LDOB	0x626F646C
#define QCOM_SMD_RPM_MEM_CLK	0x326b6c63
#define QCOM_SMD_RPM_MISC_CLK	0x306b6c63
#define QCOM_SMD_RPM_NCPA	0x6170636E
#define QCOM_SMD_RPM_NCPB	0x6270636E
#define QCOM_SMD_RPM_OCMEM_PWR	0x706d636f
#define QCOM_SMD_RPM_QPIC_CLK	0x63697071
#define QCOM_SMD_RPM_SMPA	0x61706d73
#define QCOM_SMD_RPM_SMPB	0x62706d73
#define QCOM_SMD_RPM_SPDM	0x63707362
#define QCOM_SMD_RPM_VSA	0x00617376

int qcom_rpm_smd_write(struct qcom_smd_rpm *rpm,
		       int state,
		       u32 resource_type, u32 resource_id,
		       void *buf, size_t count);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        #ifndef __SOC_MEDIATEK_INFRACFG_H
#define __SOC_MEDIATEK_INFRACFG_H

#define MT8173_TOP_AXI_PROT_EN_MCI_M2		BIT(0)
#define MT8173_TOP_AXI_PROT_EN_MM_M0		BIT(1)
#define MT8173_TOP_AXI_PROT_EN_MM_M1		BIT(2)
#define MT8173_TOP_AXI_PROT_EN_MMAPB_S		BIT(6)
#define MT8173_TOP_AXI_PROT_EN_L2C_M2		BIT(9)
#define MT8173_TOP_AXI_PROT_EN_L2SS_SMI		BIT(11)
#define MT8173_TOP_AXI_PROT_EN_L2SS_ADD		BIT(12)
#define MT8173_TOP_AXI_PROT_EN_CCI_M2		BIT(13)
#define MT8173_TOP_AXI_PROT_EN_MFG_S		BIT(14)
#define MT8173_TOP_AXI_PROT_EN_PERI_M0		BIT(15)
#define MT8173_TOP_AXI_PROT_EN_PERI_M1		BIT(16)
#define MT8173_TOP_AXI_PROT_EN_DEBUGSYS		BIT(17)
#define MT8173_TOP_AXI_PROT_EN_CQ_DMA		BIT(18)
#define MT8173_TOP_AXI_PROT_EN_GCPU		BIT(19)
#define MT8173_TOP_AXI_PROT_EN_IOMMU		BIT(20)
#define MT8173_TOP_AXI_PROT_EN_MFG_M0		BIT(21)
#define MT8173_TOP_AXI_PROT_EN_MFG_M1		BIT(22)
#define MT8173_TOP_AXI_PROT_EN_MFG_SNOOP_OUT	BIT(23)

int mtk_infracfg_set_bus_protection(struct regmap *infracfg, u32 mask);
int mtk_infracfg_clear_bus_protection(struct regmap *infracfg, u32 mask);

#endif /* __SOC_MEDIATEK_INFRACFG_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /*
 * Allwinner SoCs SRAM Controller Driver
 *
 * Copyright (C) 2015 Maxime Ripard
 *
 * Author: Maxime Ripard <maxime.ripard@free-electrons.com>
 *
 * This file is licensed under the terms of the GNU General Public
 * License version 2.  This program is licensed "as is" without any
 * warranty of any kind, whether express or implied.
 */

#ifndef _SUNXI_SRAM_H_
#define _SUNXI_SRAM_H_

int sunxi_sram_claim(struct device *dev);
int sunxi_sram_release(struct device *dev);

#endif /* _SUNXI_SRAM_H_ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        #ifndef _LINUX_ISICOM_H
#define _LINUX_ISICOM_H

#define		YES	1
#define		NO	0

/*
 *  ISICOM Driver definitions ...
 *
 */

#define		ISICOM_NAME	"ISICom"

/*
 *      PCI definitions
 */

#define		DEVID_COUNT	9
#define		VENDOR_ID	0x10b5

/*
 *	These are now officially allocated numbers
 */

#define		ISICOM_NMAJOR	112	/* normal  */
#define		ISICOM_CMAJOR	113	/* callout */
#define		ISICOM_MAGIC	(('M' << 8) | 'T')

#define		WAKEUP_CHARS	256	/* hard coded for now	*/
#define		TX_SIZE		254

#define		BOARD_COUNT	4
#define		PORT_COUNT	(BOARD_COUNT*16)

/*   character sizes  */

#define		ISICOM_CS5		0x0000
#define		ISICOM_CS6		0x0001
#define		ISICOM_CS7		0x0002
#define		ISICOM_CS8		0x0003

/* stop bits */

#define		ISICOM_1SB		0x0000
#define		ISICOM_2SB		0x0004

/* parity */

#define		ISICOM_NOPAR		0x0000
#define		ISICOM_ODPAR		0x0008
#define		ISICOM_EVPAR		0x0018

/* flow control */

#define		ISICOM_CTSRTS		0x03
#define		ISICOM_INITIATE_XONXOFF	0x04
#define		ISICOM_RESPOND_XONXOFF	0x08

#define	BOARD(line)  (((line) >> 4) & 0x3)

	/*	isi kill queue bitmap	*/

#define		ISICOM_KILLTX		0x01
#define		ISICOM_KILLRX		0x02

	/* isi_board status bitmap */

#define		FIRMWARE_LOADED		0x0001
#define		BOARD_ACTIVE		0x0002
#define		BOARD_INIT		0x0004

 	/* isi_port status bitmap  */

#define		ISI_CTS			0x1000
#define		ISI_DSR			0x2000
#define		ISI_RI			0x4000
#define		ISI_DCD			0x8000
#define		ISI_DTR			0x0100
#define		ISI_RTS			0x0200


#define		ISI_TXOK		0x0001

#endif	/*	ISICOM_H	*/
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               #ifndef __LINUX_PREEMPT_H
#define __LINUX_PREEMPT_H

/*
 * include/linux/preempt.h - macros for accessing and manipulating
 * preempt_count (used for kernel preemption, interrupt count, etc.)
 */

#include <linux/linkage.h>
#include <linux/list.h>

/*
 * We put the hardirq and softirq counter into the preemption
 * counter. The bitmask has the following meaning:
 *
 * - bits 0-7 are the preemption count (max preemption depth: 256)
 * - bits 8-15 are the softirq count (max # of softirqs: 256)
 *
 * The hardirq count could in theory be the same as the number of
 * interrupts in the system, but we run all interrupt handlers with
 * interrupts disabled, so we cannot have nesting interrupts. Though
 * there are a few palaeontologic drivers which reenable interrupts in
 * the handler, so we need more than one bit here.
 *
 *         PREEMPT_MASK:	0x000000ff
 *         SOFTIRQ_MASK:	0x0000ff00
 *         HARDIRQ_MASK:	0x000f0000
 *             NMI_MASK:	0x00100000
 * PREEMPT_NEED_RESCHED:	0x80000000
 */
#define PREEMPT_BITS	8
#define SOFTIRQ_BITS	8
#define HARDIRQ_BITS	4
#define NMI_BITS	1

#define PREEMPT_SHIFT	0
#define SOFTIRQ_SHIFT	(PREEMPT_SHIFT + PREEMPT_BITS)
#define HARDIRQ_SHIFT	(SOFTIRQ_SHIFT + SOFTIRQ_BITS)
#define NMI_SHIFT	(HARDIRQ_SHIFT + HARDIRQ_BITS)

#define __IRQ_MASK(x)	((1UL << (x))-1)

#define PREEMPT_MASK	(__IRQ_MASK(PREEMPT_BITS) << PREEMPT_SHIFT)
#define SOFTIRQ_MASK	(__IRQ_MASK(SOFTIRQ_BITS) << SOFTIRQ_SHIFT)
#define HARDIRQ_MASK	(__IRQ_MASK(HARDIRQ_BITS) << HARDIRQ_SHIFT)
#define NMI_MASK	(__IRQ_MASK(NMI_BITS)     << NMI_SHIFT)

#define PREEMPT_OFFSET	(1UL << PREEMPT_SHIFT)
#define SOFTIRQ_OFFSET	(1UL << SOFTIRQ_SHIFT)
#define HARDIRQ_OFFSET	(1UL << HARDIRQ_SHIFT)
#define NMI_OFFSET	(1UL << NMI_SHIFT)

#define SOFTIRQ_DISABLE_OFFSET	(2 * SOFTIRQ_OFFSET)

/* We use the MSB mostly because its available */
#define PREEMPT_NEED_RESCHED	0x80000000

/* preempt_count() and related functions, depends on PREEMPT_NEED_RESCHED */
#include <asm/preempt.h>

#define hardirq_count()	(preempt_count() & HARDIRQ_MASK)
#define softirq_count()	(preempt_count() & SOFTIRQ_MASK)
#define irq_count()	(preempt_count() & (HARDIRQ_MASK | SOFTIRQ_MASK \
				 | NMI_MASK))

/*
 * Are we doing bottom half or hardware interrupt processing?
 *
 * in_irq()       - We're in (hard) IRQ context
 * in_softirq()   - We have BH disabled, or are processing softirqs
 * in_interrupt() - We're in NMI,IRQ,SoftIRQ context or have BH disabled
 * in_serving_softirq() - We're in softirq context
 * in_nmi()       - We're in NMI context
 * in_task()	  - We're in task context
 *
 * Note: due to the BH disabled confusion: in_softirq(),in_interrupt() really
 *       should not be used in new code.
 */
#define in_irq()		(hardirq_count())
#define in_softirq()		(softirq_count())
#define in_interrupt()		(irq_count())
#define in_serving_softirq()	(softirq_count() & SOFTIRQ_OFFSET)
#define in_nmi()		(preempt_count() & NMI_MASK)
#define in_task()		(!(preempt_count() & \
				   (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))

/*
 * The preempt_count offset after preempt_disable();
 */
#if defined(CONFIG_PREEMPT_COUNT)
# define PREEMPT_DISABLE_OFFSET	PREEMPT_OFFSET
#else
# define PREEMPT_DISABLE_OFFSET	0
#endif

/*
 * The preempt_count offset after spin_lock()
 */
#define PREEMPT_LOCK_OFFSET	PREEMPT_DISABLE_OFFSET

/*
 * The preempt_count offset needed for things like:
 *
 *  spin_lock_bh()
 *
 * Which need to disable both preemption (CONFIG_PREEMPT_COUNT) and
 * softirqs, such that unlock sequences of:
 *
 *  spin_unlock();
 *  local_bh_enable();
 *
 * Work as expected.
 */
#define SOFTIRQ_LOCK_OFFSET (SOFTIRQ_DISABLE_OFFSET + PREEMPT_LOCK_OFFSET)

/*
 * Are we running in atomic context?  WARNING: this macro cannot
 * always detect atomic context; in particular, it cannot know about
 * held spinlocks in non-preemptible kernels.  Thus it should not be
 * used in the general case to determine whether sleeping is possible.
 * Do not use in_atomic() in driver code.
 */
#define in_atomic()	(preempt_count() != 0)

/*
 * Check whether we were atomic before we did preempt_disable():
 * (used by the scheduler)
 */
#define in_atomic_preempt_off() (preempt_count() != PREEMPT_DISABLE_OFFSET)

#if defined(CONFIG_DEBUG_PREEMPT) || defined(CONFIG_PREEMPT_TRACER)
extern void preempt_count_add(int val);
extern void preempt_count_sub(int val);
#define preempt_count_dec_and_test() \
	({ preempt_count_sub(1); should_resched(0); })
#else
#define preempt_count_add(val)	__preempt_count_add(val)
#define preempt_count_sub(val)	__preempt_count_sub(val)
#define preempt_count_dec_and_test() __preempt_count_dec_and_test()
#endif

#define __preempt_count_inc() __preempt_count_add(1)
#define __preempt_count_dec() __preempt_count_sub(1)

#define preempt_count_inc() preempt_count_add(1)
#define preempt_count_dec() preempt_count_sub(1)

#ifdef CONFIG_PREEMPT_COUNT

#define preempt_disable() \
do { \
	preempt_count_inc(); \
	barrier(); \
} while (0)

#define sched_preempt_enable_no_resched() \
do { \
	barrier(); \
	preempt_count_dec(); \
} while (0)

#define preempt_enable_no_resched() sched_preempt_enable_no_resched()

#define preemptible()	(preempt_count() == 0 && !irqs_disabled())

#ifdef CONFIG_PREEMPT
#define preempt_enable() \
do { \
	barrier(); \
	if (unlikely(preempt_count_dec_and_test())) \
		__preempt_schedule(); \
} while (0)

#define preempt_enable_notrace() \
do { \
	barrier(); \
	if (unlikely(__preempt_count_dec_and_test())) \
		__preempt_schedule_notrace(); \
} while (0)

#define preempt_check_resched() \
do { \
	if (should_resched(0)) \
		__preempt_schedule(); \
} while (0)

#else /* !CONFIG_PREEMPT */
#define preempt_enable() \
do { \
	barrier(); \
	preempt_count_dec(); \
} while (0)

#define preempt_enable_notrace() \
do { \
	barrier(); \
	__preempt_count_dec(); \
} while (0)

#define preempt_check_resched() do { } while (0)
#endif /* CONFIG_PREEMPT */

#define preempt_disable_notrace() \
do { \
	__preempt_count_inc(); \
	barrier(); \
} while (0)

#define preempt_enable_no_resched_notrace() \
do { \
	barrier(); \
	__preempt_count_dec(); \
} while (0)

#else /* !CONFIG_PREEMPT_COUNT */

/*
 * Even if we don't have any preemption, we need preempt disable/enable
 * to be barriers, so that we don't have things like get_user/put_user
 * that can cause faults and scheduling migrate into our preempt-protected
 * region.
 */
#define preempt_disable()			barrier()
#define sched_preempt_enable_no_resched()	barrier()
#define preempt_enable_no_resched()		barrier()
#define preempt_enable()			barrier()
#define preempt_check_resched()			do { } while (0)

#define preempt_disable_notrace()		barrier()
#define preempt_enable_no_resched_notrace()	barrier()
#define preempt_enable_notrace()		barrier()
#define preemptible()				0

#endif /* CONFIG_PREEMPT_COUNT */

#ifdef CONFIG_IPIPE
#define hard_preempt_disable()				\
	({						\
		unsigned long __flags__;		\
		__flags__ = hard_local_irq_save();	\
		if (__ipipe_root_p)			\
			preempt_disable();		\
		__flags__;				\
	})

#define hard_preempt_enable(__flags__)			\
	do {						\
		if (__ipipe_root_p) {			\
			preempt_enable_no_resched();	\
			hard_local_irq_restore(__flags__);	\
			preempt_check_resched();	\
		} else					\
			hard_local_irq_restore(__flags__);	\
	} while (0)

#elif defined(MODULE)
/*
 * Modules have no business playing preemption tricks.
 */
#undef sched_preempt_enable_no_resched
#undef preempt_enable_no_resched
#undef preempt_enable_no_resched_notrace
#undef preempt_check_resched
#endif	/* !IPIPE && MODULE */

#define preempt_set_need_resched() \
do { \
	set_preempt_need_resched(); \
} while (0)
#define preempt_fold_need_resched() \
do { \
	if (tif_need_resched()) \
		set_preempt_need_resched(); \
} while (0)

#ifdef CONFIG_PREEMPT_NOTIFIERS

struct preempt_notifier;

/**
 * preempt_ops - notifiers called when a task is preempted and rescheduled
 * @sched_in: we're about to be rescheduled:
 *    notifier: struct preempt_notifier for the task being scheduled
 *    cpu:  cpu we're scheduled on
 * @sched_out: we've just been preempted
 *    notifier: struct preempt_notifier for the task being preempted
 *    next: the task that's kicking us out
 *
 * Please note that sched_in and out are called under different
 * contexts.  sched_out is called with rq lock held and irq disabled
 * while sched_in is called without rq lock and irq enabled.  This
 * difference is intentional and depended upon by its users.
 */
struct preempt_ops {
	void (*sched_in)(struct preempt_notifier *notifier, int cpu);
	void (*sched_out)(struct preempt_notifier *notifier,
			  struct task_struct *next);
};

/**
 * preempt_notifier - key for installing preemption notifiers
 * @link: internal use
 * @ops: defines the notifier functions to be called
 *
 * Usually used in conjunction with container_of().
 */
struct preempt_notifier {
	struct hlist_node link;
	struct preempt_ops *ops;
};

void preempt_notifier_inc(void);
void preempt_notifier_dec(void);
void preempt_notifier_register(struct preempt_notifier *notifier);
void preempt_notifier_unregister(struct preempt_notifier *notifier);

static inline void preempt_notifier_init(struct preempt_notifier *notifier,
				     struct preempt_ops *ops)
{
	INIT_HLIST_NODE(&notifier->link);
	notifier->ops = ops;
}

#endif

#endif /* __LINUX_PREEMPT_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*
 * VFIO API definition
 *
 * Copyright (C) 2012 Red Hat, Inc.  All rights reserved.
 *     Author: Alex Williamson <alex.williamson@redhat.com>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */
#ifndef VFIO_H
#define VFIO_H


#include <linux/iommu.h>
#include <linux/mm.h>
#include <linux/workqueue.h>
#include <linux/poll.h>
#include <uapi/linux/vfio.h>

/**
 * struct vfio_device_ops - VFIO bus driver device callbacks
 *
 * @open: Called when userspace creates new file descriptor for device
 * @release: Called when userspace releases file descriptor for device
 * @read: Perform read(2) on device file descriptor
 * @write: Perform write(2) on device file descriptor
 * @ioctl: Perform ioctl(2) on device file descriptor, supporting VFIO_DEVICE_*
 *         operations documented below
 * @mmap: Perform mmap(2) on a region of the device file descriptor
 * @request: Request for the bus driver to release the device
 */
struct vfio_device_ops {
	char	*name;
	int	(*open)(void *device_data);
	void	(*release)(void *device_data);
	ssize_t	(*read)(void *device_data, char __user *buf,
			size_t count, loff_t *ppos);
	ssize_t	(*write)(void *device_data, const char __user *buf,
			 size_t count, loff_t *size);
	long	(*ioctl)(void *device_data, unsigned int cmd,
			 unsigned long arg);
	int	(*mmap)(void *device_data, struct vm_area_struct *vma);
	void	(*request)(void *device_data, unsigned int count);
};

extern struct iommu_group *vfio_iommu_group_get(struct device *dev);
extern void vfio_iommu_group_put(struct iommu_group *group, struct device *dev);

extern int vfio_add_group_dev(struct device *dev,
			      const struct vfio_device_ops *ops,
			      void *device_data);

extern void *vfio_del_group_dev(struct device *dev);
extern struct vfio_device *vfio_device_get_from_dev(struct device *dev);
extern void vfio_device_put(struct vfio_device *device);
extern void *vfio_device_data(struct vfio_device *device);

/**
 * struct vfio_iommu_driver_ops - VFIO IOMMU driver callbacks
 */
struct vfio_iommu_driver_ops {
	char		*name;
	struct module	*owner;
	void		*(*open)(unsigned long arg);
	void		(*release)(void *iommu_data);
	ssize_t		(*read)(void *iommu_data, char __user *buf,
				size_t count, loff_t *ppos);
	ssize_t		(*write)(void *iommu_data, const char __user *buf,
				 size_t count, loff_t *size);
	long		(*ioctl)(void *iommu_data, unsigned int cmd,
				 unsigned long arg);
	int		(*mmap)(void *iommu_data, struct vm_area_struct *vma);
	int		(*attach_group)(void *iommu_data,
					struct iommu_group *group);
	void		(*detach_group)(void *iommu_data,
					struct iommu_group *group);

};

extern int vfio_register_iommu_driver(const struct vfio_iommu_driver_ops *ops);

extern void vfio_unregister_iommu_driver(
				const struct vfio_iommu_driver_ops *ops);

/*
 * External user API
 */
extern struct vfio_group *vfio_group_get_external_user(struct file *filep);
extern void vfio_group_put_external_user(struct vfio_group *group);
extern bool vfio_external_group_match_file(struct vfio_group *group,
					   struct file *filep);
extern int vfio_external_user_iommu_id(struct vfio_group *group);
extern long vfio_external_check_extension(struct vfio_group *group,
					  unsigned long arg);

/*
 * Sub-module helpers
 */
struct vfio_info_cap {
	struct vfio_info_cap_header *buf;
	size_t size;
};
extern struct vfio_info_cap_header *vfio_info_cap_add(
		struct vfio_info_cap *caps, size_t size, u16 id, u16 version);
extern void vfio_info_cap_shift(struct vfio_info_cap *caps, size_t offset);

struct pci_dev;
#ifdef CONFIG_EEH
extern void vfio_spapr_pci_eeh_open(struct pci_dev *pdev);
extern void vfio_spapr_pci_eeh_release(struct pci_dev *pdev);
extern long vfio_spapr_iommu_eeh_ioctl(struct iommu_group *group,
				       unsigned int cmd,
				       unsigned long arg);
#else
static inline void vfio_spapr_pci_eeh_open(struct pci_dev *pdev)
{
}

static inline void vfio_spapr_pci_eeh_release(struct pci_dev *pdev)
{
}

static inline long vfio_spapr_iommu_eeh_ioctl(struct iommu_group *group,
					      unsigned int cmd,
					      unsigned long arg)
{
	return -ENOTTY;
}
#endif /* CONFIG_EEH */

/*
 * IRQfd - generic
 */
struct virqfd {
	void			*opaque;
	struct eventfd_ctx	*eventfd;
	int			(*handler)(void *, void *);
	void			(*thread)(void *, void *);
	void			*data;
	struct work_struct	inject;
	wait_queue_t		wait;
	poll_table		pt;
	struct work_struct	shutdown;
	struct virqfd		**pvirqfd;
};

extern int vfio_virqfd_enable(void *opaque,
			      int (*handler)(void *, void *),
			      void (*thread)(void *, void *),
			      void *data, struct virqfd **pvirqfd, int fd);
extern void vfio_virqfd_disable(struct virqfd **pvirqfd);

#endif /* VFIO_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #ifndef _LINUX_NLS_H
#define _LINUX_NLS_H

#include <linux/init.h>

/* Unicode has changed over the years.  Unicode code points no longer
 * fit into 16 bits; as of Unicode 5 valid code points range from 0
 * to 0x10ffff (17 planes, where each plane holds 65536 code points).
 *
 * The original decision to represent Unicode characters as 16-bit
 * wchar_t values is now outdated.  But plane 0 still includes the
 * most commonly used characters, so we will retain it.  The newer
 * 32-bit unicode_t type can be used when it is necessary to
 * represent the full Unicode character set.
 */

/* Plane-0 Unicode character */
typedef u16 wchar_t;
#define MAX_WCHAR_T	0xffff

/* Arbitrary Unicode character */
typedef u32 unicode_t;

struct nls_table {
	const char *charset;
	const char *alias;
	int (*uni2char) (wchar_t uni, unsigned char *out, int boundlen);
	int (*char2uni) (const unsigned char *rawstring, int boundlen,
			 wchar_t *uni);
	const unsigned char *charset2lower;
	const unsigned char *charset2upper;
	struct module *owner;
	struct nls_table *next;
};

/* this value hold the maximum octet of charset */
#define NLS_MAX_CHARSET_SIZE 6 /* for UTF-8 */

/* Byte order for UTF-16 strings */
enum utf16_endian {
	UTF16_HOST_ENDIAN,
	UTF16_LITTLE_ENDIAN,
	UTF16_BIG_ENDIAN
};

/* nls_base.c */
extern int __register_nls(struct nls_table *, struct module *);
extern int unregister_nls(struct nls_table *);
extern struct nls_table *load_nls(char *);
extern void unload_nls(struct nls_table *);
extern struct nls_table *load_nls_default(void);
#define register_nls(nls) __register_nls((nls), THIS_MODULE)

extern int utf8_to_utf32(const u8 *s, int len, unicode_t *pu);
extern int utf32_to_utf8(unicode_t u, u8 *s, int maxlen);
extern int utf8s_to_utf16s(const u8 *s, int len,
		enum utf16_endian endian, wchar_t *pwcs, int maxlen);
extern int utf16s_to_utf8s(const wchar_t *pwcs, int len,
		enum utf16_endian endian, u8 *s, int maxlen);

static inline unsigned char nls_tolower(struct nls_table *t, unsigned char c)
{
	unsigned char nc = t->charset2lower[c];

	return nc ? nc : c;
}

static inline unsigned char nls_toupper(struct nls_table *t, unsigned char c)
{
	unsigned char nc = t->charset2upper[c];

	return nc ? nc : c;
}

static inline int nls_strnicmp(struct nls_table *t, const unsigned char *s1,
		const unsigned char *s2, int len)
{
	while (len--) {
		if (nls_tolower(t, *s1++) != nls_tolower(t, *s2++))
			return 1;
	}

	return 0;
}

/*
 * nls_nullsize - return length of null character for codepage
 * @codepage - codepage for which to return length of NULL terminator
 *
 * Since we can't guarantee that the null terminator will be a particular
 * length, we have to check against the codepage. If there's a problem
 * determining it, assume a single-byte NULL terminator.
 */
static inline int
nls_nullsize(const struct nls_table *codepage)
{
	int charlen;
	char tmp[NLS_MAX_CHARSET_SIZE];

	charlen = codepage->uni2char(0, tmp, NLS_MAX_CHARSET_SIZE);

	return charlen > 0 ? charlen : 1;
}

#define MODULE_ALIAS_NLS(name)	MODULE_ALIAS("nls_" __stringify(name))

#endif /* _LINUX_NLS_H */

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          #ifndef __LINUX_NETFILTER_H
#define __LINUX_NETFILTER_H

#include <linux/init.h>
#include <linux/skbuff.h>
#include <linux/net.h>
#include <linux/if.h>
#include <linux/in.h>
#include <linux/in6.h>
#include <linux/wait.h>
#include <linux/list.h>
#include <linux/static_key.h>
#include <linux/netfilter_defs.h>
#include <linux/netdevice.h>
#include <net/net_namespace.h>

#ifdef CONFIG_NETFILTER
static inline int NF_DROP_GETERR(int verdict)
{
	return -(verdict >> NF_VERDICT_QBITS);
}

static inline int nf_inet_addr_cmp(const union nf_inet_addr *a1,
				   const union nf_inet_addr *a2)
{
	return a1->all[0] == a2->all[0] &&
	       a1->all[1] == a2->all[1] &&
	       a1->all[2] == a2->all[2] &&
	       a1->all[3] == a2->all[3];
}

static inline void nf_inet_addr_mask(const union nf_inet_addr *a1,
				     union nf_inet_addr *result,
				     const union nf_inet_addr *mask)
{
	result->all[0] = a1->all[0] & mask->all[0];
	result->all[1] = a1->all[1] & mask->all[1];
	result->all[2] = a1->all[2] & mask->all[2];
	result->all[3] = a1->all[3] & mask->all[3];
}

int netfilter_init(void);

struct sk_buff;

struct nf_hook_ops;

struct sock;

struct nf_hook_state {
	unsigned int hook;
	int thresh;
	u_int8_t pf;
	struct net_device *in;
	struct net_device *out;
	struct sock *sk;
	struct net *net;
	struct nf_hook_entry __rcu *hook_entries;
	int (*okfn)(struct net *, struct sock *, struct sk_buff *);
};

typedef unsigned int nf_hookfn(void *priv,
			       struct sk_buff *skb,
			       const struct nf_hook_state *state);
struct nf_hook_ops {
	struct list_head	list;

	/* User fills in from here down. */
	nf_hookfn		*hook;
	struct net_device	*dev;
	void			*priv;
	u_int8_t		pf;
	unsigned int		hooknum;
	/* Hooks are ordered in ascending priority. */
	int			priority;
};

struct nf_hook_entry {
	struct nf_hook_entry __rcu	*next;
	struct nf_hook_ops		ops;
	const struct nf_hook_ops	*orig_ops;
};

static inline void nf_hook_state_init(struct nf_hook_state *p,
				      struct nf_hook_entry *hook_entry,
				      unsigned int hook,
				      int thresh, u_int8_t pf,
				      struct net_device *indev,
				      struct net_device *outdev,
				      struct sock *sk,
				      struct net *net,
				      int (*okfn)(struct net *, struct sock *, struct sk_buff *))
{
	p->hook = hook;
	p->thresh = thresh;
	p->pf = pf;
	p->in = indev;
	p->out = outdev;
	p->sk = sk;
	p->net = net;
	RCU_INIT_POINTER(p->hook_entries, hook_entry);
	p->okfn = okfn;
}



struct nf_sockopt_ops {
	struct list_head list;

	u_int8_t pf;

	/* Non-inclusive ranges: use 0/0/NULL to never get called. */
	int set_optmin;
	int set_optmax;
	int (*set)(struct sock *sk, int optval, void __user *user, unsigned int len);
#ifdef CONFIG_COMPAT
	int (*compat_set)(struct sock *sk, int optval,
			void __user *user, unsigned int len);
#endif
	int get_optmin;
	int get_optmax;
	int (*get)(struct sock *sk, int optval, void __user *user, int *len);
#ifdef CONFIG_COMPAT
	int (*compat_get)(struct sock *sk, int optval,
			void __user *user, int *len);
#endif
	/* Use the module struct to lock set/get code in place */
	struct module *owner;
};

/* Function to register/unregister hook points. */
int nf_register_net_hook(struct net *net, const struct nf_hook_ops *ops);
void nf_unregister_net_hook(struct net *net, const struct nf_hook_ops *ops);
int nf_register_net_hooks(struct net *net, const struct nf_hook_ops *reg,
			  unsigned int n);
void nf_unregister_net_hooks(struct net *net, const struct nf_hook_ops *reg,
			     unsigned int n);

int nf_register_hook(struct nf_hook_ops *reg);
void nf_unregister_hook(struct nf_hook_ops *reg);
int nf_register_hooks(struct nf_hook_ops *reg, unsigned int n);
void nf_unregister_hooks(struct nf_hook_ops *reg, unsigned int n);
int _nf_register_hooks(struct nf_hook_ops *reg, unsigned int n);
void _nf_unregister_hooks(struct nf_hook_ops *reg, unsigned int n);

/* Functions to register get/setsockopt ranges (non-inclusive).  You
   need to check permissions yourself! */
int nf_register_sockopt(struct nf_sockopt_ops *reg);
void nf_unregister_sockopt(struct nf_sockopt_ops *reg);

#ifdef HAVE_JUMP_LABEL
extern struct static_key nf_hooks_needed[NFPROTO_NUMPROTO][NF_MAX_HOOKS];
#endif

int nf_hook_slow(struct sk_buff *skb, struct nf_hook_state *state);

/**
 *	nf_hook_thresh - call a netfilter hook
 *
 *	Returns 1 if the hook has allowed the packet to pass.  The function
 *	okfn must be invoked by the caller in this case.  Any other return
 *	value indicates the packet has been consumed by the hook.
 */
static inline int nf_hook_thresh(u_int8_t pf, unsigned int hook,
				 struct net *net,
				 struct sock *sk,
				 struct sk_buff *skb,
				 struct net_device *indev,
				 struct net_device *outdev,
				 int (*okfn)(struct net *, struct sock *, struct sk_buff *),
				 int thresh)
{
	struct nf_hook_entry *hook_head;
	int ret = 1;

#ifdef HAVE_JUMP_LABEL
	if (__builtin_constant_p(pf) &&
	    __builtin_constant_p(hook) &&
	    !static_key_false(&nf_hooks_needed[pf][hook]))
		return 1;
#endif

	rcu_read_lock();
	hook_head = rcu_dereference(net->nf.hooks[pf][hook]);
	if (hook_head) {
		struct nf_hook_state state;

		nf_hook_state_init(&state, hook_head, hook, thresh,
				   pf, indev, outdev, sk, net, okfn);

		ret = nf_hook_slow(skb, &state);
	}
	rcu_read_unlock();

	return ret;
}

static inline int nf_hook(u_int8_t pf, unsigned int hook, struct net *net,
			  struct sock *sk, struct sk_buff *skb,
			  struct net_device *indev, struct net_device *outdev,
			  int (*okfn)(struct net *, struct sock *, struct sk_buff *))
{
	return nf_hook_thresh(pf, hook, net, sk, skb, indev, outdev, okfn, INT_MIN);
}
                   
/* Activate hook; either okfn or kfree_skb called, unless a hook
   returns NF_STOLEN (in which case, it's up to the hook to deal with
   the consequences).

   Returns -ERRNO if packet dropped.  Zero means queued, stolen or
   accepted.
*/

/* RR:
   > I don't want nf_hook to return anything because people might forget
   > about async and trust the return value to mean "packet was ok".

   AK:
   Just document it clearly, then you can expect some sense from kernel
   coders :)
*/

static inline int
NF_HOOK_THRESH(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
	       struct sk_buff *skb, struct net_device *in,
	       struct net_device *out,
	       int (*okfn)(struct net *, struct sock *, struct sk_buff *),
	       int thresh)
{
	int ret = nf_hook_thresh(pf, hook, net, sk, skb, in, out, okfn, thresh);
	if (ret == 1)
		ret = okfn(net, sk, skb);
	return ret;
}

static inline int
NF_HOOK_COND(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
	     struct sk_buff *skb, struct net_device *in, struct net_device *out,
	     int (*okfn)(struct net *, struct sock *, struct sk_buff *),
	     bool cond)
{
	int ret;

	if (!cond ||
	    ((ret = nf_hook_thresh(pf, hook, net, sk, skb, in, out, okfn, INT_MIN)) == 1))
		ret = okfn(net, sk, skb);
	return ret;
}

static inline int
NF_HOOK(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk, struct sk_buff *skb,
	struct net_device *in, struct net_device *out,
	int (*okfn)(struct net *, struct sock *, struct sk_buff *))
{
	return NF_HOOK_THRESH(pf, hook, net, sk, skb, in, out, okfn, INT_MIN);
}

/* Call setsockopt() */
int nf_setsockopt(struct sock *sk, u_int8_t pf, int optval, char __user *opt,
		  unsigned int len);
int nf_getsockopt(struct sock *sk, u_int8_t pf, int optval, char __user *opt,
		  int *len);
#ifdef CONFIG_COMPAT
int compat_nf_setsockopt(struct sock *sk, u_int8_t pf, int optval,
		char __user *opt, unsigned int len);
int compat_nf_getsockopt(struct sock *sk, u_int8_t pf, int optval,
		char __user *opt, int *len);
#endif

/* Call this before modifying an existing packet: ensures it is
   modifiable and linear to the point you care about (writable_len).
   Returns true or false. */
int skb_make_writable(struct sk_buff *skb, unsigned int writable_len);

struct flowi;
struct nf_queue_entry;

struct nf_afinfo {
	unsigned short	family;
	__sum16		(*checksum)(struct sk_buff *skb, unsigned int hook,
				    unsigned int dataoff, u_int8_t protocol);
	__sum16		(*checksum_partial)(struct sk_buff *skb,
					    unsigned int hook,
					    unsigned int dataoff,
					    unsigned int len,
					    u_int8_t protocol);
	int		(*route)(struct net *net, struct dst_entry **dst,
				 struct flowi *fl, bool strict);
	void		(*saveroute)(const struct sk_buff *skb,
				     struct nf_queue_entry *entry);
	int		(*reroute)(struct net *net, struct sk_buff *skb,
				   const struct nf_queue_entry *entry);
	int		route_key_size;
};

extern const struct nf_afinfo __rcu *nf_afinfo[NFPROTO_NUMPROTO];
static inline const struct nf_afinfo *nf_get_afinfo(unsigned short family)
{
	return rcu_dereference(nf_afinfo[family]);
}

static inline __sum16
nf_checksum(struct sk_buff *skb, unsigned int hook, unsigned int dataoff,
	    u_int8_t protocol, unsigned short family)
{
	const struct nf_afinfo *afinfo;
	__sum16 csum = 0;

	rcu_read_lock();
	afinfo = nf_get_afinfo(family);
	if (afinfo)
		csum = afinfo->checksum(skb, hook, dataoff, protocol);
	rcu_read_unlock();
	return csum;
}

static inline __sum16
nf_checksum_partial(struct sk_buff *skb, unsigned int hook,
		    unsigned int dataoff, unsigned int len,
		    u_int8_t protocol, unsigned short family)
{
	const struct nf_afinfo *afinfo;
	__sum16 csum = 0;

	rcu_read_lock();
	afinfo = nf_get_afinfo(family);
	if (afinfo)
		csum = afinfo->checksum_partial(skb, hook, dataoff, len,
						protocol);
	rcu_read_unlock();
	return csum;
}

int nf_register_afinfo(const struct nf_afinfo *afinfo);
void nf_unregister_afinfo(const struct nf_afinfo *afinfo);

#include <net/flow.h>
extern void (*nf_nat_decode_session_hook)(struct sk_buff *, struct flowi *);

static inline void
nf_nat_decode_session(struct sk_buff *skb, struct flowi *fl, u_int8_t family)
{
#ifdef CONFIG_NF_NAT_NEEDED
	void (*decodefn)(struct sk_buff *, struct flowi *);

	rcu_read_lock();
	decodefn = rcu_dereference(nf_nat_decode_session_hook);
	if (decodefn)
		decodefn(skb, fl);
	rcu_read_unlock();
#endif
}

#else /* !CONFIG_NETFILTER */
static inline int
NF_HOOK_COND(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
	     struct sk_buff *skb, struct net_device *in, struct net_device *out,
	     int (*okfn)(struct net *, struct sock *, struct sk_buff *),
	     bool cond)
{
	return okfn(net, sk, skb);
}

static inline int
NF_HOOK(uint8_t pf, unsigned int hook, struct net *net, struct sock *sk,
	struct sk_buff *skb, struct net_device *in, struct net_device *out,
	int (*okfn)(struct net *, struct sock *, struct sk_buff *))
{
	return okfn(net, sk, skb);
}

static inline int nf_hook(u_int8_t pf, unsigned int hook, struct net *net,
			  struct sock *sk, struct sk_buff *skb,
			  struct net_device *indev, struct net_device *outdev,
			  int (*okfn)(struct net *, struct sock *, struct sk_buff *))
{
	return 1;
}
struct flowi;
static inline void
nf_nat_decode_session(struct sk_buff *skb, struct flowi *fl, u_int8_t family)
{
}
#endif /*CONFIG_NETFILTER*/

#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
#include <linux/netfilter/nf_conntrack_zones_common.h>

extern void (*ip_ct_attach)(struct sk_buff *, const struct sk_buff *) __rcu;
void nf_ct_attach(struct sk_buff *, const struct sk_buff *);
extern void (*nf_ct_destroy)(struct nf_conntrack *) __rcu;
#else
static inline void nf_ct_attach(struct sk_buff *new, struct sk_buff *skb) {}
#endif

struct nf_conn;
enum ip_conntrack_info;
struct nlattr;

struct nfnl_ct_hook {
	struct nf_conn *(*get_ct)(const struct sk_buff *skb,
				  enum ip_conntrack_info *ctinfo);
	size_t (*build_size)(const struct nf_conn *ct);
	int (*build)(struct sk_buff *skb, struct nf_conn *ct,
		     enum ip_conntrack_info ctinfo,
		     u_int16_t ct_attr, u_int16_t ct_info_attr);
	int (*parse)(const struct nlattr *attr, struct nf_conn *ct);
	int (*attach_expect)(const struct nlattr *attr, struct nf_conn *ct,
			     u32 portid, u32 report);
	void (*seq_adjust)(struct sk_buff *skb, struct nf_conn *ct,
			   enum ip_conntrack_info ctinfo, s32 off);
};
extern struct nfnl_ct_hook __rcu *nfnl_ct_hook;

/**
 * nf_skb_duplicated - TEE target has sent a packet
 *
 * When a xtables target sends a packet, the OUTPUT and POSTROUTING
 * hooks are traversed again, i.e. nft and xtables are invoked recursively.
 *
 * This is used by xtables TEE target to prevent the duplicated skb from
 * being duplicated again.
 */
DECLARE_PER_CPU(bool, nf_skb_duplicated);

#endif /*__LINUX_NETFILTER_H*/
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       /*
 *
 * Definitions for mount interface. This describes the in the kernel build 
 * linkedlist with mounted filesystems.
 *
 * Author:  Marco van Wieringen <mvw@planets.elm.net>
 *
 */
#ifndef _LINUX_MOUNT_H
#define _LINUX_MOUNT_H

#include <linux/types.h>
#include <linux/list.h>
#include <linux/nodemask.h>
#include <linux/spinlock.h>
#include <linux/seqlock.h>
#include <linux/atomic.h>

struct super_block;
struct vfsmount;
struct dentry;
struct mnt_namespace;

#define MNT_NOSUID	0x01
#define MNT_NODEV	0x02
#define MNT_NOEXEC	0x04
#define MNT_NOATIME	0x08
#define MNT_NODIRATIME	0x10
#define MNT_RELATIME	0x20
#define MNT_READONLY	0x40	/* does the user want this to be r/o? */

#define MNT_SHRINKABLE	0x100
#define MNT_WRITE_HOLD	0x200

#define MNT_SHARED	0x1000	/* if the vfsmount is a shared mount */
#define MNT_UNBINDABLE	0x2000	/* if the vfsmount is a unbindable mount */
/*
 * MNT_SHARED_MASK is the set of flags that should be cleared when a
 * mount becomes shared.  Currently, this is only the flag that says a
 * mount cannot be bind mounted, since this is how we create a mount
 * that shares events with another mount.  If you add a new MNT_*
 * flag, consider how it interacts with shared mounts.
 */
#define MNT_SHARED_MASK	(MNT_UNBINDABLE)
#define MNT_USER_SETTABLE_MASK  (MNT_NOSUID | MNT_NODEV | MNT_NOEXEC \
				 | MNT_NOATIME | MNT_NODIRATIME | MNT_RELATIME \
				 | MNT_READONLY)
#define MNT_ATIME_MASK (MNT_NOATIME | MNT_NODIRATIME | MNT_RELATIME )

#define MNT_INTERNAL_FLAGS (MNT_SHARED | MNT_WRITE_HOLD | MNT_INTERNAL | \
			    MNT_DOOMED | MNT_SYNC_UMOUNT | MNT_MARKED)

#define MNT_INTERNAL	0x4000

#define MNT_LOCK_ATIME		0x040000
#define MNT_LOCK_NOEXEC		0x080000
#define MNT_LOCK_NOSUID		0x100000
#define MNT_LOCK_NODEV		0x200000
#define MNT_LOCK_READONLY	0x400000
#define MNT_LOCKED		0x800000
#define MNT_DOOMED		0x1000000
#define MNT_SYNC_UMOUNT		0x2000000
#define MNT_MARKED		0x4000000
#define MNT_UMOUNT		0x8000000

struct vfsmount {
	struct dentry *mnt_root;	/* root of the mounted tree */
	struct super_block *mnt_sb;	/* pointer to superblock */
	int mnt_flags;
};

struct file; /* forward dec */
struct path;

extern int mnt_want_write(struct vfsmount *mnt);
extern int mnt_want_write_file(struct file *file);
extern int mnt_clone_write(struct vfsmount *mnt);
extern void mnt_drop_write(struct vfsmount *mnt);
extern void mnt_drop_write_file(struct file *file);
extern void mntput(struct vfsmount *mnt);
extern struct vfsmount *mntget(struct vfsmount *mnt);
extern struct vfsmount *mnt_clone_internal(struct path *path);
extern int __mnt_is_readonly(struct vfsmount *mnt);
extern bool mnt_may_suid(struct vfsmount *mnt);

struct path;
extern struct vfsmount *clone_private_mount(struct path *path);

struct file_system_type;
extern struct vfsmount *vfs_kern_mount(struct file_system_type *type,
				      int flags, const char *name,
				      void *data);
extern struct vfsmount *vfs_submount(const struct dentry *mountpoint,
				     struct file_system_type *type,
				     const char *name, void *data);

extern void mnt_set_expiry(struct vfsmount *mnt, struct list_head *expiry_list);
extern void mark_mounts_for_expiry(struct list_head *mounts);

extern dev_t name_to_dev_t(const char *name);

extern unsigned int sysctl_mount_max;

#endif /* _LINUX_MOUNT_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  /* ASN.1 BER/DER/CER parsing state machine internal definitions
 *
 * Copyright (C) 2012 Red Hat, Inc. All Rights Reserved.
 * Written by David Howells (dhowells@redhat.com)
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public Licence
 * as published by the Free Software Foundation; either version
 * 2 of the Licence, or (at your option) any later version.
 */

#ifndef _LINUX_ASN1_BER_BYTECODE_H
#define _LINUX_ASN1_BER_BYTECODE_H

#ifdef __KERNEL__
#include <linux/types.h>
#endif
#include <linux/asn1.h>

typedef int (*asn1_action_t)(void *context,
			     size_t hdrlen, /* In case of ANY type */
			     unsigned char tag, /* In case of ANY type */
			     const void *value, size_t vlen);

struct asn1_decoder {
	const unsigned char *machine;
	size_t machlen;
	const asn1_action_t *actions;
};

enum asn1_opcode {
	/* The tag-matching ops come first and the odd-numbered slots
	 * are for OR_SKIP ops.
	 */
#define ASN1_OP_MATCH__SKIP		  0x01
#define ASN1_OP_MATCH__ACT		  0x02
#define ASN1_OP_MATCH__JUMP		  0x04
#define ASN1_OP_MATCH__ANY		  0x08
#define ASN1_OP_MATCH__COND		  0x10

	ASN1_OP_MATCH			= 0x00,
	ASN1_OP_MATCH_OR_SKIP		= 0x01,
	ASN1_OP_MATCH_ACT		= 0x02,
	ASN1_OP_MATCH_ACT_OR_SKIP	= 0x03,
	ASN1_OP_MATCH_JUMP		= 0x04,
	ASN1_OP_MATCH_JUMP_OR_SKIP	= 0x05,
	ASN1_OP_MATCH_ANY		= 0x08,
	ASN1_OP_MATCH_ANY_OR_SKIP	= 0x09,
	ASN1_OP_MATCH_ANY_ACT		= 0x0a,
	ASN1_OP_MATCH_ANY_ACT_OR_SKIP	= 0x0b,
	/* Everything before here matches unconditionally */

	ASN1_OP_COND_MATCH_OR_SKIP	= 0x11,
	ASN1_OP_COND_MATCH_ACT_OR_SKIP	= 0x13,
	ASN1_OP_COND_MATCH_JUMP_OR_SKIP	= 0x15,
	ASN1_OP_COND_MATCH_ANY		= 0x18,
	ASN1_OP_COND_MATCH_ANY_OR_SKIP	= 0x19,
	ASN1_OP_COND_MATCH_ANY_ACT	= 0x1a,
	ASN1_OP_COND_MATCH_ANY_ACT_OR_SKIP = 0x1b,

	/* Everything before here will want a tag from the data */
#define ASN1_OP__MATCHES_TAG ASN1_OP_COND_MATCH_ANY_ACT_OR_SKIP

	/* These are here to help fill up space */
	ASN1_OP_COND_FAIL		= 0x1c,
	ASN1_OP_COMPLETE		= 0x1d,
	ASN1_OP_ACT			= 0x1e,
	ASN1_OP_MAYBE_ACT		= 0x1f,

	/* The following eight have bit 0 -> SET, 1 -> OF, 2 -> ACT */
	ASN1_OP_END_SEQ			= 0x20,
	ASN1_OP_END_SET			= 0x21,
	ASN1_OP_END_SEQ_OF		= 0x22,
	ASN1_OP_END_SET_OF		= 0x23,
	ASN1_OP_END_SEQ_ACT		= 0x24,
	ASN1_OP_END_SET_ACT		= 0x25,
	ASN1_OP_END_SEQ_OF_ACT		= 0x26,
	ASN1_OP_END_SET_OF_ACT		= 0x27,
#define ASN1_OP_END__SET		  0x01
#define ASN1_OP_END__OF			  0x02
#define ASN1_OP_END__ACT		  0x04

	ASN1_OP_RETURN			= 0x28,

	ASN1_OP__NR
};

#define _tag(CLASS, CP, TAG) ((ASN1_##CLASS << 6) | (ASN1_##CP << 5) | ASN1_##TAG)
#define _tagn(CLASS, CP, TAG) ((ASN1_##CLASS << 6) | (ASN1_##CP << 5) | TAG)
#define _jump_target(N) (N)
#define _action(N) (N)

#endif /* _LINUX_ASN1_BER_BYTECODE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #ifndef _LINUX_UTSNAME_H
#define _LINUX_UTSNAME_H


#include <linux/sched.h>
#include <linux/kref.h>
#include <linux/nsproxy.h>
#include <linux/ns_common.h>
#include <linux/err.h>
#include <uapi/linux/utsname.h>

enum uts_proc {
	UTS_PROC_OSTYPE,
	UTS_PROC_OSRELEASE,
	UTS_PROC_VERSION,
	UTS_PROC_HOSTNAME,
	UTS_PROC_DOMAINNAME,
};

struct user_namespace;
extern struct user_namespace init_user_ns;

struct uts_namespace {
	struct kref kref;
	struct new_utsname name;
	struct user_namespace *user_ns;
	struct ucounts *ucounts;
	struct ns_common ns;
};
extern struct uts_namespace init_uts_ns;

#ifdef CONFIG_UTS_NS
static inline void get_uts_ns(struct uts_namespace *ns)
{
	kref_get(&ns->kref);
}

extern struct uts_namespace *copy_utsname(unsigned long flags,
	struct user_namespace *user_ns, struct uts_namespace *old_ns);
extern void free_uts_ns(struct kref *kref);

static inline void put_uts_ns(struct uts_namespace *ns)
{
	kref_put(&ns->kref, free_uts_ns);
}
#else
static inline void get_uts_ns(struct uts_namespace *ns)
{
}

static inline void put_uts_ns(struct uts_namespace *ns)
{
}

static inline struct uts_namespace *copy_utsname(unsigned long flags,
	struct user_namespace *user_ns, struct uts_namespace *old_ns)
{
	if (flags & CLONE_NEWUTS)
		return ERR_PTR(-EINVAL);

	return old_ns;
}
#endif

#ifdef CONFIG_PROC_SYSCTL
extern void uts_proc_notify(enum uts_proc proc);
#else
static inline void uts_proc_notify(enum uts_proc proc)
{
}
#endif

static inline struct new_utsname *utsname(void)
{
	return &current->nsproxy->uts_ns->name;
}

static inline struct new_utsname *init_utsname(void)
{
	return &init_uts_ns.name;
}

extern struct rw_semaphore uts_sem;

#endif /* _LINUX_UTSNAME_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         /*
 * Percpu refcounts:
 * (C) 2012 Google, Inc.
 * Author: Kent Overstreet <koverstreet@google.com>
 *
 * This implements a refcount with similar semantics to atomic_t - atomic_inc(),
 * atomic_dec_and_test() - but percpu.
 *
 * There's one important difference between percpu refs and normal atomic_t
 * refcounts; you have to keep track of your initial refcount, and then when you
 * start shutting down you call percpu_ref_kill() _before_ dropping the initial
 * refcount.
 *
 * The refcount will have a range of 0 to ((1U << 31) - 1), i.e. one bit less
 * than an atomic_t - this is because of the way shutdown works, see
 * percpu_ref_kill()/PERCPU_COUNT_BIAS.
 *
 * Before you call percpu_ref_kill(), percpu_ref_put() does not check for the
 * refcount hitting 0 - it can't, if it was in percpu mode. percpu_ref_kill()
 * puts the ref back in single atomic_t mode, collecting the per cpu refs and
 * issuing the appropriate barriers, and then marks the ref as shutting down so
 * that percpu_ref_put() will check for the ref hitting 0.  After it returns,
 * it's safe to drop the initial ref.
 *
 * USAGE:
 *
 * See fs/aio.c for some example usage; it's used there for struct kioctx, which
 * is created when userspaces calls io_setup(), and destroyed when userspace
 * calls io_destroy() or the process exits.
 *
 * In the aio code, kill_ioctx() is called when we wish to destroy a kioctx; it
 * calls percpu_ref_kill(), then hlist_del_rcu() and synchronize_rcu() to remove
 * the kioctx from the proccess's list of kioctxs - after that, there can't be
 * any new users of the kioctx (from lookup_ioctx()) and it's then safe to drop
 * the initial ref with percpu_ref_put().
 *
 * Code that does a two stage shutdown like this often needs some kind of
 * explicit synchronization to ensure the initial refcount can only be dropped
 * once - percpu_ref_kill() does this for you, it returns true once and false if
 * someone else already called it. The aio code uses it this way, but it's not
 * necessary if the code has some other mechanism to synchronize teardown.
 * around.
 */

#ifndef _LINUX_PERCPU_REFCOUNT_H
#define _LINUX_PERCPU_REFCOUNT_H

#include <linux/atomic.h>
#include <linux/kernel.h>
#include <linux/percpu.h>
#include <linux/rcupdate.h>
#include <linux/gfp.h>

struct percpu_ref;
typedef void (percpu_ref_func_t)(struct percpu_ref *);

/* flags set in the lower bits of percpu_ref->percpu_count_ptr */
enum {
	__PERCPU_REF_ATOMIC	= 1LU << 0,	/* operating in atomic mode */
	__PERCPU_REF_DEAD	= 1LU << 1,	/* (being) killed */
	__PERCPU_REF_ATOMIC_DEAD = __PERCPU_REF_ATOMIC | __PERCPU_REF_DEAD,

	__PERCPU_REF_FLAG_BITS	= 2,
};

/* @flags for percpu_ref_init() */
enum {
	/*
	 * Start w/ ref == 1 in atomic mode.  Can be switched to percpu
	 * operation using percpu_ref_switch_to_percpu().  If initialized
	 * with this flag, the ref will stay in atomic mode until
	 * percpu_ref_switch_to_percpu() is invoked on it.
	 */
	PERCPU_REF_INIT_ATOMIC	= 1 << 0,

	/*
	 * Start dead w/ ref == 0 in atomic mode.  Must be revived with
	 * percpu_ref_reinit() before used.  Implies INIT_ATOMIC.
	 */
	PERCPU_REF_INIT_DEAD	= 1 << 1,
};

struct percpu_ref {
	atomic_long_t		count;
	/*
	 * The low bit of the pointer indicates whether the ref is in percpu
	 * mode; if set, then get/put will manipulate the atomic_t.
	 */
	unsigned long		percpu_count_ptr;
	percpu_ref_func_t	*release;
	percpu_ref_func_t	*confirm_switch;
	bool			force_atomic:1;
	struct rcu_head		rcu;
};

int __must_check percpu_ref_init(struct percpu_ref *ref,
				 percpu_ref_func_t *release, unsigned int flags,
				 gfp_t gfp);
void percpu_ref_exit(struct percpu_ref *ref);
void percpu_ref_switch_to_atomic(struct percpu_ref *ref,
				 percpu_ref_func_t *confirm_switch);
void percpu_ref_switch_to_percpu(struct percpu_ref *ref);
void percpu_ref_kill_and_confirm(struct percpu_ref *ref,
				 percpu_ref_func_t *confirm_kill);
void percpu_ref_reinit(struct percpu_ref *ref);

/**
 * percpu_ref_kill - drop the initial ref
 * @ref: percpu_ref to kill
 *
 * Must be used to drop the initial ref on a percpu refcount; must be called
 * precisely once before shutdown.
 *
 * Puts @ref in non percpu mode, then does a call_rcu() before gathering up the
 * percpu counters and dropping the initial ref.
 */
static inline void percpu_ref_kill(struct percpu_ref *ref)
{
	percpu_ref_kill_and_confirm(ref, NULL);
}

/*
 * Internal helper.  Don't use outside percpu-refcount proper.  The
 * function doesn't return the pointer and let the caller test it for NULL
 * because doing so forces the compiler to generate two conditional
 * branches as it can't assume that @ref->percpu_count is not NULL.
 */
static inline bool __ref_is_percpu(struct percpu_ref *ref,
					  unsigned long __percpu **percpu_countp)
{
	unsigned long percpu_ptr;

	/*
	 * The value of @ref->percpu_count_ptr is tested for
	 * !__PERCPU_REF_ATOMIC, which may be set asynchronously, and then
	 * used as a pointer.  If the compiler generates a separate fetch
	 * when using it as a pointer, __PERCPU_REF_ATOMIC may be set in
	 * between contaminating the pointer value, meaning that
	 * READ_ONCE() is required when fetching it.
	 */
	percpu_ptr = READ_ONCE(ref->percpu_count_ptr);

	/* paired with smp_store_release() in __percpu_ref_switch_to_percpu() */
	smp_read_barrier_depends();

	/*
	 * Theoretically, the following could test just ATOMIC; however,
	 * then we'd have to mask off DEAD separately as DEAD may be
	 * visible without ATOMIC if we race with percpu_ref_kill().  DEAD
	 * implies ATOMIC anyway.  Test them together.
	 */
	if (unlikely(percpu_ptr & __PERCPU_REF_ATOMIC_DEAD))
		return false;

	*percpu_countp = (unsigned long __percpu *)percpu_ptr;
	return true;
}

/**
 * percpu_ref_get_many - increment a percpu refcount
 * @ref: percpu_ref to get
 * @nr: number of references to get
 *
 * Analogous to atomic_long_add().
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline void percpu_ref_get_many(struct percpu_ref *ref, unsigned long nr)
{
	unsigned long __percpu *percpu_count;

	rcu_read_lock_sched();

	if (__ref_is_percpu(ref, &percpu_count))
		this_cpu_add(*percpu_count, nr);
	else
		atomic_long_add(nr, &ref->count);

	rcu_read_unlock_sched();
}

/**
 * percpu_ref_get - increment a percpu refcount
 * @ref: percpu_ref to get
 *
 * Analagous to atomic_long_inc().
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline void percpu_ref_get(struct percpu_ref *ref)
{
	percpu_ref_get_many(ref, 1);
}

/**
 * percpu_ref_tryget - try to increment a percpu refcount
 * @ref: percpu_ref to try-get
 *
 * Increment a percpu refcount unless its count already reached zero.
 * Returns %true on success; %false on failure.
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline bool percpu_ref_tryget(struct percpu_ref *ref)
{
	unsigned long __percpu *percpu_count;
	bool ret;

	rcu_read_lock_sched();

	if (__ref_is_percpu(ref, &percpu_count)) {
		this_cpu_inc(*percpu_count);
		ret = true;
	} else {
		ret = atomic_long_inc_not_zero(&ref->count);
	}

	rcu_read_unlock_sched();

	return ret;
}

/**
 * percpu_ref_tryget_live - try to increment a live percpu refcount
 * @ref: percpu_ref to try-get
 *
 * Increment a percpu refcount unless it has already been killed.  Returns
 * %true on success; %false on failure.
 *
 * Completion of percpu_ref_kill() in itself doesn't guarantee that this
 * function will fail.  For such guarantee, percpu_ref_kill_and_confirm()
 * should be used.  After the confirm_kill callback is invoked, it's
 * guaranteed that no new reference will be given out by
 * percpu_ref_tryget_live().
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline bool percpu_ref_tryget_live(struct percpu_ref *ref)
{
	unsigned long __percpu *percpu_count;
	bool ret = false;

	rcu_read_lock_sched();

	if (__ref_is_percpu(ref, &percpu_count)) {
		this_cpu_inc(*percpu_count);
		ret = true;
	} else if (!(ref->percpu_count_ptr & __PERCPU_REF_DEAD)) {
		ret = atomic_long_inc_not_zero(&ref->count);
	}

	rcu_read_unlock_sched();

	return ret;
}

/**
 * percpu_ref_put_many - decrement a percpu refcount
 * @ref: percpu_ref to put
 * @nr: number of references to put
 *
 * Decrement the refcount, and if 0, call the release function (which was passed
 * to percpu_ref_init())
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline void percpu_ref_put_many(struct percpu_ref *ref, unsigned long nr)
{
	unsigned long __percpu *percpu_count;

	rcu_read_lock_sched();

	if (__ref_is_percpu(ref, &percpu_count))
		this_cpu_sub(*percpu_count, nr);
	else if (unlikely(atomic_long_sub_and_test(nr, &ref->count)))
		ref->release(ref);

	rcu_read_unlock_sched();
}

/**
 * percpu_ref_put - decrement a percpu refcount
 * @ref: percpu_ref to put
 *
 * Decrement the refcount, and if 0, call the release function (which was passed
 * to percpu_ref_init())
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline void percpu_ref_put(struct percpu_ref *ref)
{
	percpu_ref_put_many(ref, 1);
}

/**
 * percpu_ref_is_dying - test whether a percpu refcount is dying or dead
 * @ref: percpu_ref to test
 *
 * Returns %true if @ref is dying or dead.
 *
 * This function is safe to call as long as @ref is between init and exit
 * and the caller is responsible for synchronizing against state changes.
 */
static inline bool percpu_ref_is_dying(struct percpu_ref *ref)
{
	return ref->percpu_count_ptr & __PERCPU_REF_DEAD;
}

/**
 * percpu_ref_is_zero - test whether a percpu refcount reached zero
 * @ref: percpu_ref to test
 *
 * Returns %true if @ref reached zero.
 *
 * This function is safe to call as long as @ref is between init and exit.
 */
static inline bool percpu_ref_is_zero(struct percpu_ref *ref)
{
	unsigned long __percpu *percpu_count;

	if (__ref_is_percpu(ref, &percpu_count))
		return false;
	return !atomic_long_read(&ref->count);
}

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #ifndef _LINUX_MODULELOADER_H
#define _LINUX_MODULELOADER_H
/* The stuff needed for archs to support modules. */

#include <linux/module.h>
#include <linux/elf.h>

/* These may be implemented by architectures that need to hook into the
 * module loader code.  Architectures that don't need to do anything special
 * can just rely on the 'weak' default hooks defined in kernel/module.c.
 * Note, however, that at least one of apply_relocate or apply_relocate_add
 * must be implemented by each architecture.
 */

/* Adjust arch-specific sections.  Return 0 on success.  */
int module_frob_arch_sections(Elf_Ehdr *hdr,
			      Elf_Shdr *sechdrs,
			      char *secstrings,
			      struct module *mod);

/* Additional bytes needed by arch in front of individual sections */
unsigned int arch_mod_section_prepend(struct module *mod, unsigned int section);

/* Allocator used for allocating struct module, core sections and init
   sections.  Returns NULL on failure. */
void *module_alloc(unsigned long size);

/* Free memory returned from module_alloc. */
void module_memfree(void *module_region);

/*
 * Apply the given relocation to the (simplified) ELF.  Return -error
 * or 0.
 */
#ifdef CONFIG_MODULES_USE_ELF_REL
int apply_relocate(Elf_Shdr *sechdrs,
		   const char *strtab,
		   unsigned int symindex,
		   unsigned int relsec,
		   struct module *mod);
#else
static inline int apply_relocate(Elf_Shdr *sechdrs,
				 const char *strtab,
				 unsigned int symindex,
				 unsigned int relsec,
				 struct module *me)
{
	printk(KERN_ERR "module %s: REL relocation unsupported\n",
	       module_name(me));
	return -ENOEXEC;
}
#endif

/*
 * Apply the given add relocation to the (simplified) ELF.  Return
 * -error or 0
 */
#ifdef CONFIG_MODULES_USE_ELF_RELA
int apply_relocate_add(Elf_Shdr *sechdrs,
		       const char *strtab,
		       unsigned int symindex,
		       unsigned int relsec,
		       struct module *mod);
#else
static inline int apply_relocate_add(Elf_Shdr *sechdrs,
				     const char *strtab,
				     unsigned int symindex,
				     unsigned int relsec,
				     struct module *me)
{
	printk(KERN_ERR "module %s: REL relocation unsupported\n",
	       module_name(me));
	return -ENOEXEC;
}
#endif

/* Any final processing of module before access.  Return -error or 0. */
int module_finalize(const Elf_Ehdr *hdr,
		    const Elf_Shdr *sechdrs,
		    struct module *mod);

/* Any cleanup needed when module leaves. */
void module_arch_cleanup(struct module *mod);

/* Any cleanup before freeing mod->module_init */
void module_arch_freeing_init(struct module *mod);

#ifdef CONFIG_KASAN
#include <linux/kasan.h>
#define MODULE_ALIGN (PAGE_SIZE << KASAN_SHADOW_SCALE_SHIFT)
#else
#define MODULE_ALIGN PAGE_SIZE
#endif

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     #ifndef _LINUX_FIRMWARE_H
#define _LINUX_FIRMWARE_H

#include <linux/types.h>
#include <linux/compiler.h>
#include <linux/gfp.h>

#define FW_ACTION_NOHOTPLUG 0
#define FW_ACTION_HOTPLUG 1

struct firmware {
	size_t size;
	const u8 *data;
	struct page **pages;

	/* firmware loader private fields */
	void *priv;
};

struct module;
struct device;

struct builtin_fw {
	char *name;
	void *data;
	unsigned long size;
};

/* We have to play tricks here much like stringify() to get the
   __COUNTER__ macro to be expanded as we want it */
#define __fw_concat1(x, y) x##y
#define __fw_concat(x, y) __fw_concat1(x, y)

#define DECLARE_BUILTIN_FIRMWARE(name, blob)				     \
	DECLARE_BUILTIN_FIRMWARE_SIZE(name, &(blob), sizeof(blob))

#define DECLARE_BUILTIN_FIRMWARE_SIZE(name, blob, size)			     \
	static const struct builtin_fw __fw_concat(__builtin_fw,__COUNTER__) \
	__used __section(.builtin_fw) = { name, blob, size }

#if defined(CONFIG_FW_LOADER) || (defined(CONFIG_FW_LOADER_MODULE) && defined(MODULE))
int request_firmware(const struct firmware **fw, const char *name,
		     struct device *device);
int request_firmware_nowait(
	struct module *module, bool uevent,
	const char *name, struct device *device, gfp_t gfp, void *context,
	void (*cont)(const struct firmware *fw, void *context));
int request_firmware_direct(const struct firmware **fw, const char *name,
			    struct device *device);
int request_firmware_into_buf(const struct firmware **firmware_p,
	const char *name, struct device *device, void *buf, size_t size);

void release_firmware(const struct firmware *fw);
#else
static inline int request_firmware(const struct firmware **fw,
				   const char *name,
				   struct device *device)
{
	return -EINVAL;
}
static inline int request_firmware_nowait(
	struct module *module, bool uevent,
	const char *name, struct device *device, gfp_t gfp, void *context,
	void (*cont)(const struct firmware *fw, void *context))
{
	return -EINVAL;
}

static inline void release_firmware(const struct firmware *fw)
{
}

static inline int request_firmware_direct(const struct firmware **fw,
					  const char *name,
					  struct device *device)
{
	return -EINVAL;
}

static inline int request_firmware_into_buf(const struct firmware **firmware_p,
	const char *name, struct device *device, void *buf, size_t size)
{
	return -EINVAL;
}

#endif
#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /*
 *		Swansea University Computer Society NET3
 *
 *	This work is derived from NET2Debugged, which is in turn derived
 *	from NET2D which was written by:
 * 		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
 *
 *		This work was derived from Ross Biro's inspirational work
 *		for the LINUX operating system.  His version numbers were:
 *
 *		$Id: Space.c,v     0.8.4.5  1992/12/12 19:25:04 bir7 Exp $
 *		$Id: arp.c,v       0.8.4.6  1993/01/28 22:30:00 bir7 Exp $
 *		$Id: arp.h,v       0.8.4.6  1993/01/28 22:30:00 bir7 Exp $
 *		$Id: dev.c,v       0.8.4.13 1993/01/23 18:00:11 bir7 Exp $
 *		$Id: dev.h,v       0.8.4.7  1993/01/23 18:00:11 bir7 Exp $
 *		$Id: eth.c,v       0.8.4.4  1993/01/22 23:21:38 bir7 Exp $
 *		$Id: eth.h,v       0.8.4.1  1992/11/10 00:17:18 bir7 Exp $
 *		$Id: icmp.c,v      0.8.4.9  1993/01/23 18:00:11 bir7 Exp $
 *		$Id: icmp.h,v      0.8.4.2  1992/11/15 14:55:30 bir7 Exp $
 * 		$Id: ip.c,v        0.8.4.8  1992/12/12 19:25:04 bir7 Exp $
 * 		$Id: ip.h,v        0.8.4.2  1993/01/23 18:00:11 bir7 Exp $
 * 		$Id: loopback.c,v  0.8.4.8  1993/01/23 18:00:11 bir7 Exp $
 * 		$Id: packet.c,v    0.8.4.7  1993/01/26 22:04:00 bir7 Exp $
 *		$Id: protocols.c,v 0.8.4.3  1992/11/15 14:55:30 bir7 Exp $
 *		$Id: raw.c,v       0.8.4.12 1993/01/26 22:04:00 bir7 Exp $
 *		$Id: sock.c,v      0.8.4.6  1993/01/28 22:30:00 bir7 Exp $
 *		$Id: sock.h,v      0.8.4.7  1993/01/26 22:04:00 bir7 Exp $
 *		$Id: tcp.c,v       0.8.4.16 1993/01/26 22:04:00 bir7 Exp $
 *		$Id: tcp.h,v       0.8.4.7  1993/01/22 22:58:08 bir7 Exp $
 *		$Id: timer.c,v     0.8.4.8  1993/01/23 18:00:11 bir7 Exp $
 *		$Id: timer.h,v     0.8.4.2  1993/01/23 18:00:11 bir7 Exp $
 *		$Id: udp.c,v       0.8.4.12 1993/01/26 22:04:00 bir7 Exp $
 *		$Id: udp.h,v       0.8.4.1  1992/11/10 00:17:18 bir7 Exp $
 *		$Id: we.c,v        0.8.4.10 1993/01/23 18:00:11 bir7 Exp $
 *		$Id: wereg.h,v     0.8.4.1  1992/11/10 00:17:18 bir7 Exp $
 *
 *		This program is free software; you can redistribute it and/or
 *		modify it under the terms of the GNU General Public License
 *		as published by the Free Software Foundation; either version
 *		2 of the License, or (at your option) any later version.
 */
#ifndef _LINUX_INET_H
#define _LINUX_INET_H

#include <linux/types.h>

/*
 * These mimic similar macros defined in user-space for inet_ntop(3).
 * See /usr/include/netinet/in.h .
 */
#define INET_ADDRSTRLEN		(16)
#define INET6_ADDRSTRLEN	(48)

extern __be32 in_aton(const char *str);
extern int in4_pton(const char *src, int srclen, u8 *dst, int delim, const char **end);
extern int in6_pton(const char *src, int srclen, u8 *dst, int delim, const char **end);
#endif	/* _LINUX_INET_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   /*
 * Copyright (c) 2015, Linaro Limited
 *
 * This software is licensed under the terms of the GNU General Public
 * License version 2, as published by the Free Software Foundation, and
 * may be copied, distributed, and modified under those terms.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */
#ifndef __LINUX_ARM_SMCCC_H
#define __LINUX_ARM_SMCCC_H

/*
 * This file provides common defines for ARM SMC Calling Convention as
 * specified in
 * http://infocenter.arm.com/help/topic/com.arm.doc.den0028a/index.html
 */

#define ARM_SMCCC_STD_CALL		0
#define ARM_SMCCC_FAST_CALL		1
#define ARM_SMCCC_TYPE_SHIFT		31

#define ARM_SMCCC_SMC_32		0
#define ARM_SMCCC_SMC_64		1
#define ARM_SMCCC_CALL_CONV_SHIFT	30

#define ARM_SMCCC_OWNER_MASK		0x3F
#define ARM_SMCCC_OWNER_SHIFT		24

#define ARM_SMCCC_FUNC_MASK		0xFFFF

#define ARM_SMCCC_IS_FAST_CALL(smc_val)	\
	((smc_val) & (ARM_SMCCC_FAST_CALL << ARM_SMCCC_TYPE_SHIFT))
#define ARM_SMCCC_IS_64(smc_val) \
	((smc_val) & (ARM_SMCCC_SMC_64 << ARM_SMCCC_CALL_CONV_SHIFT))
#define ARM_SMCCC_FUNC_NUM(smc_val)	((smc_val) & ARM_SMCCC_FUNC_MASK)
#define ARM_SMCCC_OWNER_NUM(smc_val) \
	(((smc_val) >> ARM_SMCCC_OWNER_SHIFT) & ARM_SMCCC_OWNER_MASK)

#define ARM_SMCCC_CALL_VAL(type, calling_convention, owner, func_num) \
	(((type) << ARM_SMCCC_TYPE_SHIFT) | \
	((calling_convention) << ARM_SMCCC_CALL_CONV_SHIFT) | \
	(((owner) & ARM_SMCCC_OWNER_MASK) << ARM_SMCCC_OWNER_SHIFT) | \
	((func_num) & ARM_SMCCC_FUNC_MASK))

#define ARM_SMCCC_OWNER_ARCH		0
#define ARM_SMCCC_OWNER_CPU		1
#define ARM_SMCCC_OWNER_SIP		2
#define ARM_SMCCC_OWNER_OEM		3
#define ARM_SMCCC_OWNER_STANDARD	4
#define ARM_SMCCC_OWNER_TRUSTED_APP	48
#define ARM_SMCCC_OWNER_TRUSTED_APP_END	49
#define ARM_SMCCC_OWNER_TRUSTED_OS	50
#define ARM_SMCCC_OWNER_TRUSTED_OS_END	63

#define ARM_SMCCC_QUIRK_NONE		0
#define ARM_SMCCC_QUIRK_QCOM_A6		1 /* Save/restore register a6 */

#ifndef __ASSEMBLY__

#include <linux/linkage.h>
#include <linux/types.h>
/**
 * struct arm_smccc_res - Result from SMC/HVC call
 * @a0-a3 result values from registers 0 to 3
 */
struct arm_smccc_res {
	unsigned long a0;
	unsigned long a1;
	unsigned long a2;
	unsigned long a3;
};

/**
 * struct arm_smccc_quirk - Contains quirk information
 * @id: quirk identification
 * @state: quirk specific information
 * @a6: Qualcomm quirk entry for returning post-smc call contents of a6
 */
struct arm_smccc_quirk {
	int	id;
	union {
		unsigned long a6;
	} state;
};

/**
 * __arm_smccc_smc() - make SMC calls
 * @a0-a7: arguments passed in registers 0 to 7
 * @res: result values from registers 0 to 3
 * @quirk: points to an arm_smccc_quirk, or NULL when no quirks are required.
 *
 * This function is used to make SMC calls following SMC Calling Convention.
 * The content of the supplied param are copied to registers 0 to 7 prior
 * to the SMC instruction. The return values are updated with the content
 * from register 0 to 3 on return from the SMC instruction.  An optional
 * quirk structure provides vendor specific behavior.
 */
asmlinkage void __arm_smccc_smc(unsigned long a0, unsigned long a1,
			unsigned long a2, unsigned long a3, unsigned long a4,
			unsigned long a5, unsigned long a6, unsigned long a7,
			struct arm_smccc_res *res, struct arm_smccc_quirk *quirk);

/**
 * __arm_smccc_hvc() - make HVC calls
 * @a0-a7: arguments passed in registers 0 to 7
 * @res: result values from registers 0 to 3
 * @quirk: points to an arm_smccc_quirk, or NULL when no quirks are required.
 *
 * This function is used to make HVC calls following SMC Calling
 * Convention.  The content of the supplied param are copied to registers 0
 * to 7 prior to the HVC instruction. The return values are updated with
 * the content from register 0 to 3 on return from the HVC instruction.  An
 * optional quirk structure provides vendor specific behavior.
 */
asmlinkage void __arm_smccc_hvc(unsigned long a0, unsigned long a1,
			unsigned long a2, unsigned long a3, unsigned long a4,
			unsigned long a5, unsigned long a6, unsigned long a7,
			struct arm_smccc_res *res, struct arm_smccc_quirk *quirk);

#define arm_smccc_smc(...) __arm_smccc_smc(__VA_ARGS__, NULL)

#define arm_smccc_smc_quirk(...) __arm_smccc_smc(__VA_ARGS__)

#define arm_smccc_hvc(...) __arm_smccc_hvc(__VA_ARGS__, NULL)

#define arm_smccc_hvc_quirk(...) __arm_smccc_hvc(__VA_ARGS__)

#endif /*__ASSEMBLY__*/
#endif /*__LINUX_ARM_SMCCC_H*/
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /*
 * Copyright (c) 1999-2002 Vojtech Pavlik
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 as published by
 * the Free Software Foundation.
 */
#ifndef _INPUT_H
#define _INPUT_H

#include <linux/time.h>
#include <linux/list.h>
#include <uapi/linux/input.h>
/* Implementation details, userspace should not care about these */
#define ABS_MT_FIRST		ABS_MT_TOUCH_MAJOR
#define ABS_MT_LAST		ABS_MT_TOOL_Y

/*
 * In-kernel definitions.
 */

#include <linux/device.h>
#include <linux/fs.h>
#include <linux/timer.h>
#include <linux/mod_devicetable.h>

/**
 * struct input_value - input value representation
 * @type: type of value (EV_KEY, EV_ABS, etc)
 * @code: the value code
 * @value: the value
 */
struct input_value {
	__u16 type;
	__u16 code;
	__s32 value;
};

/**
 * struct input_dev - represents an input device
 * @name: name of the device
 * @phys: physical path to the device in the system hierarchy
 * @uniq: unique identification code for the device (if device has it)
 * @id: id of the device (struct input_id)
 * @propbit: bitmap of device properties and quirks
 * @evbit: bitmap of types of events supported by the device (EV_KEY,
 *	EV_REL, etc.)
 * @keybit: bitmap of keys/buttons this device has
 * @relbit: bitmap of relative axes for the device
 * @absbit: bitmap of absolute axes for the device
 * @mscbit: bitmap of miscellaneous events supported by the device
 * @ledbit: bitmap of leds present on the device
 * @sndbit: bitmap of sound effects supported by the device
 * @ffbit: bitmap of force feedback effects supported by the device
 * @swbit: bitmap of switches present on the device
 * @hint_events_per_packet: average number of events generated by the
 *	device in a packet (between EV_SYN/SYN_REPORT events). Used by
 *	event handlers to estimate size of the buffer needed to hold
 *	events.
 * @keycodemax: size of keycode table
 * @keycodesize: size of elements in keycode table
 * @keycode: map of scancodes to keycodes for this device
 * @getkeycode: optional legacy method to retrieve current keymap.
 * @setkeycode: optional method to alter current keymap, used to implement
 *	sparse keymaps. If not supplied default mechanism will be used.
 *	The method is being called while holding event_lock and thus must
 *	not sleep
 * @ff: force feedback structure associated with the device if device
 *	supports force feedback effects
 * @repeat_key: stores key code of the last key pressed; used to implement
 *	software autorepeat
 * @timer: timer for software autorepeat
 * @rep: current values for autorepeat parameters (delay, rate)
 * @mt: pointer to multitouch state
 * @absinfo: array of &struct input_absinfo elements holding information
 *	about absolute axes (current value, min, max, flat, fuzz,
 *	resolution)
 * @key: reflects current state of device's keys/buttons
 * @led: reflects current state of device's LEDs
 * @snd: reflects current state of sound effects
 * @sw: reflects current state of device's switches
 * @open: this method is called when the very first user calls
 *	input_open_device(). The driver must prepare the device
 *	to start generating events (start polling thread,
 *	request an IRQ, submit URB, etc.)
 * @close: this method is called when the very last user calls
 *	input_close_device().
 * @flush: purges the device. Most commonly used to get rid of force
 *	feedback effects loaded into the device when disconnecting
 *	from it
 * @event: event handler for events sent _to_ the device, like EV_LED
 *	or EV_SND. The device is expected to carry out the requested
 *	action (turn on a LED, play sound, etc.) The call is protected
 *	by @event_lock and must not sleep
 * @grab: input handle that currently has the device grabbed (via
 *	EVIOCGRAB ioctl). When a handle grabs a device it becomes sole
 *	recipient for all input events coming from the device
 * @event_lock: this spinlock is taken when input core receives
 *	and processes a new event for the device (in input_event()).
 *	Code that accesses and/or modifies parameters of a device
 *	(such as keymap or absmin, absmax, absfuzz, etc.) after device
 *	has been registered with input core must take this lock.
 * @mutex: serializes calls to open(), close() and flush() methods
 * @users: stores number of users (input handlers) that opened this
 *	device. It is used by input_open_device() and input_close_device()
 *	to make sure that dev->open() is only called when the first
 *	user opens device and dev->close() is called when the very
 *	last user closes the device
 * @going_away: marks devices that are in a middle of unregistering and
 *	causes input_open_device*() fail with -ENODEV.
 * @dev: driver model's view of this device
 * @h_list: list of input handles associated with the device. When
 *	accessing the list dev->mutex must be held
 * @node: used to place the device onto input_dev_list
 * @num_vals: number of values queued in the current frame
 * @max_vals: maximum number of values queued in a frame
 * @vals: array of values queued in the current frame
 * @devres_managed: indicates that devices is managed with devres framework
 *	and needs not be explicitly unregistered or freed.
 */
struct input_dev {
	const char *name;
	const char *phys;
	const char *uniq;
	struct input_id id;

	unsigned long propbit[BITS_TO_LONGS(INPUT_PROP_CNT)];

	unsigned long evbit[BITS_TO_LONGS(EV_CNT)];
	unsigned long keybit[BITS_TO_LONGS(KEY_CNT)];
	unsigned long relbit[BITS_TO_LONGS(REL_CNT)];
	unsigned long absbit[BITS_TO_LONGS(ABS_CNT)];
	unsigned long mscbit[BITS_TO_LONGS(MSC_CNT)];
	unsigned long ledbit[BITS_TO_LONGS(LED_CNT)];
	unsigned long sndbit[BITS_TO_LONGS(SND_CNT)];
	unsigned long ffbit[BITS_TO_LONGS(FF_CNT)];
	unsigned long swbit[BITS_TO_LONGS(SW_CNT)];

	unsigned int hint_events_per_packet;

	unsigned int keycodemax;
	unsigned int keycodesize;
	void *keycode;

	int (*setkeycode)(struct input_dev *dev,
			  const struct input_keymap_entry *ke,
			  unsigned int *old_keycode);
	int (*getkeycode)(struct input_dev *dev,
			  struct input_keymap_entry *ke);

	struct ff_device *ff;

	unsigned int repeat_key;
	struct timer_list timer;

	int rep[REP_CNT];

	struct input_mt *mt;

	struct input_absinfo *absinfo;

	unsigned long key[BITS_TO_LONGS(KEY_CNT)];
	unsigned long led[BITS_TO_LONGS(LED_CNT)];
	unsigned long snd[BITS_TO_LONGS(SND_CNT)];
	unsigned long sw[BITS_TO_LONGS(SW_CNT)];

	int (*open)(struct input_dev *dev);
	void (*close)(struct input_dev *dev);
	int (*flush)(struct input_dev *dev, struct file *file);
	int (*event)(struct input_dev *dev, unsigned int type, unsigned int code, int value);

	struct input_handle __rcu *grab;

	spinlock_t event_lock;
	struct mutex mutex;

	unsigned int users;
	bool going_away;

	struct device dev;

	struct list_head	h_list;
	struct list_head	node;

	unsigned int num_vals;
	unsigned int max_vals;
	struct input_value *vals;

	bool devres_managed;
};
#define to_input_dev(d) container_of(d, struct input_dev, dev)

/*
 * Verify that we are in sync with input_device_id mod_devicetable.h #defines
 */

#if EV_MAX != INPUT_DEVICE_ID_EV_MAX
#error "EV_MAX and INPUT_DEVICE_ID_EV_MAX do not match"
#endif

#if KEY_MIN_INTERESTING != INPUT_DEVICE_ID_KEY_MIN_INTERESTING
#error "KEY_MIN_INTERESTING and INPUT_DEVICE_ID_KEY_MIN_INTERESTING do not match"
#endif

#if KEY_MAX != INPUT_DEVICE_ID_KEY_MAX
#error "KEY_MAX and INPUT_DEVICE_ID_KEY_MAX do not match"
#endif

#if REL_MAX != INPUT_DEVICE_ID_REL_MAX
#error "REL_MAX and INPUT_DEVICE_ID_REL_MAX do not match"
#endif

#if ABS_MAX != INPUT_DEVICE_ID_ABS_MAX
#error "ABS_MAX and INPUT_DEVICE_ID_ABS_MAX do not match"
#endif

#if MSC_MAX != INPUT_DEVICE_ID_MSC_MAX
#error "MSC_MAX and INPUT_DEVICE_ID_MSC_MAX do not match"
#endif

#if LED_MAX != INPUT_DEVICE_ID_LED_MAX
#error "LED_MAX and INPUT_DEVICE_ID_LED_MAX do not match"
#endif

#if SND_MAX != INPUT_DEVICE_ID_SND_MAX
#error "SND_MAX and INPUT_DEVICE_ID_SND_MAX do not match"
#endif

#if FF_MAX != INPUT_DEVICE_ID_FF_MAX
#error "FF_MAX and INPUT_DEVICE_ID_FF_MAX do not match"
#endif

#if SW_MAX != INPUT_DEVICE_ID_SW_MAX
#error "SW_MAX and INPUT_DEVICE_ID_SW_MAX do not match"
#endif

#define INPUT_DEVICE_ID_MATCH_DEVICE \
	(INPUT_DEVICE_ID_MATCH_BUS | INPUT_DEVICE_ID_MATCH_VENDOR | INPUT_DEVICE_ID_MATCH_PRODUCT)
#define INPUT_DEVICE_ID_MATCH_DEVICE_AND_VERSION \
	(INPUT_DEVICE_ID_MATCH_DEVICE | INPUT_DEVICE_ID_MATCH_VERSION)

struct input_handle;

/**
 * struct input_handler - implements one of interfaces for input devices
 * @private: driver-specific data
 * @event: event handler. This method is being called by input core with
 *	interrupts disabled and dev->event_lock spinlock held and so
 *	it may not sleep
 * @events: event sequence handler. This method is being called by
 *	input core with interrupts disabled and dev->event_lock
 *	spinlock held and so it may not sleep
 * @filter: similar to @event; separates normal event handlers from
 *	"filters".
 * @match: called after comparing device's id with handler's id_table
 *	to perform fine-grained matching between device and handler
 * @connect: called when attaching a handler to an input device
 * @disconnect: disconnects a handler from input device
 * @start: starts handler for given handle. This function is called by
 *	input core right after connect() method and also when a process
 *	that "grabbed" a device releases it
 * @legacy_minors: set to %true by drivers using legacy minor ranges
 * @minor: beginning of range of 32 legacy minors for devices this driver
 *	can provide
 * @name: name of the handler, to be shown in /proc/bus/input/handlers
 * @id_table: pointer to a table of input_device_ids this driver can
 *	handle
 * @h_list: list of input handles associated with the handler
 * @node: for placing the driver onto input_handler_list
 *
 * Input handlers attach to input devices and create input handles. There
 * are likely several handlers attached to any given input device at the
 * same time. All of them will get their copy of input event generated by
 * the device.
 *
 * The very same structure is used to implement input filters. Input core
 * allows filters to run first and will not pass event to regular handlers
 * if any of the filters indicate that the event should be filtered (by
 * returning %true from their filter() method).
 *
 * Note that input core serializes calls to connect() and disconnect()
 * methods.
 */
struct input_handler {

	void *private;

	void (*event)(struct input_handle *handle, unsigned int type, unsigned int code, int value);
	void (*events)(struct input_handle *handle,
		       const struct input_value *vals, unsigned int count);
	bool (*filter)(struct input_handle *handle, unsigned int type, unsigned int code, int value);
	bool (*match)(struct input_handler *handler, struct input_dev *dev);
	int (*connect)(struct input_handler *handler, struct input_dev *dev, const struct input_device_id *id);
	void (*disconnect)(struct input_handle *handle);
	void (*start)(struct input_handle *handle);

	bool legacy_minors;
	int minor;
	const char *name;

	const struct input_device_id *id_table;

	struct list_head	h_list;
	struct list_head	node;
};

/**
 * struct input_handle - links input device with an input handler
 * @private: handler-specific data
 * @open: counter showing whether the handle is 'open', i.e. should deliver
 *	events from its device
 * @name: name given to the handle by handler that created it
 * @dev: input device the handle is attached to
 * @handler: handler that works with the device through this handle
 * @d_node: used to put the handle on device's list of attached handles
 * @h_node: used to put the handle on handler's list of handles from which
 *	it gets events
 */
struct input_handle {

	void *private;

	int open;
	const char *name;

	struct input_dev *dev;
	struct input_handler *handler;

	struct list_head	d_node;
	struct list_head	h_node;
};

struct input_dev __must_check *input_allocate_device(void);
struct input_dev __must_check *devm_input_allocate_device(struct device *);
void input_free_device(struct input_dev *dev);

static inline struct input_dev *input_get_device(struct input_dev *dev)
{
	return dev ? to_input_dev(get_device(&dev->dev)) : NULL;
}

static inline void input_put_device(struct input_dev *dev)
{
	if (dev)
		put_device(&dev->dev);
}

static inline void *input_get_drvdata(struct input_dev *dev)
{
	return dev_get_drvdata(&dev->dev);
}

static inline void input_set_drvdata(struct input_dev *dev, void *data)
{
	dev_set_drvdata(&dev->dev, data);
}

int __must_check input_register_device(struct input_dev *);
void input_unregister_device(struct input_dev *);

void input_reset_device(struct input_dev *);

int __must_check input_register_handler(struct input_handler *);
void input_unregister_handler(struct input_handler *);

int __must_check input_get_new_minor(int legacy_base, unsigned int legacy_num,
				     bool allow_dynamic);
void input_free_minor(unsigned int minor);

int input_handler_for_each_handle(struct input_handler *, void *data,
				  int (*fn)(struct input_handle *, void *));

int input_register_handle(struct input_handle *);
void input_unregister_handle(struct input_handle *);

int input_grab_device(struct input_handle *);
void input_release_device(struct input_handle *);

int input_open_device(struct input_handle *);
void input_close_device(struct input_handle *);

int input_flush_device(struct input_handle *handle, struct file *file);

void input_event(struct input_dev *dev, unsigned int type, unsigned int code, int value);
void input_inject_event(struct input_handle *handle, unsigned int type, unsigned int code, int value);

static inline void input_report_key(struct input_dev *dev, unsigned int code, int value)
{
	input_event(dev, EV_KEY, code, !!value);
}

static inline void input_report_rel(struct input_dev *dev, unsigned int code, int value)
{
	input_event(dev, EV_REL, code, value);
}

static inline void input_report_abs(struct input_dev *dev, unsigned int code, int value)
{
	input_event(dev, EV_ABS, code, value);
}

static inline void input_report_ff_status(struct input_dev *dev, unsigned int code, int value)
{
	input_event(dev, EV_FF_STATUS, code, value);
}

static inline void input_report_switch(struct input_dev *dev, unsigned int code, int value)
{
	input_event(dev, EV_SW, code, !!value);
}

static inline void input_sync(struct input_dev *dev)
{
	input_event(dev, EV_SYN, SYN_REPORT, 0);
}

static inline void input_mt_sync(struct input_dev *dev)
{
	input_event(dev, EV_SYN, SYN_MT_REPORT, 0);
}

void input_set_capability(struct input_dev *dev, unsigned int type, unsigned int code);

/**
 * input_set_events_per_packet - tell handlers about the driver event rate
 * @dev: the input device used by the driver
 * @n_events: the average number of events between calls to input_sync()
 *
 * If the event rate sent from a device is unusually large, use this
 * function to set the expected event rate. This will allow handlers
 * to set up an appropriate buffer size for the event stream, in order
 * to minimize information loss.
 */
static inline void input_set_events_per_packet(struct input_dev *dev, int n_events)
{
	dev->hint_events_per_packet = n_events;
}

void input_alloc_absinfo(struct input_dev *dev);
void input_set_abs_params(struct input_dev *dev, unsigned int axis,
			  int min, int max, int fuzz, int flat);

#define INPUT_GENERATE_ABS_ACCESSORS(_suffix, _item)			\
static inline int input_abs_get_##_suffix(struct input_dev *dev,	\
					  unsigned int axis)		\
{									\
	return dev->absinfo ? dev->absinfo[axis]._item : 0;		\
}									\
									\
static inline void input_abs_set_##_suffix(struct input_dev *dev,	\
					   unsigned int axis, int val)	\
{									\
	input_alloc_absinfo(dev);					\
	if (dev->absinfo)						\
		dev->absinfo[axis]._item = val;				\
}

INPUT_GENERATE_ABS_ACCESSORS(val, value)
INPUT_GENERATE_ABS_ACCESSORS(min, minimum)
INPUT_GENERATE_ABS_ACCESSORS(max, maximum)
INPUT_GENERATE_ABS_ACCESSORS(fuzz, fuzz)
INPUT_GENERATE_ABS_ACCESSORS(flat, flat)
INPUT_GENERATE_ABS_ACCESSORS(res, resolution)

int input_scancode_to_scalar(const struct input_keymap_entry *ke,
			     unsigned int *scancode);

int input_get_keycode(struct input_dev *dev, struct input_keymap_entry *ke);
int input_set_keycode(struct input_dev *dev,
		      const struct input_keymap_entry *ke);

void input_enable_softrepeat(struct input_dev *dev, int delay, int period);

extern struct class input_class;

/**
 * struct ff_device - force-feedback part of an input device
 * @upload: Called to upload an new effect into device
 * @erase: Called to erase an effect from device
 * @playback: Called to request device to start playing specified effect
 * @set_gain: Called to set specified gain
 * @set_autocenter: Called to auto-center device
 * @destroy: called by input core when parent input device is being
 *	destroyed
 * @private: driver-specific data, will be freed automatically
 * @ffbit: bitmap of force feedback capabilities truly supported by
 *	device (not emulated like ones in input_dev->ffbit)
 * @mutex: mutex for serializing access to the device
 * @max_effects: maximum number of effects supported by device
 * @effects: pointer to an array of effects currently loaded into device
 * @effect_owners: array of effect owners; when file handle owning
 *	an effect gets closed the effect is automatically erased
 *
 * Every force-feedback device must implement upload() and playback()
 * methods; erase() is optional. set_gain() and set_autocenter() need
 * only be implemented if driver sets up FF_GAIN and FF_AUTOCENTER
 * bits.
 *
 * Note that playback(), set_gain() and set_autocenter() are called with
 * dev->event_lock spinlock held and interrupts off and thus may not
 * sleep.
 */
struct ff_device {
	int (*upload)(struct input_dev *dev, struct ff_effect *effect,
		      struct ff_effect *old);
	int (*erase)(struct input_dev *dev, int effect_id);

	int (*playback)(struct input_dev *dev, int effect_id, int value);
	void (*set_gain)(struct input_dev *dev, u16 gain);
	void (*set_autocenter)(struct input_dev *dev, u16 magnitude);

	void (*destroy)(struct ff_device *);

	void *private;

	unsigned long ffbit[BITS_TO_LONGS(FF_CNT)];

	struct mutex mutex;

	int max_effects;
	struct ff_effect *effects;
	struct file *effect_owners[];
};

int input_ff_create(struct input_dev *dev, unsigned int max_effects);
void input_ff_destroy(struct input_dev *dev);

int input_ff_event(struct input_dev *dev, unsigned int type, unsigned int code, int value);

int input_ff_upload(struct input_dev *dev, struct ff_effect *effect, struct file *file);
int input_ff_erase(struct input_dev *dev, int effect_id, struct file *file);

int input_ff_create_memless(struct input_dev *dev, void *data,
		int (*play_effect)(struct input_dev *, void *, struct ff_effect *));

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             #ifndef _LINUX_SWAPFILE_H
#define _LINUX_SWAPFILE_H

/*
 * these were static in swapfile.c but frontswap.c needs them and we don't
 * want to expose them to the dozens of source files that include swap.h
 */
extern spinlock_t swap_lock;
extern struct plist_head swap_active_head;
extern struct swap_info_struct *swap_info[];
extern int try_to_unuse(unsigned int, bool, unsigned long);

#endif /* _LINUX_SWAPFILE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /* $Id: isdn_divertif.h,v 1.4.6.1 2001/09/23 22:25:05 kai Exp $
 *
 * Header for the diversion supplementary interface for i4l.
 *
 * Author    Werner Cornelius (werner@titro.de)
 * Copyright by Werner Cornelius (werner@titro.de)
 *
 * This software may be used and distributed according to the terms
 * of the GNU General Public License, incorporated herein by reference.
 *
 */
#ifndef _LINUX_ISDN_DIVERTIF_H
#define _LINUX_ISDN_DIVERTIF_H

#include <linux/isdnif.h>
#include <linux/types.h>
#include <uapi/linux/isdn_divertif.h>

/***************************************************************/
/* structure exchanging data between isdn hl and divert module */
/***************************************************************/ 
typedef struct
  { ulong if_magic; /* magic info and version */
    int cmd; /* command */
    int (*stat_callback)(isdn_ctrl *); /* supplied by divert module when calling */
    int (*ll_cmd)(isdn_ctrl *); /* supplied by hl on return */
    char * (*drv_to_name)(int); /* map a driver id to name, supplied by hl */
    int (*name_to_drv)(char *); /* map a driver id to name, supplied by hl */
  } isdn_divert_if;

/*********************/
/* function register */
/*********************/
extern int DIVERT_REG_NAME(isdn_divert_if *);
#endif /* _LINUX_ISDN_DIVERTIF_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           /*
 * HP Human Interface Loop Master Link Controller driver.
 *
 * Copyright (c) 2001 Brian S. Julin
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions, and the following disclaimer,
 *    without modification.
 * 2. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * Alternatively, this software may be distributed under the terms of the
 * GNU General Public License ("GPL").
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR
 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 *
 * References:
 * HP-HIL Technical Reference Manual.  Hewlett Packard Product No. 45918A
 *
 */

#include <linux/hil.h>
#include <linux/time.h>
#include <linux/interrupt.h>
#include <linux/semaphore.h>
#include <linux/serio.h>
#include <linux/list.h>

typedef struct hil_mlc hil_mlc;

/* The HIL has a complicated state engine.
 * We define the structure of nodes in the state engine here.
 */
enum hilse_act {
  	/* HILSE_OUT prepares to receive input if the next node
	 * is an IN or EXPECT, and then sends the given packet.
	 */
	HILSE_OUT = 0,

  	/* HILSE_CTS checks if the loop is busy. */
	HILSE_CTS,

	/* HILSE_OUT_LAST sends the given command packet to 
	 * the last configured/running device on the loop.
	 */
	HILSE_OUT_LAST,

	/* HILSE_OUT_DISC sends the given command packet to
	 * the next device past the last configured/running one.
	 */
	HILSE_OUT_DISC,

	/* HILSE_FUNC runs a callback function with given arguments.
	 * a positive return value causes the "ugly" branch to be taken.
	 */
	HILSE_FUNC,

  	/* HILSE_IN simply expects any non-errored packet to arrive 
	 * within arg usecs.
	 */
	HILSE_IN		= 0x100,

  	/* HILSE_EXPECT expects a particular packet to arrive 
	 * within arg usecs, any other packet is considered an error.
	 */
	HILSE_EXPECT,

  	/* HILSE_EXPECT_LAST as above but dev field should be last 
	 * discovered/operational device.
	 */
	HILSE_EXPECT_LAST,

  	/* HILSE_EXPECT_LAST as above but dev field should be first 
	 * undiscovered/inoperational device.
	 */
	HILSE_EXPECT_DISC
};

typedef int	(hilse_func) (hil_mlc *mlc, int arg);
struct hilse_node {
	enum hilse_act		act;	/* How to process this node         */
	union {
		hilse_func	*func;	/* Function to call if HILSE_FUNC   */
		hil_packet	packet;	/* Packet to send or to compare     */
	} object;
	int			arg;	/* Timeout in usec or parm for func */
	int			good;	/* Node to jump to on success       */
	int			bad;	/* Node to jump to on error         */
	int			ugly;	/* Node to jump to on timeout       */
};

/* Methods for back-end drivers, e.g. hp_sdc_mlc */
typedef int	(hil_mlc_cts) (hil_mlc *mlc);
typedef void	(hil_mlc_out) (hil_mlc *mlc);
typedef int	(hil_mlc_in)  (hil_mlc *mlc, suseconds_t timeout);

struct hil_mlc_devinfo {
	uint8_t	idd[16];	/* Device ID Byte and Describe Record */
	uint8_t	rsc[16];	/* Security Code Header and Record */
	uint8_t	exd[16];	/* Extended Describe Record */
	uint8_t	rnm[16];	/* Device name as returned by RNM command */
};

struct hil_mlc_serio_map {
	hil_mlc *mlc;
	int di_revmap;
	int didx;
};

/* How many (possibly old/detached) devices the we try to keep track of */
#define HIL_MLC_DEVMEM 16

struct hil_mlc {
	struct list_head	list;	/* hil_mlc is organized as linked list */

	rwlock_t		lock;

	void *priv; /* Data specific to a particular type of MLC */

	int 			seidx;	/* Current node in state engine */
	int			istarted, ostarted;

	hil_mlc_cts		*cts;
	struct semaphore	csem;   /* Raised when loop idle */

	hil_mlc_out		*out;
	struct semaphore	osem;   /* Raised when outpacket dispatched */
	hil_packet		opacket;

	hil_mlc_in		*in;
	struct semaphore	isem;   /* Raised when a packet arrives */
	hil_packet		ipacket[16];
	hil_packet		imatch;
	int			icount;
	struct timeval		instart;
	suseconds_t		intimeout;

	int			ddi;	/* Last operational device id */
	int			lcv;	/* LCV to throttle loops */
	struct timeval		lcv_tv; /* Time loop was started */

	int			di_map[7]; /* Maps below items to live devs */
	struct hil_mlc_devinfo	di[HIL_MLC_DEVMEM];
	struct serio		*serio[HIL_MLC_DEVMEM];
	struct hil_mlc_serio_map serio_map[HIL_MLC_DEVMEM];
	hil_packet		serio_opacket[HIL_MLC_DEVMEM];
	int			serio_oidx[HIL_MLC_DEVMEM];
	struct hil_mlc_devinfo	di_scratch; /* Temporary area */

	int			opercnt;

	struct tasklet_struct	*tasklet;
};

int hil_mlc_register(hil_mlc *mlc);
int hil_mlc_unregister(hil_mlc *mlc);
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            #ifndef _LINUX_DIRENT_H
#define _LINUX_DIRENT_H

struct linux_dirent64 {
	u64		d_ino;
	s64		d_off;
	unsigned short	d_reclen;
	unsigned char	d_type;
	char		d_name[0];
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               #ifndef _LINUX_RMAP_H
#define _LINUX_RMAP_H
/*
 * Declarations for Reverse Mapping functions in mm/rmap.c
 */

#include <linux/list.h>
#include <linux/slab.h>
#include <linux/mm.h>
#include <linux/rwsem.h>
#include <linux/memcontrol.h>

/*
 * The anon_vma heads a list of private "related" vmas, to scan if
 * an anonymous page pointing to this anon_vma needs to be unmapped:
 * the vmas on the list will be related by forking, or by splitting.
 *
 * Since vmas come and go as they are split and merged (particularly
 * in mprotect), the mapping field of an anonymous page cannot point
 * directly to a vma: instead it points to an anon_vma, on whose list
 * the related vmas can be easily linked or unlinked.
 *
 * After unlinking the last vma on the list, we must garbage collect
 * the anon_vma object itself: we're guaranteed no page can be
 * pointing to this anon_vma once its vma list is empty.
 */
struct anon_vma {
	struct anon_vma *root;		/* Root of this anon_vma tree */
	struct rw_semaphore rwsem;	/* W: modification, R: walking the list */
	/*
	 * The refcount is taken on an anon_vma when there is no
	 * guarantee that the vma of page tables will exist for
	 * the duration of the operation. A caller that takes
	 * the reference is responsible for clearing up the
	 * anon_vma if they are the last user on release
	 */
	atomic_t refcount;

	/*
	 * Count of child anon_vmas and VMAs which points to this anon_vma.
	 *
	 * This counter is used for making decision about reusing anon_vma
	 * instead of forking new one. See comments in function anon_vma_clone.
	 */
	unsigned degree;

	struct anon_vma *parent;	/* Parent of this anon_vma */

	/*
	 * NOTE: the LSB of the rb_root.rb_node is set by
	 * mm_take_all_locks() _after_ taking the above lock. So the
	 * rb_root must only be read/written after taking the above lock
	 * to be sure to see a valid next pointer. The LSB bit itself
	 * is serialized by a system wide lock only visible to
	 * mm_take_all_locks() (mm_all_locks_mutex).
	 */
	struct rb_root rb_root;	/* Interval tree of private "related" vmas */
};

/*
 * The copy-on-write semantics of fork mean that an anon_vma
 * can become associated with multiple processes. Furthermore,
 * each child process will have its own anon_vma, where new
 * pages for that process are instantiated.
 *
 * This structure allows us to find the anon_vmas associated
 * with a VMA, or the VMAs associated with an anon_vma.
 * The "same_vma" list contains the anon_vma_chains linking
 * all the anon_vmas associated with this VMA.
 * The "rb" field indexes on an interval tree the anon_vma_chains
 * which link all the VMAs associated with this anon_vma.
 */
struct anon_vma_chain {
	struct vm_area_struct *vma;
	struct anon_vma *anon_vma;
	struct list_head same_vma;   /* locked by mmap_sem & page_table_lock */
	struct rb_node rb;			/* locked by anon_vma->rwsem */
	unsigned long rb_subtree_last;
#ifdef CONFIG_DEBUG_VM_RB
	unsigned long cached_vma_start, cached_vma_last;
#endif
};

enum ttu_flags {
	TTU_UNMAP = 1,			/* unmap mode */
	TTU_MIGRATION = 2,		/* migration mode */
	TTU_MUNLOCK = 4,		/* munlock mode */
	TTU_LZFREE = 8,			/* lazy free mode */
	TTU_SPLIT_HUGE_PMD = 16,	/* split huge PMD if any */

	TTU_IGNORE_MLOCK = (1 << 8),	/* ignore mlock */
	TTU_IGNORE_ACCESS = (1 << 9),	/* don't age */
	TTU_IGNORE_HWPOISON = (1 << 10),/* corrupted page is recoverable */
	TTU_BATCH_FLUSH = (1 << 11),	/* Batch TLB flushes where possible
					 * and caller guarantees they will
					 * do a final flush if necessary */
	TTU_RMAP_LOCKED = (1 << 12)	/* do not grab rmap lock:
					 * caller holds it */
};

#ifdef CONFIG_MMU
static inline void get_anon_vma(struct anon_vma *anon_vma)
{
	atomic_inc(&anon_vma->refcount);
}

void __put_anon_vma(struct anon_vma *anon_vma);

static inline void put_anon_vma(struct anon_vma *anon_vma)
{
	if (atomic_dec_and_test(&anon_vma->refcount))
		__put_anon_vma(anon_vma);
}

static inline void anon_vma_lock_write(struct anon_vma *anon_vma)
{
	down_write(&anon_vma->root->rwsem);
}

static inline void anon_vma_unlock_write(struct anon_vma *anon_vma)
{
	up_write(&anon_vma->root->rwsem);
}

static inline void anon_vma_lock_read(struct anon_vma *anon_vma)
{
	down_read(&anon_vma->root->rwsem);
}

static inline void anon_vma_unlock_read(struct anon_vma *anon_vma)
{
	up_read(&anon_vma->root->rwsem);
}


/*
 * anon_vma helper functions.
 */
void anon_vma_init(void);	/* create anon_vma_cachep */
int  anon_vma_prepare(struct vm_area_struct *);
void unlink_anon_vmas(struct vm_area_struct *);
int anon_vma_clone(struct vm_area_struct *, struct vm_area_struct *);
int anon_vma_fork(struct vm_area_struct *, struct vm_area_struct *);

static inline void anon_vma_merge(struct vm_area_struct *vma,
				  struct vm_area_struct *next)
{
	VM_BUG_ON_VMA(vma->anon_vma != next->anon_vma, vma);
	unlink_anon_vmas(next);
}

struct anon_vma *page_get_anon_vma(struct page *page);

/* bitflags for do_page_add_anon_rmap() */
#define RMAP_EXCLUSIVE 0x01
#define RMAP_COMPOUND 0x02

/*
 * rmap interfaces called when adding or removing pte of page
 */
void page_move_anon_rmap(struct page *, struct vm_area_struct *);
void page_add_anon_rmap(struct page *, struct vm_area_struct *,
		unsigned long, bool);
void do_page_add_anon_rmap(struct page *, struct vm_area_struct *,
			   unsigned long, int);
void page_add_new_anon_rmap(struct page *, struct vm_area_struct *,
		unsigned long, bool);
void page_add_file_rmap(struct page *, bool);
void page_remove_rmap(struct page *, bool);

void hugepage_add_anon_rmap(struct page *, struct vm_area_struct *,
			    unsigned long);
void hugepage_add_new_anon_rmap(struct page *, struct vm_area_struct *,
				unsigned long);

static inline void page_dup_rmap(struct page *page, bool compound)
{
	atomic_inc(compound ? compound_mapcount_ptr(page) : &page->_mapcount);
}

/*
 * Called from mm/vmscan.c to handle paging out
 */
int page_referenced(struct page *, int is_locked,
			struct mem_cgroup *memcg, unsigned long *vm_flags);

#define TTU_ACTION(x) ((x) & TTU_ACTION_MASK)

int try_to_unmap(struct page *, enum ttu_flags flags);

/*
 * Used by uprobes to replace a userspace page safely
 */
pte_t *__page_check_address(struct page *, struct mm_struct *,
				unsigned long, spinlock_t **, int);

static inline pte_t *page_check_address(struct page *page, struct mm_struct *mm,
					unsigned long address,
					spinlock_t **ptlp, int sync)
{
	pte_t *ptep;

	__cond_lock(*ptlp, ptep = __page_check_address(page, mm, address,
						       ptlp, sync));
	return ptep;
}

/*
 * Used by idle page tracking to check if a page was referenced via page
 * tables.
 */
#ifdef CONFIG_TRANSPARENT_HUGEPAGE
bool page_check_address_transhuge(struct page *page, struct mm_struct *mm,
				  unsigned long address, pmd_t **pmdp,
				  pte_t **ptep, spinlock_t **ptlp);
#else
static inline bool page_check_address_transhuge(struct page *page,
				struct mm_struct *mm, unsigned long address,
				pmd_t **pmdp, pte_t **ptep, spinlock_t **ptlp)
{
	*ptep = page_check_address(page, mm, address, ptlp, 0);
	*pmdp = NULL;
	return !!*ptep;
}
#endif

/*
 * Used by swapoff to help locate where page is expected in vma.
 */
unsigned long page_address_in_vma(struct page *, struct vm_area_struct *);

/*
 * Cleans the PTEs of shared mappings.
 * (and since clean PTEs should also be readonly, write protects them too)
 *
 * returns the number of cleaned PTEs.
 */
int page_mkclean(struct page *);

/*
 * called in munlock()/munmap() path to check for other vmas holding
 * the page mlocked.
 */
int try_to_munlock(struct page *);

void remove_migration_ptes(struct page *old, struct page *new, bool locked);

/*
 * Called by memory-failure.c to kill processes.
 */
struct anon_vma *page_lock_anon_vma_read(struct page *page);
void page_unlock_anon_vma_read(struct anon_vma *anon_vma);
int page_mapped_in_vma(struct page *page, struct vm_area_struct *vma);

/*
 * rmap_walk_control: To control rmap traversing for specific needs
 *
 * arg: passed to rmap_one() and invalid_vma()
 * rmap_one: executed on each vma where page is mapped
 * done: for checking traversing termination condition
 * anon_lock: for getting anon_lock by optimized way rather than default
 * invalid_vma: for skipping uninterested vma
 */
struct rmap_walk_control {
	void *arg;
	int (*rmap_one)(struct page *page, struct vm_area_struct *vma,
					unsigned long addr, void *arg);
	int (*done)(struct page *page);
	struct anon_vma *(*anon_lock)(struct page *page);
	bool (*invalid_vma)(struct vm_area_struct *vma, void *arg);
};

int rmap_walk(struct page *page, struct rmap_walk_control *rwc);
int rmap_walk_locked(struct page *page, struct rmap_walk_control *rwc);

#else	/* !CONFIG_MMU */

#define anon_vma_init()		do {} while (0)
#define anon_vma_prepare(vma)	(0)
#define anon_vma_link(vma)	do {} while (0)

static inline int page_referenced(struct page *page, int is_locked,
				  struct mem_cgroup *memcg,
				  unsigned long *vm_flags)
{
	*vm_flags = 0;
	return 0;
}

#define try_to_unmap(page, refs) SWAP_FAIL

static inline int page_mkclean(struct page *page)
{
	return 0;
}


#endif	/* CONFIG_MMU */

/*
 * Return values of try_to_unmap
 */
#define SWAP_SUCCESS	0
#define SWAP_AGAIN	1
#define SWAP_FAIL	2
#define SWAP_MLOCK	3
#define SWAP_LZFREE	4

#endif	/* _LINUX_RMAP_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /*
 * Copyright (c) 2009-2013, NVIDIA Corporation. All rights reserved.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.
 *
 * You should have received a copy of the GNU General Public License along
 * with this program; if not, write to the Free Software Foundation, Inc.,
 * 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
 */

#ifndef __LINUX_HOST1X_H
#define __LINUX_HOST1X_H

#include <linux/device.h>
#include <linux/types.h>

enum host1x_class {
	HOST1X_CLASS_HOST1X = 0x1,
	HOST1X_CLASS_GR2D = 0x51,
	HOST1X_CLASS_GR2D_SB = 0x52,
	HOST1X_CLASS_GR3D = 0x60,
};

struct host1x_client;

struct host1x_client_ops {
	int (*init)(struct host1x_client *client);
	int (*exit)(struct host1x_client *client);
};

struct host1x_client {
	struct list_head list;
	struct device *parent;
	struct device *dev;

	const struct host1x_client_ops *ops;

	enum host1x_class class;
	struct host1x_channel *channel;

	struct host1x_syncpt **syncpts;
	unsigned int num_syncpts;
};

/*
 * host1x buffer objects
 */

struct host1x_bo;
struct sg_table;

struct host1x_bo_ops {
	struct host1x_bo *(*get)(struct host1x_bo *bo);
	void (*put)(struct host1x_bo *bo);
	dma_addr_t (*pin)(struct host1x_bo *bo, struct sg_table **sgt);
	void (*unpin)(struct host1x_bo *bo, struct sg_table *sgt);
	void *(*mmap)(struct host1x_bo *bo);
	void (*munmap)(struct host1x_bo *bo, void *addr);
	void *(*kmap)(struct host1x_bo *bo, unsigned int pagenum);
	void (*kunmap)(struct host1x_bo *bo, unsigned int pagenum, void *addr);
};

struct host1x_bo {
	const struct host1x_bo_ops *ops;
};

static inline void host1x_bo_init(struct host1x_bo *bo,
				  const struct host1x_bo_ops *ops)
{
	bo->ops = ops;
}

static inline struct host1x_bo *host1x_bo_get(struct host1x_bo *bo)
{
	return bo->ops->get(bo);
}

static inline void host1x_bo_put(struct host1x_bo *bo)
{
	bo->ops->put(bo);
}

static inline dma_addr_t host1x_bo_pin(struct host1x_bo *bo,
				       struct sg_table **sgt)
{
	return bo->ops->pin(bo, sgt);
}

static inline void host1x_bo_unpin(struct host1x_bo *bo, struct sg_table *sgt)
{
	bo->ops->unpin(bo, sgt);
}

static inline void *host1x_bo_mmap(struct host1x_bo *bo)
{
	return bo->ops->mmap(bo);
}

static inline void host1x_bo_munmap(struct host1x_bo *bo, void *addr)
{
	bo->ops->munmap(bo, addr);
}

static inline void *host1x_bo_kmap(struct host1x_bo *bo, unsigned int pagenum)
{
	return bo->ops->kmap(bo, pagenum);
}

static inline void host1x_bo_kunmap(struct host1x_bo *bo,
				    unsigned int pagenum, void *addr)
{
	bo->ops->kunmap(bo, pagenum, addr);
}

/*
 * host1x syncpoints
 */

#define HOST1X_SYNCPT_CLIENT_MANAGED	(1 << 0)
#define HOST1X_SYNCPT_HAS_BASE		(1 << 1)

struct host1x_syncpt_base;
struct host1x_syncpt;
struct host1x;

struct host1x_syncpt *host1x_syncpt_get(struct host1x *host, u32 id);
u32 host1x_syncpt_id(struct host1x_syncpt *sp);
u32 host1x_syncpt_read_min(struct host1x_syncpt *sp);
u32 host1x_syncpt_read_max(struct host1x_syncpt *sp);
u32 host1x_syncpt_read(struct host1x_syncpt *sp);
int host1x_syncpt_incr(struct host1x_syncpt *sp);
u32 host1x_syncpt_incr_max(struct host1x_syncpt *sp, u32 incrs);
int host1x_syncpt_wait(struct host1x_syncpt *sp, u32 thresh, long timeout,
		       u32 *value);
struct host1x_syncpt *host1x_syncpt_request(struct device *dev,
					    unsigned long flags);
void host1x_syncpt_free(struct host1x_syncpt *sp);

struct host1x_syncpt_base *host1x_syncpt_get_base(struct host1x_syncpt *sp);
u32 host1x_syncpt_base_id(struct host1x_syncpt_base *base);

/*
 * host1x channel
 */

struct host1x_channel;
struct host1x_job;

struct host1x_channel *host1x_channel_request(struct device *dev);
void host1x_channel_free(struct host1x_channel *channel);
struct host1x_channel *host1x_channel_get(struct host1x_channel *channel);
void host1x_channel_put(struct host1x_channel *channel);
int host1x_job_submit(struct host1x_job *job);

/*
 * host1x job
 */

struct host1x_reloc {
	struct {
		struct host1x_bo *bo;
		unsigned long offset;
	} cmdbuf;
	struct {
		struct host1x_bo *bo;
		unsigned long offset;
	} target;
	unsigned long shift;
};

struct host1x_job {
	/* When refcount goes to zero, job can be freed */
	struct kref ref;

	/* List entry */
	struct list_head list;

	/* Channel where job is submitted to */
	struct host1x_channel *channel;

	u32 client;

	/* Gathers and their memory */
	struct host1x_job_gather *gathers;
	unsigned int num_gathers;

	/* Wait checks to be processed at submit time */
	struct host1x_waitchk *waitchk;
	unsigned int num_waitchk;
	u32 waitchk_mask;

	/* Array of handles to be pinned & unpinned */
	struct host1x_reloc *relocarray;
	unsigned int num_relocs;
	struct host1x_job_unpin_data *unpins;
	unsigned int num_unpins;

	dma_addr_t *addr_phys;
	dma_addr_t *gather_addr_phys;
	dma_addr_t *reloc_addr_phys;

	/* Sync point id, number of increments and end related to the submit */
	u32 syncpt_id;
	u32 syncpt_incrs;
	u32 syncpt_end;

	/* Maximum time to wait for this job */
	unsigned int timeout;

	/* Index and number of slots used in the push buffer */
	unsigned int first_get;
	unsigned int num_slots;

	/* Copy of gathers */
	size_t gather_copy_size;
	dma_addr_t gather_copy;
	u8 *gather_copy_mapped;

	/* Check if register is marked as an address reg */
	int (*is_addr_reg)(struct device *dev, u32 reg, u32 class);

	/* Request a SETCLASS to this class */
	u32 class;

	/* Add a channel wait for previous ops to complete */
	bool serialize;
};

struct host1x_job *host1x_job_alloc(struct host1x_channel *ch,
				    u32 num_cmdbufs, u32 num_relocs,
				    u32 num_waitchks);
void host1x_job_add_gather(struct host1x_job *job, struct host1x_bo *mem_id,
			   u32 words, u32 offset);
struct host1x_job *host1x_job_get(struct host1x_job *job);
void host1x_job_put(struct host1x_job *job);
int host1x_job_pin(struct host1x_job *job, struct device *dev);
void host1x_job_unpin(struct host1x_job *job);

/*
 * subdevice probe infrastructure
 */

struct host1x_device;

struct host1x_driver {
	struct device_driver driver;

	const struct of_device_id *subdevs;
	struct list_head list;

	int (*probe)(struct host1x_device *device);
	int (*remove)(struct host1x_device *device);
	void (*shutdown)(struct host1x_device *device);
};

static inline struct host1x_driver *
to_host1x_driver(struct device_driver *driver)
{
	return container_of(driver, struct host1x_driver, driver);
}

int host1x_driver_register_full(struct host1x_driver *driver,
				struct module *owner);
void host1x_driver_unregister(struct host1x_driver *driver);

#define host1x_driver_register(driver) \
	host1x_driver_register_full(driver, THIS_MODULE)

struct host1x_device {
	struct host1x_driver *driver;
	struct list_head list;
	struct device dev;

	struct mutex subdevs_lock;
	struct list_head subdevs;
	struct list_head active;

	struct mutex clients_lock;
	struct list_head clients;

	bool registered;
};

static inline struct host1x_device *to_host1x_device(struct device *dev)
{
	return container_of(dev, struct host1x_device, dev);
}

int host1x_device_init(struct host1x_device *device);
int host1x_device_exit(struct host1x_device *device);

int host1x_client_register(struct host1x_client *client);
int host1x_client_unregister(struct host1x_client *client);

struct tegra_mipi_device;

struct tegra_mipi_device *tegra_mipi_request(struct device *device);
void tegra_mipi_free(struct tegra_mipi_device *device);
int tegra_mipi_enable(struct tegra_mipi_device *device);
int tegra_mipi_disable(struct tegra_mipi_device *device);
int tegra_mipi_calibrate(struct tegra_mipi_device *device);

#endif
                                                                                                                                                                        /*
 * This file is provided under a dual BSD/GPLv2 license.  When using or
 *   redistributing this file, you may do so under either license.
 *
 *   GPL LICENSE SUMMARY
 *
 *   Copyright(c) 2012 Intel Corporation. All rights reserved.
 *   Copyright (C) 2015 EMC Corporation. All Rights Reserved.
 *
 *   This program is free software; you can redistribute it and/or modify
 *   it under the terms of version 2 of the GNU General Public License as
 *   published by the Free Software Foundation.
 *
 *   BSD LICENSE
 *
 *   Copyright(c) 2012 Intel Corporation. All rights reserved.
 *   Copyright (C) 2015 EMC Corporation. All Rights Reserved.
 *
 *   Redistribution and use in source and binary forms, with or without
 *   modification, are permitted provided that the following conditions
 *   are met:
 *
 *     * Redistributions of source code must retain the above copyright
 *       notice, this list of conditions and the following disclaimer.
 *     * Redistributions in binary form must reproduce the above copy
 *       notice, this list of conditions and the following disclaimer in
 *       the documentation and/or other materials provided with the
 *       distribution.
 *     * Neither the name of Intel Corporation nor the names of its
 *       contributors may be used to endorse or promote products derived
 *       from this software without specific prior written permission.
 *
 *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 *   "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
 *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * PCIe NTB Transport Linux driver
 *
 * Contact Information:
 * Jon Mason <jon.mason@intel.com>
 */

struct ntb_transport_qp;

struct ntb_transport_client {
	struct device_driver driver;
	int (*probe)(struct device *client_dev);
	void (*remove)(struct device *client_dev);
};

int ntb_transport_register_client(struct ntb_transport_client *drvr);
void ntb_transport_unregister_client(struct ntb_transport_client *drvr);
int ntb_transport_register_client_dev(char *device_name);
void ntb_transport_unregister_client_dev(char *device_name);

struct ntb_queue_handlers {
	void (*rx_handler)(struct ntb_transport_qp *qp, void *qp_data,
			   void *data, int len);
	void (*tx_handler)(struct ntb_transport_qp *qp, void *qp_data,
			   void *data, int len);
	void (*event_handler)(void *data, int status);
};

unsigned char ntb_transport_qp_num(struct ntb_transport_qp *qp);
unsigned int ntb_transport_max_size(struct ntb_transport_qp *qp);
struct ntb_transport_qp *
ntb_transport_create_queue(void *data, struct device *client_dev,
			   const struct ntb_queue_handlers *handlers);
void ntb_transport_free_queue(struct ntb_transport_qp *qp);
int ntb_transport_rx_enqueue(struct ntb_transport_qp *qp, void *cb, void *data,
			     unsigned int len);
int ntb_transport_tx_enqueue(struct ntb_transport_qp *qp, void *cb, void *data,
			     unsigned int len);
void *ntb_transport_rx_remove(struct ntb_transport_qp *qp, unsigned int *len);
void ntb_transport_link_up(struct ntb_transport_qp *qp);
void ntb_transport_link_down(struct ntb_transport_qp *qp);
bool ntb_transport_link_query(struct ntb_transport_qp *qp);
unsigned int ntb_transport_tx_free_entry(struct ntb_transport_qp *qp);
                                                                                                                                                                                                            #ifndef _NAMESPACE_H_
#define _NAMESPACE_H_
#ifdef __KERNEL__

struct mnt_namespace;
struct fs_struct;
struct user_namespace;

extern struct mnt_namespace *copy_mnt_ns(unsigned long, struct mnt_namespace *,
		struct user_namespace *, struct fs_struct *);
extern void put_mnt_ns(struct mnt_namespace *ns);

extern const struct file_operations proc_mounts_operations;
extern const struct file_operations proc_mountinfo_operations;
extern const struct file_operations proc_mountstats_operations;

#endif
#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /*
 * Discontiguous memory support, Kanoj Sarcar, SGI, Nov 1999
 */
#ifndef _LINUX_BOOTMEM_H
#define _LINUX_BOOTMEM_H

#include <linux/mmzone.h>
#include <linux/mm_types.h>
#include <asm/dma.h>
#include <asm/processor.h>

/*
 *  simple boot-time physical memory area allocator.
 */

extern unsigned long max_low_pfn;
extern unsigned long min_low_pfn;

/*
 * highest page
 */
extern unsigned long max_pfn;
/*
 * highest possible page
 */
extern unsigned long long max_possible_pfn;

#ifndef CONFIG_NO_BOOTMEM
/*
 * node_bootmem_map is a map pointer - the bits represent all physical 
 * memory pages (including holes) on the node.
 */
typedef struct bootmem_data {
	unsigned long node_min_pfn;
	unsigned long node_low_pfn;
	void *node_bootmem_map;
	unsigned long last_end_off;
	unsigned long hint_idx;
	struct list_head list;
} bootmem_data_t;

extern bootmem_data_t bootmem_node_data[];
#endif

extern unsigned long bootmem_bootmap_pages(unsigned long);

extern unsigned long init_bootmem_node(pg_data_t *pgdat,
				       unsigned long freepfn,
				       unsigned long startpfn,
				       unsigned long endpfn);
extern unsigned long init_bootmem(unsigned long addr, unsigned long memend);

extern unsigned long free_all_bootmem(void);
extern void reset_node_managed_pages(pg_data_t *pgdat);
extern void reset_all_zones_managed_pages(void);

extern void free_bootmem_node(pg_data_t *pgdat,
			      unsigned long addr,
			      unsigned long size);
extern void free_bootmem(unsigned long physaddr, unsigned long size);
extern void free_bootmem_late(unsigned long physaddr, unsigned long size);

/*
 * Flags for reserve_bootmem (also if CONFIG_HAVE_ARCH_BOOTMEM_NODE,
 * the architecture-specific code should honor this).
 *
 * If flags is BOOTMEM_DEFAULT, then the return value is always 0 (success).
 * If flags contains BOOTMEM_EXCLUSIVE, then -EBUSY is returned if the memory
 * already was reserved.
 */
#define BOOTMEM_DEFAULT		0
#define BOOTMEM_EXCLUSIVE	(1<<0)

extern int reserve_bootmem(unsigned long addr,
			   unsigned long size,
			   int flags);
extern int reserve_bootmem_node(pg_data_t *pgdat,
				unsigned long physaddr,
				unsigned long size,
				int flags);

extern void *__alloc_bootmem(unsigned long size,
			     unsigned long align,
			     unsigned long goal);
extern void *__alloc_bootmem_nopanic(unsigned long size,
				     unsigned long align,
				     unsigned long goal) __malloc;
extern void *__alloc_bootmem_node(pg_data_t *pgdat,
				  unsigned long size,
				  unsigned long align,
				  unsigned long goal) __malloc;
void *__alloc_bootmem_node_high(pg_data_t *pgdat,
				  unsigned long size,
				  unsigned long align,
				  unsigned long goal) __malloc;
extern void *__alloc_bootmem_node_nopanic(pg_data_t *pgdat,
				  unsigned long size,
				  unsigned long align,
				  unsigned long goal) __malloc;
void *___alloc_bootmem_node_nopanic(pg_data_t *pgdat,
				  unsigned long size,
				  unsigned long align,
				  unsigned long goal,
				  unsigned long limit) __malloc;
extern void *__alloc_bootmem_low(unsigned long size,
				 unsigned long align,
				 unsigned long goal) __malloc;
void *__alloc_bootmem_low_nopanic(unsigned long size,
				 unsigned long align,
				 unsigned long goal) __malloc;
extern void *__alloc_bootmem_low_node(pg_data_t *pgdat,
				      unsigned long size,
				      unsigned long align,
				      unsigned long goal) __malloc;

#ifdef CONFIG_NO_BOOTMEM
/* We are using top down, so it is safe to use 0 here */
#define BOOTMEM_LOW_LIMIT 0
#else
#define BOOTMEM_LOW_LIMIT __pa(MAX_DMA_ADDRESS)
#endif

#ifndef ARCH_LOW_ADDRESS_LIMIT
#define ARCH_LOW_ADDRESS_LIMIT  0xffffffffUL
#endif

#define alloc_bootmem(x) \
	__alloc_bootmem(x, SMP_CACHE_BYTES, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_align(x, align) \
	__alloc_bootmem(x, align, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_nopanic(x) \
	__alloc_bootmem_nopanic(x, SMP_CACHE_BYTES, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_pages(x) \
	__alloc_bootmem(x, PAGE_SIZE, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_pages_nopanic(x) \
	__alloc_bootmem_nopanic(x, PAGE_SIZE, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_node(pgdat, x) \
	__alloc_bootmem_node(pgdat, x, SMP_CACHE_BYTES, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_node_nopanic(pgdat, x) \
	__alloc_bootmem_node_nopanic(pgdat, x, SMP_CACHE_BYTES, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_pages_node(pgdat, x) \
	__alloc_bootmem_node(pgdat, x, PAGE_SIZE, BOOTMEM_LOW_LIMIT)
#define alloc_bootmem_pages_node_nopanic(pgdat, x) \
	__alloc_bootmem_node_nopanic(pgdat, x, PAGE_SIZE, BOOTMEM_LOW_LIMIT)

#define alloc_bootmem_low(x) \
	__alloc_bootmem_low(x, SMP_CACHE_BYTES, 0)
#define alloc_bootmem_low_pages_nopanic(x) \
	__alloc_bootmem_low_nopanic(x, PAGE_SIZE, 0)
#define alloc_bootmem_low_pages(x) \
	__alloc_bootmem_low(x, PAGE_SIZE, 0)
#define alloc_bootmem_low_pages_node(pgdat, x) \
	__alloc_bootmem_low_node(pgdat, x, PAGE_SIZE, 0)


#if defined(CONFIG_HAVE_MEMBLOCK) && defined(CONFIG_NO_BOOTMEM)

/* FIXME: use MEMBLOCK_ALLOC_* variants here */
#define BOOTMEM_ALLOC_ACCESSIBLE	0
#define BOOTMEM_ALLOC_ANYWHERE		(~(phys_addr_t)0)

/* FIXME: Move to memblock.h at a point where we remove nobootmem.c */
void *memblock_virt_alloc_try_nid_nopanic(phys_addr_t size,
		phys_addr_t align, phys_addr_t min_addr,
		phys_addr_t max_addr, int nid);
void *memblock_virt_alloc_try_nid(phys_addr_t size, phys_addr_t align,
		phys_addr_t min_addr, phys_addr_t max_addr, int nid);
void __memblock_free_early(phys_addr_t base, phys_addr_t size);
void __memblock_free_late(phys_addr_t base, phys_addr_t size);

static inline void * __init memblock_virt_alloc(
					phys_addr_t size,  phys_addr_t align)
{
	return memblock_virt_alloc_try_nid(size, align, BOOTMEM_LOW_LIMIT,
					    BOOTMEM_ALLOC_ACCESSIBLE,
					    NUMA_NO_NODE);
}

static inline void * __init memblock_virt_alloc_nopanic(
					phys_addr_t size, phys_addr_t align)
{
	return memblock_virt_alloc_try_nid_nopanic(size, align,
						    BOOTMEM_LOW_LIMIT,
						    BOOTMEM_ALLOC_ACCESSIBLE,
						    NUMA_NO_NODE);
}

static inline void * __init memblock_virt_alloc_low(
					phys_addr_t size, phys_addr_t align)
{
	return memblock_virt_alloc_try_nid(size, align,
						   BOOTMEM_LOW_LIMIT,
						   ARCH_LOW_ADDRESS_LIMIT,
						   NUMA_NO_NODE);
}
static inline void * __init memblock_virt_alloc_low_nopanic(
					phys_addr_t size, phys_addr_t align)
{
	return memblock_virt_alloc_try_nid_nopanic(size, align,
						   BOOTMEM_LOW_LIMIT,
						   ARCH_LOW_ADDRESS_LIMIT,
						   NUMA_NO_NODE);
}

static inline void * __init memblock_virt_alloc_from_nopanic(
		phys_addr_t size, phys_addr_t align, phys_addr_t min_addr)
{
	return memblock_virt_alloc_try_nid_nopanic(size, align, min_addr,
						    BOOTMEM_ALLOC_ACCESSIBLE,
						    NUMA_NO_NODE);
}

static inline void * __init memblock_virt_alloc_node(
						phys_addr_t size, int nid)
{
	return memblock_virt_alloc_try_nid(size, 0, BOOTMEM_LOW_LIMIT,
					    BOOTMEM_ALLOC_ACCESSIBLE, nid);
}

static inline void * __init memblock_virt_alloc_node_nopanic(
						phys_addr_t size, int nid)
{
	return memblock_virt_alloc_try_nid_nopanic(size, 0, BOOTMEM_LOW_LIMIT,
						    BOOTMEM_ALLOC_ACCESSIBLE,
						    nid);
}

static inline void __init memblock_free_early(
					phys_addr_t base, phys_addr_t size)
{
	__memblock_free_early(base, size);
}

static inline void __init memblock_free_early_nid(
				phys_addr_t base, phys_addr_t size, int nid)
{
	__memblock_free_early(base, size);
}

static inline void __init memblock_free_late(
					phys_addr_t base, phys_addr_t size)
{
	__memblock_free_late(base, size);
}

#else

#define BOOTMEM_ALLOC_ACCESSIBLE	0


/* Fall back to all the existing bootmem APIs */
static inline void * __init memblock_virt_alloc(
					phys_addr_t size,  phys_addr_t align)
{
	if (!align)
		align = SMP_CACHE_BYTES;
	return __alloc_bootmem(size, align, BOOTMEM_LOW_LIMIT);
}

static inline void * __init memblock_virt_alloc_nopanic(
					phys_addr_t size, phys_addr_t align)
{
	if (!align)
		align = SMP_CACHE_BYTES;
	return __alloc_bootmem_nopanic(size, align, BOOTMEM_LOW_LIMIT);
}

static inline void * __init memblock_virt_alloc_low(
					phys_addr_t size, phys_addr_t align)
{
	if (!align)
		align = SMP_CACHE_BYTES;
	return __alloc_bootmem_low(size, align, 0);
}

static inline void * __init memblock_virt_alloc_low_nopanic(
					phys_addr_t size, phys_addr_t align)
{
	if (!align)
		align = SMP_CACHE_BYTES;
	return __alloc_bootmem_low_nopanic(size, align, 0);
}

static inline void * __init memblock_virt_alloc_from_nopanic(
		phys_addr_t size, phys_addr_t align, phys_addr_t min_addr)
{
	return __alloc_bootmem_nopanic(size, align, min_addr);
}

static inline void * __init memblock_virt_alloc_node(
						phys_addr_t size, int nid)
{
	return __alloc_bootmem_node(NODE_DATA(nid), size, SMP_CACHE_BYTES,
				     BOOTMEM_LOW_LIMIT);
}

static inline void * __init memblock_virt_alloc_node_nopanic(
						phys_addr_t size, int nid)
{
	return __alloc_bootmem_node_nopanic(NODE_DATA(nid), size,
					     SMP_CACHE_BYTES,
					     BOOTMEM_LOW_LIMIT);
}

static inline void * __init memblock_virt_alloc_try_nid(phys_addr_t size,
	phys_addr_t align, phys_addr_t min_addr, phys_addr_t max_addr, int nid)
{
	return __alloc_bootmem_node_high(NODE_DATA(nid), size, align,
					  min_addr);
}

static inline void * __init memblock_virt_alloc_try_nid_nopanic(
			phys_addr_t size, phys_addr_t align,
			phys_addr_t min_addr, phys_addr_t max_addr, int nid)
{
	return ___alloc_bootmem_node_nopanic(NODE_DATA(nid), size, align,
				min_addr, max_addr);
}

static inline void __init memblock_free_early(
					phys_addr_t base, phys_addr_t size)
{
	free_bootmem(base, size);
}

static inline void __init memblock_free_early_nid(
				phys_addr_t base, phys_addr_t size, int nid)
{
	free_bootmem_node(NODE_DATA(nid), base, size);
}

static inline void __init memblock_free_late(
					phys_addr_t base, phys_addr_t size)
{
	free_bootmem_late(base, size);
}
#endif /* defined(CONFIG_HAVE_MEMBLOCK) && defined(CONFIG_NO_BOOTMEM) */

#ifdef CONFIG_HAVE_ARCH_ALLOC_REMAP
extern void *alloc_remap(int nid, unsigned long size);
#else
static inline void *alloc_remap(int nid, unsigned long size)
{
	return NULL;
}
#endif /* CONFIG_HAVE_ARCH_ALLOC_REMAP */

extern void *alloc_large_system_hash(const char *tablename,
				     unsigned long bucketsize,
				     unsigned long numentries,
				     int scale,
				     int flags,
				     unsigned int *_hash_shift,
				     unsigned int *_hash_mask,
				     unsigned long low_limit,
				     unsigned long high_limit);

#define HASH_EARLY	0x00000001	/* Allocating during early boot? */
#define HASH_SMALL	0x00000002	/* sub-page allocation allowed, min
					 * shift passed via *_hash_shift */

/* Only NUMA needs hash distribution. 64bit NUMA architectures have
 * sufficient vmalloc space.
 */
#ifdef CONFIG_NUMA
#define HASHDIST_DEFAULT IS_ENABLED(CONFIG_64BIT)
extern int hashdist;		/* Distribute hashes across NUMA nodes? */
#else
#define hashdist (0)
#endif


#endif /* _LINUX_BOOTMEM_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*
 * ACPI helpers for DMA request / controller
 *
 * Based on of_dma.h
 *
 * Copyright (C) 2013, Intel Corporation
 * Author: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 */

#ifndef __LINUX_ACPI_DMA_H
#define __LINUX_ACPI_DMA_H

#include <linux/list.h>
#include <linux/device.h>
#include <linux/err.h>
#include <linux/dmaengine.h>

/**
 * struct acpi_dma_spec - slave device DMA resources
 * @chan_id:	channel unique id
 * @slave_id:	request line unique id
 * @dev:	struct device of the DMA controller to be used in the filter
 *		function
 */
struct acpi_dma_spec {
	int		chan_id;
	int		slave_id;
	struct device	*dev;
};

/**
 * struct acpi_dma - representation of the registered DMAC
 * @dma_controllers:	linked list node
 * @dev:		struct device of this controller
 * @acpi_dma_xlate:	callback function to find a suitable channel
 * @data:		private data used by a callback function
 * @base_request_line:	first supported request line (CSRT)
 * @end_request_line:	last supported request line (CSRT)
 */
struct acpi_dma {
	struct list_head	dma_controllers;
	struct device		*dev;
	struct dma_chan		*(*acpi_dma_xlate)
				(struct acpi_dma_spec *, struct acpi_dma *);
	void			*data;
	unsigned short		base_request_line;
	unsigned short		end_request_line;
};

/* Used with acpi_dma_simple_xlate() */
struct acpi_dma_filter_info {
	dma_cap_mask_t	dma_cap;
	dma_filter_fn	filter_fn;
};

#ifdef CONFIG_DMA_ACPI

int acpi_dma_controller_register(struct device *dev,
		struct dma_chan *(*acpi_dma_xlate)
		(struct acpi_dma_spec *, struct acpi_dma *),
		void *data);
int acpi_dma_controller_free(struct device *dev);
int devm_acpi_dma_controller_register(struct device *dev,
		struct dma_chan *(*acpi_dma_xlate)
		(struct acpi_dma_spec *, struct acpi_dma *),
		void *data);
void devm_acpi_dma_controller_free(struct device *dev);

struct dma_chan *acpi_dma_request_slave_chan_by_index(struct device *dev,
						      size_t index);
struct dma_chan *acpi_dma_request_slave_chan_by_name(struct device *dev,
						     const char *name);

struct dma_chan *acpi_dma_simple_xlate(struct acpi_dma_spec *dma_spec,
				       struct acpi_dma *adma);
#else

static inline int acpi_dma_controller_register(struct device *dev,
		struct dma_chan *(*acpi_dma_xlate)
		(struct acpi_dma_spec *, struct acpi_dma *),
		void *data)
{
	return -ENODEV;
}
static inline int acpi_dma_controller_free(struct device *dev)
{
	return -ENODEV;
}
static inline int devm_acpi_dma_controller_register(struct device *dev,
		struct dma_chan *(*acpi_dma_xlate)
		(struct acpi_dma_spec *, struct acpi_dma *),
		void *data)
{
	return -ENODEV;
}
static inline void devm_acpi_dma_controller_free(struct device *dev)
{
}

static inline struct dma_chan *acpi_dma_request_slave_chan_by_index(
		struct device *dev, size_t index)
{
	return ERR_PTR(-ENODEV);
}
static inline struct dma_chan *acpi_dma_request_slave_chan_by_name(
		struct device *dev, const char *name)
{
	return ERR_PTR(-ENODEV);
}

#define acpi_dma_simple_xlate	NULL

#endif

#define acpi_dma_request_slave_channel	acpi_dma_request_slave_chan_by_index

#endif /* __LINUX_ACPI_DMA_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /*
 *  linux/include/linux/nmi.h
 */
#ifndef LINUX_NMI_H
#define LINUX_NMI_H

#include <linux/sched.h>
#include <asm/irq.h>

/*
 * The run state of the lockup detectors is controlled by the content of the
 * 'watchdog_enabled' variable. Each lockup detector has its dedicated bit -
 * bit 0 for the hard lockup detector and bit 1 for the soft lockup detector.
 *
 * 'watchdog_user_enabled', 'nmi_watchdog_enabled' and 'soft_watchdog_enabled'
 * are variables that are only used as an 'interface' between the parameters
 * in /proc/sys/kernel and the internal state bits in 'watchdog_enabled'. The
 * 'watchdog_thresh' variable is handled differently because its value is not
 * boolean, and the lockup detectors are 'suspended' while 'watchdog_thresh'
 * is equal zero.
 */
#define NMI_WATCHDOG_ENABLED_BIT   0
#define SOFT_WATCHDOG_ENABLED_BIT  1
#define NMI_WATCHDOG_ENABLED      (1 << NMI_WATCHDOG_ENABLED_BIT)
#define SOFT_WATCHDOG_ENABLED     (1 << SOFT_WATCHDOG_ENABLED_BIT)

/**
 * touch_nmi_watchdog - restart NMI watchdog timeout.
 * 
 * If the architecture supports the NMI watchdog, touch_nmi_watchdog()
 * may be used to reset the timeout - for code which intentionally
 * disables interrupts for a long time. This call is stateless.
 */
#if defined(CONFIG_HAVE_NMI_WATCHDOG) || defined(CONFIG_HARDLOCKUP_DETECTOR)
#include <asm/nmi.h>
extern void touch_nmi_watchdog(void);
#else
static inline void touch_nmi_watchdog(void)
{
	touch_softlockup_watchdog();
}
#endif

#if defined(CONFIG_HARDLOCKUP_DETECTOR)
extern void hardlockup_detector_disable(void);
#else
static inline void hardlockup_detector_disable(void) {}
#endif

/*
 * Create trigger_all_cpu_backtrace() out of the arch-provided
 * base function. Return whether such support was available,
 * to allow calling code to fall back to some other mechanism:
 */
#ifdef arch_trigger_cpumask_backtrace
static inline bool trigger_all_cpu_backtrace(void)
{
	arch_trigger_cpumask_backtrace(cpu_online_mask, false);
	return true;
}

static inline bool trigger_allbutself_cpu_backtrace(void)
{
	arch_trigger_cpumask_backtrace(cpu_online_mask, true);
	return true;
}

static inline bool trigger_cpumask_backtrace(struct cpumask *mask)
{
	arch_trigger_cpumask_backtrace(mask, false);
	return true;
}

static inline bool trigger_single_cpu_backtrace(int cpu)
{
	arch_trigger_cpumask_backtrace(cpumask_of(cpu), false);
	return true;
}

/* generic implementation */
void nmi_trigger_cpumask_backtrace(const cpumask_t *mask,
				   bool exclude_self,
				   void (*raise)(cpumask_t *mask));
bool nmi_cpu_backtrace(struct pt_regs *regs);

#else
static inline bool trigger_all_cpu_backtrace(void)
{
	return false;
}
static inline bool trigger_allbutself_cpu_backtrace(void)
{
	return false;
}
static inline bool trigger_cpumask_backtrace(struct cpumask *mask)
{
	return false;
}
static inline bool trigger_single_cpu_backtrace(int cpu)
{
	return false;
}
#endif

#ifdef CONFIG_LOCKUP_DETECTOR
u64 hw_nmi_get_sample_period(int watchdog_thresh);
extern int nmi_watchdog_enabled;
extern int soft_watchdog_enabled;
extern int watchdog_user_enabled;
extern int watchdog_thresh;
extern unsigned long watchdog_enabled;
extern unsigned long *watchdog_cpumask_bits;
extern atomic_t watchdog_park_in_progress;
#ifdef CONFIG_SMP
extern int sysctl_softlockup_all_cpu_backtrace;
extern int sysctl_hardlockup_all_cpu_backtrace;
#else
#define sysctl_softlockup_all_cpu_backtrace 0
#define sysctl_hardlockup_all_cpu_backtrace 0
#endif
extern bool is_hardlockup(void);
struct ctl_table;
extern int proc_watchdog(struct ctl_table *, int ,
			 void __user *, size_t *, loff_t *);
extern int proc_nmi_watchdog(struct ctl_table *, int ,
			     void __user *, size_t *, loff_t *);
extern int proc_soft_watchdog(struct ctl_table *, int ,
			      void __user *, size_t *, loff_t *);
extern int proc_watchdog_thresh(struct ctl_table *, int ,
				void __user *, size_t *, loff_t *);
extern int proc_watchdog_cpumask(struct ctl_table *, int,
				 void __user *, size_t *, loff_t *);
extern int lockup_detector_suspend(void);
extern void lockup_detector_resume(void);
#else
static inline int lockup_detector_suspend(void)
{
	return 0;
}

static inline void lockup_detector_resume(void)
{
}
#endif

#ifdef CONFIG_HAVE_ACPI_APEI_NMI
#include <asm/nmi.h>
#endif

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           /* $Id: concap.h,v 1.3.2.2 2004/01/12 23:08:35 keil Exp $
 *
 * Copyright 1997 by Henner Eisen <eis@baty.hanse.de>
 *
 * This software may be used and distributed according to the terms
 * of the GNU General Public License, incorporated herein by reference.
 */

#ifndef _LINUX_CONCAP_H
#define _LINUX_CONCAP_H

#include <linux/skbuff.h>
#include <linux/netdevice.h>

/* Stuff to support encapsulation protocols genericly. The encapsulation
   protocol is processed at the uppermost layer of the network interface.

   Based on a ideas developed in a 'synchronous device' thread in the
   linux-x25 mailing list contributed by Alan Cox, Thomasz Motylewski
   and Jonathan Naylor.

   For more documetation on this refer to Documentation/isdn/README.concap
*/

struct concap_proto_ops;
struct concap_device_ops;

/* this manages all data needed by the encapsulation protocol
 */
struct concap_proto{
	struct net_device *net_dev;	/* net device using our service  */
	struct concap_device_ops *dops;	/* callbacks provided by device */
 	struct concap_proto_ops  *pops;	/* callbacks provided by us */
 	spinlock_t lock;
	int flags;
	void *proto_data;		/* protocol specific private data, to
					   be accessed via *pops methods only*/
	/*
	  :
	  whatever 
	  :
	  */
};

/* Operations to be supported by the net device. Called by the encapsulation
 * protocol entity. No receive method is offered because the encapsulation
 * protocol directly calls netif_rx().
 */
struct concap_device_ops{

	/* to request data is submitted by device*/ 
	int (*data_req)(struct concap_proto *, struct sk_buff *);

	/* Control methods must be set to NULL by devices which do not
	   support connection control.*/
	/* to request a connection is set up */ 
	int (*connect_req)(struct concap_proto *);

	/* to request a connection is released */
	int (*disconn_req)(struct concap_proto *);	
};

/* Operations to be supported by the encapsulation protocol. Called by
 * device driver.
 */
struct concap_proto_ops{

	/* create a new encapsulation protocol instance of same type */
	struct concap_proto *  (*proto_new) (void);

	/* delete encapsulation protocol instance and free all its resources.
	   cprot may no loger be referenced after calling this */
	void (*proto_del)(struct concap_proto *cprot);

	/* initialize the protocol's data. To be called at interface startup
	   or when the device driver resets the interface. All services of the
	   encapsulation protocol may be used after this*/
	int (*restart)(struct concap_proto *cprot, 
		       struct net_device *ndev,
		       struct concap_device_ops *dops);

	/* inactivate an encapsulation protocol instance. The encapsulation
	   protocol may not call any *dops methods after this. */
	int (*close)(struct concap_proto *cprot);

	/* process a frame handed down to us by upper layer */
	int (*encap_and_xmit)(struct concap_proto *cprot, struct sk_buff *skb);

	/* to be called for each data entity received from lower layer*/ 
	int (*data_ind)(struct concap_proto *cprot, struct sk_buff *skb);

	/* to be called when a connection was set up/down.
	   Protocols that don't process these primitives might fill in
	   dummy methods here */
	int (*connect_ind)(struct concap_proto *cprot);
	int (*disconn_ind)(struct concap_proto *cprot);
  /*
    Some network device support functions, like net_header(), rebuild_header(),
    and others, that depend solely on the encapsulation protocol, might
    be provided here, too. The net device would just fill them in its
    corresponding fields when it is opened.
    */
};

/* dummy restart/close/connect/reset/disconn methods
 */
extern int concap_nop(struct concap_proto *cprot); 

/* dummy submit method
 */
extern int concap_drop_skb(struct concap_proto *cprot, struct sk_buff *skb);
#endif
                                                                                                                                                                                                                                                                                                                              /*
 * Copyright 1997 Transmeta Corporation - All Rights Reserved
 *
 * This file is part of the Linux kernel and is made available under
 * the terms of the GNU General Public License, version 2, or at your
 * option, any later version, incorporated herein by reference.
 */

#ifndef _LINUX_AUTO_FS_H
#define _LINUX_AUTO_FS_H

#include <linux/fs.h>
#include <linux/ioctl.h>
#include <uapi/linux/auto_fs.h>
#endif /* _LINUX_AUTO_FS_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            #ifndef _LINUX_PID_H
#define _LINUX_PID_H

#include <linux/rcupdate.h>

enum pid_type
{
	PIDTYPE_PID,
	PIDTYPE_PGID,
	PIDTYPE_SID,
	PIDTYPE_MAX,
	/* only valid to __task_pid_nr_ns() */
	__PIDTYPE_TGID
};

/*
 * What is struct pid?
 *
 * A struct pid is the kernel's internal notion of a process identifier.
 * It refers to individual tasks, process groups, and sessions.  While
 * there are processes attached to it the struct pid lives in a hash
 * table, so it and then the processes that it refers to can be found
 * quickly from the numeric pid value.  The attached processes may be
 * quickly accessed by following pointers from struct pid.
 *
 * Storing pid_t values in the kernel and referring to them later has a
 * problem.  The process originally with that pid may have exited and the
 * pid allocator wrapped, and another process could have come along
 * and been assigned that pid.
 *
 * Referring to user space processes by holding a reference to struct
 * task_struct has a problem.  When the user space process exits
 * the now useless task_struct is still kept.  A task_struct plus a
 * stack consumes around 10K of low kernel memory.  More precisely
 * this is THREAD_SIZE + sizeof(struct task_struct).  By comparison
 * a struct pid is about 64 bytes.
 *
 * Holding a reference to struct pid solves both of these problems.
 * It is small so holding a reference does not consume a lot of
 * resources, and since a new struct pid is allocated when the numeric pid
 * value is reused (when pids wrap around) we don't mistakenly refer to new
 * processes.
 */


/*
 * struct upid is used to get the id of the struct pid, as it is
 * seen in particular namespace. Later the struct pid is found with
 * find_pid_ns() using the int nr and struct pid_namespace *ns.
 */

struct upid {
	/* Try to keep pid_chain in the same cacheline as nr for find_vpid */
	int nr;
	struct pid_namespace *ns;
	struct hlist_node pid_chain;
};

struct pid
{
	atomic_t count;
	unsigned int level;
	/* lists of tasks that use this pid */
	struct hlist_head tasks[PIDTYPE_MAX];
	struct rcu_head rcu;
	struct upid numbers[1];
};

extern struct pid init_struct_pid;

struct pid_link
{
	struct hlist_node node;
	struct pid *pid;
};

static inline struct pid *get_pid(struct pid *pid)
{
	if (pid)
		atomic_inc(&pid->count);
	return pid;
}

extern void put_pid(struct pid *pid);
extern struct task_struct *pid_task(struct pid *pid, enum pid_type);
extern struct task_struct *get_pid_task(struct pid *pid, enum pid_type);

extern struct pid *get_task_pid(struct task_struct *task, enum pid_type type);

/*
 * these helpers must be called with the tasklist_lock write-held.
 */
extern void attach_pid(struct task_struct *task, enum pid_type);
extern void detach_pid(struct task_struct *task, enum pid_type);
extern void change_pid(struct task_struct *task, enum pid_type,
			struct pid *pid);
extern void transfer_pid(struct task_struct *old, struct task_struct *new,
			 enum pid_type);

struct pid_namespace;
extern struct pid_namespace init_pid_ns;

/*
 * look up a PID in the hash table. Must be called with the tasklist_lock
 * or rcu_read_lock() held.
 *
 * find_pid_ns() finds the pid in the namespace specified
 * find_vpid() finds the pid by its virtual id, i.e. in the current namespace
 *
 * see also find_task_by_vpid() set in include/linux/sched.h
 */
extern struct pid *find_pid_ns(int nr, struct pid_namespace *ns);
extern struct pid *find_vpid(int nr);

/*
 * Lookup a PID in the hash table, and return with it's count elevated.
 */
extern struct pid *find_get_pid(int nr);
extern struct pid *find_ge_pid(int nr, struct pid_namespace *);
int next_pidmap(struct pid_namespace *pid_ns, unsigned int last);

extern struct pid *alloc_pid(struct pid_namespace *ns);
extern void free_pid(struct pid *pid);
extern void disable_pid_allocation(struct pid_namespace *ns);

/*
 * ns_of_pid() returns the pid namespace in which the specified pid was
 * allocated.
 *
 * NOTE:
 * 	ns_of_pid() is expected to be called for a process (task) that has
 * 	an attached 'struct pid' (see attach_pid(), detach_pid()) i.e @pid
 * 	is expected to be non-NULL. If @pid is NULL, caller should handle
 * 	the resulting NULL pid-ns.
 */
static inline struct pid_namespace *ns_of_pid(struct pid *pid)
{
	struct pid_namespace *ns = NULL;
	if (pid)
		ns = pid->numbers[pid->level].ns;
	return ns;
}

/*
 * is_child_reaper returns true if the pid is the init process
 * of the current namespace. As this one could be checked before
 * pid_ns->child_reaper is assigned in copy_process, we check
 * with the pid number.
 */
static inline bool is_child_reaper(struct pid *pid)
{
	return pid->numbers[pid->level].nr == 1;
}

/*
 * the helpers to get the pid's id seen from different namespaces
 *
 * pid_nr()    : global id, i.e. the id seen from the init namespace;
 * pid_vnr()   : virtual id, i.e. the id seen from the pid namespace of
 *               current.
 * pid_nr_ns() : id seen from the ns specified.
 *
 * see also task_xid_nr() etc in include/linux/sched.h
 */

static inline pid_t pid_nr(struct pid *pid)
{
	pid_t nr = 0;
	if (pid)
		nr = pid->numbers[0].nr;
	return nr;
}

pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns);
pid_t pid_vnr(struct pid *pid);

#define do_each_pid_task(pid, type, task)				\
	do {								\
		if ((pid) != NULL)					\
			hlist_for_each_entry_rcu((task),		\
				&(pid)->tasks[type], pids[type].node) {

			/*
			 * Both old and new leaders may be attached to
			 * the same pid in the middle of de_thread().
			 */
#define while_each_pid_task(pid, type, task)				\
				if (type == PIDTYPE_PID)		\
					break;				\
			}						\
	} while (0)

#define do_each_pid_thread(pid, type, task)				\
	do_each_pid_task(pid, type, task) {				\
		struct task_struct *tg___ = task;			\
		do {

#define while_each_pid_thread(pid, type, task)				\
		} while_each_thread(tg___, task);			\
		task = tg___;						\
	} while_each_pid_task(pid, type, task)
#endif /* _LINUX_PID_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         /*
 * leds-regulator.h - platform data structure for regulator driven LEDs.
 *
 * Copyright (C) 2009 Antonio Ospite <ospite@studenti.unina.it>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 *
 */

#ifndef __LINUX_LEDS_REGULATOR_H
#define __LINUX_LEDS_REGULATOR_H

/*
 * Use "vled" as supply id when declaring the regulator consumer:
 *
 * static struct regulator_consumer_supply pcap_regulator_VVIB_consumers [] = {
 * 	{ .dev_name = "leds-regulator.0", .supply = "vled" },
 * };
 *
 * If you have several regulator driven LEDs, you can append a numerical id to
 * .dev_name as done above, and use the same id when declaring the platform
 * device:
 *
 * static struct led_regulator_platform_data a780_vibrator_data = {
 * 	.name   = "a780::vibrator",
 * };
 *
 * static struct platform_device a780_vibrator = {
 * 	.name = "leds-regulator",
 * 	.id   = 0,
 * 	.dev  = {
 * 		.platform_data = &a780_vibrator_data,
 * 	},
 * };
 */

#include <linux/leds.h>

struct led_regulator_platform_data {
	char *name;                     /* LED name as expected by LED class */
	enum led_brightness brightness; /* initial brightness value */
};

#endif /* __LINUX_LEDS_REGULATOR_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           /*
 * Copyright (c) 2007 Cisco Systems, Inc.  All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *	- Redistributions of source code must retain the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer.
 *
 *	- Redistributions in binary form must reproduce the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer in the documentation and/or other materials
 *	  provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_QP_H
#define MLX4_QP_H

#include <linux/types.h>
#include <linux/if_ether.h>

#include <linux/mlx4/device.h>

#define MLX4_INVALID_LKEY	0x100

enum mlx4_qp_optpar {
	MLX4_QP_OPTPAR_ALT_ADDR_PATH		= 1 << 0,
	MLX4_QP_OPTPAR_RRE			= 1 << 1,
	MLX4_QP_OPTPAR_RAE			= 1 << 2,
	MLX4_QP_OPTPAR_RWE			= 1 << 3,
	MLX4_QP_OPTPAR_PKEY_INDEX		= 1 << 4,
	MLX4_QP_OPTPAR_Q_KEY			= 1 << 5,
	MLX4_QP_OPTPAR_RNR_TIMEOUT		= 1 << 6,
	MLX4_QP_OPTPAR_PRIMARY_ADDR_PATH	= 1 << 7,
	MLX4_QP_OPTPAR_SRA_MAX			= 1 << 8,
	MLX4_QP_OPTPAR_RRA_MAX			= 1 << 9,
	MLX4_QP_OPTPAR_PM_STATE			= 1 << 10,
	MLX4_QP_OPTPAR_RETRY_COUNT		= 1 << 12,
	MLX4_QP_OPTPAR_RNR_RETRY		= 1 << 13,
	MLX4_QP_OPTPAR_ACK_TIMEOUT		= 1 << 14,
	MLX4_QP_OPTPAR_SCHED_QUEUE		= 1 << 16,
	MLX4_QP_OPTPAR_COUNTER_INDEX		= 1 << 20,
	MLX4_QP_OPTPAR_VLAN_STRIPPING		= 1 << 21,
};

enum mlx4_qp_state {
	MLX4_QP_STATE_RST			= 0,
	MLX4_QP_STATE_INIT			= 1,
	MLX4_QP_STATE_RTR			= 2,
	MLX4_QP_STATE_RTS			= 3,
	MLX4_QP_STATE_SQER			= 4,
	MLX4_QP_STATE_SQD			= 5,
	MLX4_QP_STATE_ERR			= 6,
	MLX4_QP_STATE_SQ_DRAINING		= 7,
	MLX4_QP_NUM_STATE
};

enum {
	MLX4_QP_ST_RC				= 0x0,
	MLX4_QP_ST_UC				= 0x1,
	MLX4_QP_ST_RD				= 0x2,
	MLX4_QP_ST_UD				= 0x3,
	MLX4_QP_ST_XRC				= 0x6,
	MLX4_QP_ST_MLX				= 0x7
};

enum {
	MLX4_QP_PM_MIGRATED			= 0x3,
	MLX4_QP_PM_ARMED			= 0x0,
	MLX4_QP_PM_REARM			= 0x1
};

enum {
	/* params1 */
	MLX4_QP_BIT_SRE				= 1 << 15,
	MLX4_QP_BIT_SWE				= 1 << 14,
	MLX4_QP_BIT_SAE				= 1 << 13,
	/* params2 */
	MLX4_QP_BIT_RRE				= 1 << 15,
	MLX4_QP_BIT_RWE				= 1 << 14,
	MLX4_QP_BIT_RAE				= 1 << 13,
	MLX4_QP_BIT_FPP				= 1 <<	3,
	MLX4_QP_BIT_RIC				= 1 <<	4,
};

enum {
	MLX4_RSS_HASH_XOR			= 0,
	MLX4_RSS_HASH_TOP			= 1,

	MLX4_RSS_UDP_IPV6			= 1 << 0,
	MLX4_RSS_UDP_IPV4			= 1 << 1,
	MLX4_RSS_TCP_IPV6			= 1 << 2,
	MLX4_RSS_IPV6				= 1 << 3,
	MLX4_RSS_TCP_IPV4			= 1 << 4,
	MLX4_RSS_IPV4				= 1 << 5,

	MLX4_RSS_BY_OUTER_HEADERS		= 0 << 6,
	MLX4_RSS_BY_INNER_HEADERS		= 2 << 6,
	MLX4_RSS_BY_INNER_HEADERS_IPONLY	= 3 << 6,

	/* offset of mlx4_rss_context within mlx4_qp_context.pri_path */
	MLX4_RSS_OFFSET_IN_QPC_PRI_PATH		= 0x24,
	/* offset of being RSS indirection QP within mlx4_qp_context.flags */
	MLX4_RSS_QPC_FLAG_OFFSET		= 13,
};

#define MLX4_EN_RSS_KEY_SIZE 40

struct mlx4_rss_context {
	__be32			base_qpn;
	__be32			default_qpn;
	u16			reserved;
	u8			hash_fn;
	u8			flags;
	__be32			rss_key[MLX4_EN_RSS_KEY_SIZE / sizeof(__be32)];
	__be32			base_qpn_udp;
};

struct mlx4_qp_path {
	u8			fl;
	union {
		u8			vlan_control;
		u8			control;
	};
	u8			disable_pkey_check;
	u8			pkey_index;
	u8			counter_index;
	u8			grh_mylmc;
	__be16			rlid;
	u8			ackto;
	u8			mgid_index;
	u8			static_rate;
	u8			hop_limit;
	__be32			tclass_flowlabel;
	u8			rgid[16];
	u8			sched_queue;
	u8			vlan_index;
	u8			feup;
	u8			fvl_rx;
	u8			reserved4[2];
	u8			dmac[ETH_ALEN];
};

enum { /* fl */
	MLX4_FL_CV	= 1 << 6,
	MLX4_FL_SV	= 1 << 5,
	MLX4_FL_ETH_HIDE_CQE_VLAN	= 1 << 2,
	MLX4_FL_ETH_SRC_CHECK_MC_LB	= 1 << 1,
	MLX4_FL_ETH_SRC_CHECK_UC_LB	= 1 << 0,
};

enum { /* control */
	MLX4_CTRL_ETH_SRC_CHECK_IF_COUNTER	= 1 << 7,
};

enum { /* vlan_control */
	MLX4_VLAN_CTRL_ETH_TX_BLOCK_TAGGED	= 1 << 6,
	MLX4_VLAN_CTRL_ETH_TX_BLOCK_PRIO_TAGGED	= 1 << 5, /* 802.1p priority tag */
	MLX4_VLAN_CTRL_ETH_TX_BLOCK_UNTAGGED	= 1 << 4,
	MLX4_VLAN_CTRL_ETH_RX_BLOCK_TAGGED	= 1 << 2,
	MLX4_VLAN_CTRL_ETH_RX_BLOCK_PRIO_TAGGED	= 1 << 1, /* 802.1p priority tag */
	MLX4_VLAN_CTRL_ETH_RX_BLOCK_UNTAGGED	= 1 << 0
};

enum { /* feup */
	MLX4_FEUP_FORCE_ETH_UP          = 1 << 6, /* force Eth UP */
	MLX4_FSM_FORCE_ETH_SRC_MAC      = 1 << 5, /* force Source MAC */
	MLX4_FVL_FORCE_ETH_VLAN         = 1 << 3  /* force Eth vlan */
};

enum { /* fvl_rx */
	MLX4_FVL_RX_FORCE_ETH_VLAN      = 1 << 0 /* enforce Eth rx vlan */
};

struct mlx4_qp_context {
	__be32			flags;
	__be32			pd;
	u8			mtu_msgmax;
	u8			rq_size_stride;
	u8			sq_size_stride;
	u8			rlkey_roce_mode;
	__be32			usr_page;
	__be32			local_qpn;
	__be32			remote_qpn;
	struct			mlx4_qp_path pri_path;
	struct			mlx4_qp_path alt_path;
	__be32			params1;
	u32			reserved1;
	__be32			next_send_psn;
	__be32			cqn_send;
	__be16                  roce_entropy;
	__be16                  reserved2[3];
	__be32			last_acked_psn;
	__be32			ssn;
	__be32			params2;
	__be32			rnr_nextrecvpsn;
	__be32			xrcd;
	__be32			cqn_recv;
	__be64			db_rec_addr;
	__be32			qkey;
	__be32			srqn;
	__be32			msn;
	__be16			rq_wqe_counter;
	__be16			sq_wqe_counter;
	u32			reserved3;
	__be16			rate_limit_params;
	u8			reserved4;
	u8			qos_vport;
	__be32			param3;
	__be32			nummmcpeers_basemkey;
	u8			log_page_size;
	u8			reserved5[2];
	u8			mtt_base_addr_h;
	__be32			mtt_base_addr_l;
	u32			reserved6[10];
};

struct mlx4_update_qp_context {
	__be64			qp_mask;
	__be64			primary_addr_path_mask;
	__be64			secondary_addr_path_mask;
	u64			reserved1;
	struct mlx4_qp_context	qp_context;
	u64			reserved2[58];
};

enum {
	MLX4_UPD_QP_MASK_PM_STATE	= 32,
	MLX4_UPD_QP_MASK_VSD		= 33,
	MLX4_UPD_QP_MASK_QOS_VPP	= 34,
	MLX4_UPD_QP_MASK_RATE_LIMIT	= 35,
};

enum {
	MLX4_UPD_QP_PATH_MASK_PKEY_INDEX		= 0 + 32,
	MLX4_UPD_QP_PATH_MASK_FSM			= 1 + 32,
	MLX4_UPD_QP_PATH_MASK_MAC_INDEX			= 2 + 32,
	MLX4_UPD_QP_PATH_MASK_FVL			= 3 + 32,
	MLX4_UPD_QP_PATH_MASK_CV			= 4 + 32,
	MLX4_UPD_QP_PATH_MASK_VLAN_INDEX		= 5 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_HIDE_CQE_VLAN		= 6 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_TX_BLOCK_UNTAGGED	= 7 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_TX_BLOCK_1P		= 8 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_TX_BLOCK_TAGGED	= 9 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_RX_BLOCK_UNTAGGED	= 10 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_RX_BLOCK_1P		= 11 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_RX_BLOCK_TAGGED	= 12 + 32,
	MLX4_UPD_QP_PATH_MASK_FEUP			= 13 + 32,
	MLX4_UPD_QP_PATH_MASK_SCHED_QUEUE		= 14 + 32,
	MLX4_UPD_QP_PATH_MASK_IF_COUNTER_INDEX		= 15 + 32,
	MLX4_UPD_QP_PATH_MASK_FVL_RX			= 16 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_SRC_CHECK_UC_LB	= 18 + 32,
	MLX4_UPD_QP_PATH_MASK_ETH_SRC_CHECK_MC_LB	= 19 + 32,
	MLX4_UPD_QP_PATH_MASK_SV			= 22 + 32,
};

enum { /* param3 */
	MLX4_STRIP_VLAN = 1 << 30
};

/* Which firmware version adds support for NEC (NoErrorCompletion) bit */
#define MLX4_FW_VER_WQE_CTRL_NEC mlx4_fw_ver(2, 2, 232)

enum {
	MLX4_WQE_CTRL_NEC		= 1 << 29,
	MLX4_WQE_CTRL_IIP		= 1 << 28,
	MLX4_WQE_CTRL_ILP		= 1 << 27,
	MLX4_WQE_CTRL_FENCE		= 1 << 6,
	MLX4_WQE_CTRL_CQ_UPDATE		= 3 << 2,
	MLX4_WQE_CTRL_SOLICITED		= 1 << 1,
	MLX4_WQE_CTRL_IP_CSUM		= 1 << 4,
	MLX4_WQE_CTRL_TCP_UDP_CSUM	= 1 << 5,
	MLX4_WQE_CTRL_INS_CVLAN		= 1 << 6,
	MLX4_WQE_CTRL_INS_SVLAN		= 1 << 7,
	MLX4_WQE_CTRL_STRONG_ORDER	= 1 << 7,
	MLX4_WQE_CTRL_FORCE_LOOPBACK	= 1 << 0,
};

union mlx4_wqe_qpn_vlan {
	struct {
		__be16	vlan_tag;
		u8	ins_vlan;
		u8	fence_size;
	};
	__be32		bf_qpn;
};

struct mlx4_wqe_ctrl_seg {
	__be32			owner_opcode;
	union mlx4_wqe_qpn_vlan	qpn_vlan;
	/*
	 * High 24 bits are SRC remote buffer; low 8 bits are flags:
	 * [7]   SO (strong ordering)
	 * [5]   TCP/UDP checksum
	 * [4]   IP checksum
	 * [3:2] C (generate completion queue entry)
	 * [1]   SE (solicited event)
	 * [0]   FL (force loopback)
	 */
	union {
		__be32			srcrb_flags;
		__be16			srcrb_flags16[2];
	};
	/*
	 * imm is immediate data for send/RDMA write w/ immediate;
	 * also invalidation key for send with invalidate; input
	 * modifier for WQEs on CCQs.
	 */
	__be32			imm;
};

enum {
	MLX4_WQE_MLX_VL15	= 1 << 17,
	MLX4_WQE_MLX_SLR	= 1 << 16
};

struct mlx4_wqe_mlx_seg {
	u8			owner;
	u8			reserved1[2];
	u8			opcode;
	__be16			sched_prio;
	u8			reserved2;
	u8			size;
	/*
	 * [17]    VL15
	 * [16]    SLR
	 * [15:12] static rate
	 * [11:8]  SL
	 * [4]     ICRC
	 * [3:2]   C
	 * [0]     FL (force loopback)
	 */
	__be32			flags;
	__be16			rlid;
	u16			reserved3;
};

struct mlx4_wqe_datagram_seg {
	__be32			av[8];
	__be32			dqpn;
	__be32			qkey;
	__be16			vlan;
	u8			mac[ETH_ALEN];
};

struct mlx4_wqe_lso_seg {
	__be32			mss_hdr_size;
	__be32			header[0];
};

enum mlx4_wqe_bind_seg_flags2 {
	MLX4_WQE_BIND_ZERO_BASED = (1 << 30),
	MLX4_WQE_BIND_TYPE_2     = (1 << 31),
};

struct mlx4_wqe_bind_seg {
	__be32			flags1;
	__be32			flags2;
	__be32			new_rkey;
	__be32			lkey;
	__be64			addr;
	__be64			length;
};

enum {
	MLX4_WQE_FMR_PERM_LOCAL_READ	= 1 << 27,
	MLX4_WQE_FMR_PERM_LOCAL_WRITE	= 1 << 28,
	MLX4_WQE_FMR_AND_BIND_PERM_REMOTE_READ	= 1 << 29,
	MLX4_WQE_FMR_AND_BIND_PERM_REMOTE_WRITE	= 1 << 30,
	MLX4_WQE_FMR_AND_BIND_PERM_ATOMIC	= 1 << 31
};

struct mlx4_wqe_fmr_seg {
	__be32			flags;
	__be32			mem_key;
	__be64			buf_list;
	__be64			start_addr;
	__be64			reg_len;
	__be32			offset;
	__be32			page_size;
	u32			reserved[2];
};

struct mlx4_wqe_fmr_ext_seg {
	u8			flags;
	u8			reserved;
	__be16			app_mask;
	__be16			wire_app_tag;
	__be16			mem_app_tag;
	__be32			wire_ref_tag_base;
	__be32			mem_ref_tag_base;
};

struct mlx4_wqe_local_inval_seg {
	u64			reserved1;
	__be32			mem_key;
	u32			reserved2;
	u64			reserved3[2];
};

struct mlx4_wqe_raddr_seg {
	__be64			raddr;
	__be32			rkey;
	u32			reserved;
};

struct mlx4_wqe_atomic_seg {
	__be64			swap_add;
	__be64			compare;
};

struct mlx4_wqe_masked_atomic_seg {
	__be64			swap_add;
	__be64			compare;
	__be64			swap_add_mask;
	__be64			compare_mask;
};

struct mlx4_wqe_data_seg {
	__be32			byte_count;
	__be32			lkey;
	__be64			addr;
};

enum {
	MLX4_INLINE_ALIGN	= 64,
	MLX4_INLINE_SEG		= 1 << 31,
};

struct mlx4_wqe_inline_seg {
	__be32			byte_count;
};

enum mlx4_update_qp_attr {
	MLX4_UPDATE_QP_SMAC		= 1 << 0,
	MLX4_UPDATE_QP_VSD		= 1 << 1,
	MLX4_UPDATE_QP_RATE_LIMIT	= 1 << 2,
	MLX4_UPDATE_QP_QOS_VPORT	= 1 << 3,
	MLX4_UPDATE_QP_ETH_SRC_CHECK_MC_LB      = 1 << 4,
	MLX4_UPDATE_QP_SUPPORTED_ATTRS	= (1 << 5) - 1
};

enum mlx4_update_qp_params_flags {
	MLX4_UPDATE_QP_PARAMS_FLAGS_ETH_CHECK_MC_LB     = 1 << 0,
	MLX4_UPDATE_QP_PARAMS_FLAGS_VSD_ENABLE		= 1 << 1,
};

struct mlx4_update_qp_params {
	u8	smac_index;
	u8	qos_vport;
	u32	flags;
	u16	rate_unit;
	u16	rate_val;
};

int mlx4_update_qp(struct mlx4_dev *dev, u32 qpn,
		   enum mlx4_update_qp_attr attr,
		   struct mlx4_update_qp_params *params);
int mlx4_qp_modify(struct mlx4_dev *dev, struct mlx4_mtt *mtt,
		   enum mlx4_qp_state cur_state, enum mlx4_qp_state new_state,
		   struct mlx4_qp_context *context, enum mlx4_qp_optpar optpar,
		   int sqd_event, struct mlx4_qp *qp);

int mlx4_qp_query(struct mlx4_dev *dev, struct mlx4_qp *qp,
		  struct mlx4_qp_context *context);

int mlx4_qp_to_ready(struct mlx4_dev *dev, struct mlx4_mtt *mtt,
		     struct mlx4_qp_context *context,
		     struct mlx4_qp *qp, enum mlx4_qp_state *qp_state);

static inline struct mlx4_qp *__mlx4_qp_lookup(struct mlx4_dev *dev, u32 qpn)
{
	return radix_tree_lookup(&dev->qp_table_tree, qpn & (dev->caps.num_qps - 1));
}

void mlx4_qp_remove(struct mlx4_dev *dev, struct mlx4_qp *qp);

static inline u16 folded_qp(u32 q)
{
	u16 res;

	res = ((q & 0xff) ^ ((q & 0xff0000) >> 16)) | (q & 0xff00);
	return res;
}

u16 mlx4_qp_roce_entropy(struct mlx4_dev *dev, u32 qpn);

#endif /* MLX4_QP_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         /*
 * Copyright (c) 2007 Cisco Systems, Inc.  All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *	- Redistributions of source code must retain the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer.
 *
 *	- Redistributions in binary form must reproduce the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer in the documentation and/or other materials
 *	  provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_SRQ_H
#define MLX4_SRQ_H

struct mlx4_wqe_srq_next_seg {
	u16			reserved1;
	__be16			next_wqe_index;
	u32			reserved2[3];
};

struct mlx4_srq *mlx4_srq_lookup(struct mlx4_dev *dev, u32 srqn);

#endif /* MLX4_SRQ_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     /*
 * Copyright (c) 2007 Cisco Systems, Inc.  All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *	- Redistributions of source code must retain the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer.
 *
 *	- Redistributions in binary form must reproduce the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer in the documentation and/or other materials
 *	  provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_CQ_H
#define MLX4_CQ_H

#include <linux/types.h>
#include <uapi/linux/if_ether.h>

#include <linux/mlx4/device.h>
#include <linux/mlx4/doorbell.h>

struct mlx4_cqe {
	__be32			vlan_my_qpn;
	__be32			immed_rss_invalid;
	__be32			g_mlpath_rqpn;
	__be16			sl_vid;
	union {
		struct {
			__be16	rlid;
			__be16  status;
			u8      ipv6_ext_mask;
			u8      badfcs_enc;
		};
		u8  smac[ETH_ALEN];
	};
	__be32			byte_cnt;
	__be16			wqe_index;
	__be16			checksum;
	u8			reserved[3];
	u8			owner_sr_opcode;
};

struct mlx4_err_cqe {
	__be32			my_qpn;
	u32			reserved1[5];
	__be16			wqe_index;
	u8			vendor_err_syndrome;
	u8			syndrome;
	u8			reserved2[3];
	u8			owner_sr_opcode;
};

struct mlx4_ts_cqe {
	__be32			vlan_my_qpn;
	__be32			immed_rss_invalid;
	__be32			g_mlpath_rqpn;
	__be32			timestamp_hi;
	__be16			status;
	u8			ipv6_ext_mask;
	u8			badfcs_enc;
	__be32			byte_cnt;
	__be16			wqe_index;
	__be16			checksum;
	u8			reserved;
	__be16			timestamp_lo;
	u8			owner_sr_opcode;
} __packed;

enum {
	MLX4_CQE_L2_TUNNEL_IPOK		= 1 << 31,
	MLX4_CQE_CVLAN_PRESENT_MASK	= 1 << 29,
	MLX4_CQE_SVLAN_PRESENT_MASK	= 1 << 30,
	MLX4_CQE_L2_TUNNEL		= 1 << 27,
	MLX4_CQE_L2_TUNNEL_CSUM		= 1 << 26,
	MLX4_CQE_L2_TUNNEL_IPV4		= 1 << 25,

	MLX4_CQE_QPN_MASK		= 0xffffff,
	MLX4_CQE_VID_MASK		= 0xfff,
};

enum {
	MLX4_CQE_OWNER_MASK	= 0x80,
	MLX4_CQE_IS_SEND_MASK	= 0x40,
	MLX4_CQE_OPCODE_MASK	= 0x1f
};

enum {
	MLX4_CQE_SYNDROME_LOCAL_LENGTH_ERR		= 0x01,
	MLX4_CQE_SYNDROME_LOCAL_QP_OP_ERR		= 0x02,
	MLX4_CQE_SYNDROME_LOCAL_PROT_ERR		= 0x04,
	MLX4_CQE_SYNDROME_WR_FLUSH_ERR			= 0x05,
	MLX4_CQE_SYNDROME_MW_BIND_ERR			= 0x06,
	MLX4_CQE_SYNDROME_BAD_RESP_ERR			= 0x10,
	MLX4_CQE_SYNDROME_LOCAL_ACCESS_ERR		= 0x11,
	MLX4_CQE_SYNDROME_REMOTE_INVAL_REQ_ERR		= 0x12,
	MLX4_CQE_SYNDROME_REMOTE_ACCESS_ERR		= 0x13,
	MLX4_CQE_SYNDROME_REMOTE_OP_ERR			= 0x14,
	MLX4_CQE_SYNDROME_TRANSPORT_RETRY_EXC_ERR	= 0x15,
	MLX4_CQE_SYNDROME_RNR_RETRY_EXC_ERR		= 0x16,
	MLX4_CQE_SYNDROME_REMOTE_ABORTED_ERR		= 0x22,
};

enum {
	MLX4_CQE_STATUS_IPV4		= 1 << 6,
	MLX4_CQE_STATUS_IPV4F		= 1 << 7,
	MLX4_CQE_STATUS_IPV6		= 1 << 8,
	MLX4_CQE_STATUS_IPV4OPT		= 1 << 9,
	MLX4_CQE_STATUS_TCP		= 1 << 10,
	MLX4_CQE_STATUS_UDP		= 1 << 11,
	MLX4_CQE_STATUS_IPOK		= 1 << 12,
};

enum {
	MLX4_CQE_LLC                     = 1,
	MLX4_CQE_SNAP                    = 1 << 1,
	MLX4_CQE_BAD_FCS                 = 1 << 4,
};

static inline void mlx4_cq_arm(struct mlx4_cq *cq, u32 cmd,
			       void __iomem *uar_page,
			       spinlock_t *doorbell_lock)
{
	__be32 doorbell[2];
	u32 sn;
	u32 ci;

	sn = cq->arm_sn & 3;
	ci = cq->cons_index & 0xffffff;

	*cq->arm_db = cpu_to_be32(sn << 28 | cmd | ci);

	/*
	 * Make sure that the doorbell record in host memory is
	 * written before ringing the doorbell via PCI MMIO.
	 */
	wmb();

	doorbell[0] = cpu_to_be32(sn << 28 | cmd | cq->cqn);
	doorbell[1] = cpu_to_be32(ci);

	mlx4_write64(doorbell, uar_page + MLX4_CQ_DOORBELL, doorbell_lock);
}

static inline void mlx4_cq_set_ci(struct mlx4_cq *cq)
{
	*cq->set_ci_db = cpu_to_be32(cq->cons_index & 0xffffff);
}

enum {
	MLX4_CQ_DB_REQ_NOT_SOL		= 1 << 24,
	MLX4_CQ_DB_REQ_NOT		= 2 << 24
};

int mlx4_cq_modify(struct mlx4_dev *dev, struct mlx4_cq *cq,
		   u16 count, u16 period);
int mlx4_cq_resize(struct mlx4_dev *dev, struct mlx4_cq *cq,
		   int entries, struct mlx4_mtt *mtt);

#endif /* MLX4_CQ_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             /*
 * Copyright (c) 2006 Cisco Systems, Inc.  All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *      - Redistributions of source code must retain the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer.
 *
 *      - Redistributions in binary form must reproduce the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer in the documentation and/or other materials
 *        provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_DRIVER_H
#define MLX4_DRIVER_H

#include <net/devlink.h>
#include <linux/mlx4/device.h>

struct mlx4_dev;

#define MLX4_MAC_MASK	   0xffffffffffffULL

enum mlx4_dev_event {
	MLX4_DEV_EVENT_CATASTROPHIC_ERROR,
	MLX4_DEV_EVENT_PORT_UP,
	MLX4_DEV_EVENT_PORT_DOWN,
	MLX4_DEV_EVENT_PORT_REINIT,
	MLX4_DEV_EVENT_PORT_MGMT_CHANGE,
	MLX4_DEV_EVENT_SLAVE_INIT,
	MLX4_DEV_EVENT_SLAVE_SHUTDOWN,
};

enum {
	MLX4_INTFF_BONDING	= 1 << 0
};

struct mlx4_interface {
	void *			(*add)	 (struct mlx4_dev *dev);
	void			(*remove)(struct mlx4_dev *dev, void *context);
	void			(*event) (struct mlx4_dev *dev, void *context,
					  enum mlx4_dev_event event, unsigned long param);
	void *			(*get_dev)(struct mlx4_dev *dev, void *context, u8 port);
	void			(*activate)(struct mlx4_dev *dev, void *context);
	struct list_head	list;
	enum mlx4_protocol	protocol;
	int			flags;
};

int mlx4_register_interface(struct mlx4_interface *intf);
void mlx4_unregister_interface(struct mlx4_interface *intf);

int mlx4_bond(struct mlx4_dev *dev);
int mlx4_unbond(struct mlx4_dev *dev);
static inline int mlx4_is_bonded(struct mlx4_dev *dev)
{
	return !!(dev->flags & MLX4_FLAG_BONDED);
}

static inline int mlx4_is_mf_bonded(struct mlx4_dev *dev)
{
	return (mlx4_is_bonded(dev) && mlx4_is_mfunc(dev));
}

struct mlx4_port_map {
	u8	port1;
	u8	port2;
};

int mlx4_port_map_set(struct mlx4_dev *dev, struct mlx4_port_map *v2p);

void *mlx4_get_protocol_dev(struct mlx4_dev *dev, enum mlx4_protocol proto, int port);

struct devlink_port *mlx4_get_devlink_port(struct mlx4_dev *dev, int port);

static inline u64 mlx4_mac_to_u64(u8 *addr)
{
	u64 mac = 0;
	int i;

	for (i = 0; i < ETH_ALEN; i++) {
		mac <<= 8;
		mac |= addr[i];
	}
	return mac;
}

#endif /* MLX4_DRIVER_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /*
 * Copyright (c) 2006 Cisco Systems, Inc.  All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *      - Redistributions of source code must retain the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer.
 *
 *      - Redistributions in binary form must reproduce the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer in the documentation and/or other materials
 *        provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_CMD_H
#define MLX4_CMD_H

#include <linux/dma-mapping.h>
#include <linux/if_link.h>
#include <linux/mlx4/device.h>
#include <linux/netdevice.h>

enum {
	/* initialization and general commands */
	MLX4_CMD_SYS_EN		 = 0x1,
	MLX4_CMD_SYS_DIS	 = 0x2,
	MLX4_CMD_MAP_FA		 = 0xfff,
	MLX4_CMD_UNMAP_FA	 = 0xffe,
	MLX4_CMD_RUN_FW		 = 0xff6,
	MLX4_CMD_MOD_STAT_CFG	 = 0x34,
	MLX4_CMD_QUERY_DEV_CAP	 = 0x3,
	MLX4_CMD_QUERY_FW	 = 0x4,
	MLX4_CMD_ENABLE_LAM	 = 0xff8,
	MLX4_CMD_DISABLE_LAM	 = 0xff7,
	MLX4_CMD_QUERY_DDR	 = 0x5,
	MLX4_CMD_QUERY_ADAPTER	 = 0x6,
	MLX4_CMD_INIT_HCA	 = 0x7,
	MLX4_CMD_CLOSE_HCA	 = 0x8,
	MLX4_CMD_INIT_PORT	 = 0x9,
	MLX4_CMD_CLOSE_PORT	 = 0xa,
	MLX4_CMD_QUERY_HCA	 = 0xb,
	MLX4_CMD_QUERY_PORT	 = 0x43,
	MLX4_CMD_SENSE_PORT	 = 0x4d,
	MLX4_CMD_HW_HEALTH_CHECK = 0x50,
	MLX4_CMD_SET_PORT	 = 0xc,
	MLX4_CMD_SET_NODE	 = 0x5a,
	MLX4_CMD_QUERY_FUNC	 = 0x56,
	MLX4_CMD_ACCESS_DDR	 = 0x2e,
	MLX4_CMD_MAP_ICM	 = 0xffa,
	MLX4_CMD_UNMAP_ICM	 = 0xff9,
	MLX4_CMD_MAP_ICM_AUX	 = 0xffc,
	MLX4_CMD_UNMAP_ICM_AUX	 = 0xffb,
	MLX4_CMD_SET_ICM_SIZE	 = 0xffd,
	MLX4_CMD_ACCESS_REG	 = 0x3b,
	MLX4_CMD_ALLOCATE_VPP	 = 0x80,
	MLX4_CMD_SET_VPORT_QOS	 = 0x81,

	/*master notify fw on finish for slave's flr*/
	MLX4_CMD_INFORM_FLR_DONE = 0x5b,
	MLX4_CMD_VIRT_PORT_MAP   = 0x5c,
	MLX4_CMD_GET_OP_REQ      = 0x59,

	/* TPT commands */
	MLX4_CMD_SW2HW_MPT	 = 0xd,
	MLX4_CMD_QUERY_MPT	 = 0xe,
	MLX4_CMD_HW2SW_MPT	 = 0xf,
	MLX4_CMD_READ_MTT	 = 0x10,
	MLX4_CMD_WRITE_MTT	 = 0x11,
	MLX4_CMD_SYNC_TPT	 = 0x2f,

	/* EQ commands */
	MLX4_CMD_MAP_EQ		 = 0x12,
	MLX4_CMD_SW2HW_EQ	 = 0x13,
	MLX4_CMD_HW2SW_EQ	 = 0x14,
	MLX4_CMD_QUERY_EQ	 = 0x15,

	/* CQ commands */
	MLX4_CMD_SW2HW_CQ	 = 0x16,
	MLX4_CMD_HW2SW_CQ	 = 0x17,
	MLX4_CMD_QUERY_CQ	 = 0x18,
	MLX4_CMD_MODIFY_CQ	 = 0x2c,

	/* SRQ commands */
	MLX4_CMD_SW2HW_SRQ	 = 0x35,
	MLX4_CMD_HW2SW_SRQ	 = 0x36,
	MLX4_CMD_QUERY_SRQ	 = 0x37,
	MLX4_CMD_ARM_SRQ	 = 0x40,

	/* QP/EE commands */
	MLX4_CMD_RST2INIT_QP	 = 0x19,
	MLX4_CMD_INIT2RTR_QP	 = 0x1a,
	MLX4_CMD_RTR2RTS_QP	 = 0x1b,
	MLX4_CMD_RTS2RTS_QP	 = 0x1c,
	MLX4_CMD_SQERR2RTS_QP	 = 0x1d,
	MLX4_CMD_2ERR_QP	 = 0x1e,
	MLX4_CMD_RTS2SQD_QP	 = 0x1f,
	MLX4_CMD_SQD2SQD_QP	 = 0x38,
	MLX4_CMD_SQD2RTS_QP	 = 0x20,
	MLX4_CMD_2RST_QP	 = 0x21,
	MLX4_CMD_QUERY_QP	 = 0x22,
	MLX4_CMD_INIT2INIT_QP	 = 0x2d,
	MLX4_CMD_SUSPEND_QP	 = 0x32,
	MLX4_CMD_UNSUSPEND_QP	 = 0x33,
	MLX4_CMD_UPDATE_QP	 = 0x61,
	/* special QP and management commands */
	MLX4_CMD_CONF_SPECIAL_QP = 0x23,
	MLX4_CMD_MAD_IFC	 = 0x24,
	MLX4_CMD_MAD_DEMUX	 = 0x203,

	/* multicast commands */
	MLX4_CMD_READ_MCG	 = 0x25,
	MLX4_CMD_WRITE_MCG	 = 0x26,
	MLX4_CMD_MGID_HASH	 = 0x27,

	/* miscellaneous commands */
	MLX4_CMD_DIAG_RPRT	 = 0x30,
	MLX4_CMD_NOP		 = 0x31,
	MLX4_CMD_CONFIG_DEV	 = 0x3a,
	MLX4_CMD_ACCESS_MEM	 = 0x2e,
	MLX4_CMD_SET_VEP	 = 0x52,

	/* Ethernet specific commands */
	MLX4_CMD_SET_VLAN_FLTR	 = 0x47,
	MLX4_CMD_SET_MCAST_FLTR	 = 0x48,
	MLX4_CMD_DUMP_ETH_STATS	 = 0x49,

	/* Communication channel commands */
	MLX4_CMD_ARM_COMM_CHANNEL = 0x57,
	MLX4_CMD_GEN_EQE	 = 0x58,

	/* virtual commands */
	MLX4_CMD_ALLOC_RES	 = 0xf00,
	MLX4_CMD_FREE_RES	 = 0xf01,
	MLX4_CMD_MCAST_ATTACH	 = 0xf05,
	MLX4_CMD_UCAST_ATTACH	 = 0xf06,
	MLX4_CMD_PROMISC         = 0xf08,
	MLX4_CMD_QUERY_FUNC_CAP  = 0xf0a,
	MLX4_CMD_QP_ATTACH	 = 0xf0b,

	/* debug commands */
	MLX4_CMD_QUERY_DEBUG_MSG = 0x2a,
	MLX4_CMD_SET_DEBUG_MSG	 = 0x2b,

	/* statistics commands */
	MLX4_CMD_QUERY_IF_STAT	 = 0X54,
	MLX4_CMD_SET_IF_STAT	 = 0X55,

	/* register/delete flow steering network rules */
	MLX4_QP_FLOW_STEERING_ATTACH = 0x65,
	MLX4_QP_FLOW_STEERING_DETACH = 0x66,
	MLX4_FLOW_STEERING_IB_UC_QP_RANGE = 0x64,

	/* Update and read QCN parameters */
	MLX4_CMD_CONGESTION_CTRL_OPCODE = 0x68,
};

enum {
	MLX4_CMD_TIME_CLASS_A	= 60000,
	MLX4_CMD_TIME_CLASS_B	= 60000,
	MLX4_CMD_TIME_CLASS_C	= 60000,
};

enum {
	/* virtual to physical port mapping opcode modifiers */
	MLX4_GET_PORT_VIRT2PHY = 0x0,
	MLX4_SET_PORT_VIRT2PHY = 0x1,
};

enum {
	MLX4_MAILBOX_SIZE	= 4096,
	MLX4_ACCESS_MEM_ALIGN	= 256,
};

enum {
	/* Set port opcode modifiers */
	MLX4_SET_PORT_IB_OPCODE		= 0x0,
	MLX4_SET_PORT_ETH_OPCODE	= 0x1,
	MLX4_SET_PORT_BEACON_OPCODE	= 0x4,
};

enum {
	/* Set port Ethernet input modifiers */
	MLX4_SET_PORT_GENERAL   = 0x0,
	MLX4_SET_PORT_RQP_CALC  = 0x1,
	MLX4_SET_PORT_MAC_TABLE = 0x2,
	MLX4_SET_PORT_VLAN_TABLE = 0x3,
	MLX4_SET_PORT_PRIO_MAP  = 0x4,
	MLX4_SET_PORT_GID_TABLE = 0x5,
	MLX4_SET_PORT_PRIO2TC	= 0x8,
	MLX4_SET_PORT_SCHEDULER = 0x9,
	MLX4_SET_PORT_VXLAN	= 0xB,
	MLX4_SET_PORT_ROCE_ADDR	= 0xD
};

enum {
	MLX4_CMD_MAD_DEMUX_CONFIG	= 0,
	MLX4_CMD_MAD_DEMUX_QUERY_STATE	= 1,
	MLX4_CMD_MAD_DEMUX_QUERY_RESTR	= 2, /* Query mad demux restrictions */
};

enum {
	MLX4_CMD_WRAPPED,
	MLX4_CMD_NATIVE
};

/*
 * MLX4_RX_CSUM_MODE_VAL_NON_TCP_UDP -
 * Receive checksum value is reported in CQE also for non TCP/UDP packets.
 *
 * MLX4_RX_CSUM_MODE_L4 -
 * L4_CSUM bit in CQE, which indicates whether or not L4 checksum
 * was validated correctly, is supported.
 *
 * MLX4_RX_CSUM_MODE_IP_OK_IP_NON_TCP_UDP -
 * IP_OK CQE's field is supported also for non TCP/UDP IP packets.
 *
 * MLX4_RX_CSUM_MODE_MULTI_VLAN -
 * Receive Checksum offload is supported for packets with more than 2 vlan headers.
 */
enum mlx4_rx_csum_mode {
	MLX4_RX_CSUM_MODE_VAL_NON_TCP_UDP		= 1UL << 0,
	MLX4_RX_CSUM_MODE_L4				= 1UL << 1,
	MLX4_RX_CSUM_MODE_IP_OK_IP_NON_TCP_UDP		= 1UL << 2,
	MLX4_RX_CSUM_MODE_MULTI_VLAN			= 1UL << 3
};

struct mlx4_config_dev_params {
	u16	vxlan_udp_dport;
	u8	rx_csum_flags_port_1;
	u8	rx_csum_flags_port_2;
};

enum mlx4_en_congestion_control_algorithm {
	MLX4_CTRL_ALGO_802_1_QAU_REACTION_POINT = 0,
};

enum mlx4_en_congestion_control_opmod {
	MLX4_CONGESTION_CONTROL_GET_PARAMS,
	MLX4_CONGESTION_CONTROL_GET_STATISTICS,
	MLX4_CONGESTION_CONTROL_SET_PARAMS = 4,
};

struct mlx4_dev;

struct mlx4_cmd_mailbox {
	void		       *buf;
	dma_addr_t		dma;
};

int __mlx4_cmd(struct mlx4_dev *dev, u64 in_param, u64 *out_param,
	       int out_is_imm, u32 in_modifier, u8 op_modifier,
	       u16 op, unsigned long timeout, int native);

/* Invoke a command with no output parameter */
static inline int mlx4_cmd(struct mlx4_dev *dev, u64 in_param, u32 in_modifier,
			   u8 op_modifier, u16 op, unsigned long timeout,
			   int native)
{
	return __mlx4_cmd(dev, in_param, NULL, 0, in_modifier,
			  op_modifier, op, timeout, native);
}

/* Invoke a command with an output mailbox */
static inline int mlx4_cmd_box(struct mlx4_dev *dev, u64 in_param, u64 out_param,
			       u32 in_modifier, u8 op_modifier, u16 op,
			       unsigned long timeout, int native)
{
	return __mlx4_cmd(dev, in_param, &out_param, 0, in_modifier,
			  op_modifier, op, timeout, native);
}

/*
 * Invoke a command with an immediate output parameter (and copy the
 * output into the caller's out_param pointer after the command
 * executes).
 */
static inline int mlx4_cmd_imm(struct mlx4_dev *dev, u64 in_param, u64 *out_param,
			       u32 in_modifier, u8 op_modifier, u16 op,
			       unsigned long timeout, int native)
{
	return __mlx4_cmd(dev, in_param, out_param, 1, in_modifier,
			  op_modifier, op, timeout, native);
}

struct mlx4_cmd_mailbox *mlx4_alloc_cmd_mailbox(struct mlx4_dev *dev);
void mlx4_free_cmd_mailbox(struct mlx4_dev *dev, struct mlx4_cmd_mailbox *mailbox);

int mlx4_get_counter_stats(struct mlx4_dev *dev, int counter_index,
			   struct mlx4_counter *counter_stats, int reset);
int mlx4_get_vf_stats(struct mlx4_dev *dev, int port, int vf_idx,
		      struct ifla_vf_stats *vf_stats);
u32 mlx4_comm_get_version(void);
int mlx4_set_vf_mac(struct mlx4_dev *dev, int port, int vf, u64 mac);
int mlx4_set_vf_vlan(struct mlx4_dev *dev, int port, int vf, u16 vlan,
		     u8 qos, __be16 proto);
int mlx4_set_vf_rate(struct mlx4_dev *dev, int port, int vf, int min_tx_rate,
		     int max_tx_rate);
int mlx4_set_vf_spoofchk(struct mlx4_dev *dev, int port, int vf, bool setting);
int mlx4_get_vf_config(struct mlx4_dev *dev, int port, int vf, struct ifla_vf_info *ivf);
int mlx4_set_vf_link_state(struct mlx4_dev *dev, int port, int vf, int link_state);
int mlx4_config_dev_retrieval(struct mlx4_dev *dev,
			      struct mlx4_config_dev_params *params);
void mlx4_cmd_wake_completions(struct mlx4_dev *dev);
void mlx4_report_internal_err_comm_event(struct mlx4_dev *dev);
/*
 * mlx4_get_slave_default_vlan -
 * return true if VST ( default vlan)
 * if VST, will return vlan & qos (if not NULL)
 */
bool mlx4_get_slave_default_vlan(struct mlx4_dev *dev, int port, int slave,
				 u16 *vlan, u8 *qos);

#define MLX4_COMM_GET_IF_REV(cmd_chan_ver) (u8)((cmd_chan_ver) >> 8)
#define COMM_CHAN_EVENT_INTERNAL_ERR (1 << 17)

#endif /* MLX4_CMD_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             /*
 * Copyright (c) 2004 Topspin Communications.  All rights reserved.
 * Copyright (c) 2005 Sun Microsystems, Inc. All rights reserved.
 * Copyright (c) 2005 Mellanox Technologies. All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *      - Redistributions of source code must retain the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer.
 *
 *      - Redistributions in binary form must reproduce the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer in the documentation and/or other materials
 *        provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_DOORBELL_H
#define MLX4_DOORBELL_H

#include <linux/types.h>
#include <linux/io.h>

#define MLX4_SEND_DOORBELL    0x14
#define MLX4_CQ_DOORBELL      0x20

#if BITS_PER_LONG == 64
/*
 * Assume that we can just write a 64-bit doorbell atomically.  s390
 * actually doesn't have writeq() but S/390 systems don't even have
 * PCI so we won't worry about it.
 */

#define MLX4_DECLARE_DOORBELL_LOCK(name)
#define MLX4_INIT_DOORBELL_LOCK(ptr)    do { } while (0)
#define MLX4_GET_DOORBELL_LOCK(ptr)      (NULL)

static inline void mlx4_write64(__be32 val[2], void __iomem *dest,
				spinlock_t *doorbell_lock)
{
	__raw_writeq(*(u64 *) val, dest);
}

#else

/*
 * Just fall back to a spinlock to protect the doorbell if
 * BITS_PER_LONG is 32 -- there's no portable way to do atomic 64-bit
 * MMIO writes.
 */

#define MLX4_DECLARE_DOORBELL_LOCK(name) spinlock_t name;
#define MLX4_INIT_DOORBELL_LOCK(ptr)     spin_lock_init(ptr)
#define MLX4_GET_DOORBELL_LOCK(ptr)      (ptr)

static inline void mlx4_write64(__be32 val[2], void __iomem *dest,
				spinlock_t *doorbell_lock)
{
	unsigned long flags;

	spin_lock_irqsave(doorbell_lock, flags);
	__raw_writel((__force u32) val[0], dest);
	__raw_writel((__force u32) val[1], dest + 4);
	spin_unlock_irqrestore(doorbell_lock, flags);
}

#endif

#endif /* MLX4_DOORBELL_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  /*
 * Copyright (c) 2006, 2007 Cisco Systems, Inc.  All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *	- Redistributions of source code must retain the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer.
 *
 *	- Redistributions in binary form must reproduce the above
 *	  copyright notice, this list of conditions and the following
 *	  disclaimer in the documentation and/or other materials
 *	  provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_DEVICE_H
#define MLX4_DEVICE_H

#include <linux/if_ether.h>
#include <linux/pci.h>
#include <linux/completion.h>
#include <linux/radix-tree.h>
#include <linux/cpu_rmap.h>
#include <linux/crash_dump.h>

#include <linux/atomic.h>

#include <linux/timecounter.h>

#define DEFAULT_UAR_PAGE_SHIFT  12

#define MAX_MSIX_P_PORT		17
#define MAX_MSIX		64
#define MIN_MSIX_P_PORT		5
#define MLX4_IS_LEGACY_EQ_MODE(dev_cap) ((dev_cap).num_comp_vectors < \
					 (dev_cap).num_ports * MIN_MSIX_P_PORT)

#define MLX4_MAX_100M_UNITS_VAL		255	/*
						 * work around: can't set values
						 * greater then this value when
						 * using 100 Mbps units.
						 */
#define MLX4_RATELIMIT_100M_UNITS	3	/* 100 Mbps */
#define MLX4_RATELIMIT_1G_UNITS		4	/* 1 Gbps */
#define MLX4_RATELIMIT_DEFAULT		0x00ff

#define MLX4_ROCE_MAX_GIDS	128
#define MLX4_ROCE_PF_GIDS	16

enum {
	MLX4_FLAG_MSI_X		= 1 << 0,
	MLX4_FLAG_OLD_PORT_CMDS	= 1 << 1,
	MLX4_FLAG_MASTER	= 1 << 2,
	MLX4_FLAG_SLAVE		= 1 << 3,
	MLX4_FLAG_SRIOV		= 1 << 4,
	MLX4_FLAG_OLD_REG_MAC	= 1 << 6,
	MLX4_FLAG_BONDED	= 1 << 7,
	MLX4_FLAG_SECURE_HOST	= 1 << 8,
};

enum {
	MLX4_PORT_CAP_IS_SM	= 1 << 1,
	MLX4_PORT_CAP_DEV_MGMT_SUP = 1 << 19,
};

enum {
	MLX4_MAX_PORTS		= 2,
	MLX4_MAX_PORT_PKEYS	= 128,
	MLX4_MAX_PORT_GIDS	= 128
};

/* base qkey for use in sriov tunnel-qp/proxy-qp communication.
 * These qkeys must not be allowed for general use. This is a 64k range,
 * and to test for violation, we use the mask (protect against future chg).
 */
#define MLX4_RESERVED_QKEY_BASE  (0xFFFF0000)
#define MLX4_RESERVED_QKEY_MASK  (0xFFFF0000)

enum {
	MLX4_BOARD_ID_LEN = 64
};

enum {
	MLX4_MAX_NUM_PF		= 16,
	MLX4_MAX_NUM_VF		= 126,
	MLX4_MAX_NUM_VF_P_PORT  = 64,
	MLX4_MFUNC_MAX		= 128,
	MLX4_MAX_EQ_NUM		= 1024,
	MLX4_MFUNC_EQ_NUM	= 4,
	MLX4_MFUNC_MAX_EQES     = 8,
	MLX4_MFUNC_EQE_MASK     = (MLX4_MFUNC_MAX_EQES - 1)
};

/* Driver supports 3 diffrent device methods to manage traffic steering:
 *	-device managed - High level API for ib and eth flow steering. FW is
 *			  managing flow steering tables.
 *	- B0 steering mode - Common low level API for ib and (if supported) eth.
 *	- A0 steering mode - Limited low level API for eth. In case of IB,
 *			     B0 mode is in use.
 */
enum {
	MLX4_STEERING_MODE_A0,
	MLX4_STEERING_MODE_B0,
	MLX4_STEERING_MODE_DEVICE_MANAGED
};

enum {
	MLX4_STEERING_DMFS_A0_DEFAULT,
	MLX4_STEERING_DMFS_A0_DYNAMIC,
	MLX4_STEERING_DMFS_A0_STATIC,
	MLX4_STEERING_DMFS_A0_DISABLE,
	MLX4_STEERING_DMFS_A0_NOT_SUPPORTED
};

static inline const char *mlx4_steering_mode_str(int steering_mode)
{
	switch (steering_mode) {
	case MLX4_STEERING_MODE_A0:
		return "A0 steering";

	case MLX4_STEERING_MODE_B0:
		return "B0 steering";

	case MLX4_STEERING_MODE_DEVICE_MANAGED:
		return "Device managed flow steering";

	default:
		return "Unrecognize steering mode";
	}
}

enum {
	MLX4_TUNNEL_OFFLOAD_MODE_NONE,
	MLX4_TUNNEL_OFFLOAD_MODE_VXLAN
};

enum {
	MLX4_DEV_CAP_FLAG_RC		= 1LL <<  0,
	MLX4_DEV_CAP_FLAG_UC		= 1LL <<  1,
	MLX4_DEV_CAP_FLAG_UD		= 1LL <<  2,
	MLX4_DEV_CAP_FLAG_XRC		= 1LL <<  3,
	MLX4_DEV_CAP_FLAG_SRQ		= 1LL <<  6,
	MLX4_DEV_CAP_FLAG_IPOIB_CSUM	= 1LL <<  7,
	MLX4_DEV_CAP_FLAG_BAD_PKEY_CNTR	= 1LL <<  8,
	MLX4_DEV_CAP_FLAG_BAD_QKEY_CNTR	= 1LL <<  9,
	MLX4_DEV_CAP_FLAG_DPDP		= 1LL << 12,
	MLX4_DEV_CAP_FLAG_BLH		= 1LL << 15,
	MLX4_DEV_CAP_FLAG_MEM_WINDOW	= 1LL << 16,
	MLX4_DEV_CAP_FLAG_APM		= 1LL << 17,
	MLX4_DEV_CAP_FLAG_ATOMIC	= 1LL << 18,
	MLX4_DEV_CAP_FLAG_RAW_MCAST	= 1LL << 19,
	MLX4_DEV_CAP_FLAG_UD_AV_PORT	= 1LL << 20,
	MLX4_DEV_CAP_FLAG_UD_MCAST	= 1LL << 21,
	MLX4_DEV_CAP_FLAG_IBOE		= 1LL << 30,
	MLX4_DEV_CAP_FLAG_UC_LOOPBACK	= 1LL << 32,
	MLX4_DEV_CAP_FLAG_FCS_KEEP	= 1LL << 34,
	MLX4_DEV_CAP_FLAG_WOL_PORT1	= 1LL << 37,
	MLX4_DEV_CAP_FLAG_WOL_PORT2	= 1LL << 38,
	MLX4_DEV_CAP_FLAG_UDP_RSS	= 1LL << 40,
	MLX4_DEV_CAP_FLAG_VEP_UC_STEER	= 1LL << 41,
	MLX4_DEV_CAP_FLAG_VEP_MC_STEER	= 1LL << 42,
	MLX4_DEV_CAP_FLAG_COUNTERS	= 1LL << 48,
	MLX4_DEV_CAP_FLAG_RSS_IP_FRAG   = 1LL << 52,
	MLX4_DEV_CAP_FLAG_SET_ETH_SCHED = 1LL << 53,
	MLX4_DEV_CAP_FLAG_SENSE_SUPPORT	= 1LL << 55,
	MLX4_DEV_CAP_FLAG_PORT_MNG_CHG_EV = 1LL << 59,
	MLX4_DEV_CAP_FLAG_64B_EQE	= 1LL << 61,
	MLX4_DEV_CAP_FLAG_64B_CQE	= 1LL << 62
};

enum {
	MLX4_DEV_CAP_FLAG2_RSS			= 1LL <<  0,
	MLX4_DEV_CAP_FLAG2_RSS_TOP		= 1LL <<  1,
	MLX4_DEV_CAP_FLAG2_RSS_XOR		= 1LL <<  2,
	MLX4_DEV_CAP_FLAG2_FS_EN		= 1LL <<  3,
	MLX4_DEV_CAP_FLAG2_REASSIGN_MAC_EN	= 1LL <<  4,
	MLX4_DEV_CAP_FLAG2_TS			= 1LL <<  5,
	MLX4_DEV_CAP_FLAG2_VLAN_CONTROL		= 1LL <<  6,
	MLX4_DEV_CAP_FLAG2_FSM			= 1LL <<  7,
	MLX4_DEV_CAP_FLAG2_UPDATE_QP		= 1LL <<  8,
	MLX4_DEV_CAP_FLAG2_DMFS_IPOIB		= 1LL <<  9,
	MLX4_DEV_CAP_FLAG2_VXLAN_OFFLOADS	= 1LL <<  10,
	MLX4_DEV_CAP_FLAG2_MAD_DEMUX		= 1LL <<  11,
	MLX4_DEV_CAP_FLAG2_CQE_STRIDE		= 1LL <<  12,
	MLX4_DEV_CAP_FLAG2_EQE_STRIDE		= 1LL <<  13,
	MLX4_DEV_CAP_FLAG2_ETH_PROT_CTRL        = 1LL <<  14,
	MLX4_DEV_CAP_FLAG2_ETH_BACKPL_AN_REP	= 1LL <<  15,
	MLX4_DEV_CAP_FLAG2_CONFIG_DEV		= 1LL <<  16,
	MLX4_DEV_CAP_FLAG2_SYS_EQS		= 1LL <<  17,
	MLX4_DEV_CAP_FLAG2_80_VFS		= 1LL <<  18,
	MLX4_DEV_CAP_FLAG2_FS_A0		= 1LL <<  19,
	MLX4_DEV_CAP_FLAG2_RECOVERABLE_ERROR_EVENT = 1LL << 20,
	MLX4_DEV_CAP_FLAG2_PORT_REMAP		= 1LL <<  21,
	MLX4_DEV_CAP_FLAG2_QCN			= 1LL <<  22,
	MLX4_DEV_CAP_FLAG2_QP_RATE_LIMIT	= 1LL <<  23,
	MLX4_DEV_CAP_FLAG2_FLOWSTATS_EN         = 1LL <<  24,
	MLX4_DEV_CAP_FLAG2_QOS_VPP		= 1LL <<  25,
	MLX4_DEV_CAP_FLAG2_ETS_CFG		= 1LL <<  26,
	MLX4_DEV_CAP_FLAG2_PORT_BEACON		= 1LL <<  27,
	MLX4_DEV_CAP_FLAG2_IGNORE_FCS		= 1LL <<  28,
	MLX4_DEV_CAP_FLAG2_PHV_EN		= 1LL <<  29,
	MLX4_DEV_CAP_FLAG2_SKIP_OUTER_VLAN	= 1LL <<  30,
	MLX4_DEV_CAP_FLAG2_UPDATE_QP_SRC_CHECK_LB = 1ULL << 31,
	MLX4_DEV_CAP_FLAG2_LB_SRC_CHK           = 1ULL << 32,
	MLX4_DEV_CAP_FLAG2_ROCE_V1_V2		= 1ULL <<  33,
	MLX4_DEV_CAP_FLAG2_DMFS_UC_MC_SNIFFER   = 1ULL <<  34,
	MLX4_DEV_CAP_FLAG2_DIAG_PER_PORT	= 1ULL <<  35,
	MLX4_DEV_CAP_FLAG2_SVLAN_BY_QP          = 1ULL <<  36,
	MLX4_DEV_CAP_FLAG2_SL_TO_VL_CHANGE_EVENT = 1ULL << 37,
};

enum {
	MLX4_QUERY_FUNC_FLAGS_BF_RES_QP		= 1LL << 0,
	MLX4_QUERY_FUNC_FLAGS_A0_RES_QP		= 1LL << 1
};

enum {
	MLX4_VF_CAP_FLAG_RESET			= 1 << 0
};

/* bit enums for an 8-bit flags field indicating special use
 * QPs which require special handling in qp_reserve_range.
 * Currently, this only includes QPs used by the ETH interface,
 * where we expect to use blueflame.  These QPs must not have
 * bits 6 and 7 set in their qp number.
 *
 * This enum may use only bits 0..7.
 */
enum {
	MLX4_RESERVE_A0_QP	= 1 << 6,
	MLX4_RESERVE_ETH_BF_QP	= 1 << 7,
};

enum {
	MLX4_DEV_CAP_64B_EQE_ENABLED	= 1LL << 0,
	MLX4_DEV_CAP_64B_CQE_ENABLED	= 1LL << 1,
	MLX4_DEV_CAP_CQE_STRIDE_ENABLED	= 1LL << 2,
	MLX4_DEV_CAP_EQE_STRIDE_ENABLED	= 1LL << 3
};

enum {
	MLX4_USER_DEV_CAP_LARGE_CQE	= 1L << 0
};

enum {
	MLX4_FUNC_CAP_64B_EQE_CQE	= 1L << 0,
	MLX4_FUNC_CAP_EQE_CQE_STRIDE	= 1L << 1,
	MLX4_FUNC_CAP_DMFS_A0_STATIC	= 1L << 2
};


#define MLX4_ATTR_EXTENDED_PORT_INFO	cpu_to_be16(0xff90)

enum {
	MLX4_BMME_FLAG_WIN_TYPE_2B	= 1 <<  1,
	MLX4_BMME_FLAG_LOCAL_INV	= 1 <<  6,
	MLX4_BMME_FLAG_REMOTE_INV	= 1 <<  7,
	MLX4_BMME_FLAG_TYPE_2_WIN	= 1 <<  9,
	MLX4_BMME_FLAG_RESERVED_LKEY	= 1 << 10,
	MLX4_BMME_FLAG_FAST_REG_WR	= 1 << 11,
	MLX4_BMME_FLAG_ROCE_V1_V2	= 1 << 19,
	MLX4_BMME_FLAG_PORT_REMAP	= 1 << 24,
	MLX4_BMME_FLAG_VSD_INIT2RTR	= 1 << 28,
};

enum {
	MLX4_FLAG_PORT_REMAP		= MLX4_BMME_FLAG_PORT_REMAP,
	MLX4_FLAG_ROCE_V1_V2		= MLX4_BMME_FLAG_ROCE_V1_V2
};

enum mlx4_event {
	MLX4_EVENT_TYPE_COMP		   = 0x00,
	MLX4_EVENT_TYPE_PATH_MIG	   = 0x01,
	MLX4_EVENT_TYPE_COMM_EST	   = 0x02,
	MLX4_EVENT_TYPE_SQ_DRAINED	   = 0x03,
	MLX4_EVENT_TYPE_SRQ_QP_LAST_WQE	   = 0x13,
	MLX4_EVENT_TYPE_SRQ_LIMIT	   = 0x14,
	MLX4_EVENT_TYPE_CQ_ERROR	   = 0x04,
	MLX4_EVENT_TYPE_WQ_CATAS_ERROR	   = 0x05,
	MLX4_EVENT_TYPE_EEC_CATAS_ERROR	   = 0x06,
	MLX4_EVENT_TYPE_PATH_MIG_FAILED	   = 0x07,
	MLX4_EVENT_TYPE_WQ_INVAL_REQ_ERROR = 0x10,
	MLX4_EVENT_TYPE_WQ_ACCESS_ERROR	   = 0x11,
	MLX4_EVENT_TYPE_SRQ_CATAS_ERROR	   = 0x12,
	MLX4_EVENT_TYPE_LOCAL_CATAS_ERROR  = 0x08,
	MLX4_EVENT_TYPE_PORT_CHANGE	   = 0x09,
	MLX4_EVENT_TYPE_EQ_OVERFLOW	   = 0x0f,
	MLX4_EVENT_TYPE_ECC_DETECT	   = 0x0e,
	MLX4_EVENT_TYPE_CMD		   = 0x0a,
	MLX4_EVENT_TYPE_VEP_UPDATE	   = 0x19,
	MLX4_EVENT_TYPE_COMM_CHANNEL	   = 0x18,
	MLX4_EVENT_TYPE_OP_REQUIRED	   = 0x1a,
	MLX4_EVENT_TYPE_FATAL_WARNING	   = 0x1b,
	MLX4_EVENT_TYPE_FLR_EVENT	   = 0x1c,
	MLX4_EVENT_TYPE_PORT_MNG_CHG_EVENT = 0x1d,
	MLX4_EVENT_TYPE_RECOVERABLE_ERROR_EVENT  = 0x3e,
	MLX4_EVENT_TYPE_NONE		   = 0xff,
};

enum {
	MLX4_PORT_CHANGE_SUBTYPE_DOWN	= 1,
	MLX4_PORT_CHANGE_SUBTYPE_ACTIVE	= 4
};

enum {
	MLX4_RECOVERABLE_ERROR_EVENT_SUBTYPE_BAD_CABLE		= 1,
	MLX4_RECOVERABLE_ERROR_EVENT_SUBTYPE_UNSUPPORTED_CABLE	= 2,
};

enum {
	MLX4_FATAL_WARNING_SUBTYPE_WARMING = 0,
};

enum slave_port_state {
	SLAVE_PORT_DOWN = 0,
	SLAVE_PENDING_UP,
	SLAVE_PORT_UP,
};

enum slave_port_gen_event {
	SLAVE_PORT_GEN_EVENT_DOWN = 0,
	SLAVE_PORT_GEN_EVENT_UP,
	SLAVE_PORT_GEN_EVENT_NONE,
};

enum slave_port_state_event {
	MLX4_PORT_STATE_DEV_EVENT_PORT_DOWN,
	MLX4_PORT_STATE_DEV_EVENT_PORT_UP,
	MLX4_PORT_STATE_IB_PORT_STATE_EVENT_GID_VALID,
	MLX4_PORT_STATE_IB_EVENT_GID_INVALID,
};

enum {
	MLX4_PERM_LOCAL_READ	= 1 << 10,
	MLX4_PERM_LOCAL_WRITE	= 1 << 11,
	MLX4_PERM_REMOTE_READ	= 1 << 12,
	MLX4_PERM_REMOTE_WRITE	= 1 << 13,
	MLX4_PERM_ATOMIC	= 1 << 14,
	MLX4_PERM_BIND_MW	= 1 << 15,
	MLX4_PERM_MASK		= 0xFC00
};

enum {
	MLX4_OPCODE_NOP			= 0x00,
	MLX4_OPCODE_SEND_INVAL		= 0x01,
	MLX4_OPCODE_RDMA_WRITE		= 0x08,
	MLX4_OPCODE_RDMA_WRITE_IMM	= 0x09,
	MLX4_OPCODE_SEND		= 0x0a,
	MLX4_OPCODE_SEND_IMM		= 0x0b,
	MLX4_OPCODE_LSO			= 0x0e,
	MLX4_OPCODE_RDMA_READ		= 0x10,
	MLX4_OPCODE_ATOMIC_CS		= 0x11,
	MLX4_OPCODE_ATOMIC_FA		= 0x12,
	MLX4_OPCODE_MASKED_ATOMIC_CS	= 0x14,
	MLX4_OPCODE_MASKED_ATOMIC_FA	= 0x15,
	MLX4_OPCODE_BIND_MW		= 0x18,
	MLX4_OPCODE_FMR			= 0x19,
	MLX4_OPCODE_LOCAL_INVAL		= 0x1b,
	MLX4_OPCODE_CONFIG_CMD		= 0x1f,

	MLX4_RECV_OPCODE_RDMA_WRITE_IMM	= 0x00,
	MLX4_RECV_OPCODE_SEND		= 0x01,
	MLX4_RECV_OPCODE_SEND_IMM	= 0x02,
	MLX4_RECV_OPCODE_SEND_INVAL	= 0x03,

	MLX4_CQE_OPCODE_ERROR		= 0x1e,
	MLX4_CQE_OPCODE_RESIZE		= 0x16,
};

enum {
	MLX4_STAT_RATE_OFFSET	= 5
};

enum mlx4_protocol {
	MLX4_PROT_IB_IPV6 = 0,
	MLX4_PROT_ETH,
	MLX4_PROT_IB_IPV4,
	MLX4_PROT_FCOE
};

enum {
	MLX4_MTT_FLAG_PRESENT		= 1
};

enum mlx4_qp_region {
	MLX4_QP_REGION_FW = 0,
	MLX4_QP_REGION_RSS_RAW_ETH,
	MLX4_QP_REGION_BOTTOM = MLX4_QP_REGION_RSS_RAW_ETH,
	MLX4_QP_REGION_ETH_ADDR,
	MLX4_QP_REGION_FC_ADDR,
	MLX4_QP_REGION_FC_EXCH,
	MLX4_NUM_QP_REGION
};

enum mlx4_port_type {
	MLX4_PORT_TYPE_NONE	= 0,
	MLX4_PORT_TYPE_IB	= 1,
	MLX4_PORT_TYPE_ETH	= 2,
	MLX4_PORT_TYPE_AUTO	= 3
};

enum mlx4_special_vlan_idx {
	MLX4_NO_VLAN_IDX        = 0,
	MLX4_VLAN_MISS_IDX,
	MLX4_VLAN_REGULAR
};

enum mlx4_steer_type {
	MLX4_MC_STEER = 0,
	MLX4_UC_STEER,
	MLX4_NUM_STEERS
};

enum {
	MLX4_NUM_FEXCH          = 64 * 1024,
};

enum {
	MLX4_MAX_FAST_REG_PAGES = 511,
};

enum {
	/*
	 * Max wqe size for rdma read is 512 bytes, so this
	 * limits our max_sge_rd as the wqe needs to fit:
	 * - ctrl segment (16 bytes)
	 * - rdma segment (16 bytes)
	 * - scatter elements (16 bytes each)
	 */
	MLX4_MAX_SGE_RD	= (512 - 16 - 16) / 16
};

enum {
	MLX4_DEV_PMC_SUBTYPE_GUID_INFO	 = 0x14,
	MLX4_DEV_PMC_SUBTYPE_PORT_INFO	 = 0x15,
	MLX4_DEV_PMC_SUBTYPE_PKEY_TABLE	 = 0x16,
	MLX4_DEV_PMC_SUBTYPE_SL_TO_VL_MAP = 0x17,
};

/* Port mgmt change event handling */
enum {
	MLX4_EQ_PORT_INFO_MSTR_SM_LID_CHANGE_MASK	= 1 << 0,
	MLX4_EQ_PORT_INFO_GID_PFX_CHANGE_MASK		= 1 << 1,
	MLX4_EQ_PORT_INFO_LID_CHANGE_MASK		= 1 << 2,
	MLX4_EQ_PORT_INFO_CLIENT_REREG_MASK		= 1 << 3,
	MLX4_EQ_PORT_INFO_MSTR_SM_SL_CHANGE_MASK	= 1 << 4,
};

union sl2vl_tbl_to_u64 {
	u8	sl8[8];
	u64	sl64;
};

enum {
	MLX4_DEVICE_STATE_UP			= 1 << 0,
	MLX4_DEVICE_STATE_INTERNAL_ERROR	= 1 << 1,
};

enum {
	MLX4_INTERFACE_STATE_UP		= 1 << 0,
	MLX4_INTERFACE_STATE_DELETION	= 1 << 1,
	MLX4_INTERFACE_STATE_NOWAIT	= 1 << 2,
};

#define MSTR_SM_CHANGE_MASK (MLX4_EQ_PORT_INFO_MSTR_SM_SL_CHANGE_MASK | \
			     MLX4_EQ_PORT_INFO_MSTR_SM_LID_CHANGE_MASK)

enum mlx4_module_id {
	MLX4_MODULE_ID_SFP              = 0x3,
	MLX4_MODULE_ID_QSFP             = 0xC,
	MLX4_MODULE_ID_QSFP_PLUS        = 0xD,
	MLX4_MODULE_ID_QSFP28           = 0x11,
};

enum { /* rl */
	MLX4_QP_RATE_LIMIT_NONE		= 0,
	MLX4_QP_RATE_LIMIT_KBS		= 1,
	MLX4_QP_RATE_LIMIT_MBS		= 2,
	MLX4_QP_RATE_LIMIT_GBS		= 3
};

struct mlx4_rate_limit_caps {
	u16	num_rates; /* Number of different rates */
	u8	min_unit;
	u16	min_val;
	u8	max_unit;
	u16	max_val;
};

static inline u64 mlx4_fw_ver(u64 major, u64 minor, u64 subminor)
{
	return (major << 32) | (minor << 16) | subminor;
}

struct mlx4_phys_caps {
	u32			gid_phys_table_len[MLX4_MAX_PORTS + 1];
	u32			pkey_phys_table_len[MLX4_MAX_PORTS + 1];
	u32			num_phys_eqs;
	u32			base_sqpn;
	u32			base_proxy_sqpn;
	u32			base_tunnel_sqpn;
};

struct mlx4_caps {
	u64			fw_ver;
	u32			function;
	int			num_ports;
	int			vl_cap[MLX4_MAX_PORTS + 1];
	int			ib_mtu_cap[MLX4_MAX_PORTS + 1];
	__be32			ib_port_def_cap[MLX4_MAX_PORTS + 1];
	u64			def_mac[MLX4_MAX_PORTS + 1];
	int			eth_mtu_cap[MLX4_MAX_PORTS + 1];
	int			gid_table_len[MLX4_MAX_PORTS + 1];
	int			pkey_table_len[MLX4_MAX_PORTS + 1];
	int			trans_type[MLX4_MAX_PORTS + 1];
	int			vendor_oui[MLX4_MAX_PORTS + 1];
	int			wavelength[MLX4_MAX_PORTS + 1];
	u64			trans_code[MLX4_MAX_PORTS + 1];
	int			local_ca_ack_delay;
	int			num_uars;
	u32			uar_page_size;
	int			bf_reg_size;
	int			bf_regs_per_page;
	int			max_sq_sg;
	int			max_rq_sg;
	int			num_qps;
	int			max_wqes;
	int			max_sq_desc_sz;
	int			max_rq_desc_sz;
	int			max_qp_init_rdma;
	int			max_qp_dest_rdma;
	int			max_tc_eth;
	u32			*qp0_qkey;
	u32			*qp0_proxy;
	u32			*qp1_proxy;
	u32			*qp0_tunnel;
	u32			*qp1_tunnel;
	int			num_srqs;
	int			max_srq_wqes;
	int			max_srq_sge;
	int			reserved_srqs;
	int			num_cqs;
	int			max_cqes;
	int			reserved_cqs;
	int			num_sys_eqs;
	int			num_eqs;
	int			reserved_eqs;
	int			num_comp_vectors;
	int			num_mpts;
	int			max_fmr_maps;
	int			num_mtts;
	int			fmr_reserved_mtts;
	int			reserved_mtts;
	int			reserved_mrws;
	int			reserved_uars;
	int			num_mgms;
	int			num_amgms;
	int			reserved_mcgs;
	int			num_qp_per_mgm;
	int			steering_mode;
	int			dmfs_high_steer_mode;
	int			fs_log_max_ucast_qp_range_size;
	int			num_pds;
	int			reserved_pds;
	int			max_xrcds;
	int			reserved_xrcds;
	int			mtt_entry_sz;
	u32			max_msg_sz;
	u32			page_size_cap;
	u64			flags;
	u64			flags2;
	u32			bmme_flags;
	u32			reserved_lkey;
	u16			stat_rate_support;
	u8			port_width_cap[MLX4_MAX_PORTS + 1];
	int			max_gso_sz;
	int			max_rss_tbl_sz;
	int                     reserved_qps_cnt[MLX4_NUM_QP_REGION];
	int			reserved_qps;
	int                     reserved_qps_base[MLX4_NUM_QP_REGION];
	int                     log_num_macs;
	int                     log_num_vlans;
	enum mlx4_port_type	port_type[MLX4_MAX_PORTS + 1];
	u8			supported_type[MLX4_MAX_PORTS + 1];
	u8                      suggested_type[MLX4_MAX_PORTS + 1];
	u8                      default_sense[MLX4_MAX_PORTS + 1];
	u32			port_mask[MLX4_MAX_PORTS + 1];
	enum mlx4_port_type	possible_type[MLX4_MAX_PORTS + 1];
	u32			max_counters;
	u8			port_ib_mtu[MLX4_MAX_PORTS + 1];
	u16			sqp_demux;
	u32			eqe_size;
	u32			cqe_size;
	u8			eqe_factor;
	u32			userspace_caps; /* userspace must be aware of these */
	u32			function_caps;  /* VFs must be aware of these */
	u16			hca_core_clock;
	u64			phys_port_id[MLX4_MAX_PORTS + 1];
	int			tunnel_offload_mode;
	u8			rx_checksum_flags_port[MLX4_MAX_PORTS + 1];
	u8			phv_bit[MLX4_MAX_PORTS + 1];
	u8			alloc_res_qp_mask;
	u32			dmfs_high_rate_qpn_base;
	u32			dmfs_high_rate_qpn_range;
	u32			vf_caps;
	struct mlx4_rate_limit_caps rl_caps;
};

struct mlx4_buf_list {
	void		       *buf;
	dma_addr_t		map;
};

struct mlx4_buf {
	struct mlx4_buf_list	direct;
	struct mlx4_buf_list   *page_list;
	int			nbufs;
	int			npages;
	int			page_shift;
};

struct mlx4_mtt {
	u32			offset;
	int			order;
	int			page_shift;
};

enum {
	MLX4_DB_PER_PAGE = PAGE_SIZE / 4
};

struct mlx4_db_pgdir {
	struct list_head	list;
	DECLARE_BITMAP(order0, MLX4_DB_PER_PAGE);
	DECLARE_BITMAP(order1, MLX4_DB_PER_PAGE / 2);
	unsigned long	       *bits[2];
	__be32		       *db_page;
	dma_addr_t		db_dma;
};

struct mlx4_ib_user_db_page;

struct mlx4_db {
	__be32			*db;
	union {
		struct mlx4_db_pgdir		*pgdir;
		struct mlx4_ib_user_db_page	*user_page;
	}			u;
	dma_addr_t		dma;
	int			index;
	int			order;
};

struct mlx4_hwq_resources {
	struct mlx4_db		db;
	struct mlx4_mtt		mtt;
	struct mlx4_buf		buf;
};

struct mlx4_mr {
	struct mlx4_mtt		mtt;
	u64			iova;
	u64			size;
	u32			key;
	u32			pd;
	u32			access;
	int			enabled;
};

enum mlx4_mw_type {
	MLX4_MW_TYPE_1 = 1,
	MLX4_MW_TYPE_2 = 2,
};

struct mlx4_mw {
	u32			key;
	u32			pd;
	enum mlx4_mw_type	type;
	int			enabled;
};

struct mlx4_fmr {
	struct mlx4_mr		mr;
	struct mlx4_mpt_entry  *mpt;
	__be64		       *mtts;
	dma_addr_t		dma_handle;
	int			max_pages;
	int			max_maps;
	int			maps;
	u8			page_shift;
};

struct mlx4_uar {
	unsigned long		pfn;
	int			index;
	struct list_head	bf_list;
	unsigned		free_bf_bmap;
	void __iomem	       *map;
	void __iomem	       *bf_map;
};

struct mlx4_bf {
	unsigned int		offset;
	int			buf_size;
	struct mlx4_uar	       *uar;
	void __iomem	       *reg;
};

struct mlx4_cq {
	void (*comp)		(struct mlx4_cq *);
	void (*event)		(struct mlx4_cq *, enum mlx4_event);

	struct mlx4_uar	       *uar;

	u32			cons_index;

	u16                     irq;
	__be32		       *set_ci_db;
	__be32		       *arm_db;
	int			arm_sn;

	int			cqn;
	unsigned		vector;

	atomic_t		refcount;
	struct completion	free;
	struct {
		struct list_head list;
		void (*comp)(struct mlx4_cq *);
		void		*priv;
	} tasklet_ctx;
	int		reset_notify_added;
	struct list_head	reset_notify;
};

struct mlx4_qp {
	void (*event)		(struct mlx4_qp *, enum mlx4_event);

	int			qpn;

	atomic_t		refcount;
	struct completion	free;
};

struct mlx4_srq {
	void (*event)		(struct mlx4_srq *, enum mlx4_event);

	int			srqn;
	int			max;
	int			max_gs;
	int			wqe_shift;

	atomic_t		refcount;
	struct completion	free;
};

struct mlx4_av {
	__be32			port_pd;
	u8			reserved1;
	u8			g_slid;
	__be16			dlid;
	u8			reserved2;
	u8			gid_index;
	u8			stat_rate;
	u8			hop_limit;
	__be32			sl_tclass_flowlabel;
	u8			dgid[16];
};

struct mlx4_eth_av {
	__be32		port_pd;
	u8		reserved1;
	u8		smac_idx;
	u16		reserved2;
	u8		reserved3;
	u8		gid_index;
	u8		stat_rate;
	u8		hop_limit;
	__be32		sl_tclass_flowlabel;
	u8		dgid[16];
	u8		s_mac[6];
	u8		reserved4[2];
	__be16		vlan;
	u8		mac[ETH_ALEN];
};

union mlx4_ext_av {
	struct mlx4_av		ib;
	struct mlx4_eth_av	eth;
};

/* Counters should be saturate once they reach their maximum value */
#define ASSIGN_32BIT_COUNTER(counter, value) do {	\
	if ((value) > U32_MAX)				\
		counter = cpu_to_be32(U32_MAX);		\
	else						\
		counter = cpu_to_be32(value);		\
} while (0)

struct mlx4_counter {
	u8	reserved1[3];
	u8	counter_mode;
	__be32	num_ifc;
	u32	reserved2[2];
	__be64	rx_frames;
	__be64	rx_bytes;
	__be64	tx_frames;
	__be64	tx_bytes;
};

struct mlx4_quotas {
	int qp;
	int cq;
	int srq;
	int mpt;
	int mtt;
	int counter;
	int xrcd;
};

struct mlx4_vf_dev {
	u8			min_port;
	u8			n_ports;
};

enum mlx4_pci_status {
	MLX4_PCI_STATUS_DISABLED,
	MLX4_PCI_STATUS_ENABLED,
};

struct mlx4_dev_persistent {
	struct pci_dev	       *pdev;
	struct mlx4_dev	       *dev;
	int                     nvfs[MLX4_MAX_PORTS + 1];
	int			num_vfs;
	enum mlx4_port_type curr_port_type[MLX4_MAX_PORTS + 1];
	enum mlx4_port_type curr_port_poss_type[MLX4_MAX_PORTS + 1];
	struct work_struct      catas_work;
	struct workqueue_struct *catas_wq;
	struct mutex	device_state_mutex; /* protect HW state */
	u8		state;
	struct mutex	interface_state_mutex; /* protect SW state */
	u8	interface_state;
	struct mutex		pci_status_mutex; /* sync pci state */
	enum mlx4_pci_status	pci_status;
};

struct mlx4_dev {
	struct mlx4_dev_persistent *persist;
	unsigned long		flags;
	unsigned long		num_slaves;
	struct mlx4_caps	caps;
	struct mlx4_phys_caps	phys_caps;
	struct mlx4_quotas	quotas;
	struct radix_tree_root	qp_table_tree;
	u8			rev_id;
	u8			port_random_macs;
	char			board_id[MLX4_BOARD_ID_LEN];
	int			numa_node;
	int			oper_log_mgm_entry_size;
	u64			regid_promisc_array[MLX4_MAX_PORTS + 1];
	u64			regid_allmulti_array[MLX4_MAX_PORTS + 1];
	struct mlx4_vf_dev     *dev_vfs;
	u8  uar_page_shift;
};

struct mlx4_clock_params {
	u64 offset;
	u8 bar;
	u8 size;
};

struct mlx4_eqe {
	u8			reserved1;
	u8			type;
	u8			reserved2;
	u8			subtype;
	union {
		u32		raw[6];
		struct {
			__be32	cqn;
		} __packed comp;
		struct {
			u16	reserved1;
			__be16	token;
			u32	reserved2;
			u8	reserved3[3];
			u8	status;
			__be64	out_param;
		} __packed cmd;
		struct {
			__be32	qpn;
		} __packed qp;
		struct {
			__be32	srqn;
		} __packed srq;
		struct {
			__be32	cqn;
			u32	reserved1;
			u8	reserved2[3];
			u8	syndrome;
		} __packed cq_err;
		struct {
			u32	reserved1[2];
			__be32	port;
		} __packed port_change;
		struct {
			#define COMM_CHANNEL_BIT_ARRAY_SIZE	4
			u32 reserved;
			u32 bit_vec[COMM_CHANNEL_BIT_ARRAY_SIZE];
		} __packed comm_channel_arm;
		struct {
			u8	port;
			u8	reserved[3];
			__be64	mac;
		} __packed mac_update;
		struct {
			__be32	slave_id;
		} __packed flr_event;
		struct {
			__be16  current_temperature;
			__be16  warning_threshold;
		} __packed warming;
		struct {
			u8 reserved[3];
			u8 port;
			union {
				struct {
					__be16 mstr_sm_lid;
					__be16 port_lid;
					__be32 changed_attr;
					u8 reserved[3];
					u8 mstr_sm_sl;
					__be64 gid_prefix;
				} __packed port_info;
				struct {
					__be32 block_ptr;
					__be32 tbl_entries_mask;
				} __packed tbl_change_info;
				struct {
					u8 sl2vl_table[8];
				} __packed sl2vl_tbl_change_info;
			} params;
		} __packed port_mgmt_change;
		struct {
			u8 reserved[3];
			u8 port;
			u32 reserved1[5];
		} __packed bad_cable;
	}			event;
	u8			slave_id;
	u8			reserved3[2];
	u8			owner;
} __packed;

struct mlx4_init_port_param {
	int			set_guid0;
	int			set_node_guid;
	int			set_si_guid;
	u16			mtu;
	int			port_width_cap;
	u16			vl_cap;
	u16			max_gid;
	u16			max_pkey;
	u64			guid0;
	u64			node_guid;
	u64			si_guid;
};

#define MAD_IFC_DATA_SZ 192
/* MAD IFC Mailbox */
struct mlx4_mad_ifc {
	u8	base_version;
	u8	mgmt_class;
	u8	class_version;
	u8	method;
	__be16	status;
	__be16	class_specific;
	__be64	tid;
	__be16	attr_id;
	__be16	resv;
	__be32	attr_mod;
	__be64	mkey;
	__be16	dr_slid;
	__be16	dr_dlid;
	u8	reserved[28];
	u8	data[MAD_IFC_DATA_SZ];
} __packed;

#define mlx4_foreach_port(port, dev, type)				\
	for ((port) = 1; (port) <= (dev)->caps.num_ports; (port)++)	\
		if ((type) == (dev)->caps.port_mask[(port)])

#define mlx4_foreach_ib_transport_port(port, dev)                         \
	for ((port) = 1; (port) <= (dev)->caps.num_ports; (port)++)       \
		if (((dev)->caps.port_mask[port] == MLX4_PORT_TYPE_IB) || \
			((dev)->caps.flags & MLX4_DEV_CAP_FLAG_IBOE) || \
			((dev)->caps.flags2 & MLX4_DEV_CAP_FLAG2_ROCE_V1_V2))

#define MLX4_INVALID_SLAVE_ID	0xFF
#define MLX4_SINK_COUNTER_INDEX(dev)	(dev->caps.max_counters - 1)

void handle_port_mgmt_change_event(struct work_struct *work);

static inline int mlx4_master_func_num(struct mlx4_dev *dev)
{
	return dev->caps.function;
}

static inline int mlx4_is_master(struct mlx4_dev *dev)
{
	return dev->flags & MLX4_FLAG_MASTER;
}

static inline int mlx4_num_reserved_sqps(struct mlx4_dev *dev)
{
	return dev->phys_caps.base_sqpn + 8 +
		16 * MLX4_MFUNC_MAX * !!mlx4_is_master(dev);
}

static inline int mlx4_is_qp_reserved(struct mlx4_dev *dev, u32 qpn)
{
	return (qpn < dev->phys_caps.base_sqpn + 8 +
		16 * MLX4_MFUNC_MAX * !!mlx4_is_master(dev) &&
		qpn >= dev->phys_caps.base_sqpn) ||
	       (qpn < dev->caps.reserved_qps_cnt[MLX4_QP_REGION_FW]);
}

static inline int mlx4_is_guest_proxy(struct mlx4_dev *dev, int slave, u32 qpn)
{
	int guest_proxy_base = dev->phys_caps.base_proxy_sqpn + slave * 8;

	if (qpn >= guest_proxy_base && qpn < guest_proxy_base + 8)
		return 1;

	return 0;
}

static inline int mlx4_is_mfunc(struct mlx4_dev *dev)
{
	return dev->flags & (MLX4_FLAG_SLAVE | MLX4_FLAG_MASTER);
}

static inline int mlx4_is_slave(struct mlx4_dev *dev)
{
	return dev->flags & MLX4_FLAG_SLAVE;
}

static inline int mlx4_is_eth(struct mlx4_dev *dev, int port)
{
	return dev->caps.port_type[port] == MLX4_PORT_TYPE_IB ? 0 : 1;
}

int mlx4_buf_alloc(struct mlx4_dev *dev, int size, int max_direct,
		   struct mlx4_buf *buf, gfp_t gfp);
void mlx4_buf_free(struct mlx4_dev *dev, int size, struct mlx4_buf *buf);
static inline void *mlx4_buf_offset(struct mlx4_buf *buf, int offset)
{
	if (buf->nbufs == 1)
		return buf->direct.buf + offset;
	else
		return buf->page_list[offset >> PAGE_SHIFT].buf +
			(offset & (PAGE_SIZE - 1));
}

int mlx4_pd_alloc(struct mlx4_dev *dev, u32 *pdn);
void mlx4_pd_free(struct mlx4_dev *dev, u32 pdn);
int mlx4_xrcd_alloc(struct mlx4_dev *dev, u32 *xrcdn);
void mlx4_xrcd_free(struct mlx4_dev *dev, u32 xrcdn);

int mlx4_uar_alloc(struct mlx4_dev *dev, struct mlx4_uar *uar);
void mlx4_uar_free(struct mlx4_dev *dev, struct mlx4_uar *uar);
int mlx4_bf_alloc(struct mlx4_dev *dev, struct mlx4_bf *bf, int node);
void mlx4_bf_free(struct mlx4_dev *dev, struct mlx4_bf *bf);

int mlx4_mtt_init(struct mlx4_dev *dev, int npages, int page_shift,
		  struct mlx4_mtt *mtt);
void mlx4_mtt_cleanup(struct mlx4_dev *dev, struct mlx4_mtt *mtt);
u64 mlx4_mtt_addr(struct mlx4_dev *dev, struct mlx4_mtt *mtt);

int mlx4_mr_alloc(struct mlx4_dev *dev, u32 pd, u64 iova, u64 size, u32 access,
		  int npages, int page_shift, struct mlx4_mr *mr);
int mlx4_mr_free(struct mlx4_dev *dev, struct mlx4_mr *mr);
int mlx4_mr_enable(struct mlx4_dev *dev, struct mlx4_mr *mr);
int mlx4_mw_alloc(struct mlx4_dev *dev, u32 pd, enum mlx4_mw_type type,
		  struct mlx4_mw *mw);
void mlx4_mw_free(struct mlx4_dev *dev, struct mlx4_mw *mw);
int mlx4_mw_enable(struct mlx4_dev *dev, struct mlx4_mw *mw);
int mlx4_write_mtt(struct mlx4_dev *dev, struct mlx4_mtt *mtt,
		   int start_index, int npages, u64 *page_list);
int mlx4_buf_write_mtt(struct mlx4_dev *dev, struct mlx4_mtt *mtt,
		       struct mlx4_buf *buf, gfp_t gfp);

int mlx4_db_alloc(struct mlx4_dev *dev, struct mlx4_db *db, int order,
		  gfp_t gfp);
void mlx4_db_free(struct mlx4_dev *dev, struct mlx4_db *db);

int mlx4_alloc_hwq_res(struct mlx4_dev *dev, struct mlx4_hwq_resources *wqres,
		       int size);
void mlx4_free_hwq_res(struct mlx4_dev *mdev, struct mlx4_hwq_resources *wqres,
		       int size);

int mlx4_cq_alloc(struct mlx4_dev *dev, int nent, struct mlx4_mtt *mtt,
		  struct mlx4_uar *uar, u64 db_rec, struct mlx4_cq *cq,
		  unsigned vector, int collapsed, int timestamp_en);
void mlx4_cq_free(struct mlx4_dev *dev, struct mlx4_cq *cq);
int mlx4_qp_reserve_range(struct mlx4_dev *dev, int cnt, int align,
			  int *base, u8 flags);
void mlx4_qp_release_range(struct mlx4_dev *dev, int base_qpn, int cnt);

int mlx4_qp_alloc(struct mlx4_dev *dev, int qpn, struct mlx4_qp *qp,
		  gfp_t gfp);
void mlx4_qp_free(struct mlx4_dev *dev, struct mlx4_qp *qp);

int mlx4_srq_alloc(struct mlx4_dev *dev, u32 pdn, u32 cqn, u16 xrcdn,
		   struct mlx4_mtt *mtt, u64 db_rec, struct mlx4_srq *srq);
void mlx4_srq_free(struct mlx4_dev *dev, struct mlx4_srq *srq);
int mlx4_srq_arm(struct mlx4_dev *dev, struct mlx4_srq *srq, int limit_watermark);
int mlx4_srq_query(struct mlx4_dev *dev, struct mlx4_srq *srq, int *limit_watermark);

int mlx4_INIT_PORT(struct mlx4_dev *dev, int port);
int mlx4_CLOSE_PORT(struct mlx4_dev *dev, int port);

int mlx4_unicast_attach(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],
			int block_mcast_loopback, enum mlx4_protocol prot);
int mlx4_unicast_detach(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],
			enum mlx4_protocol prot);
int mlx4_multicast_attach(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],
			  u8 port, int block_mcast_loopback,
			  enum mlx4_protocol protocol, u64 *reg_id);
int mlx4_multicast_detach(struct mlx4_dev *dev, struct mlx4_qp *qp, u8 gid[16],
			  enum mlx4_protocol protocol, u64 reg_id);

enum {
	MLX4_DOMAIN_UVERBS	= 0x1000,
	MLX4_DOMAIN_ETHTOOL     = 0x2000,
	MLX4_DOMAIN_RFS         = 0x3000,
	MLX4_DOMAIN_NIC    = 0x5000,
};

enum mlx4_net_trans_rule_id {
	MLX4_NET_TRANS_RULE_ID_ETH = 0,
	MLX4_NET_TRANS_RULE_ID_IB,
	MLX4_NET_TRANS_RULE_ID_IPV6,
	MLX4_NET_TRANS_RULE_ID_IPV4,
	MLX4_NET_TRANS_RULE_ID_TCP,
	MLX4_NET_TRANS_RULE_ID_UDP,
	MLX4_NET_TRANS_RULE_ID_VXLAN,
	MLX4_NET_TRANS_RULE_NUM, /* should be last */
};

extern const u16 __sw_id_hw[];

static inline int map_hw_to_sw_id(u16 header_id)
{

	int i;
	for (i = 0; i < MLX4_NET_TRANS_RULE_NUM; i++) {
		if (header_id == __sw_id_hw[i])
			return i;
	}
	return -EINVAL;
}

enum mlx4_net_trans_promisc_mode {
	MLX4_FS_REGULAR = 1,
	MLX4_FS_ALL_DEFAULT,
	MLX4_FS_MC_DEFAULT,
	MLX4_FS_MIRROR_RX_PORT,
	MLX4_FS_MIRROR_SX_PORT,
	MLX4_FS_UC_SNIFFER,
	MLX4_FS_MC_SNIFFER,
	MLX4_FS_MODE_NUM, /* should be last */
};

struct mlx4_spec_eth {
	u8	dst_mac[ETH_ALEN];
	u8	dst_mac_msk[ETH_ALEN];
	u8	src_mac[ETH_ALEN];
	u8	src_mac_msk[ETH_ALEN];
	u8	ether_type_enable;
	__be16	ether_type;
	__be16	vlan_id_msk;
	__be16	vlan_id;
};

struct mlx4_spec_tcp_udp {
	__be16 dst_port;
	__be16 dst_port_msk;
	__be16 src_port;
	__be16 src_port_msk;
};

struct mlx4_spec_ipv4 {
	__be32 dst_ip;
	__be32 dst_ip_msk;
	__be32 src_ip;
	__be32 src_ip_msk;
};

struct mlx4_spec_ib {
	__be32  l3_qpn;
	__be32	qpn_msk;
	u8	dst_gid[16];
	u8	dst_gid_msk[16];
};

struct mlx4_spec_vxlan {
	__be32 vni;
	__be32 vni_mask;

};

struct mlx4_spec_list {
	struct	list_head list;
	enum	mlx4_net_trans_rule_id id;
	union {
		struct mlx4_spec_eth eth;
		struct mlx4_spec_ib ib;
		struct mlx4_spec_ipv4 ipv4;
		struct mlx4_spec_tcp_udp tcp_udp;
		struct mlx4_spec_vxlan vxlan;
	};
};

enum mlx4_net_trans_hw_rule_queue {
	MLX4_NET_TRANS_Q_FIFO,
	MLX4_NET_TRANS_Q_LIFO,
};

struct mlx4_net_trans_rule {
	struct	list_head list;
	enum	mlx4_net_trans_hw_rule_queue queue_mode;
	bool	exclusive;
	bool	allow_loopback;
	enum	mlx4_net_trans_promisc_mode promisc_mode;
	u8	port;
	u16	priority;
	u32	qpn;
};

struct mlx4_net_trans_rule_hw_ctrl {
	__be16 prio;
	u8 type;
	u8 flags;
	u8 rsvd1;
	u8 funcid;
	u8 vep;
	u8 port;
	__be32 qpn;
	__be32 rsvd2;
};

struct mlx4_net_trans_rule_hw_ib {
	u8 size;
	u8 rsvd1;
	__be16 id;
	u32 rsvd2;
	__be32 l3_qpn;
	__be32 qpn_mask;
	u8 dst_gid[16];
	u8 dst_gid_msk[16];
} __packed;

struct mlx4_net_trans_rule_hw_eth {
	u8	size;
	u8	rsvd;
	__be16	id;
	u8	rsvd1[6];
	u8	dst_mac[6];
	u16	rsvd2;
	u8	dst_mac_msk[6];
	u16	rsvd3;
	u8	src_mac[6];
	u16	rsvd4;
	u8	src_mac_msk[6];
	u8      rsvd5;
	u8      ether_type_enable;
	__be16  ether_type;
	__be16  vlan_tag_msk;
	__be16  vlan_tag;
} __packed;

struct mlx4_net_trans_rule_hw_tcp_udp {
	u8	size;
	u8	rsvd;
	__be16	id;
	__be16	rsvd1[3];
	__be16	dst_port;
	__be16	rsvd2;
	__be16	dst_port_msk;
	__be16	rsvd3;
	__be16	src_port;
	__be16	rsvd4;
	__be16	src_port_msk;
} __packed;

struct mlx4_net_trans_rule_hw_ipv4 {
	u8	size;
	u8	rsvd;
	__be16	id;
	__be32	rsvd1;
	__be32	dst_ip;
	__be32	dst_ip_msk;
	__be32	src_ip;
	__be32	src_ip_msk;
} __packed;

struct mlx4_net_trans_rule_hw_vxlan {
	u8	size;
	u8	rsvd;
	__be16	id;
	__be32	rsvd1;
	__be32	vni;
	__be32	vni_mask;
} __packed;

struct _rule_hw {
	union {
		struct {
			u8 size;
			u8 rsvd;
			__be16 id;
		};
		struct mlx4_net_trans_rule_hw_eth eth;
		struct mlx4_net_trans_rule_hw_ib ib;
		struct mlx4_net_trans_rule_hw_ipv4 ipv4;
		struct mlx4_net_trans_rule_hw_tcp_udp tcp_udp;
		struct mlx4_net_trans_rule_hw_vxlan vxlan;
	};
};

enum {
	VXLAN_STEER_BY_OUTER_MAC	= 1 << 0,
	VXLAN_STEER_BY_OUTER_VLAN	= 1 << 1,
	VXLAN_STEER_BY_VSID_VNI		= 1 << 2,
	VXLAN_STEER_BY_INNER_MAC	= 1 << 3,
	VXLAN_STEER_BY_INNER_VLAN	= 1 << 4,
};

enum {
	MLX4_OP_MOD_QUERY_TRANSPORT_CI_ERRORS = 0x2,
};

int mlx4_flow_steer_promisc_add(struct mlx4_dev *dev, u8 port, u32 qpn,
				enum mlx4_net_trans_promisc_mode mode);
int mlx4_flow_steer_promisc_remove(struct mlx4_dev *dev, u8 port,
				   enum mlx4_net_trans_promisc_mode mode);
int mlx4_multicast_promisc_add(struct mlx4_dev *dev, u32 qpn, u8 port);
int mlx4_multicast_promisc_remove(struct mlx4_dev *dev, u32 qpn, u8 port);
int mlx4_unicast_promisc_add(struct mlx4_dev *dev, u32 qpn, u8 port);
int mlx4_unicast_promisc_remove(struct mlx4_dev *dev, u32 qpn, u8 port);
int mlx4_SET_MCAST_FLTR(struct mlx4_dev *dev, u8 port, u64 mac, u64 clear, u8 mode);

int mlx4_register_mac(struct mlx4_dev *dev, u8 port, u64 mac);
void mlx4_unregister_mac(struct mlx4_dev *dev, u8 port, u64 mac);
int mlx4_get_base_qpn(struct mlx4_dev *dev, u8 port);
int __mlx4_replace_mac(struct mlx4_dev *dev, u8 port, int qpn, u64 new_mac);
int mlx4_SET_PORT_general(struct mlx4_dev *dev, u8 port, int mtu,
			  u8 pptx, u8 pfctx, u8 pprx, u8 pfcrx);
int mlx4_SET_PORT_qpn_calc(struct mlx4_dev *dev, u8 port, u32 base_qpn,
			   u8 promisc);
int mlx4_SET_PORT_BEACON(struct mlx4_dev *dev, u8 port, u16 time);
int mlx4_SET_PORT_fcs_check(struct mlx4_dev *dev, u8 port,
			    u8 ignore_fcs_value);
int mlx4_SET_PORT_VXLAN(struct mlx4_dev *dev, u8 port, u8 steering, int enable);
int set_phv_bit(struct mlx4_dev *dev, u8 port, int new_val);
int get_phv_bit(struct mlx4_dev *dev, u8 port, int *phv);
int mlx4_get_is_vlan_offload_disabled(struct mlx4_dev *dev, u8 port,
				      bool *vlan_offload_disabled);
void mlx4_handle_eth_header_mcast_prio(struct mlx4_net_trans_rule_hw_ctrl *ctrl,
				       struct _rule_hw *eth_header);
int mlx4_find_cached_mac(struct mlx4_dev *dev, u8 port, u64 mac, int *idx);
int mlx4_find_cached_vlan(struct mlx4_dev *dev, u8 port, u16 vid, int *idx);
int mlx4_register_vlan(struct mlx4_dev *dev, u8 port, u16 vlan, int *index);
void mlx4_unregister_vlan(struct mlx4_dev *dev, u8 port, u16 vlan);

int mlx4_map_phys_fmr(struct mlx4_dev *dev, struct mlx4_fmr *fmr, u64 *page_list,
		      int npages, u64 iova, u32 *lkey, u32 *rkey);
int mlx4_fmr_alloc(struct mlx4_dev *dev, u32 pd, u32 access, int max_pages,
		   int max_maps, u8 page_shift, struct mlx4_fmr *fmr);
int mlx4_fmr_enable(struct mlx4_dev *dev, struct mlx4_fmr *fmr);
void mlx4_fmr_unmap(struct mlx4_dev *dev, struct mlx4_fmr *fmr,
		    u32 *lkey, u32 *rkey);
int mlx4_fmr_free(struct mlx4_dev *dev, struct mlx4_fmr *fmr);
int mlx4_SYNC_TPT(struct mlx4_dev *dev);
int mlx4_test_interrupt(struct mlx4_dev *dev, int vector);
int mlx4_test_async(struct mlx4_dev *dev);
int mlx4_query_diag_counters(struct mlx4_dev *dev, u8 op_modifier,
			     const u32 offset[], u32 value[],
			     size_t array_len, u8 port);
u32 mlx4_get_eqs_per_port(struct mlx4_dev *dev, u8 port);
bool mlx4_is_eq_vector_valid(struct mlx4_dev *dev, u8 port, int vector);
struct cpu_rmap *mlx4_get_cpu_rmap(struct mlx4_dev *dev, int port);
int mlx4_assign_eq(struct mlx4_dev *dev, u8 port, int *vector);
void mlx4_release_eq(struct mlx4_dev *dev, int vec);

int mlx4_is_eq_shared(struct mlx4_dev *dev, int vector);
int mlx4_eq_get_irq(struct mlx4_dev *dev, int vec);

int mlx4_get_phys_port_id(struct mlx4_dev *dev);
int mlx4_wol_read(struct mlx4_dev *dev, u64 *config, int port);
int mlx4_wol_write(struct mlx4_dev *dev, u64 config, int port);

int mlx4_counter_alloc(struct mlx4_dev *dev, u32 *idx);
void mlx4_counter_free(struct mlx4_dev *dev, u32 idx);
int mlx4_get_default_counter_index(struct mlx4_dev *dev, int port);

void mlx4_set_admin_guid(struct mlx4_dev *dev, __be64 guid, int entry,
			 int port);
__be64 mlx4_get_admin_guid(struct mlx4_dev *dev, int entry, int port);
void mlx4_set_random_admin_guid(struct mlx4_dev *dev, int entry, int port);
int mlx4_flow_attach(struct mlx4_dev *dev,
		     struct mlx4_net_trans_rule *rule, u64 *reg_id);
int mlx4_flow_detach(struct mlx4_dev *dev, u64 reg_id);
int mlx4_map_sw_to_hw_steering_mode(struct mlx4_dev *dev,
				    enum mlx4_net_trans_promisc_mode flow_type);
int mlx4_map_sw_to_hw_steering_id(struct mlx4_dev *dev,
				  enum mlx4_net_trans_rule_id id);
int mlx4_hw_rule_sz(struct mlx4_dev *dev, enum mlx4_net_trans_rule_id id);

int mlx4_tunnel_steer_add(struct mlx4_dev *dev, unsigned char *addr,
			  int port, int qpn, u16 prio, u64 *reg_id);

void mlx4_sync_pkey_table(struct mlx4_dev *dev, int slave, int port,
			  int i, int val);

int mlx4_get_parav_qkey(struct mlx4_dev *dev, u32 qpn, u32 *qkey);

int mlx4_is_slave_active(struct mlx4_dev *dev, int slave);
int mlx4_gen_pkey_eqe(struct mlx4_dev *dev, int slave, u8 port);
int mlx4_gen_guid_change_eqe(struct mlx4_dev *dev, int slave, u8 port);
int mlx4_gen_slaves_port_mgt_ev(struct mlx4_dev *dev, u8 port, int attr);
int mlx4_gen_port_state_change_eqe(struct mlx4_dev *dev, int slave, u8 port, u8 port_subtype_change);
enum slave_port_state mlx4_get_slave_port_state(struct mlx4_dev *dev, int slave, u8 port);
int set_and_calc_slave_port_state(struct mlx4_dev *dev, int slave, u8 port, int event, enum slave_port_gen_event *gen_event);

void mlx4_put_slave_node_guid(struct mlx4_dev *dev, int slave, __be64 guid);
__be64 mlx4_get_slave_node_guid(struct mlx4_dev *dev, int slave);

int mlx4_get_slave_from_roce_gid(struct mlx4_dev *dev, int port, u8 *gid,
				 int *slave_id);
int mlx4_get_roce_gid_from_slave(struct mlx4_dev *dev, int port, int slave_id,
				 u8 *gid);

int mlx4_FLOW_STEERING_IB_UC_QP_RANGE(struct mlx4_dev *dev, u32 min_range_qpn,
				      u32 max_range_qpn);

cycle_t mlx4_read_clock(struct mlx4_dev *dev);

struct mlx4_active_ports {
	DECLARE_BITMAP(ports, MLX4_MAX_PORTS);
};
/* Returns a bitmap of the physical ports which are assigned to slave */
struct mlx4_active_ports mlx4_get_active_ports(struct mlx4_dev *dev, int slave);

/* Returns the physical port that represents the virtual port of the slave, */
/* or a value < 0 in case of an error. If a slave has 2 ports, the identity */
/* mapping is returned.							    */
int mlx4_slave_convert_port(struct mlx4_dev *dev, int slave, int port);

struct mlx4_slaves_pport {
	DECLARE_BITMAP(slaves, MLX4_MFUNC_MAX);
};
/* Returns a bitmap of all slaves that are assigned to port. */
struct mlx4_slaves_pport mlx4_phys_to_slaves_pport(struct mlx4_dev *dev,
						   int port);

/* Returns a bitmap of all slaves that are assigned exactly to all the */
/* the ports that are set in crit_ports.			       */
struct mlx4_slaves_pport mlx4_phys_to_slaves_pport_actv(
		struct mlx4_dev *dev,
		const struct mlx4_active_ports *crit_ports);

/* Returns the slave's virtual port that represents the physical port. */
int mlx4_phys_to_slave_port(struct mlx4_dev *dev, int slave, int port);

int mlx4_get_base_gid_ix(struct mlx4_dev *dev, int slave, int port);

int mlx4_config_vxlan_port(struct mlx4_dev *dev, __be16 udp_port);
int mlx4_disable_rx_port_check(struct mlx4_dev *dev, bool dis);
int mlx4_config_roce_v2_port(struct mlx4_dev *dev, u16 udp_port);
int mlx4_virt2phy_port_map(struct mlx4_dev *dev, u32 port1, u32 port2);
int mlx4_vf_smi_enabled(struct mlx4_dev *dev, int slave, int port);
int mlx4_vf_get_enable_smi_admin(struct mlx4_dev *dev, int slave, int port);
int mlx4_vf_set_enable_smi_admin(struct mlx4_dev *dev, int slave, int port,
				 int enable);
int mlx4_mr_hw_get_mpt(struct mlx4_dev *dev, struct mlx4_mr *mmr,
		       struct mlx4_mpt_entry ***mpt_entry);
int mlx4_mr_hw_write_mpt(struct mlx4_dev *dev, struct mlx4_mr *mmr,
			 struct mlx4_mpt_entry **mpt_entry);
int mlx4_mr_hw_change_pd(struct mlx4_dev *dev, struct mlx4_mpt_entry *mpt_entry,
			 u32 pdn);
int mlx4_mr_hw_change_access(struct mlx4_dev *dev,
			     struct mlx4_mpt_entry *mpt_entry,
			     u32 access);
void mlx4_mr_hw_put_mpt(struct mlx4_dev *dev,
			struct mlx4_mpt_entry **mpt_entry);
void mlx4_mr_rereg_mem_cleanup(struct mlx4_dev *dev, struct mlx4_mr *mr);
int mlx4_mr_rereg_mem_write(struct mlx4_dev *dev, struct mlx4_mr *mr,
			    u64 iova, u64 size, int npages,
			    int page_shift, struct mlx4_mpt_entry *mpt_entry);

int mlx4_get_module_info(struct mlx4_dev *dev, u8 port,
			 u16 offset, u16 size, u8 *data);
int mlx4_max_tc(struct mlx4_dev *dev);

/* Returns true if running in low memory profile (kdump kernel) */
static inline bool mlx4_low_memory_profile(void)
{
	return is_kdump_kernel();
}

/* ACCESS REG commands */
enum mlx4_access_reg_method {
	MLX4_ACCESS_REG_QUERY = 0x1,
	MLX4_ACCESS_REG_WRITE = 0x2,
};

/* ACCESS PTYS Reg command */
enum mlx4_ptys_proto {
	MLX4_PTYS_IB = 1<<0,
	MLX4_PTYS_EN = 1<<2,
};

struct mlx4_ptys_reg {
	u8 resrvd1;
	u8 local_port;
	u8 resrvd2;
	u8 proto_mask;
	__be32 resrvd3[2];
	__be32 eth_proto_cap;
	__be16 ib_width_cap;
	__be16 ib_speed_cap;
	__be32 resrvd4;
	__be32 eth_proto_admin;
	__be16 ib_width_admin;
	__be16 ib_speed_admin;
	__be32 resrvd5;
	__be32 eth_proto_oper;
	__be16 ib_width_oper;
	__be16 ib_speed_oper;
	__be32 resrvd6;
	__be32 eth_proto_lp_adv;
} __packed;

int mlx4_ACCESS_PTYS_REG(struct mlx4_dev *dev,
			 enum mlx4_access_reg_method method,
			 struct mlx4_ptys_reg *ptys_reg);

int mlx4_get_internal_clock_params(struct mlx4_dev *dev,
				   struct mlx4_clock_params *params);

static inline int mlx4_to_hw_uar_index(struct mlx4_dev *dev, int index)
{
	return (index << (PAGE_SHIFT - dev->uar_page_shift));
}

static inline int mlx4_get_num_reserved_uar(struct mlx4_dev *dev)
{
	/* The first 128 UARs are used for EQ doorbells */
	return (128 >> (PAGE_SHIFT - dev->uar_page_shift));
}
#endif /* MLX4_DEVICE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    #ifndef __LINUX_COMPILER_H
#define __LINUX_COMPILER_H

#ifndef __ASSEMBLY__

#ifdef __CHECKER__
# define __user		__attribute__((noderef, address_space(1)))
# define __kernel	__attribute__((address_space(0)))
# define __safe		__attribute__((safe))
# define __force	__attribute__((force))
# define __nocast	__attribute__((nocast))
# define __iomem	__attribute__((noderef, address_space(2)))
# define __must_hold(x)	__attribute__((context(x,1,1)))
# define __acquires(x)	__attribute__((context(x,0,1)))
# define __releases(x)	__attribute__((context(x,1,0)))
# define __acquire(x)	__context__(x,1)
# define __release(x)	__context__(x,-1)
# define __cond_lock(x,c)	((c) ? ({ __acquire(x); 1; }) : 0)
# define __percpu	__attribute__((noderef, address_space(3)))
#ifdef CONFIG_SPARSE_RCU_POINTER
# define __rcu		__attribute__((noderef, address_space(4)))
#else /* CONFIG_SPARSE_RCU_POINTER */
# define __rcu
#endif /* CONFIG_SPARSE_RCU_POINTER */
# define __private	__attribute__((noderef))
extern void __chk_user_ptr(const volatile void __user *);
extern void __chk_io_ptr(const volatile void __iomem *);
# define ACCESS_PRIVATE(p, member) (*((typeof((p)->member) __force *) &(p)->member))
#else /* __CHECKER__ */
# define __user
# define __kernel
# define __safe
# define __force
# define __nocast
# define __iomem
# define __chk_user_ptr(x) (void)0
# define __chk_io_ptr(x) (void)0
# define __builtin_warning(x, y...) (1)
# define __must_hold(x)
# define __acquires(x)
# define __releases(x)
# define __acquire(x) (void)0
# define __release(x) (void)0
# define __cond_lock(x,c) (c)
# define __percpu
# define __rcu
# define __private
# define ACCESS_PRIVATE(p, member) ((p)->member)
#endif /* __CHECKER__ */

/* Indirect macros required for expanded argument pasting, eg. __LINE__. */
#define ___PASTE(a,b) a##b
#define __PASTE(a,b) ___PASTE(a,b)

#ifdef __KERNEL__

#ifdef __GNUC__
#include <linux/compiler-gcc.h>
#endif

#if defined(CC_USING_HOTPATCH) && !defined(__CHECKER__)
#define notrace __attribute__((hotpatch(0,0)))
#else
#define notrace __attribute__((no_instrument_function))
#endif

/* Intel compiler defines __GNUC__. So we will overwrite implementations
 * coming from above header files here
 */
#ifdef __INTEL_COMPILER
# include <linux/compiler-intel.h>
#endif

/* Clang compiler defines __GNUC__. So we will overwrite implementations
 * coming from above header files here
 */
#ifdef __clang__
#include <linux/compiler-clang.h>
#endif

/*
 * Generic compiler-dependent macros required for kernel
 * build go below this comment. Actual compiler/compiler version
 * specific implementations come from the above header files
 */

struct ftrace_branch_data {
	const char *func;
	const char *file;
	unsigned line;
	union {
		struct {
			unsigned long correct;
			unsigned long incorrect;
		};
		struct {
			unsigned long miss;
			unsigned long hit;
		};
		unsigned long miss_hit[2];
	};
};

/*
 * Note: DISABLE_BRANCH_PROFILING can be used by special lowlevel code
 * to disable branch tracing on a per file basis.
 */
#if defined(CONFIG_TRACE_BRANCH_PROFILING) \
    && !defined(DISABLE_BRANCH_PROFILING) && !defined(__CHECKER__)
void ftrace_likely_update(struct ftrace_branch_data *f, int val, int expect);

#define likely_notrace(x)	__builtin_expect(!!(x), 1)
#define unlikely_notrace(x)	__builtin_expect(!!(x), 0)

#define __branch_check__(x, expect) ({					\
			int ______r;					\
			static struct ftrace_branch_data		\
				__attribute__((__aligned__(4)))		\
				__attribute__((section("_ftrace_annotated_branch"))) \
				______f = {				\
				.func = __func__,			\
				.file = __FILE__,			\
				.line = __LINE__,			\
			};						\
			______r = likely_notrace(x);			\
			ftrace_likely_update(&______f, ______r, expect); \
			______r;					\
		})

/*
 * Using __builtin_constant_p(x) to ignore cases where the return
 * value is always the same.  This idea is taken from a similar patch
 * written by Daniel Walker.
 */
# ifndef likely
#  define likely(x)	(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 1))
# endif
# ifndef unlikely
#  define unlikely(x)	(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 0))
# endif

#ifdef CONFIG_PROFILE_ALL_BRANCHES
/*
 * "Define 'is'", Bill Clinton
 * "Define 'if'", Steven Rostedt
 */
#define if(cond, ...) __trace_if( (cond , ## __VA_ARGS__) )
#define __trace_if(cond) \
	if (__builtin_constant_p(!!(cond)) ? !!(cond) :			\
	({								\
		int ______r;						\
		static struct ftrace_branch_data			\
			__attribute__((__aligned__(4)))			\
			__attribute__((section("_ftrace_branch")))	\
			______f = {					\
				.func = __func__,			\
				.file = __FILE__,			\
				.line = __LINE__,			\
			};						\
		______r = !!(cond);					\
		______f.miss_hit[______r]++;					\
		______r;						\
	}))
#endif /* CONFIG_PROFILE_ALL_BRANCHES */

#else
# define likely(x)	__builtin_expect(!!(x), 1)
# define unlikely(x)	__builtin_expect(!!(x), 0)
#endif

/* Optimization barrier */
#ifndef barrier
# define barrier() __memory_barrier()
#endif

#ifndef barrier_data
# define barrier_data(ptr) barrier()
#endif

/* Unreachable code */
#ifndef unreachable
# define unreachable() do { } while (1)
#endif

/*
 * KENTRY - kernel entry point
 * This can be used to annotate symbols (functions or data) that are used
 * without their linker symbol being referenced explicitly. For example,
 * interrupt vector handlers, or functions in the kernel image that are found
 * programatically.
 *
 * Not required for symbols exported with EXPORT_SYMBOL, or initcalls. Those
 * are handled in their own way (with KEEP() in linker scripts).
 *
 * KENTRY can be avoided if the symbols in question are marked as KEEP() in the
 * linker script. For example an architecture could KEEP() its entire
 * boot/exception vector code rather than annotate each function and data.
 */
#ifndef KENTRY
# define KENTRY(sym)						\
	extern typeof(sym) sym;					\
	static const unsigned long __kentry_##sym		\
	__used							\
	__attribute__((section("___kentry" "+" #sym ), used))	\
	= (unsigned long)&sym;
#endif

#ifndef RELOC_HIDE
# define RELOC_HIDE(ptr, off)					\
  ({ unsigned long __ptr;					\
     __ptr = (unsigned long) (ptr);				\
    (typeof(ptr)) (__ptr + (off)); })
#endif

#ifndef OPTIMIZER_HIDE_VAR
#define OPTIMIZER_HIDE_VAR(var) barrier()
#endif

/* Not-quite-unique ID. */
#ifndef __UNIQUE_ID
# define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __LINE__)
#endif

#include <uapi/linux/types.h>

#define __READ_ONCE_SIZE						\
({									\
	switch (size) {							\
	case 1: *(__u8 *)res = *(volatile __u8 *)p; break;		\
	case 2: *(__u16 *)res = *(volatile __u16 *)p; break;		\
	case 4: *(__u32 *)res = *(volatile __u32 *)p; break;		\
	case 8: *(__u64 *)res = *(volatile __u64 *)p; break;		\
	default:							\
		barrier();						\
		__builtin_memcpy((void *)res, (const void *)p, size);	\
		barrier();						\
	}								\
})

static __always_inline
void __read_once_size(const volatile void *p, void *res, int size)
{
	__READ_ONCE_SIZE;
}

#ifdef CONFIG_KASAN
/*
 * This function is not 'inline' because __no_sanitize_address confilcts
 * with inlining. Attempt to inline it may cause a build failure.
 * 	https://gcc.gnu.org/bugzilla/show_bug.cgi?id=67368
 * '__maybe_unused' allows us to avoid defined-but-not-used warnings.
 */
static __no_sanitize_address __maybe_unused
void __read_once_size_nocheck(const volatile void *p, void *res, int size)
{
	__READ_ONCE_SIZE;
}
#else
static __always_inline
void __read_once_size_nocheck(const volatile void *p, void *res, int size)
{
	__READ_ONCE_SIZE;
}
#endif

static __always_inline void __write_once_size(volatile void *p, void *res, int size)
{
	switch (size) {
	case 1: *(volatile __u8 *)p = *(__u8 *)res; break;
	case 2: *(volatile __u16 *)p = *(__u16 *)res; break;
	case 4: *(volatile __u32 *)p = *(__u32 *)res; break;
	case 8: *(volatile __u64 *)p = *(__u64 *)res; break;
	default:
		barrier();
		__builtin_memcpy((void *)p, (const void *)res, size);
		barrier();
	}
}

/*
 * Prevent the compiler from merging or refetching reads or writes. The
 * compiler is also forbidden from reordering successive instances of
 * READ_ONCE, WRITE_ONCE and ACCESS_ONCE (see below), but only when the
 * compiler is aware of some particular ordering.  One way to make the
 * compiler aware of ordering is to put the two invocations of READ_ONCE,
 * WRITE_ONCE or ACCESS_ONCE() in different C statements.
 *
 * In contrast to ACCESS_ONCE these two macros will also work on aggregate
 * data types like structs or unions. If the size of the accessed data
 * type exceeds the word size of the machine (e.g., 32 bits or 64 bits)
 * READ_ONCE() and WRITE_ONCE() will fall back to memcpy(). There's at
 * least two memcpy()s: one for the __builtin_memcpy() and then one for
 * the macro doing the copy of variable - '__u' allocated on the stack.
 *
 * Their two major use cases are: (1) Mediating communication between
 * process-level code and irq/NMI handlers, all running on the same CPU,
 * and (2) Ensuring that the compiler does not  fold, spindle, or otherwise
 * mutilate accesses that either do not require ordering or that interact
 * with an explicit memory barrier or atomic instruction that provides the
 * required ordering.
 */

#define __READ_ONCE(x, check)						\
({									\
	union { typeof(x) __val; char __c[1]; } __u;			\
	if (check)							\
		__read_once_size(&(x), __u.__c, sizeof(x));		\
	else								\
		__read_once_size_nocheck(&(x), __u.__c, sizeof(x));	\
	__u.__val;							\
})
#define READ_ONCE(x) __READ_ONCE(x, 1)

/*
 * Use READ_ONCE_NOCHECK() instead of READ_ONCE() if you need
 * to hide memory access from KASAN.
 */
#define READ_ONCE_NOCHECK(x) __READ_ONCE(x, 0)

#define WRITE_ONCE(x, val) \
({							\
	union { typeof(x) __val; char __c[1]; } __u =	\
		{ .__val = (__force typeof(x)) (val) }; \
	__write_once_size(&(x), __u.__c, sizeof(x));	\
	__u.__val;					\
})

#endif /* __KERNEL__ */

#endif /* __ASSEMBLY__ */

#ifdef __KERNEL__
/*
 * Allow us to mark functions as 'deprecated' and have gcc emit a nice
 * warning for each use, in hopes of speeding the functions removal.
 * Usage is:
 * 		int __deprecated foo(void)
 */
#ifndef __deprecated
# define __deprecated		/* unimplemented */
#endif

#ifdef MODULE
#define __deprecated_for_modules __deprecated
#else
#define __deprecated_for_modules
#endif

#ifndef __must_check
#define __must_check
#endif

#ifndef CONFIG_ENABLE_MUST_CHECK
#undef __must_check
#define __must_check
#endif
#ifndef CONFIG_ENABLE_WARN_DEPRECATED
#undef __deprecated
#undef __deprecated_for_modules
#define __deprecated
#define __deprecated_for_modules
#endif

#ifndef __malloc
#define __malloc
#endif

/*
 * Allow us to avoid 'defined but not used' warnings on functions and data,
 * as well as force them to be emitted to the assembly file.
 *
 * As of gcc 3.4, static functions that are not marked with attribute((used))
 * may be elided from the assembly file.  As of gcc 3.4, static data not so
 * marked will not be elided, but this may change in a future gcc version.
 *
 * NOTE: Because distributions shipped with a backported unit-at-a-time
 * compiler in gcc 3.3, we must define __used to be __attribute__((used))
 * for gcc >=3.3 instead of 3.4.
 *
 * In prior versions of gcc, such functions and data would be emitted, but
 * would be warned about except with attribute((unused)).
 *
 * Mark functions that are referenced only in inline assembly as __used so
 * the code is emitted even though it appears to be unreferenced.
 */
#ifndef __used
# define __used			/* unimplemented */
#endif

#ifndef __maybe_unused
# define __maybe_unused		/* unimplemented */
#endif

#ifndef __always_unused
# define __always_unused	/* unimplemented */
#endif

#ifndef noinline
#define noinline
#endif

/*
 * Rather then using noinline to prevent stack consumption, use
 * noinline_for_stack instead.  For documentation reasons.
 */
#define noinline_for_stack noinline

#ifndef __always_inline
#define __always_inline inline
#endif

#endif /* __KERNEL__ */

/*
 * From the GCC manual:
 *
 * Many functions do not examine any values except their arguments,
 * and have no effects except the return value.  Basically this is
 * just slightly more strict class than the `pure' attribute above,
 * since function is not allowed to read global memory.
 *
 * Note that a function that has pointer arguments and examines the
 * data pointed to must _not_ be declared `const'.  Likewise, a
 * function that calls a non-`const' function usually must not be
 * `const'.  It does not make sense for a `const' function to return
 * `void'.
 */
#ifndef __attribute_const__
# define __attribute_const__	/* unimplemented */
#endif

#ifndef __latent_entropy
# define __latent_entropy
#endif

/*
 * Tell gcc if a function is cold. The compiler will assume any path
 * directly leading to the call is unlikely.
 */

#ifndef __cold
#define __cold
#endif

/* Simple shorthand for a section definition */
#ifndef __section
# define __section(S) __attribute__ ((__section__(#S)))
#endif

#ifndef __visible
#define __visible
#endif

/*
 * Assume alignment of return value.
 */
#ifndef __assume_aligned
#define __assume_aligned(a, ...)
#endif


/* Are two types/vars the same type (ignoring qualifiers)? */
#ifndef __same_type
# define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))
#endif

/* Is this type a native word size -- useful for atomic operations */
#ifndef __native_word
# define __native_word(t) (sizeof(t) == sizeof(char) || sizeof(t) == sizeof(short) || sizeof(t) == sizeof(int) || sizeof(t) == sizeof(long))
#endif

/* Compile time object size, -1 for unknown */
#ifndef __compiletime_object_size
# define __compiletime_object_size(obj) -1
#endif
#ifndef __compiletime_warning
# define __compiletime_warning(message)
#endif
#ifndef __compiletime_error
# define __compiletime_error(message)
/*
 * Sparse complains of variable sized arrays due to the temporary variable in
 * __compiletime_assert. Unfortunately we can't just expand it out to make
 * sparse see a constant array size without breaking compiletime_assert on old
 * versions of GCC (e.g. 4.2.4), so hide the array from sparse altogether.
 */
# ifndef __CHECKER__
#  define __compiletime_error_fallback(condition) \
	do { ((void)sizeof(char[1 - 2 * condition])); } while (0)
# endif
#endif
#ifndef __compiletime_error_fallback
# define __compiletime_error_fallback(condition) do { } while (0)
#endif

#define __compiletime_assert(condition, msg, prefix, suffix)		\
	do {								\
		bool __cond = !(condition);				\
		extern void prefix ## suffix(void) __compiletime_error(msg); \
		if (__cond)						\
			prefix ## suffix();				\
		__compiletime_error_fallback(__cond);			\
	} while (0)

#define _compiletime_assert(condition, msg, prefix, suffix) \
	__compiletime_assert(condition, msg, prefix, suffix)

/**
 * compiletime_assert - break build and emit msg if condition is false
 * @condition: a compile-time constant condition to check
 * @msg:       a message to emit if condition is false
 *
 * In tradition of POSIX assert, this macro will break the build if the
 * supplied condition is *false*, emitting the supplied error message if the
 * compiler has support to do so.
 */
#define compiletime_assert(condition, msg) \
	_compiletime_assert(condition, msg, __compiletime_assert_, __LINE__)

#define compiletime_assert_atomic_type(t)				\
	compiletime_assert(__native_word(t),				\
		"Need native word sized stores/loads for atomicity.")

/*
 * Prevent the compiler from merging or refetching accesses.  The compiler
 * is also forbidden from reordering successive instances of ACCESS_ONCE(),
 * but only when the compiler is aware of some particular ordering.  One way
 * to make the compiler aware of ordering is to put the two invocations of
 * ACCESS_ONCE() in different C statements.
 *
 * ACCESS_ONCE will only work on scalar types. For union types, ACCESS_ONCE
 * on a union member will work as long as the size of the member matches the
 * size of the union and the size is smaller than word size.
 *
 * The major use cases of ACCESS_ONCE used to be (1) Mediating communication
 * between process-level code and irq/NMI handlers, all running on the same CPU,
 * and (2) Ensuring that the compiler does not  fold, spindle, or otherwise
 * mutilate accesses that either do not require ordering or that interact
 * with an explicit memory barrier or atomic instruction that provides the
 * required ordering.
 *
 * If possible use READ_ONCE()/WRITE_ONCE() instead.
 */
#define __ACCESS_ONCE(x) ({ \
	 __maybe_unused typeof(x) __var = (__force typeof(x)) 0; \
	(volatile typeof(x) *)&(x); })
#define ACCESS_ONCE(x) (*__ACCESS_ONCE(x))

/**
 * lockless_dereference() - safely load a pointer for later dereference
 * @p: The pointer to load
 *
 * Similar to rcu_dereference(), but for situations where the pointed-to
 * object's lifetime is managed by something other than RCU.  That
 * "something other" might be reference counting or simple immortality.
 *
 * The seemingly unused variable ___typecheck_p validates that @p is
 * indeed a pointer type by using a pointer to typeof(*p) as the type.
 * Taking a pointer to typeof(*p) again is needed in case p is void *.
 */
#define lockless_dereference(p) \
({ \
	typeof(p) _________p1 = READ_ONCE(p); \
	typeof(*(p)) *___typecheck_p __maybe_unused; \
	smp_read_barrier_depends(); /* Dependency order vs. p above. */ \
	(_________p1); \
})

/* Ignore/forbid kprobes attach on very low level functions marked by this attribute: */
#ifdef CONFIG_KPROBES
# define __kprobes	__attribute__((__section__(".kprobes.text")))
# define nokprobe_inline	__always_inline
#else
# define __kprobes
# define nokprobe_inline	inline
#endif
#endif /* __LINUX_COMPILER_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    /* Atomic operations usable in machine independent code */
#ifndef _LINUX_ATOMIC_H
#define _LINUX_ATOMIC_H
#include <asm/atomic.h>
#include <asm/barrier.h>

/*
 * Relaxed variants of xchg, cmpxchg and some atomic operations.
 *
 * We support four variants:
 *
 * - Fully ordered: The default implementation, no suffix required.
 * - Acquire: Provides ACQUIRE semantics, _acquire suffix.
 * - Release: Provides RELEASE semantics, _release suffix.
 * - Relaxed: No ordering guarantees, _relaxed suffix.
 *
 * For compound atomics performing both a load and a store, ACQUIRE
 * semantics apply only to the load and RELEASE semantics only to the
 * store portion of the operation. Note that a failed cmpxchg_acquire
 * does -not- imply any memory ordering constraints.
 *
 * See Documentation/memory-barriers.txt for ACQUIRE/RELEASE definitions.
 */

#ifndef atomic_read_acquire
#define  atomic_read_acquire(v)		smp_load_acquire(&(v)->counter)
#endif

#ifndef atomic_set_release
#define  atomic_set_release(v, i)	smp_store_release(&(v)->counter, (i))
#endif

/*
 * The idea here is to build acquire/release variants by adding explicit
 * barriers on top of the relaxed variant. In the case where the relaxed
 * variant is already fully ordered, no additional barriers are needed.
 *
 * Besides, if an arch has a special barrier for acquire/release, it could
 * implement its own __atomic_op_* and use the same framework for building
 * variants
 */
#ifndef __atomic_op_acquire
#define __atomic_op_acquire(op, args...)				\
({									\
	typeof(op##_relaxed(args)) __ret  = op##_relaxed(args);		\
	smp_mb__after_atomic();						\
	__ret;								\
})
#endif

#ifndef __atomic_op_release
#define __atomic_op_release(op, args...)				\
({									\
	smp_mb__before_atomic();					\
	op##_relaxed(args);						\
})
#endif

#ifndef __atomic_op_fence
#define __atomic_op_fence(op, args...)					\
({									\
	typeof(op##_relaxed(args)) __ret;				\
	smp_mb__before_atomic();					\
	__ret = op##_relaxed(args);					\
	smp_mb__after_atomic();						\
	__ret;								\
})
#endif

/* atomic_add_return_relaxed */
#ifndef atomic_add_return_relaxed
#define  atomic_add_return_relaxed	atomic_add_return
#define  atomic_add_return_acquire	atomic_add_return
#define  atomic_add_return_release	atomic_add_return

#else /* atomic_add_return_relaxed */

#ifndef atomic_add_return_acquire
#define  atomic_add_return_acquire(...)					\
	__atomic_op_acquire(atomic_add_return, __VA_ARGS__)
#endif

#ifndef atomic_add_return_release
#define  atomic_add_return_release(...)					\
	__atomic_op_release(atomic_add_return, __VA_ARGS__)
#endif

#ifndef atomic_add_return
#define  atomic_add_return(...)						\
	__atomic_op_fence(atomic_add_return, __VA_ARGS__)
#endif
#endif /* atomic_add_return_relaxed */

/* atomic_inc_return_relaxed */
#ifndef atomic_inc_return_relaxed
#define  atomic_inc_return_relaxed	atomic_inc_return
#define  atomic_inc_return_acquire	atomic_inc_return
#define  atomic_inc_return_release	atomic_inc_return

#else /* atomic_inc_return_relaxed */

#ifndef atomic_inc_return_acquire
#define  atomic_inc_return_acquire(...)					\
	__atomic_op_acquire(atomic_inc_return, __VA_ARGS__)
#endif

#ifndef atomic_inc_return_release
#define  atomic_inc_return_release(...)					\
	__atomic_op_release(atomic_inc_return, __VA_ARGS__)
#endif

#ifndef atomic_inc_return
#define  atomic_inc_return(...)						\
	__atomic_op_fence(atomic_inc_return, __VA_ARGS__)
#endif
#endif /* atomic_inc_return_relaxed */

/* atomic_sub_return_relaxed */
#ifndef atomic_sub_return_relaxed
#define  atomic_sub_return_relaxed	atomic_sub_return
#define  atomic_sub_return_acquire	atomic_sub_return
#define  atomic_sub_return_release	atomic_sub_return

#else /* atomic_sub_return_relaxed */

#ifndef atomic_sub_return_acquire
#define  atomic_sub_return_acquire(...)					\
	__atomic_op_acquire(atomic_sub_return, __VA_ARGS__)
#endif

#ifndef atomic_sub_return_release
#define  atomic_sub_return_release(...)					\
	__atomic_op_release(atomic_sub_return, __VA_ARGS__)
#endif

#ifndef atomic_sub_return
#define  atomic_sub_return(...)						\
	__atomic_op_fence(atomic_sub_return, __VA_ARGS__)
#endif
#endif /* atomic_sub_return_relaxed */

/* atomic_dec_return_relaxed */
#ifndef atomic_dec_return_relaxed
#define  atomic_dec_return_relaxed	atomic_dec_return
#define  atomic_dec_return_acquire	atomic_dec_return
#define  atomic_dec_return_release	atomic_dec_return

#else /* atomic_dec_return_relaxed */

#ifndef atomic_dec_return_acquire
#define  atomic_dec_return_acquire(...)					\
	__atomic_op_acquire(atomic_dec_return, __VA_ARGS__)
#endif

#ifndef atomic_dec_return_release
#define  atomic_dec_return_release(...)					\
	__atomic_op_release(atomic_dec_return, __VA_ARGS__)
#endif

#ifndef atomic_dec_return
#define  atomic_dec_return(...)						\
	__atomic_op_fence(atomic_dec_return, __VA_ARGS__)
#endif
#endif /* atomic_dec_return_relaxed */


/* atomic_fetch_add_relaxed */
#ifndef atomic_fetch_add_relaxed
#define atomic_fetch_add_relaxed	atomic_fetch_add
#define atomic_fetch_add_acquire	atomic_fetch_add
#define atomic_fetch_add_release	atomic_fetch_add

#else /* atomic_fetch_add_relaxed */

#ifndef atomic_fetch_add_acquire
#define atomic_fetch_add_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_add, __VA_ARGS__)
#endif

#ifndef atomic_fetch_add_release
#define atomic_fetch_add_release(...)					\
	__atomic_op_release(atomic_fetch_add, __VA_ARGS__)
#endif

#ifndef atomic_fetch_add
#define atomic_fetch_add(...)						\
	__atomic_op_fence(atomic_fetch_add, __VA_ARGS__)
#endif
#endif /* atomic_fetch_add_relaxed */

/* atomic_fetch_inc_relaxed */
#ifndef atomic_fetch_inc_relaxed

#ifndef atomic_fetch_inc
#define atomic_fetch_inc(v)	        atomic_fetch_add(1, (v))
#define atomic_fetch_inc_relaxed(v)	atomic_fetch_add_relaxed(1, (v))
#define atomic_fetch_inc_acquire(v)	atomic_fetch_add_acquire(1, (v))
#define atomic_fetch_inc_release(v)	atomic_fetch_add_release(1, (v))
#else /* atomic_fetch_inc */
#define atomic_fetch_inc_relaxed	atomic_fetch_inc
#define atomic_fetch_inc_acquire	atomic_fetch_inc
#define atomic_fetch_inc_release	atomic_fetch_inc
#endif /* atomic_fetch_inc */

#else /* atomic_fetch_inc_relaxed */

#ifndef atomic_fetch_inc_acquire
#define atomic_fetch_inc_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_inc, __VA_ARGS__)
#endif

#ifndef atomic_fetch_inc_release
#define atomic_fetch_inc_release(...)					\
	__atomic_op_release(atomic_fetch_inc, __VA_ARGS__)
#endif

#ifndef atomic_fetch_inc
#define atomic_fetch_inc(...)						\
	__atomic_op_fence(atomic_fetch_inc, __VA_ARGS__)
#endif
#endif /* atomic_fetch_inc_relaxed */

/* atomic_fetch_sub_relaxed */
#ifndef atomic_fetch_sub_relaxed
#define atomic_fetch_sub_relaxed	atomic_fetch_sub
#define atomic_fetch_sub_acquire	atomic_fetch_sub
#define atomic_fetch_sub_release	atomic_fetch_sub

#else /* atomic_fetch_sub_relaxed */

#ifndef atomic_fetch_sub_acquire
#define atomic_fetch_sub_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_sub, __VA_ARGS__)
#endif

#ifndef atomic_fetch_sub_release
#define atomic_fetch_sub_release(...)					\
	__atomic_op_release(atomic_fetch_sub, __VA_ARGS__)
#endif

#ifndef atomic_fetch_sub
#define atomic_fetch_sub(...)						\
	__atomic_op_fence(atomic_fetch_sub, __VA_ARGS__)
#endif
#endif /* atomic_fetch_sub_relaxed */

/* atomic_fetch_dec_relaxed */
#ifndef atomic_fetch_dec_relaxed

#ifndef atomic_fetch_dec
#define atomic_fetch_dec(v)	        atomic_fetch_sub(1, (v))
#define atomic_fetch_dec_relaxed(v)	atomic_fetch_sub_relaxed(1, (v))
#define atomic_fetch_dec_acquire(v)	atomic_fetch_sub_acquire(1, (v))
#define atomic_fetch_dec_release(v)	atomic_fetch_sub_release(1, (v))
#else /* atomic_fetch_dec */
#define atomic_fetch_dec_relaxed	atomic_fetch_dec
#define atomic_fetch_dec_acquire	atomic_fetch_dec
#define atomic_fetch_dec_release	atomic_fetch_dec
#endif /* atomic_fetch_dec */

#else /* atomic_fetch_dec_relaxed */

#ifndef atomic_fetch_dec_acquire
#define atomic_fetch_dec_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_dec, __VA_ARGS__)
#endif

#ifndef atomic_fetch_dec_release
#define atomic_fetch_dec_release(...)					\
	__atomic_op_release(atomic_fetch_dec, __VA_ARGS__)
#endif

#ifndef atomic_fetch_dec
#define atomic_fetch_dec(...)						\
	__atomic_op_fence(atomic_fetch_dec, __VA_ARGS__)
#endif
#endif /* atomic_fetch_dec_relaxed */

/* atomic_fetch_or_relaxed */
#ifndef atomic_fetch_or_relaxed
#define atomic_fetch_or_relaxed	atomic_fetch_or
#define atomic_fetch_or_acquire	atomic_fetch_or
#define atomic_fetch_or_release	atomic_fetch_or

#else /* atomic_fetch_or_relaxed */

#ifndef atomic_fetch_or_acquire
#define atomic_fetch_or_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_or, __VA_ARGS__)
#endif

#ifndef atomic_fetch_or_release
#define atomic_fetch_or_release(...)					\
	__atomic_op_release(atomic_fetch_or, __VA_ARGS__)
#endif

#ifndef atomic_fetch_or
#define atomic_fetch_or(...)						\
	__atomic_op_fence(atomic_fetch_or, __VA_ARGS__)
#endif
#endif /* atomic_fetch_or_relaxed */

/* atomic_fetch_and_relaxed */
#ifndef atomic_fetch_and_relaxed
#define atomic_fetch_and_relaxed	atomic_fetch_and
#define atomic_fetch_and_acquire	atomic_fetch_and
#define atomic_fetch_and_release	atomic_fetch_and

#else /* atomic_fetch_and_relaxed */

#ifndef atomic_fetch_and_acquire
#define atomic_fetch_and_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_and, __VA_ARGS__)
#endif

#ifndef atomic_fetch_and_release
#define atomic_fetch_and_release(...)					\
	__atomic_op_release(atomic_fetch_and, __VA_ARGS__)
#endif

#ifndef atomic_fetch_and
#define atomic_fetch_and(...)						\
	__atomic_op_fence(atomic_fetch_and, __VA_ARGS__)
#endif
#endif /* atomic_fetch_and_relaxed */

#ifdef atomic_andnot
/* atomic_fetch_andnot_relaxed */
#ifndef atomic_fetch_andnot_relaxed
#define atomic_fetch_andnot_relaxed	atomic_fetch_andnot
#define atomic_fetch_andnot_acquire	atomic_fetch_andnot
#define atomic_fetch_andnot_release	atomic_fetch_andnot

#else /* atomic_fetch_andnot_relaxed */

#ifndef atomic_fetch_andnot_acquire
#define atomic_fetch_andnot_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_andnot, __VA_ARGS__)
#endif

#ifndef atomic_fetch_andnot_release
#define atomic_fetch_andnot_release(...)					\
	__atomic_op_release(atomic_fetch_andnot, __VA_ARGS__)
#endif

#ifndef atomic_fetch_andnot
#define atomic_fetch_andnot(...)						\
	__atomic_op_fence(atomic_fetch_andnot, __VA_ARGS__)
#endif
#endif /* atomic_fetch_andnot_relaxed */
#endif /* atomic_andnot */

/* atomic_fetch_xor_relaxed */
#ifndef atomic_fetch_xor_relaxed
#define atomic_fetch_xor_relaxed	atomic_fetch_xor
#define atomic_fetch_xor_acquire	atomic_fetch_xor
#define atomic_fetch_xor_release	atomic_fetch_xor

#else /* atomic_fetch_xor_relaxed */

#ifndef atomic_fetch_xor_acquire
#define atomic_fetch_xor_acquire(...)					\
	__atomic_op_acquire(atomic_fetch_xor, __VA_ARGS__)
#endif

#ifndef atomic_fetch_xor_release
#define atomic_fetch_xor_release(...)					\
	__atomic_op_release(atomic_fetch_xor, __VA_ARGS__)
#endif

#ifndef atomic_fetch_xor
#define atomic_fetch_xor(...)						\
	__atomic_op_fence(atomic_fetch_xor, __VA_ARGS__)
#endif
#endif /* atomic_fetch_xor_relaxed */


/* atomic_xchg_relaxed */
#ifndef atomic_xchg_relaxed
#define  atomic_xchg_relaxed		atomic_xchg
#define  atomic_xchg_acquire		atomic_xchg
#define  atomic_xchg_release		atomic_xchg

#else /* atomic_xchg_relaxed */

#ifndef atomic_xchg_acquire
#define  atomic_xchg_acquire(...)					\
	__atomic_op_acquire(atomic_xchg, __VA_ARGS__)
#endif

#ifndef atomic_xchg_release
#define  atomic_xchg_release(...)					\
	__atomic_op_release(atomic_xchg, __VA_ARGS__)
#endif

#ifndef atomic_xchg
#define  atomic_xchg(...)						\
	__atomic_op_fence(atomic_xchg, __VA_ARGS__)
#endif
#endif /* atomic_xchg_relaxed */

/* atomic_cmpxchg_relaxed */
#ifndef atomic_cmpxchg_relaxed
#define  atomic_cmpxchg_relaxed		atomic_cmpxchg
#define  atomic_cmpxchg_acquire		atomic_cmpxchg
#define  atomic_cmpxchg_release		atomic_cmpxchg

#else /* atomic_cmpxchg_relaxed */

#ifndef atomic_cmpxchg_acquire
#define  atomic_cmpxchg_acquire(...)					\
	__atomic_op_acquire(atomic_cmpxchg, __VA_ARGS__)
#endif

#ifndef atomic_cmpxchg_release
#define  atomic_cmpxchg_release(...)					\
	__atomic_op_release(atomic_cmpxchg, __VA_ARGS__)
#endif

#ifndef atomic_cmpxchg
#define  atomic_cmpxchg(...)						\
	__atomic_op_fence(atomic_cmpxchg, __VA_ARGS__)
#endif
#endif /* atomic_cmpxchg_relaxed */

/* cmpxchg_relaxed */
#ifndef cmpxchg_relaxed
#define  cmpxchg_relaxed		cmpxchg
#define  cmpxchg_acquire		cmpxchg
#define  cmpxchg_release		cmpxchg

#else /* cmpxchg_relaxed */

#ifndef cmpxchg_acquire
#define  cmpxchg_acquire(...)						\
	__atomic_op_acquire(cmpxchg, __VA_ARGS__)
#endif

#ifndef cmpxchg_release
#define  cmpxchg_release(...)						\
	__atomic_op_release(cmpxchg, __VA_ARGS__)
#endif

#ifndef cmpxchg
#define  cmpxchg(...)							\
	__atomic_op_fence(cmpxchg, __VA_ARGS__)
#endif
#endif /* cmpxchg_relaxed */

/* cmpxchg64_relaxed */
#ifndef cmpxchg64_relaxed
#define  cmpxchg64_relaxed		cmpxchg64
#define  cmpxchg64_acquire		cmpxchg64
#define  cmpxchg64_release		cmpxchg64

#else /* cmpxchg64_relaxed */

#ifndef cmpxchg64_acquire
#define  cmpxchg64_acquire(...)						\
	__atomic_op_acquire(cmpxchg64, __VA_ARGS__)
#endif

#ifndef cmpxchg64_release
#define  cmpxchg64_release(...)						\
	__atomic_op_release(cmpxchg64, __VA_ARGS__)
#endif

#ifndef cmpxchg64
#define  cmpxchg64(...)							\
	__atomic_op_fence(cmpxchg64, __VA_ARGS__)
#endif
#endif /* cmpxchg64_relaxed */

/* xchg_relaxed */
#ifndef xchg_relaxed
#define  xchg_relaxed			xchg
#define  xchg_acquire			xchg
#define  xchg_release			xchg

#else /* xchg_relaxed */

#ifndef xchg_acquire
#define  xchg_acquire(...)		__atomic_op_acquire(xchg, __VA_ARGS__)
#endif

#ifndef xchg_release
#define  xchg_release(...)		__atomic_op_release(xchg, __VA_ARGS__)
#endif

#ifndef xchg
#define  xchg(...)			__atomic_op_fence(xchg, __VA_ARGS__)
#endif
#endif /* xchg_relaxed */

/**
 * atomic_add_unless - add unless the number is already a given value
 * @v: pointer of type atomic_t
 * @a: the amount to add to v...
 * @u: ...unless v is equal to u.
 *
 * Atomically adds @a to @v, so long as @v was not already @u.
 * Returns non-zero if @v was not @u, and zero otherwise.
 */
static inline int atomic_add_unless(atomic_t *v, int a, int u)
{
	return __atomic_add_unless(v, a, u) != u;
}

/**
 * atomic_inc_not_zero - increment unless the number is zero
 * @v: pointer of type atomic_t
 *
 * Atomically increments @v by 1, so long as @v is non-zero.
 * Returns non-zero if @v was non-zero, and zero otherwise.
 */
#ifndef atomic_inc_not_zero
#define atomic_inc_not_zero(v)		atomic_add_unless((v), 1, 0)
#endif

#ifndef atomic_andnot
static inline void atomic_andnot(int i, atomic_t *v)
{
	atomic_and(~i, v);
}

static inline int atomic_fetch_andnot(int i, atomic_t *v)
{
	return atomic_fetch_and(~i, v);
}

static inline int atomic_fetch_andnot_relaxed(int i, atomic_t *v)
{
	return atomic_fetch_and_relaxed(~i, v);
}

static inline int atomic_fetch_andnot_acquire(int i, atomic_t *v)
{
	return atomic_fetch_and_acquire(~i, v);
}

static inline int atomic_fetch_andnot_release(int i, atomic_t *v)
{
	return atomic_fetch_and_release(~i, v);
}
#endif

/**
 * atomic_inc_not_zero_hint - increment if not null
 * @v: pointer of type atomic_t
 * @hint: probable value of the atomic before the increment
 *
 * This version of atomic_inc_not_zero() gives a hint of probable
 * value of the atomic. This helps processor to not read the memory
 * before doing the atomic read/modify/write cycle, lowering
 * number of bus transactions on some arches.
 *
 * Returns: 0 if increment was not done, 1 otherwise.
 */
#ifndef atomic_inc_not_zero_hint
static inline int atomic_inc_not_zero_hint(atomic_t *v, int hint)
{
	int val, c = hint;

	/* sanity test, should be removed by compiler if hint is a constant */
	if (!hint)
		return atomic_inc_not_zero(v);

	do {
		val = atomic_cmpxchg(v, c, c + 1);
		if (val == c)
			return 1;
		c = val;
	} while (c);

	return 0;
}
#endif

#ifndef atomic_inc_unless_negative
static inline int atomic_inc_unless_negative(atomic_t *p)
{
	int v, v1;
	for (v = 0; v >= 0; v = v1) {
		v1 = atomic_cmpxchg(p, v, v + 1);
		if (likely(v1 == v))
			return 1;
	}
	return 0;
}
#endif

#ifndef atomic_dec_unless_positive
static inline int atomic_dec_unless_positive(atomic_t *p)
{
	int v, v1;
	for (v = 0; v <= 0; v = v1) {
		v1 = atomic_cmpxchg(p, v, v - 1);
		if (likely(v1 == v))
			return 1;
	}
	return 0;
}
#endif

/*
 * atomic_dec_if_positive - decrement by 1 if old value positive
 * @v: pointer of type atomic_t
 *
 * The function returns the old value of *v minus 1, even if
 * the atomic variable, v, was not decremented.
 */
#ifndef atomic_dec_if_positive
static inline int atomic_dec_if_positive(atomic_t *v)
{
	int c, old, dec;
	c = atomic_read(v);
	for (;;) {
		dec = c - 1;
		if (unlikely(dec < 0))
			break;
		old = atomic_cmpxchg((v), c, dec);
		if (likely(old == c))
			break;
		c = old;
	}
	return dec;
}
#endif

#ifdef CONFIG_GENERIC_ATOMIC64
#include <asm-generic/atomic64.h>
#endif

#ifndef atomic64_read_acquire
#define  atomic64_read_acquire(v)	smp_load_acquire(&(v)->counter)
#endif

#ifndef atomic64_set_release
#define  atomic64_set_release(v, i)	smp_store_release(&(v)->counter, (i))
#endif

/* atomic64_add_return_relaxed */
#ifndef atomic64_add_return_relaxed
#define  atomic64_add_return_relaxed	atomic64_add_return
#define  atomic64_add_return_acquire	atomic64_add_return
#define  atomic64_add_return_release	atomic64_add_return

#else /* atomic64_add_return_relaxed */

#ifndef atomic64_add_return_acquire
#define  atomic64_add_return_acquire(...)				\
	__atomic_op_acquire(atomic64_add_return, __VA_ARGS__)
#endif

#ifndef atomic64_add_return_release
#define  atomic64_add_return_release(...)				\
	__atomic_op_release(atomic64_add_return, __VA_ARGS__)
#endif

#ifndef atomic64_add_return
#define  atomic64_add_return(...)					\
	__atomic_op_fence(atomic64_add_return, __VA_ARGS__)
#endif
#endif /* atomic64_add_return_relaxed */

/* atomic64_inc_return_relaxed */
#ifndef atomic64_inc_return_relaxed
#define  atomic64_inc_return_relaxed	atomic64_inc_return
#define  atomic64_inc_return_acquire	atomic64_inc_return
#define  atomic64_inc_return_release	atomic64_inc_return

#else /* atomic64_inc_return_relaxed */

#ifndef atomic64_inc_return_acquire
#define  atomic64_inc_return_acquire(...)				\
	__atomic_op_acquire(atomic64_inc_return, __VA_ARGS__)
#endif

#ifndef atomic64_inc_return_release
#define  atomic64_inc_return_release(...)				\
	__atomic_op_release(atomic64_inc_return, __VA_ARGS__)
#endif

#ifndef atomic64_inc_return
#define  atomic64_inc_return(...)					\
	__atomic_op_fence(atomic64_inc_return, __VA_ARGS__)
#endif
#endif /* atomic64_inc_return_relaxed */


/* atomic64_sub_return_relaxed */
#ifndef atomic64_sub_return_relaxed
#define  atomic64_sub_return_relaxed	atomic64_sub_return
#define  atomic64_sub_return_acquire	atomic64_sub_return
#define  atomic64_sub_return_release	atomic64_sub_return

#else /* atomic64_sub_return_relaxed */

#ifndef atomic64_sub_return_acquire
#define  atomic64_sub_return_acquire(...)				\
	__atomic_op_acquire(atomic64_sub_return, __VA_ARGS__)
#endif

#ifndef atomic64_sub_return_release
#define  atomic64_sub_return_release(...)				\
	__atomic_op_release(atomic64_sub_return, __VA_ARGS__)
#endif

#ifndef atomic64_sub_return
#define  atomic64_sub_return(...)					\
	__atomic_op_fence(atomic64_sub_return, __VA_ARGS__)
#endif
#endif /* atomic64_sub_return_relaxed */

/* atomic64_dec_return_relaxed */
#ifndef atomic64_dec_return_relaxed
#define  atomic64_dec_return_relaxed	atomic64_dec_return
#define  atomic64_dec_return_acquire	atomic64_dec_return
#define  atomic64_dec_return_release	atomic64_dec_return

#else /* atomic64_dec_return_relaxed */

#ifndef atomic64_dec_return_acquire
#define  atomic64_dec_return_acquire(...)				\
	__atomic_op_acquire(atomic64_dec_return, __VA_ARGS__)
#endif

#ifndef atomic64_dec_return_release
#define  atomic64_dec_return_release(...)				\
	__atomic_op_release(atomic64_dec_return, __VA_ARGS__)
#endif

#ifndef atomic64_dec_return
#define  atomic64_dec_return(...)					\
	__atomic_op_fence(atomic64_dec_return, __VA_ARGS__)
#endif
#endif /* atomic64_dec_return_relaxed */


/* atomic64_fetch_add_relaxed */
#ifndef atomic64_fetch_add_relaxed
#define atomic64_fetch_add_relaxed	atomic64_fetch_add
#define atomic64_fetch_add_acquire	atomic64_fetch_add
#define atomic64_fetch_add_release	atomic64_fetch_add

#else /* atomic64_fetch_add_relaxed */

#ifndef atomic64_fetch_add_acquire
#define atomic64_fetch_add_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_add, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_add_release
#define atomic64_fetch_add_release(...)					\
	__atomic_op_release(atomic64_fetch_add, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_add
#define atomic64_fetch_add(...)						\
	__atomic_op_fence(atomic64_fetch_add, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_add_relaxed */

/* atomic64_fetch_inc_relaxed */
#ifndef atomic64_fetch_inc_relaxed

#ifndef atomic64_fetch_inc
#define atomic64_fetch_inc(v)		atomic64_fetch_add(1, (v))
#define atomic64_fetch_inc_relaxed(v)	atomic64_fetch_add_relaxed(1, (v))
#define atomic64_fetch_inc_acquire(v)	atomic64_fetch_add_acquire(1, (v))
#define atomic64_fetch_inc_release(v)	atomic64_fetch_add_release(1, (v))
#else /* atomic64_fetch_inc */
#define atomic64_fetch_inc_relaxed	atomic64_fetch_inc
#define atomic64_fetch_inc_acquire	atomic64_fetch_inc
#define atomic64_fetch_inc_release	atomic64_fetch_inc
#endif /* atomic64_fetch_inc */

#else /* atomic64_fetch_inc_relaxed */

#ifndef atomic64_fetch_inc_acquire
#define atomic64_fetch_inc_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_inc, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_inc_release
#define atomic64_fetch_inc_release(...)					\
	__atomic_op_release(atomic64_fetch_inc, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_inc
#define atomic64_fetch_inc(...)						\
	__atomic_op_fence(atomic64_fetch_inc, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_inc_relaxed */

/* atomic64_fetch_sub_relaxed */
#ifndef atomic64_fetch_sub_relaxed
#define atomic64_fetch_sub_relaxed	atomic64_fetch_sub
#define atomic64_fetch_sub_acquire	atomic64_fetch_sub
#define atomic64_fetch_sub_release	atomic64_fetch_sub

#else /* atomic64_fetch_sub_relaxed */

#ifndef atomic64_fetch_sub_acquire
#define atomic64_fetch_sub_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_sub, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_sub_release
#define atomic64_fetch_sub_release(...)					\
	__atomic_op_release(atomic64_fetch_sub, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_sub
#define atomic64_fetch_sub(...)						\
	__atomic_op_fence(atomic64_fetch_sub, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_sub_relaxed */

/* atomic64_fetch_dec_relaxed */
#ifndef atomic64_fetch_dec_relaxed

#ifndef atomic64_fetch_dec
#define atomic64_fetch_dec(v)		atomic64_fetch_sub(1, (v))
#define atomic64_fetch_dec_relaxed(v)	atomic64_fetch_sub_relaxed(1, (v))
#define atomic64_fetch_dec_acquire(v)	atomic64_fetch_sub_acquire(1, (v))
#define atomic64_fetch_dec_release(v)	atomic64_fetch_sub_release(1, (v))
#else /* atomic64_fetch_dec */
#define atomic64_fetch_dec_relaxed	atomic64_fetch_dec
#define atomic64_fetch_dec_acquire	atomic64_fetch_dec
#define atomic64_fetch_dec_release	atomic64_fetch_dec
#endif /* atomic64_fetch_dec */

#else /* atomic64_fetch_dec_relaxed */

#ifndef atomic64_fetch_dec_acquire
#define atomic64_fetch_dec_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_dec, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_dec_release
#define atomic64_fetch_dec_release(...)					\
	__atomic_op_release(atomic64_fetch_dec, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_dec
#define atomic64_fetch_dec(...)						\
	__atomic_op_fence(atomic64_fetch_dec, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_dec_relaxed */

/* atomic64_fetch_or_relaxed */
#ifndef atomic64_fetch_or_relaxed
#define atomic64_fetch_or_relaxed	atomic64_fetch_or
#define atomic64_fetch_or_acquire	atomic64_fetch_or
#define atomic64_fetch_or_release	atomic64_fetch_or

#else /* atomic64_fetch_or_relaxed */

#ifndef atomic64_fetch_or_acquire
#define atomic64_fetch_or_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_or, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_or_release
#define atomic64_fetch_or_release(...)					\
	__atomic_op_release(atomic64_fetch_or, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_or
#define atomic64_fetch_or(...)						\
	__atomic_op_fence(atomic64_fetch_or, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_or_relaxed */

/* atomic64_fetch_and_relaxed */
#ifndef atomic64_fetch_and_relaxed
#define atomic64_fetch_and_relaxed	atomic64_fetch_and
#define atomic64_fetch_and_acquire	atomic64_fetch_and
#define atomic64_fetch_and_release	atomic64_fetch_and

#else /* atomic64_fetch_and_relaxed */

#ifndef atomic64_fetch_and_acquire
#define atomic64_fetch_and_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_and, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_and_release
#define atomic64_fetch_and_release(...)					\
	__atomic_op_release(atomic64_fetch_and, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_and
#define atomic64_fetch_and(...)						\
	__atomic_op_fence(atomic64_fetch_and, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_and_relaxed */

#ifdef atomic64_andnot
/* atomic64_fetch_andnot_relaxed */
#ifndef atomic64_fetch_andnot_relaxed
#define atomic64_fetch_andnot_relaxed	atomic64_fetch_andnot
#define atomic64_fetch_andnot_acquire	atomic64_fetch_andnot
#define atomic64_fetch_andnot_release	atomic64_fetch_andnot

#else /* atomic64_fetch_andnot_relaxed */

#ifndef atomic64_fetch_andnot_acquire
#define atomic64_fetch_andnot_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_andnot, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_andnot_release
#define atomic64_fetch_andnot_release(...)					\
	__atomic_op_release(atomic64_fetch_andnot, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_andnot
#define atomic64_fetch_andnot(...)						\
	__atomic_op_fence(atomic64_fetch_andnot, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_andnot_relaxed */
#endif /* atomic64_andnot */

/* atomic64_fetch_xor_relaxed */
#ifndef atomic64_fetch_xor_relaxed
#define atomic64_fetch_xor_relaxed	atomic64_fetch_xor
#define atomic64_fetch_xor_acquire	atomic64_fetch_xor
#define atomic64_fetch_xor_release	atomic64_fetch_xor

#else /* atomic64_fetch_xor_relaxed */

#ifndef atomic64_fetch_xor_acquire
#define atomic64_fetch_xor_acquire(...)					\
	__atomic_op_acquire(atomic64_fetch_xor, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_xor_release
#define atomic64_fetch_xor_release(...)					\
	__atomic_op_release(atomic64_fetch_xor, __VA_ARGS__)
#endif

#ifndef atomic64_fetch_xor
#define atomic64_fetch_xor(...)						\
	__atomic_op_fence(atomic64_fetch_xor, __VA_ARGS__)
#endif
#endif /* atomic64_fetch_xor_relaxed */


/* atomic64_xchg_relaxed */
#ifndef atomic64_xchg_relaxed
#define  atomic64_xchg_relaxed		atomic64_xchg
#define  atomic64_xchg_acquire		atomic64_xchg
#define  atomic64_xchg_release		atomic64_xchg

#else /* atomic64_xchg_relaxed */

#ifndef atomic64_xchg_acquire
#define  atomic64_xchg_acquire(...)					\
	__atomic_op_acquire(atomic64_xchg, __VA_ARGS__)
#endif

#ifndef atomic64_xchg_release
#define  atomic64_xchg_release(...)					\
	__atomic_op_release(atomic64_xchg, __VA_ARGS__)
#endif

#ifndef atomic64_xchg
#define  atomic64_xchg(...)						\
	__atomic_op_fence(atomic64_xchg, __VA_ARGS__)
#endif
#endif /* atomic64_xchg_relaxed */

/* atomic64_cmpxchg_relaxed */
#ifndef atomic64_cmpxchg_relaxed
#define  atomic64_cmpxchg_relaxed	atomic64_cmpxchg
#define  atomic64_cmpxchg_acquire	atomic64_cmpxchg
#define  atomic64_cmpxchg_release	atomic64_cmpxchg

#else /* atomic64_cmpxchg_relaxed */

#ifndef atomic64_cmpxchg_acquire
#define  atomic64_cmpxchg_acquire(...)					\
	__atomic_op_acquire(atomic64_cmpxchg, __VA_ARGS__)
#endif

#ifndef atomic64_cmpxchg_release
#define  atomic64_cmpxchg_release(...)					\
	__atomic_op_release(atomic64_cmpxchg, __VA_ARGS__)
#endif

#ifndef atomic64_cmpxchg
#define  atomic64_cmpxchg(...)						\
	__atomic_op_fence(atomic64_cmpxchg, __VA_ARGS__)
#endif
#endif /* atomic64_cmpxchg_relaxed */

#ifndef atomic64_andnot
static inline void atomic64_andnot(long long i, atomic64_t *v)
{
	atomic64_and(~i, v);
}

static inline long long atomic64_fetch_andnot(long long i, atomic64_t *v)
{
	return atomic64_fetch_and(~i, v);
}

static inline long long atomic64_fetch_andnot_relaxed(long long i, atomic64_t *v)
{
	return atomic64_fetch_and_relaxed(~i, v);
}

static inline long long atomic64_fetch_andnot_acquire(long long i, atomic64_t *v)
{
	return atomic64_fetch_and_acquire(~i, v);
}

static inline long long atomic64_fetch_andnot_release(long long i, atomic64_t *v)
{
	return atomic64_fetch_and_release(~i, v);
}
#endif

#include <asm-generic/atomic-long.h>

#endif /* _LINUX_ATOMIC_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       #ifndef _LINUX_RESET_CONTROLLER_H_
#define _LINUX_RESET_CONTROLLER_H_

#include <linux/list.h>

struct reset_controller_dev;

/**
 * struct reset_control_ops
 *
 * @reset: for self-deasserting resets, does all necessary
 *         things to reset the device
 * @assert: manually assert the reset line, if supported
 * @deassert: manually deassert the reset line, if supported
 * @status: return the status of the reset line, if supported
 */
struct reset_control_ops {
	int (*reset)(struct reset_controller_dev *rcdev, unsigned long id);
	int (*assert)(struct reset_controller_dev *rcdev, unsigned long id);
	int (*deassert)(struct reset_controller_dev *rcdev, unsigned long id);
	int (*status)(struct reset_controller_dev *rcdev, unsigned long id);
};

struct module;
struct device_node;
struct of_phandle_args;

/**
 * struct reset_controller_dev - reset controller entity that might
 *                               provide multiple reset controls
 * @ops: a pointer to device specific struct reset_control_ops
 * @owner: kernel module of the reset controller driver
 * @list: internal list of reset controller devices
 * @reset_control_head: head of internal list of requested reset controls
 * @of_node: corresponding device tree node as phandle target
 * @of_reset_n_cells: number of cells in reset line specifiers
 * @of_xlate: translation function to translate from specifier as found in the
 *            device tree to id as given to the reset control ops
 * @nr_resets: number of reset controls in this reset controller device
 */
struct reset_controller_dev {
	const struct reset_control_ops *ops;
	struct module *owner;
	struct list_head list;
	struct list_head reset_control_head;
	struct device_node *of_node;
	int of_reset_n_cells;
	int (*of_xlate)(struct reset_controller_dev *rcdev,
			const struct of_phandle_args *reset_spec);
	unsigned int nr_resets;
};

int reset_controller_register(struct reset_controller_dev *rcdev);
void reset_controller_unregister(struct reset_controller_dev *rcdev);

struct device;
int devm_reset_controller_register(struct device *dev,
				   struct reset_controller_dev *rcdev);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        /*
 * powercap.h: Data types and headers for sysfs power capping interface
 * Copyright (c) 2013, Intel Corporation.
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms and conditions of the GNU General Public License,
 * version 2, as published by the Free Software Foundation.
 *
 * This program is distributed in the hope it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.
 *
 * You should have received a copy of the GNU General Public License along with
 * this program; if not, write to the Free Software Foundation, Inc.
 *
 */

#ifndef __POWERCAP_H__
#define __POWERCAP_H__

#include <linux/device.h>
#include <linux/idr.h>

/*
 * A power cap class device can contain multiple powercap control_types.
 * Each control_type can have multiple power zones, which can be independently
 * controlled. Each power zone can have one or more constraints.
 */

struct powercap_control_type;
struct powercap_zone;
struct powercap_zone_constraint;

/**
 * struct powercap_control_type_ops - Define control type callbacks
 * @set_enable:		Enable/Disable whole control type.
 *			Default is enabled. But this callback allows all zones
 *			to be in disable state and remove any applied power
 *			limits. If disabled power zone can only be monitored
 *			not controlled.
 * @get_enable:		get Enable/Disable status.
 * @release:		Callback to inform that last reference to this
 *			control type is closed. So it is safe to free data
 *			structure associated with this control type.
 *			This callback is mandatory if the client own memory
 *			for the control type.
 *
 * This structure defines control type callbacks to be implemented by client
 * drivers
 */
struct powercap_control_type_ops {
	int (*set_enable) (struct powercap_control_type *, bool mode);
	int (*get_enable) (struct powercap_control_type *, bool *mode);
	int (*release) (struct powercap_control_type *);
};

/**
 * struct powercap_control_type- Defines a powercap control_type
 * @name:		name of control_type
 * @dev:		device for this control_type
 * @idr:		idr to have unique id for its child
 * @root_node:		Root holding power zones for this control_type
 * @ops:		Pointer to callback struct
 * @node_lock:		mutex for control type
 * @allocated:		This is possible that client owns the memory
 *			used by this structure. In this case
 *			this flag is set to false by framework to
 *			prevent deallocation during release process.
 *			Otherwise this flag is set to true.
 * @ctrl_inst:		link to the control_type list
 *
 * Defines powercap control_type. This acts as a container for power
 * zones, which use same method to control power. E.g. RAPL, RAPL-PCI etc.
 * All fields are private and should not be used by client drivers.
 */
struct powercap_control_type {
	struct device dev;
	struct idr idr;
	int nr_zones;
	const struct powercap_control_type_ops *ops;
	struct mutex lock;
	bool allocated;
	struct list_head node;
};

/**
 * struct powercap_zone_ops - Define power zone callbacks
 * @get_max_energy_range_uj:	Get maximum range of energy counter in
 *				micro-joules.
 * @get_energy_uj:		Get current energy counter in micro-joules.
 * @reset_energy_uj:		Reset micro-joules energy counter.
 * @get_max_power_range_uw:	Get maximum range of power counter in
 *				micro-watts.
 * @get_power_uw:		Get current power counter in micro-watts.
 * @set_enable:			Enable/Disable power zone controls.
 *				Default is enabled.
 * @get_enable:			get Enable/Disable status.
 * @release:			Callback to inform that last reference to this
 *				control type is closed. So it is safe to free
 *				data structure associated with this
 *				control type. Mandatory, if client driver owns
 *				the power_zone memory.
 *
 * This structure defines zone callbacks to be implemented by client drivers.
 * Client drives can define both energy and power related callbacks. But at
 * the least one type (either power or energy) is mandatory. Client drivers
 * should handle mutual exclusion, if required in callbacks.
 */
struct powercap_zone_ops {
	int (*get_max_energy_range_uj) (struct powercap_zone *, u64 *);
	int (*get_energy_uj) (struct powercap_zone *, u64 *);
	int (*reset_energy_uj) (struct powercap_zone *);
	int (*get_max_power_range_uw) (struct powercap_zone *, u64 *);
	int (*get_power_uw) (struct powercap_zone *, u64 *);
	int (*set_enable) (struct powercap_zone *, bool mode);
	int (*get_enable) (struct powercap_zone *, bool *mode);
	int (*release) (struct powercap_zone *);
};

#define	POWERCAP_ZONE_MAX_ATTRS		6
#define	POWERCAP_CONSTRAINTS_ATTRS	8
#define MAX_CONSTRAINTS_PER_ZONE	10
/**
 * struct powercap_zone- Defines instance of a power cap zone
 * @id:			Unique id
 * @name:		Power zone name.
 * @control_type_inst:	Control type instance for this zone.
 * @ops:		Pointer to the zone operation structure.
 * @dev:		Instance of a device.
 * @const_id_cnt:	Number of constraint defined.
 * @idr:		Instance to an idr entry for children zones.
 * @parent_idr:		To remove reference from the parent idr.
 * @private_data:	Private data pointer if any for this zone.
 * @zone_dev_attrs:	Attributes associated with this device.
 * @zone_attr_count:	Attribute count.
 * @dev_zone_attr_group: Attribute group for attributes.
 * @dev_attr_groups:	Attribute group store to register with device.
 * @allocated:		This is possible that client owns the memory
 *			used by this structure. In this case
 *			this flag is set to false by framework to
 *			prevent deallocation during release process.
 *			Otherwise this flag is set to true.
 * @constraint_ptr:	List of constraints for this zone.
 *
 * This defines a power zone instance. The fields of this structure are
 * private, and should not be used by client drivers.
 */
struct powercap_zone {
	int id;
	char *name;
	void *control_type_inst;
	const struct powercap_zone_ops *ops;
	struct device dev;
	int const_id_cnt;
	struct idr idr;
	struct idr *parent_idr;
	void *private_data;
	struct attribute **zone_dev_attrs;
	int zone_attr_count;
	struct attribute_group dev_zone_attr_group;
	const struct attribute_group *dev_attr_groups[2]; /* 1 group + NULL */
	bool allocated;
	struct powercap_zone_constraint *constraints;
};

/**
 * struct powercap_zone_constraint_ops - Define constraint callbacks
 * @set_power_limit_uw:		Set power limit in micro-watts.
 * @get_power_limit_uw:		Get power limit in micro-watts.
 * @set_time_window_us:		Set time window in micro-seconds.
 * @get_time_window_us:		Get time window in micro-seconds.
 * @get_max_power_uw:		Get max power allowed in micro-watts.
 * @get_min_power_uw:		Get min power allowed in micro-watts.
 * @get_max_time_window_us:	Get max time window allowed in micro-seconds.
 * @get_min_time_window_us:	Get min time window allowed in micro-seconds.
 * @get_name:			Get the name of constraint
 *
 * This structure is used to define the constraint callbacks for the client
 * drivers. The following callbacks are mandatory and can't be NULL:
 *  set_power_limit_uw
 *  get_power_limit_uw
 *  set_time_window_us
 *  get_time_window_us
 *  get_name
 *  Client drivers should handle mutual exclusion, if required in callbacks.
 */
struct powercap_zone_constraint_ops {
	int (*set_power_limit_uw) (struct powercap_zone *, int, u64);
	int (*get_power_limit_uw) (struct powercap_zone *, int, u64 *);
	int (*set_time_window_us) (struct powercap_zone *, int, u64);
	int (*get_time_window_us) (struct powercap_zone *, int, u64 *);
	int (*get_max_power_uw) (struct powercap_zone *, int, u64 *);
	int (*get_min_power_uw) (struct powercap_zone *, int, u64 *);
	int (*get_max_time_window_us) (struct powercap_zone *, int, u64 *);
	int (*get_min_time_window_us) (struct powercap_zone *, int, u64 *);
	const char *(*get_name) (struct powercap_zone *, int);
};

/**
 * struct powercap_zone_constraint- Defines instance of a constraint
 * @id:			Instance Id of this constraint.
 * @power_zone:		Pointer to the power zone for this constraint.
 * @ops:		Pointer to the constraint callbacks.
 *
 * This defines a constraint instance.
 */
struct powercap_zone_constraint {
	int id;
	struct powercap_zone *power_zone;
	const struct powercap_zone_constraint_ops *ops;
};


/* For clients to get their device pointer, may be used for dev_dbgs */
#define POWERCAP_GET_DEV(power_zone)	(&power_zone->dev)

/**
* powercap_set_zone_data() - Set private data for a zone
* @power_zone:	A pointer to the valid zone instance.
* @pdata:	A pointer to the user private data.
*
* Allows client drivers to associate some private data to zone instance.
*/
static inline void powercap_set_zone_data(struct powercap_zone *power_zone,
						void *pdata)
{
	if (power_zone)
		power_zone->private_data = pdata;
}

/**
* powercap_get_zone_data() - Get private data for a zone
* @power_zone:	A pointer to the valid zone instance.
*
* Allows client drivers to get private data associate with a zone,
* using call to powercap_set_zone_data.
*/
static inline void *powercap_get_zone_data(struct powercap_zone *power_zone)
{
	if (power_zone)
		return power_zone->private_data;
	return NULL;
}

/**
* powercap_register_control_type() - Register a control_type with framework
* @control_type:	Pointer to client allocated memory for the control type
*			structure storage. If this is NULL, powercap framework
*			will allocate memory and own it.
*			Advantage of this parameter is that client can embed
*			this data in its data structures and allocate in a
*			single call, preventing multiple allocations.
* @control_type_name:	The Name of this control_type, which will be shown
*			in the sysfs Interface.
* @ops:			Callbacks for control type. This parameter is optional.
*
* Used to create a control_type with the power capping class. Here control_type
* can represent a type of technology, which can control a range of power zones.
* For example a control_type can be RAPL (Running Average Power Limit)
* Intel 64 and IA-32 Processor Architectures. The name can be any string
* which must be unique, otherwise this function returns NULL.
* A pointer to the control_type instance is returned on success.
*/
struct powercap_control_type *powercap_register_control_type(
				struct powercap_control_type *control_type,
				const char *name,
				const struct powercap_control_type_ops *ops);

/**
* powercap_unregister_control_type() - Unregister a control_type from framework
* @instance:	A pointer to the valid control_type instance.
*
* Used to unregister a control_type with the power capping class.
* All power zones registered under this control type have to be unregistered
* before calling this function, or it will fail with an error code.
*/
int powercap_unregister_control_type(struct powercap_control_type *instance);

/* Zone register/unregister API */

/**
* powercap_register_zone() - Register a power zone
* @power_zone:	Pointer to client allocated memory for the power zone structure
*		storage. If this is NULL, powercap framework will allocate
*		memory and own it. Advantage of this parameter is that client
*		can embed this data in its data structures and allocate in a
*		single call, preventing multiple allocations.
* @control_type: A control_type instance under which this zone operates.
* @name:	A name for this zone.
* @parent:	A pointer to the parent power zone instance if any or NULL
* @ops:		Pointer to zone operation callback structure.
* @no_constraints: Number of constraints for this zone
* @const_ops:	Pointer to constraint callback structure
*
* Register a power zone under a given control type. A power zone must register
* a pointer to a structure representing zone callbacks.
* A power zone can be located under a parent power zone, in which case @parent
* should point to it.  Otherwise, if @parent is NULL, the new power zone will
* be located directly under the given control type
* For each power zone there may be a number of constraints that appear in the
* sysfs under that zone as attributes with unique numeric IDs.
* Returns pointer to the power_zone on success.
*/
struct powercap_zone *powercap_register_zone(
			struct powercap_zone *power_zone,
			struct powercap_control_type *control_type,
			const char *name,
			struct powercap_zone *parent,
			const struct powercap_zone_ops *ops,
			int nr_constraints,
			const struct powercap_zone_constraint_ops *const_ops);

/**
* powercap_unregister_zone() - Unregister a zone device
* @control_type:	A pointer to the valid instance of a control_type.
* @power_zone:	A pointer to the valid zone instance for a control_type
*
* Used to unregister a zone device for a control_type.  Caller should
* make sure that children for this zone are unregistered first.
*/
int powercap_unregister_zone(struct powercap_control_type *control_type,
				struct powercap_zone *power_zone);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       #ifndef _LINUX_CPUSET_H
#define _LINUX_CPUSET_H
/*
 *  cpuset interface
 *
 *  Copyright (C) 2003 BULL SA
 *  Copyright (C) 2004-2006 Silicon Graphics, Inc.
 *
 */

#include <linux/sched.h>
#include <linux/cpumask.h>
#include <linux/nodemask.h>
#include <linux/mm.h>
#include <linux/jump_label.h>

#ifdef CONFIG_CPUSETS

/*
 * Static branch rewrites can happen in an arbitrary order for a given
 * key. In code paths where we need to loop with read_mems_allowed_begin() and
 * read_mems_allowed_retry() to get a consistent view of mems_allowed, we need
 * to ensure that begin() always gets rewritten before retry() in the
 * disabled -> enabled transition. If not, then if local irqs are disabled
 * around the loop, we can deadlock since retry() would always be
 * comparing the latest value of the mems_allowed seqcount against 0 as
 * begin() still would see cpusets_enabled() as false. The enabled -> disabled
 * transition should happen in reverse order for the same reasons (want to stop
 * looking at real value of mems_allowed.sequence in retry() first).
 */
extern struct static_key_false cpusets_pre_enable_key;
extern struct static_key_false cpusets_enabled_key;
static inline bool cpusets_enabled(void)
{
	return static_branch_unlikely(&cpusets_enabled_key);
}

static inline int nr_cpusets(void)
{
	/* jump label reference count + the top-level cpuset */
	return static_key_count(&cpusets_enabled_key.key) + 1;
}

static inline void cpuset_inc(void)
{
	static_branch_inc(&cpusets_pre_enable_key);
	static_branch_inc(&cpusets_enabled_key);
}

static inline void cpuset_dec(void)
{
	static_branch_dec(&cpusets_enabled_key);
	static_branch_dec(&cpusets_pre_enable_key);
}

extern int cpuset_init(void);
extern void cpuset_init_smp(void);
extern void cpuset_force_rebuild(void);
extern void cpuset_update_active_cpus(bool cpu_online);
extern void cpuset_wait_for_hotplug(void);
extern void cpuset_cpus_allowed(struct task_struct *p, struct cpumask *mask);
extern void cpuset_cpus_allowed_fallback(struct task_struct *p);
extern nodemask_t cpuset_mems_allowed(struct task_struct *p);
#define cpuset_current_mems_allowed (current->mems_allowed)
void cpuset_init_current_mems_allowed(void);
int cpuset_nodemask_valid_mems_allowed(nodemask_t *nodemask);

extern bool __cpuset_node_allowed(int node, gfp_t gfp_mask);

static inline bool cpuset_node_allowed(int node, gfp_t gfp_mask)
{
	if (cpusets_enabled())
		return __cpuset_node_allowed(node, gfp_mask);
	return true;
}

static inline bool __cpuset_zone_allowed(struct zone *z, gfp_t gfp_mask)
{
	return __cpuset_node_allowed(zone_to_nid(z), gfp_mask);
}

static inline bool cpuset_zone_allowed(struct zone *z, gfp_t gfp_mask)
{
	if (cpusets_enabled())
		return __cpuset_zone_allowed(z, gfp_mask);
	return true;
}

extern int cpuset_mems_allowed_intersects(const struct task_struct *tsk1,
					  const struct task_struct *tsk2);

#define cpuset_memory_pressure_bump() 				\
	do {							\
		if (cpuset_memory_pressure_enabled)		\
			__cpuset_memory_pressure_bump();	\
	} while (0)
extern int cpuset_memory_pressure_enabled;
extern void __cpuset_memory_pressure_bump(void);

extern void cpuset_task_status_allowed(struct seq_file *m,
					struct task_struct *task);
extern int proc_cpuset_show(struct seq_file *m, struct pid_namespace *ns,
			    struct pid *pid, struct task_struct *tsk);

extern int cpuset_mem_spread_node(void);
extern int cpuset_slab_spread_node(void);

static inline int cpuset_do_page_mem_spread(void)
{
	return task_spread_page(current);
}

static inline int cpuset_do_slab_mem_spread(void)
{
	return task_spread_slab(current);
}

extern int current_cpuset_is_being_rebound(void);

extern void rebuild_sched_domains(void);

extern void cpuset_print_current_mems_allowed(void);

/*
 * read_mems_allowed_begin is required when making decisions involving
 * mems_allowed such as during page allocation. mems_allowed can be updated in
 * parallel and depending on the new value an operation can fail potentially
 * causing process failure. A retry loop with read_mems_allowed_begin and
 * read_mems_allowed_retry prevents these artificial failures.
 */
static inline unsigned int read_mems_allowed_begin(void)
{
	if (!static_branch_unlikely(&cpusets_pre_enable_key))
		return 0;

	return read_seqcount_begin(&current->mems_allowed_seq);
}

/*
 * If this returns true, the operation that took place after
 * read_mems_allowed_begin may have failed artificially due to a concurrent
 * update of mems_allowed. It is up to the caller to retry the operation if
 * appropriate.
 */
static inline bool read_mems_allowed_retry(unsigned int seq)
{
	if (!static_branch_unlikely(&cpusets_enabled_key))
		return false;

	return read_seqcount_retry(&current->mems_allowed_seq, seq);
}

static inline void set_mems_allowed(nodemask_t nodemask)
{
	unsigned long flags;

	task_lock(current);
	local_irq_save(flags);
	write_seqcount_begin(&current->mems_allowed_seq);
	current->mems_allowed = nodemask;
	write_seqcount_end(&current->mems_allowed_seq);
	local_irq_restore(flags);
	task_unlock(current);
}

#else /* !CONFIG_CPUSETS */

static inline bool cpusets_enabled(void) { return false; }

static inline int cpuset_init(void) { return 0; }
static inline void cpuset_init_smp(void) {}

static inline void cpuset_force_rebuild(void) { }

static inline void cpuset_update_active_cpus(bool cpu_online)
{
	partition_sched_domains(1, NULL, NULL);
}

static inline void cpuset_wait_for_hotplug(void) { }

static inline void cpuset_cpus_allowed(struct task_struct *p,
				       struct cpumask *mask)
{
	cpumask_copy(mask, cpu_possible_mask);
}

static inline void cpuset_cpus_allowed_fallback(struct task_struct *p)
{
}

static inline nodemask_t cpuset_mems_allowed(struct task_struct *p)
{
	return node_possible_map;
}

#define cpuset_current_mems_allowed (node_states[N_MEMORY])
static inline void cpuset_init_current_mems_allowed(void) {}

static inline int cpuset_nodemask_valid_mems_allowed(nodemask_t *nodemask)
{
	return 1;
}

static inline bool cpuset_node_allowed(int node, gfp_t gfp_mask)
{
	return true;
}

static inline bool __cpuset_zone_allowed(struct zone *z, gfp_t gfp_mask)
{
	return true;
}

static inline bool cpuset_zone_allowed(struct zone *z, gfp_t gfp_mask)
{
	return true;
}

static inline int cpuset_mems_allowed_intersects(const struct task_struct *tsk1,
						 const struct task_struct *tsk2)
{
	return 1;
}

static inline void cpuset_memory_pressure_bump(void) {}

static inline void cpuset_task_status_allowed(struct seq_file *m,
						struct task_struct *task)
{
}

static inline int cpuset_mem_spread_node(void)
{
	return 0;
}

static inline int cpuset_slab_spread_node(void)
{
	return 0;
}

static inline int cpuset_do_page_mem_spread(void)
{
	return 0;
}

static inline int cpuset_do_slab_mem_spread(void)
{
	return 0;
}

static inline int current_cpuset_is_being_rebound(void)
{
	return 0;
}

static inline void rebuild_sched_domains(void)
{
	partition_sched_domains(1, NULL, NULL);
}

static inline void cpuset_print_current_mems_allowed(void)
{
}

static inline void set_mems_allowed(nodemask_t nodemask)
{
}

static inline unsigned int read_mems_allowed_begin(void)
{
	return 0;
}

static inline bool read_mems_allowed_retry(unsigned int seq)
{
	return false;
}

#endif /* !CONFIG_CPUSETS */

#endif /* _LINUX_CPUSET_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             /*
 * efs_vh.h
 *
 * Copyright (c) 1999 Al Smith
 *
 * Portions derived from IRIX header files (c) 1985 MIPS Computer Systems, Inc.
 */

#ifndef __EFS_VH_H__
#define __EFS_VH_H__

#define VHMAGIC		0xbe5a941	/* volume header magic number */
#define NPARTAB		16		/* 16 unix partitions */
#define NVDIR		15		/* max of 15 directory entries */
#define BFNAMESIZE	16		/* max 16 chars in boot file name */
#define VDNAMESIZE	8

struct volume_directory {
	char	vd_name[VDNAMESIZE];	/* name */
	__be32	vd_lbn;			/* logical block number */
	__be32	vd_nbytes;		/* file length in bytes */
};

struct partition_table {	/* one per logical partition */
	__be32	pt_nblks;	/* # of logical blks in partition */
	__be32	pt_firstlbn;	/* first lbn of partition */
	__be32	pt_type;	/* use of partition */
};

struct volume_header {
	__be32	vh_magic;			/* identifies volume header */
	__be16	vh_rootpt;			/* root partition number */
	__be16	vh_swappt;			/* swap partition number */
	char	vh_bootfile[BFNAMESIZE];	/* name of file to boot */
	char	pad[48];			/* device param space */
	struct volume_directory vh_vd[NVDIR];	/* other vol hdr contents */
	struct partition_table  vh_pt[NPARTAB];	/* device partition layout */
	__be32	vh_csum;			/* volume header checksum */
	__be32	vh_fill;			/* fill out to 512 bytes */
};

/* partition type sysv is used for EFS format CD-ROM partitions */
#define SGI_SYSV	0x05
#define SGI_EFS		0x07
#define IS_EFS(x)	(((x) == SGI_EFS) || ((x) == SGI_SYSV))

struct pt_types {
	int	pt_type;
	char	*pt_name;
};

#endif /* __EFS_VH_H__ */

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /*
 * pca9532.h - platform data structure for pca9532 led controller
 *
 * Copyright (C) 2008 Riku Voipio <riku.voipio@movial.fi>
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; version 2 of the License.
 *
 * Datasheet: http://www.nxp.com/acrobat/datasheets/PCA9532_3.pdf
 *
 */

#ifndef __LINUX_PCA9532_H
#define __LINUX_PCA9532_H

#include <linux/leds.h>
#include <linux/workqueue.h>
#include <dt-bindings/leds/leds-pca9532.h>

enum pca9532_state {
	PCA9532_OFF  = 0x0,
	PCA9532_ON   = 0x1,
	PCA9532_PWM0 = 0x2,
	PCA9532_PWM1 = 0x3
};

struct pca9532_led {
	u8 id;
	struct i2c_client *client;
	const char *name;
	const char *default_trigger;
	struct led_classdev ldev;
	struct work_struct work;
	u32 type;
	enum pca9532_state state;
};

struct pca9532_platform_data {
	struct pca9532_led leds[16];
	u8 pwm[2];
	u8 psc[2];
	int gpio_base;
};

#endif /* __LINUX_PCA9532_H */

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               /*
 * rational fractions
 *
 * Copyright (C) 2009 emlix GmbH, Oskar Schirmer <oskar@scara.com>
 *
 * helper functions when coping with rational numbers,
 * e.g. when calculating optimum numerator/denominator pairs for
 * pll configuration taking into account restricted register size
 */

#ifndef _LINUX_RATIONAL_H
#define _LINUX_RATIONAL_H

void rational_best_approximation(
	unsigned long given_numerator, unsigned long given_denominator,
	unsigned long max_numerator, unsigned long max_denominator,
	unsigned long *best_numerator, unsigned long *best_denominator);

#endif /* _LINUX_RATIONAL_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        /*
 *  User level driver support for input subsystem
 *
 * Heavily based on evdev.c by Vojtech Pavlik
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
 *
 * Author: Aristeu Sergio Rozanski Filho <aris@cathedrallabs.org>
 *
 * Changes/Revisions:
 *	0.5	08/13/2015 (David Herrmann <dh.herrmann@gmail.com> &
 *			    Benjamin Tissoires <benjamin.tissoires@redhat.com>)
 *		- add UI_DEV_SETUP ioctl
 *		- add UI_ABS_SETUP ioctl
 *		- add UI_GET_VERSION ioctl
 *	0.4	01/09/2014 (Benjamin Tissoires <benjamin.tissoires@redhat.com>)
 *		- add UI_GET_SYSNAME ioctl
 *	0.3	24/05/2006 (Anssi Hannula <anssi.hannulagmail.com>)
 *		- update ff support for the changes in kernel interface
 *		- add UINPUT_VERSION
 *	0.2	16/10/2004 (Micah Dowty <micah@navi.cx>)
 *		- added force feedback support
 *             - added UI_SET_PHYS
 *	0.1	20/06/2002
 *		- first public version
 */
#ifndef __UINPUT_H_
#define __UINPUT_H_

#include <uapi/linux/uinput.h>

#define UINPUT_NAME		"uinput"
#define UINPUT_BUFFER_SIZE	16
#define UINPUT_NUM_REQUESTS	16

enum uinput_state { UIST_NEW_DEVICE, UIST_SETUP_COMPLETE, UIST_CREATED };

struct uinput_request {
	unsigned int		id;
	unsigned int		code;	/* UI_FF_UPLOAD, UI_FF_ERASE */

	int			retval;
	struct completion	done;

	union {
		unsigned int	effect_id;
		struct {
			struct ff_effect *effect;
			struct ff_effect *old;
		} upload;
	} u;
};

struct uinput_device {
	struct input_dev	*dev;
	struct mutex		mutex;
	enum uinput_state	state;
	wait_queue_head_t	waitq;
	unsigned char		ready;
	unsigned char		head;
	unsigned char		tail;
	struct input_event	buff[UINPUT_BUFFER_SIZE];
	unsigned int		ff_effects_max;

	struct uinput_request	*requests[UINPUT_NUM_REQUESTS];
	wait_queue_head_t	requests_waitq;
	spinlock_t		requests_lock;
};
#endif	/* __UINPUT_H_ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  /*
 * ipmi.h
 *
 * MontaVista IPMI interface
 *
 * Author: MontaVista Software, Inc.
 *         Corey Minyard <minyard@mvista.com>
 *         source@mvista.com
 *
 * Copyright 2002 MontaVista Software Inc.
 *
 *  This program is free software; you can redistribute it and/or modify it
 *  under the terms of the GNU General Public License as published by the
 *  Free Software Foundation; either version 2 of the License, or (at your
 *  option) any later version.
 *
 *
 *  THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESS OR IMPLIED
 *  WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
 *  MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
 *  IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
 *  INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
 *  BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
 *  OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 *  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
 *  TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
 *  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 *  You should have received a copy of the GNU General Public License along
 *  with this program; if not, write to the Free Software Foundation, Inc.,
 *  675 Mass Ave, Cambridge, MA 02139, USA.
 */
#ifndef __LINUX_IPMI_H
#define __LINUX_IPMI_H

#include <uapi/linux/ipmi.h>

#include <linux/list.h>
#include <linux/proc_fs.h>
#include <linux/acpi.h> /* For acpi_handle */

struct module;
struct device;

/* Opaque type for a IPMI message user.  One of these is needed to
   send and receive messages. */
typedef struct ipmi_user *ipmi_user_t;

/*
 * Stuff coming from the receive interface comes as one of these.
 * They are allocated, the receiver must free them with
 * ipmi_free_recv_msg() when done with the message.  The link is not
 * used after the message is delivered, so the upper layer may use the
 * link to build a linked list, if it likes.
 */
struct ipmi_recv_msg {
	struct list_head link;

	/* The type of message as defined in the "Receive Types"
	   defines above. */
	int              recv_type;

	ipmi_user_t      user;
	struct ipmi_addr addr;
	long             msgid;
	struct kernel_ipmi_msg  msg;

	/* The user_msg_data is the data supplied when a message was
	   sent, if this is a response to a sent message.  If this is
	   not a response to a sent message, then user_msg_data will
	   be NULL.  If the user above is NULL, then this will be the
	   intf. */
	void             *user_msg_data;

	/* Call this when done with the message.  It will presumably free
	   the message and do any other necessary cleanup. */
	void (*done)(struct ipmi_recv_msg *msg);

	/* Place-holder for the data, don't make any assumptions about
	   the size or existence of this, since it may change. */
	unsigned char   msg_data[IPMI_MAX_MSG_LENGTH];
};

/* Allocate and free the receive message. */
void ipmi_free_recv_msg(struct ipmi_recv_msg *msg);

struct ipmi_user_hndl {
	/* Routine type to call when a message needs to be routed to
	   the upper layer.  This will be called with some locks held,
	   the only IPMI routines that can be called are ipmi_request
	   and the alloc/free operations.  The handler_data is the
	   variable supplied when the receive handler was registered. */
	void (*ipmi_recv_hndl)(struct ipmi_recv_msg *msg,
			       void                 *user_msg_data);

	/* Called when the interface detects a watchdog pre-timeout.  If
	   this is NULL, it will be ignored for the user. */
	void (*ipmi_watchdog_pretimeout)(void *handler_data);
};

/* Create a new user of the IPMI layer on the given interface number. */
int ipmi_create_user(unsigned int          if_num,
		     struct ipmi_user_hndl *handler,
		     void                  *handler_data,
		     ipmi_user_t           *user);

/* Destroy the given user of the IPMI layer.  Note that after this
   function returns, the system is guaranteed to not call any
   callbacks for the user.  Thus as long as you destroy all the users
   before you unload a module, you will be safe.  And if you destroy
   the users before you destroy the callback structures, it should be
   safe, too. */
int ipmi_destroy_user(ipmi_user_t user);

/* Get the IPMI version of the BMC we are talking to. */
void ipmi_get_version(ipmi_user_t   user,
		      unsigned char *major,
		      unsigned char *minor);

/* Set and get the slave address and LUN that we will use for our
   source messages.  Note that this affects the interface, not just
   this user, so it will affect all users of this interface.  This is
   so some initialization code can come in and do the OEM-specific
   things it takes to determine your address (if not the BMC) and set
   it for everyone else.  Note that each channel can have its own address. */
int ipmi_set_my_address(ipmi_user_t   user,
			unsigned int  channel,
			unsigned char address);
int ipmi_get_my_address(ipmi_user_t   user,
			unsigned int  channel,
			unsigned char *address);
int ipmi_set_my_LUN(ipmi_user_t   user,
		    unsigned int  channel,
		    unsigned char LUN);
int ipmi_get_my_LUN(ipmi_user_t   user,
		    unsigned int  channel,
		    unsigned char *LUN);

/*
 * Like ipmi_request, but lets you specify the number of retries and
 * the retry time.  The retries is the number of times the message
 * will be resent if no reply is received.  If set to -1, the default
 * value will be used.  The retry time is the time in milliseconds
 * between retries.  If set to zero, the default value will be
 * used.
 *
 * Don't use this unless you *really* have to.  It's primarily for the
 * IPMI over LAN converter; since the LAN stuff does its own retries,
 * it makes no sense to do it here.  However, this can be used if you
 * have unusual requirements.
 */
int ipmi_request_settime(ipmi_user_t      user,
			 struct ipmi_addr *addr,
			 long             msgid,
			 struct kernel_ipmi_msg  *msg,
			 void             *user_msg_data,
			 int              priority,
			 int              max_retries,
			 unsigned int     retry_time_ms);

/*
 * Like ipmi_request, but with messages supplied.  This will not
 * allocate any memory, and the messages may be statically allocated
 * (just make sure to do the "done" handling on them).  Note that this
 * is primarily for the watchdog timer, since it should be able to
 * send messages even if no memory is available.  This is subject to
 * change as the system changes, so don't use it unless you REALLY
 * have to.
 */
int ipmi_request_supply_msgs(ipmi_user_t          user,
			     struct ipmi_addr     *addr,
			     long                 msgid,
			     struct kernel_ipmi_msg *msg,
			     void                 *user_msg_data,
			     void                 *supplied_smi,
			     struct ipmi_recv_msg *supplied_recv,
			     int                  priority);

/*
 * Poll the IPMI interface for the user.  This causes the IPMI code to
 * do an immediate check for information from the driver and handle
 * anything that is immediately pending.  This will not block in any
 * way.  This is useful if you need to spin waiting for something to
 * happen in the IPMI driver.
 */
void ipmi_poll_interface(ipmi_user_t user);

/*
 * When commands come in to the SMS, the user can register to receive
 * them.  Only one user can be listening on a specific netfn/cmd/chan tuple
 * at a time, you will get an EBUSY error if the command is already
 * registered.  If a command is received that does not have a user
 * registered, the driver will automatically return the proper
 * error.  Channels are specified as a bitfield, use IPMI_CHAN_ALL to
 * mean all channels.
 */
int ipmi_register_for_cmd(ipmi_user_t   user,
			  unsigned char netfn,
			  unsigned char cmd,
			  unsigned int  chans);
int ipmi_unregister_for_cmd(ipmi_user_t   user,
			    unsigned char netfn,
			    unsigned char cmd,
			    unsigned int  chans);

/*
 * Go into a mode where the driver will not autonomously attempt to do
 * things with the interface.  It will still respond to attentions and
 * interrupts, and it will expect that commands will complete.  It
 * will not automatcially check for flags, events, or things of that
 * nature.
 *
 * This is primarily used for firmware upgrades.  The idea is that
 * when you go into firmware upgrade mode, you do this operation
 * and the driver will not attempt to do anything but what you tell
 * it or what the BMC asks for.
 *
 * Note that if you send a command that resets the BMC, the driver
 * will still expect a response from that command.  So the BMC should
 * reset itself *after* the response is sent.  Resetting before the
 * response is just silly.
 *
 * If in auto maintenance mode, the driver will automatically go into
 * maintenance mode for 30 seconds if it sees a cold reset, a warm
 * reset, or a firmware NetFN.  This means that code that uses only
 * firmware NetFN commands to do upgrades will work automatically
 * without change, assuming it sends a message every 30 seconds or
 * less.
 *
 * See the IPMI_MAINTENANCE_MODE_xxx defines for what the mode means.
 */
int ipmi_get_maintenance_mode(ipmi_user_t user);
int ipmi_set_maintenance_mode(ipmi_user_t user, int mode);

/*
 * When the user is created, it will not receive IPMI events by
 * default.  The user must set this to TRUE to get incoming events.
 * The first user that sets this to TRUE will receive all events that
 * have been queued while no one was waiting for events.
 */
int ipmi_set_gets_events(ipmi_user_t user, bool val);

/*
 * Called when a new SMI is registered.  This will also be called on
 * every existing interface when a new watcher is registered with
 * ipmi_smi_watcher_register().
 */
struct ipmi_smi_watcher {
	struct list_head link;

	/* You must set the owner to the current module, if you are in
	   a module (generally just set it to "THIS_MODULE"). */
	struct module *owner;

	/* These two are called with read locks held for the interface
	   the watcher list.  So you can add and remove users from the
	   IPMI interface, send messages, etc., but you cannot add
	   or remove SMI watchers or SMI interfaces. */
	void (*new_smi)(int if_num, struct device *dev);
	void (*smi_gone)(int if_num);
};

int ipmi_smi_watcher_register(struct ipmi_smi_watcher *watcher);
int ipmi_smi_watcher_unregister(struct ipmi_smi_watcher *watcher);

/* The following are various helper functions for dealing with IPMI
   addresses. */

/* Return the maximum length of an IPMI address given it's type. */
unsigned int ipmi_addr_length(int addr_type);

/* Validate that the given IPMI address is valid. */
int ipmi_validate_addr(struct ipmi_addr *addr, int len);

/*
 * How did the IPMI driver find out about the device?
 */
enum ipmi_addr_src {
	SI_INVALID = 0, SI_HOTMOD, SI_HARDCODED, SI_SPMI, SI_ACPI, SI_SMBIOS,
	SI_PCI,	SI_DEVICETREE, SI_LAST
};
const char *ipmi_addr_src_to_str(enum ipmi_addr_src src);

union ipmi_smi_info_union {
#ifdef CONFIG_ACPI
	/*
	 * the acpi_info element is defined for the SI_ACPI
	 * address type
	 */
	struct {
		acpi_handle acpi_handle;
	} acpi_info;
#endif
};

struct ipmi_smi_info {
	enum ipmi_addr_src addr_src;

	/*
	 * Base device for the interface.  Don't forget to put this when
	 * you are done.
	 */
	struct device *dev;

	/*
	 * The addr_info provides more detailed info for some IPMI
	 * devices, depending on the addr_src.  Currently only SI_ACPI
	 * info is provided.
	 */
	union ipmi_smi_info_union addr_info;
};

/* This is to get the private info of ipmi_smi_t */
extern int ipmi_get_smi_info(int if_num, struct ipmi_smi_info *data);

#endif /* __LINUX_IPMI_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                /* Generic associative array implementation.
 *
 * See Documentation/assoc_array.txt for information.
 *
 * Copyright (C) 2013 Red Hat, Inc. All Rights Reserved.
 * Written by David Howells (dhowells@redhat.com)
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public Licence
 * as published by the Free Software Foundation; either version
 * 2 of the Licence, or (at your option) any later version.
 */

#ifndef _LINUX_ASSOC_ARRAY_H
#define _LINUX_ASSOC_ARRAY_H

#ifdef CONFIG_ASSOCIATIVE_ARRAY

#include <linux/types.h>

#define ASSOC_ARRAY_KEY_CHUNK_SIZE BITS_PER_LONG /* Key data retrieved in chunks of this size */

/*
 * Generic associative array.
 */
struct assoc_array {
	struct assoc_array_ptr	*root;		/* The node at the root of the tree */
	unsigned long		nr_leaves_on_tree;
};

/*
 * Operations on objects and index keys for use by array manipulation routines.
 */
struct assoc_array_ops {
	/* Method to get a chunk of an index key from caller-supplied data */
	unsigned long (*get_key_chunk)(const void *index_key, int level);

	/* Method to get a piece of an object's index key */
	unsigned long (*get_object_key_chunk)(const void *object, int level);

	/* Is this the object we're looking for? */
	bool (*compare_object)(const void *object, const void *index_key);

	/* How different is an object from an index key, to a bit position in
	 * their keys? (or -1 if they're the same)
	 */
	int (*diff_objects)(const void *object, const void *index_key);

	/* Method to free an object. */
	void (*free_object)(void *object);
};

/*
 * Access and manipulation functions.
 */
struct assoc_array_edit;

static inline void assoc_array_init(struct assoc_array *array)
{
	array->root = NULL;
	array->nr_leaves_on_tree = 0;
}

extern int assoc_array_iterate(const struct assoc_array *array,
			       int (*iterator)(const void *object,
					       void *iterator_data),
			       void *iterator_data);
extern void *assoc_array_find(const struct assoc_array *array,
			      const struct assoc_array_ops *ops,
			      const void *index_key);
extern void assoc_array_destroy(struct assoc_array *array,
				const struct assoc_array_ops *ops);
extern struct assoc_array_edit *assoc_array_insert(struct assoc_array *array,
						   const struct assoc_array_ops *ops,
						   const void *index_key,
						   void *object);
extern void assoc_array_insert_set_object(struct assoc_array_edit *edit,
					  void *object);
extern struct assoc_array_edit *assoc_array_delete(struct assoc_array *array,
						   const struct assoc_array_ops *ops,
						   const void *index_key);
extern struct assoc_array_edit *assoc_array_clear(struct assoc_array *array,
						  const struct assoc_array_ops *ops);
extern void assoc_array_apply_edit(struct assoc_array_edit *edit);
extern void assoc_array_cancel_edit(struct assoc_array_edit *edit);
extern int assoc_array_gc(struct assoc_array *array,
			  const struct assoc_array_ops *ops,
			  bool (*iterator)(void *object, void *iterator_data),
			  void *iterator_data);

#endif /* CONFIG_ASSOCIATIVE_ARRAY */
#endif /* _LINUX_ASSOC_ARRAY_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     #ifndef LINUX_HTIRQ_H
#define LINUX_HTIRQ_H

struct pci_dev;
struct irq_data;

struct ht_irq_msg {
	u32	address_lo;	/* low 32 bits of the ht irq message */
	u32	address_hi;	/* high 32 bits of the it irq message */
};

typedef void (ht_irq_update_t)(struct pci_dev *dev, int irq,
			       struct ht_irq_msg *msg);

struct ht_irq_cfg {
	struct pci_dev *dev;
	 /* Update callback used to cope with buggy hardware */
	ht_irq_update_t *update;
	unsigned pos;
	unsigned idx;
	struct ht_irq_msg msg;
};

/* Helper functions.. */
void fetch_ht_irq_msg(unsigned int irq, struct ht_irq_msg *msg);
void write_ht_irq_msg(unsigned int irq, struct ht_irq_msg *msg);
void mask_ht_irq(struct irq_data *data);
void unmask_ht_irq(struct irq_data *data);

/* The arch hook for getting things started */
int arch_setup_ht_irq(int idx, int pos, struct pci_dev *dev,
		      ht_irq_update_t *update);
void arch_teardown_ht_irq(unsigned int irq);

/* For drivers of buggy hardware */
int __ht_create_irq(struct pci_dev *dev, int idx, ht_irq_update_t *update);

#endif /* LINUX_HTIRQ_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      /*
 * PM2301 charger driver.
 *
 * Copyright (C) 2012 ST Ericsson Corporation
 *
 * Contact: Olivier LAUNAY (olivier.launay@stericsson.com
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * version 2 as published by the Free Software Foundation.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
 * 02110-1301 USA
 */

#ifndef __LINUX_PM2301_H
#define __LINUX_PM2301_H

/**
 * struct pm2xxx_bm_charger_parameters - Charger specific parameters
 * @ac_volt_max:	maximum allowed AC charger voltage in mV
 * @ac_curr_max:	maximum allowed AC charger current in mA
 */
struct pm2xxx_bm_charger_parameters {
	int ac_volt_max;
	int ac_curr_max;
};

/**
 * struct pm2xxx_bm_data - pm2xxx battery management data
 * @enable_overshoot    flag to enable VBAT overshoot control
 * @chg_params	  charger parameters
 */
struct pm2xxx_bm_data {
	bool enable_overshoot;
	const struct pm2xxx_bm_charger_parameters *chg_params;
};

struct pm2xxx_charger_platform_data {
	char **supplied_to;
	size_t num_supplicants;
	int i2c_bus;
	const char *label;
	int gpio_irq_number;
	unsigned int lpn_gpio;
	int irq_type;
};

struct pm2xxx_platform_data {
	struct pm2xxx_charger_platform_data *wall_charger;
	struct pm2xxx_bm_data *battery;
};

#endif /* __LINUX_PM2301_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     #ifndef __LINUX_MAPLE_H
#define __LINUX_MAPLE_H

#include <mach/maple.h>

struct device;
extern struct bus_type maple_bus_type;

/* Maple Bus command and response codes */
enum maple_code {
	MAPLE_RESPONSE_FILEERR =	-5,
	MAPLE_RESPONSE_AGAIN,	/* retransmit */
	MAPLE_RESPONSE_BADCMD,
	MAPLE_RESPONSE_BADFUNC,
	MAPLE_RESPONSE_NONE,	/* unit didn't respond*/
	MAPLE_COMMAND_DEVINFO =		1,
	MAPLE_COMMAND_ALLINFO,
	MAPLE_COMMAND_RESET,
	MAPLE_COMMAND_KILL,
	MAPLE_RESPONSE_DEVINFO,
	MAPLE_RESPONSE_ALLINFO,
	MAPLE_RESPONSE_OK,
	MAPLE_RESPONSE_DATATRF,
	MAPLE_COMMAND_GETCOND,
	MAPLE_COMMAND_GETMINFO,
	MAPLE_COMMAND_BREAD,
	MAPLE_COMMAND_BWRITE,
	MAPLE_COMMAND_BSYNC,
	MAPLE_COMMAND_SETCOND,
	MAPLE_COMMAND_MICCONTROL
};

enum maple_file_errors {
	MAPLE_FILEERR_INVALID_PARTITION =	0x01000000,
	MAPLE_FILEERR_PHASE_ERROR =		0x02000000,
	MAPLE_FILEERR_INVALID_BLOCK =		0x04000000,
	MAPLE_FILEERR_WRITE_ERROR =		0x08000000,
	MAPLE_FILEERR_INVALID_WRITE_LENGTH =	0x10000000,
	MAPLE_FILEERR_BAD_CRC = 		0x20000000
};

struct maple_buffer {
	char bufx[0x400];
	void *buf;
};

struct mapleq {
	struct list_head list;
	struct maple_device *dev;
	struct maple_buffer *recvbuf;
	void *sendbuf, *recvbuf_p2;
	unsigned char length;
	enum maple_code command;
};

struct maple_devinfo {
	unsigned long function;
	unsigned long function_data[3];
	unsigned char area_code;
	unsigned char connector_direction;
	char product_name[31];
	char product_licence[61];
	unsigned short standby_power;
	unsigned short max_power;
};

struct maple_device {
	struct maple_driver *driver;
	struct mapleq *mq;
	void (*callback) (struct mapleq * mq);
	void (*fileerr_handler)(struct maple_device *mdev, void *recvbuf);
	int (*can_unload)(struct maple_device *mdev);
	unsigned long when, interval, function;
	struct maple_devinfo devinfo;
	unsigned char port, unit;
	char product_name[32];
	char product_licence[64];
	atomic_t busy;
	wait_queue_head_t maple_wait;
	struct device dev;
};

struct maple_driver {
	unsigned long function;
	struct device_driver drv;
};

void maple_getcond_callback(struct maple_device *dev,
			    void (*callback) (struct mapleq * mq),
			    unsigned long interval,
			    unsigned long function);
int maple_driver_register(struct maple_driver *);
void maple_driver_unregister(struct maple_driver *);

int maple_add_packet(struct maple_device *mdev, u32 function,
	u32 command, u32 length, void *data);
void maple_clear_dev(struct maple_device *mdev);

#define to_maple_dev(n) container_of(n, struct maple_device, dev)
#define to_maple_driver(n) container_of(n, struct maple_driver, drv)

#define maple_get_drvdata(d)		dev_get_drvdata(&(d)->dev)
#define maple_set_drvdata(d,p)		dev_set_drvdata(&(d)->dev, (p))

#endif				/* __LINUX_MAPLE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                /*
 * This provides the callbacks and functions that KGDB needs to share between
 * the core, I/O and arch-specific portions.
 *
 * Author: Amit Kale <amitkale@linsyssoft.com> and
 *         Tom Rini <trini@kernel.crashing.org>
 *
 * 2001-2004 (c) Amit S. Kale and 2003-2005 (c) MontaVista Software, Inc.
 * This file is licensed under the terms of the GNU General Public License
 * version 2. This program is licensed "as is" without any warranty of any
 * kind, whether express or implied.
 */
#ifndef _KGDB_H_
#define _KGDB_H_

#include <linux/linkage.h>
#include <linux/init.h>
#include <linux/atomic.h>
#ifdef CONFIG_HAVE_ARCH_KGDB
#include <asm/kgdb.h>
#endif

#ifdef CONFIG_KGDB
struct pt_regs;

/**
 *	kgdb_skipexception - (optional) exit kgdb_handle_exception early
 *	@exception: Exception vector number
 *	@regs: Current &struct pt_regs.
 *
 *	On some architectures it is required to skip a breakpoint
 *	exception when it occurs after a breakpoint has been removed.
 *	This can be implemented in the architecture specific portion of kgdb.
 */
extern int kgdb_skipexception(int exception, struct pt_regs *regs);

struct tasklet_struct;
struct task_struct;
struct uart_port;

/**
 *	kgdb_breakpoint - compiled in breakpoint
 *
 *	This will be implemented as a static inline per architecture.  This
 *	function is called by the kgdb core to execute an architecture
 *	specific trap to cause kgdb to enter the exception processing.
 *
 */
void kgdb_breakpoint(void);

extern int kgdb_connected;
extern int kgdb_io_module_registered;

extern atomic_t			kgdb_setting_breakpoint;
extern atomic_t			kgdb_cpu_doing_single_step;

extern struct task_struct	*kgdb_usethread;
extern struct task_struct	*kgdb_contthread;

enum kgdb_bptype {
	BP_BREAKPOINT = 0,
	BP_HARDWARE_BREAKPOINT,
	BP_WRITE_WATCHPOINT,
	BP_READ_WATCHPOINT,
	BP_ACCESS_WATCHPOINT,
	BP_POKE_BREAKPOINT,
};

enum kgdb_bpstate {
	BP_UNDEFINED = 0,
	BP_REMOVED,
	BP_SET,
	BP_ACTIVE
};

struct kgdb_bkpt {
	unsigned long		bpt_addr;
	unsigned char		saved_instr[BREAK_INSTR_SIZE];
	enum kgdb_bptype	type;
	enum kgdb_bpstate	state;
};

struct dbg_reg_def_t {
	char *name;
	int size;
	int offset;
};

#ifndef DBG_MAX_REG_NUM
#define DBG_MAX_REG_NUM 0
#else
extern struct dbg_reg_def_t dbg_reg_def[];
extern char *dbg_get_reg(int regno, void *mem, struct pt_regs *regs);
extern int dbg_set_reg(int regno, void *mem, struct pt_regs *regs);
#endif
#ifndef KGDB_MAX_BREAKPOINTS
# define KGDB_MAX_BREAKPOINTS	1000
#endif

#define KGDB_HW_BREAKPOINT	1

/*
 * Functions each KGDB-supporting architecture must provide:
 */

/**
 *	kgdb_arch_init - Perform any architecture specific initalization.
 *
 *	This function will handle the initalization of any architecture
 *	specific callbacks.
 */
extern int kgdb_arch_init(void);

/**
 *	kgdb_arch_exit - Perform any architecture specific uninitalization.
 *
 *	This function will handle the uninitalization of any architecture
 *	specific callbacks, for dynamic registration and unregistration.
 */
extern void kgdb_arch_exit(void);

/**
 *	pt_regs_to_gdb_regs - Convert ptrace regs to GDB regs
 *	@gdb_regs: A pointer to hold the registers in the order GDB wants.
 *	@regs: The &struct pt_regs of the current process.
 *
 *	Convert the pt_regs in @regs into the format for registers that
 *	GDB expects, stored in @gdb_regs.
 */
extern void pt_regs_to_gdb_regs(unsigned long *gdb_regs, struct pt_regs *regs);

/**
 *	sleeping_thread_to_gdb_regs - Convert ptrace regs to GDB regs
 *	@gdb_regs: A pointer to hold the registers in the order GDB wants.
 *	@p: The &struct task_struct of the desired process.
 *
 *	Convert the register values of the sleeping process in @p to
 *	the format that GDB expects.
 *	This function is called when kgdb does not have access to the
 *	&struct pt_regs and therefore it should fill the gdb registers
 *	@gdb_regs with what has	been saved in &struct thread_struct
 *	thread field during switch_to.
 */
extern void
sleeping_thread_to_gdb_regs(unsigned long *gdb_regs, struct task_struct *p);

/**
 *	gdb_regs_to_pt_regs - Convert GDB regs to ptrace regs.
 *	@gdb_regs: A pointer to hold the registers we've received from GDB.
 *	@regs: A pointer to a &struct pt_regs to hold these values in.
 *
 *	Convert the GDB regs in @gdb_regs into the pt_regs, and store them
 *	in @regs.
 */
extern void gdb_regs_to_pt_regs(unsigned long *gdb_regs, struct pt_regs *regs);

/**
 *	kgdb_arch_handle_exception - Handle architecture specific GDB packets.
 *	@vector: The error vector of the exception that happened.
 *	@signo: The signal number of the exception that happened.
 *	@err_code: The error code of the exception that happened.
 *	@remcom_in_buffer: The buffer of the packet we have read.
 *	@remcom_out_buffer: The buffer of %BUFMAX bytes to write a packet into.
 *	@regs: The &struct pt_regs of the current process.
 *
 *	This function MUST handle the 'c' and 's' command packets,
 *	as well packets to set / remove a hardware breakpoint, if used.
 *	If there are additional packets which the hardware needs to handle,
 *	they are handled here.  The code should return -1 if it wants to
 *	process more packets, and a %0 or %1 if it wants to exit from the
 *	kgdb callback.
 */
extern int
kgdb_arch_handle_exception(int vector, int signo, int err_code,
			   char *remcom_in_buffer,
			   char *remcom_out_buffer,
			   struct pt_regs *regs);

/**
 *	kgdb_roundup_cpus - Get other CPUs into a holding pattern
 *	@flags: Current IRQ state
 *
 *	On SMP systems, we need to get the attention of the other CPUs
 *	and get them into a known state.  This should do what is needed
 *	to get the other CPUs to call kgdb_wait(). Note that on some arches,
 *	the NMI approach is not used for rounding up all the CPUs. For example,
 *	in case of MIPS, smp_call_function() is used to roundup CPUs. In
 *	this case, we have to make sure that interrupts are enabled before
 *	calling smp_call_function(). The argument to this function is
 *	the flags that will be used when restoring the interrupts. There is
 *	local_irq_save() call before kgdb_roundup_cpus().
 *
 *	On non-SMP systems, this is not called.
 */
extern void kgdb_roundup_cpus(unsigned long flags);

/**
 *	kgdb_arch_set_pc - Generic call back to the program counter
 *	@regs: Current &struct pt_regs.
 *  @pc: The new value for the program counter
 *
 *	This function handles updating the program counter and requires an
 *	architecture specific implementation.
 */
extern void kgdb_arch_set_pc(struct pt_regs *regs, unsigned long pc);


/* Optional functions. */
extern int kgdb_validate_break_address(unsigned long addr);
extern int kgdb_arch_set_breakpoint(struct kgdb_bkpt *bpt);
extern int kgdb_arch_remove_breakpoint(struct kgdb_bkpt *bpt);

/**
 *	kgdb_arch_late - Perform any architecture specific initalization.
 *
 *	This function will handle the late initalization of any
 *	architecture specific callbacks.  This is an optional function for
 *	handling things like late initialization of hw breakpoints.  The
 *	default implementation does nothing.
 */
extern void kgdb_arch_late(void);


/**
 * struct kgdb_arch - Describe architecture specific values.
 * @gdb_bpt_instr: The instruction to trigger a breakpoint.
 * @flags: Flags for the breakpoint, currently just %KGDB_HW_BREAKPOINT.
 * @set_breakpoint: Allow an architecture to specify how to set a software
 * breakpoint.
 * @remove_breakpoint: Allow an architecture to specify how to remove a
 * software breakpoint.
 * @set_hw_breakpoint: Allow an architecture to specify how to set a hardware
 * breakpoint.
 * @remove_hw_breakpoint: Allow an architecture to specify how to remove a
 * hardware breakpoint.
 * @disable_hw_break: Allow an architecture to specify how to disable
 * hardware breakpoints for a single cpu.
 * @remove_all_hw_break: Allow an architecture to specify how to remove all
 * hardware breakpoints.
 * @correct_hw_break: Allow an architecture to specify how to correct the
 * hardware debug registers.
 * @enable_nmi: Manage NMI-triggered entry to KGDB
 */
struct kgdb_arch {
	unsigned char		gdb_bpt_instr[BREAK_INSTR_SIZE];
	unsigned long		flags;

	int	(*set_breakpoint)(unsigned long, char *);
	int	(*remove_breakpoint)(unsigned long, char *);
	int	(*set_hw_breakpoint)(unsigned long, int, enum kgdb_bptype);
	int	(*remove_hw_breakpoint)(unsigned long, int, enum kgdb_bptype);
	void	(*disable_hw_break)(struct pt_regs *regs);
	void	(*remove_all_hw_break)(void);
	void	(*correct_hw_break)(void);

	void	(*enable_nmi)(bool on);
};

/**
 * struct kgdb_io - Describe the interface for an I/O driver to talk with KGDB.
 * @name: Name of the I/O driver.
 * @read_char: Pointer to a function that will return one char.
 * @write_char: Pointer to a function that will write one char.
 * @flush: Pointer to a function that will flush any pending writes.
 * @init: Pointer to a function that will initialize the device.
 * @pre_exception: Pointer to a function that will do any prep work for
 * the I/O driver.
 * @post_exception: Pointer to a function that will do any cleanup work
 * for the I/O driver.
 * @is_console: 1 if the end device is a console 0 if the I/O device is
 * not a console
 */
struct kgdb_io {
	const char		*name;
	int			(*read_char) (void);
	void			(*write_char) (u8);
	void			(*flush) (void);
	int			(*init) (void);
	void			(*pre_exception) (void);
	void			(*post_exception) (void);
	int			is_console;
};

extern struct kgdb_arch		arch_kgdb_ops;

extern unsigned long kgdb_arch_pc(int exception, struct pt_regs *regs);

#ifdef CONFIG_SERIAL_KGDB_NMI
extern int kgdb_register_nmi_console(void);
extern int kgdb_unregister_nmi_console(void);
extern bool kgdb_nmi_poll_knock(void);
#else
static inline int kgdb_register_nmi_console(void) { return 0; }
static inline int kgdb_unregister_nmi_console(void) { return 0; }
static inline bool kgdb_nmi_poll_knock(void) { return 1; }
#endif

extern int kgdb_register_io_module(struct kgdb_io *local_kgdb_io_ops);
extern void kgdb_unregister_io_module(struct kgdb_io *local_kgdb_io_ops);
extern struct kgdb_io *dbg_io_ops;

extern int kgdb_hex2long(char **ptr, unsigned long *long_val);
extern char *kgdb_mem2hex(char *mem, char *buf, int count);
extern int kgdb_hex2mem(char *buf, char *mem, int count);

extern int kgdb_isremovedbreak(unsigned long addr);
extern void kgdb_schedule_breakpoint(void);

extern int
kgdb_handle_exception(int ex_vector, int signo, int err_code,
		      struct pt_regs *regs);
extern int kgdb_nmicallback(int cpu, void *regs);
extern int kgdb_nmicallin(int cpu, int trapnr, void *regs, int err_code,
			  atomic_t *snd_rdy);
extern void gdbstub_exit(int status);

extern int			kgdb_single_step;
extern atomic_t			kgdb_active;
#define in_dbg_master() \
	(raw_smp_processor_id() == atomic_read(&kgdb_active))
extern bool dbg_is_early;
extern void __init dbg_late_init(void);
#else /* ! CONFIG_KGDB */
#define in_dbg_master() (0)
#define dbg_late_init()
#endif /* ! CONFIG_KGDB */
#endif /* _KGDB_H_ */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 #ifndef _LINUX_HASH_H
#define _LINUX_HASH_H
/* Fast hashing routine for ints,  longs and pointers.
   (C) 2002 Nadia Yvette Chambers, IBM */

#include <asm/types.h>
#include <linux/compiler.h>

/*
 * The "GOLDEN_RATIO_PRIME" is used in ifs/btrfs/brtfs_inode.h and
 * fs/inode.c.  It's not actually prime any more (the previous primes
 * were actively bad for hashing), but the name remains.
 */
#if BITS_PER_LONG == 32
#define GOLDEN_RATIO_PRIME GOLDEN_RATIO_32
#define hash_long(val, bits) hash_32(val, bits)
#elif BITS_PER_LONG == 64
#define hash_long(val, bits) hash_64(val, bits)
#define GOLDEN_RATIO_PRIME GOLDEN_RATIO_64
#else
#error Wordsize not 32 or 64
#endif

/*
 * This hash multiplies the input by a large odd number and takes the
 * high bits.  Since multiplication propagates changes to the most
 * significant end only, it is essential that the high bits of the
 * product be used for the hash value.
 *
 * Chuck Lever verified the effectiveness of this technique:
 * http://www.citi.umich.edu/techreports/reports/citi-tr-00-1.pdf
 *
 * Although a random odd number will do, it turns out that the golden
 * ratio phi = (sqrt(5)-1)/2, or its negative, has particularly nice
 * properties.  (See Knuth vol 3, section 6.4, exercise 9.)
 *
 * These are the negative, (1 - phi) = phi**2 = (3 - sqrt(5))/2,
 * which is very slightly easier to multiply by and makes no
 * difference to the hash distribution.
 */
#define GOLDEN_RATIO_32 0x61C88647
#define GOLDEN_RATIO_64 0x61C8864680B583EBull

#ifdef CONFIG_HAVE_ARCH_HASH
/* This header may use the GOLDEN_RATIO_xx constants */
#include <asm/hash.h>
#endif

/*
 * The _generic versions exist only so lib/test_hash.c can compare
 * the arch-optimized versions with the generic.
 *
 * Note that if you change these, any <asm/hash.h> that aren't updated
 * to match need to have their HAVE_ARCH_* define values updated so the
 * self-test will not false-positive.
 */
#ifndef HAVE_ARCH__HASH_32
#define __hash_32 __hash_32_generic
#endif
static inline u32 __hash_32_generic(u32 val)
{
	return val * GOLDEN_RATIO_32;
}

#ifndef HAVE_ARCH_HASH_32
#define hash_32 hash_32_generic
#endif
static inline u32 hash_32_generic(u32 val, unsigned int bits)
{
	/* High bits are more random, so use them. */
	return __hash_32(val) >> (32 - bits);
}

#ifndef HAVE_ARCH_HASH_64
#define hash_64 hash_64_generic
#endif
static __always_inline u32 hash_64_generic(u64 val, unsigned int bits)
{
#if BITS_PER_LONG == 64
	/* 64x64-bit multiply is efficient on all 64-bit processors */
	return val * GOLDEN_RATIO_64 >> (64 - bits);
#else
	/* Hash 64 bits using only 32x32-bit multiply. */
	return hash_32((u32)val ^ __hash_32(val >> 32), bits);
#endif
}

static inline u32 hash_ptr(const void *ptr, unsigned int bits)
{
	return hash_long((unsigned long)ptr, bits);
}

/* This really should be called fold32_ptr; it does no hashing to speak of. */
static inline u32 hash32_ptr(const void *ptr)
{
	unsigned long val = (unsigned long)ptr;

#if BITS_PER_LONG == 64
	val ^= (val >> 32);
#endif
	return (u32)val;
}

#endif /* _LINUX_HASH_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 /* include/linux/dm9000.h
 *
 * Copyright (c) 2004 Simtec Electronics
 *   Ben Dooks <ben@simtec.co.uk>
 *
 * Header file for dm9000 platform data
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as
 * published by the Free Software Foundation.
 *
*/

#ifndef __DM9000_PLATFORM_DATA
#define __DM9000_PLATFORM_DATA __FILE__

#include <linux/if_ether.h>

/* IO control flags */

#define DM9000_PLATF_8BITONLY	(0x0001)
#define DM9000_PLATF_16BITONLY	(0x0002)
#define DM9000_PLATF_32BITONLY	(0x0004)
#define DM9000_PLATF_EXT_PHY	(0x0008)
#define DM9000_PLATF_NO_EEPROM	(0x0010)
#define DM9000_PLATF_SIMPLE_PHY (0x0020)  /* Use NSR to find LinkStatus */

/* platform data for platform device structure's platform_data field */

struct dm9000_plat_data {
	unsigned int	flags;
	unsigned char	dev_addr[ETH_ALEN];

	/* allow replacement IO routines */

	void	(*inblk)(void __iomem *reg, void *data, int len);
	void	(*outblk)(void __iomem *reg, void *data, int len);
	void	(*dumpblk)(void __iomem *reg, int len);
};

#endif /* __DM9000_PLATFORM_DATA */

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                /* General filesystem caching backing cache interface
 *
 * Copyright (C) 2004-2007 Red Hat, Inc. All Rights Reserved.
 * Written by David Howells (dhowells@redhat.com)
 *
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version
 * 2 of the License, or (at your option) any later version.
 *
 * NOTE!!! See:
 *
 *	Documentation/filesystems/caching/backend-api.txt
 *
 * for a description of the cache backend interface declared here.
 */

#ifndef _LINUX_FSCACHE_CACHE_H
#define _LINUX_FSCACHE_CACHE_H

#include <linux/fscache.h>
#include <linux/sched.h>
#include <linux/workqueue.h>

#define NR_MAXCACHES BITS_PER_LONG

struct fscache_cache;
struct fscache_cache_ops;
struct fscache_object;
struct fscache_operation;

/*
 * cache tag definition
 */
struct fscache_cache_tag {
	struct list_head	link;
	struct fscache_cache	*cache;		/* cache referred to by this tag */
	unsigned long		flags;
#define FSCACHE_TAG_RESERVED	0		/* T if tag is reserved for a cache */
	atomic_t		usage;
	char			name[0];	/* tag name */
};

/*
 * cache definition
 */
struct fscache_cache {
	const struct fscache_cache_ops *ops;
	struct fscache_cache_tag *tag;		/* tag representing this cache */
	struct kobject		*kobj;		/* system representation of this cache */
	struct list_head	link;		/* link in list of caches */
	size_t			max_index_size;	/* maximum size of index data */
	char			identifier[36];	/* cache label */

	/* node management */
	struct work_struct	op_gc;		/* operation garbage collector */
	struct list_head	object_list;	/* list of data/index objects */
	struct list_head	op_gc_list;	/* list of ops to be deleted */
	spinlock_t		object_list_lock;
	spinlock_t		op_gc_list_lock;
	atomic_t		object_count;	/* no. of live objects in this cache */
	struct fscache_object	*fsdef;		/* object for the fsdef index */
	unsigned long		flags;
#define FSCACHE_IOERROR		0	/* cache stopped on I/O error */
#define FSCACHE_CACHE_WITHDRAWN	1	/* cache has been withdrawn */
};

extern wait_queue_head_t fscache_cache_cleared_wq;

/*
 * operation to be applied to a cache object
 * - retrieval initiation operations are done in the context of the process
 *   that issued them, and not in an async thread pool
 */
typedef void (*fscache_operation_release_t)(struct fscache_operation *op);
typedef void (*fscache_operation_processor_t)(struct fscache_operation *op);
typedef void (*fscache_operation_cancel_t)(struct fscache_operation *op);

enum fscache_operation_state {
	FSCACHE_OP_ST_BLANK,		/* Op is not yet submitted */
	FSCACHE_OP_ST_INITIALISED,	/* Op is initialised */
	FSCACHE_OP_ST_PENDING,		/* Op is blocked from running */
	FSCACHE_OP_ST_IN_PROGRESS,	/* Op is in progress */
	FSCACHE_OP_ST_COMPLETE,		/* Op is complete */
	FSCACHE_OP_ST_CANCELLED,	/* Op has been cancelled */
	FSCACHE_OP_ST_DEAD		/* Op is now dead */
};

struct fscache_operation {
	struct work_struct	work;		/* record for async ops */
	struct list_head	pend_link;	/* link in object->pending_ops */
	struct fscache_object	*object;	/* object to be operated upon */

	unsigned long		flags;
#define FSCACHE_OP_TYPE		0x000f	/* operation type */
#define FSCACHE_OP_ASYNC	0x0001	/* - async op, processor may sleep for disk */
#define FSCACHE_OP_MYTHREAD	0x0002	/* - processing is done be issuing thread, not pool */
#define FSCACHE_OP_WAITING	4	/* cleared when op is woken */
#define FSCACHE_OP_EXCLUSIVE	5	/* exclusive op, other ops must wait */
#define FSCACHE_OP_DEC_READ_CNT	6	/* decrement object->n_reads on destruction */
#define FSCACHE_OP_UNUSE_COOKIE	7	/* call fscache_unuse_cookie() on completion */
#define FSCACHE_OP_KEEP_FLAGS	0x00f0	/* flags to keep when repurposing an op */

	enum fscache_operation_state state;
	atomic_t		usage;
	unsigned		debug_id;	/* debugging ID */

	/* operation processor callback
	 * - can be NULL if FSCACHE_OP_WAITING is going to be used to perform
	 *   the op in a non-pool thread */
	fscache_operation_processor_t processor;

	/* Operation cancellation cleanup (optional) */
	fscache_operation_cancel_t cancel;

	/* operation releaser */
	fscache_operation_release_t release;
};

extern atomic_t fscache_op_debug_id;
extern void fscache_op_work_func(struct work_struct *work);

extern void fscache_enqueue_operation(struct fscache_operation *);
extern void fscache_op_complete(struct fscache_operation *, bool);
extern void fscache_put_operation(struct fscache_operation *);
extern void fscache_operation_init(struct fscache_operation *,
				   fscache_operation_processor_t,
				   fscache_operation_cancel_t,
				   fscache_operation_release_t);

/*
 * data read operation
 */
struct fscache_retrieval {
	struct fscache_operation op;
	struct fscache_cookie	*cookie;	/* The netfs cookie */
	struct address_space	*mapping;	/* netfs pages */
	fscache_rw_complete_t	end_io_func;	/* function to call on I/O completion */
	void			*context;	/* netfs read context (pinned) */
	struct list_head	to_do;		/* list of things to be done by the backend */
	unsigned long		start_time;	/* time at which retrieval started */
	atomic_t		n_pages;	/* number of pages to be retrieved */
};

typedef int (*fscache_page_retrieval_func_t)(struct fscache_retrieval *op,
					     struct page *page,
					     gfp_t gfp);

typedef int (*fscache_pages_retrieval_func_t)(struct fscache_retrieval *op,
					      struct list_head *pages,
					      unsigned *nr_pages,
					      gfp_t gfp);

/**
 * fscache_get_retrieval - Get an extra reference on a retrieval operation
 * @op: The retrieval operation to get a reference on
 *
 * Get an extra reference on a retrieval operation.
 */
static inline
struct fscache_retrieval *fscache_get_retrieval(struct fscache_retrieval *op)
{
	atomic_inc(&op->op.usage);
	return op;
}

/**
 * fscache_enqueue_retrieval - Enqueue a retrieval operation for processing
 * @op: The retrieval operation affected
 *
 * Enqueue a retrieval operation for processing by the FS-Cache thread pool.
 */
static inline void fscache_enqueue_retrieval(struct fscache_retrieval *op)
{
	fscache_enqueue_operation(&op->op);
}

/**
 * fscache_retrieval_complete - Record (partial) completion of a retrieval
 * @op: The retrieval operation affected
 * @n_pages: The number of pages to account for
 */
static inline void fscache_retrieval_complete(struct fscache_retrieval *op,
					      int n_pages)
{
	atomic_sub(n_pages, &op->n_pages);
	if (atomic_read(&op->n_pages) <= 0)
		fscache_op_complete(&op->op, true);
}

/**
 * fscache_put_retrieval - Drop a reference to a retrieval operation
 * @op: The retrieval operation affected
 *
 * Drop a reference to a retrieval operation.
 */
static inline void fscache_put_retrieval(struct fscache_retrieval *op)
{
	fscache_put_operation(&op->op);
}

/*
 * cached page storage work item
 * - used to do three things:
 *   - batch writes to the cache
 *   - do cache writes asynchronously
 *   - defer writes until cache object lookup completion
 */
struct fscache_storage {
	struct fscache_operation op;
	pgoff_t			store_limit;	/* don't write more than this */
};

/*
 * cache operations
 */
struct fscache_cache_ops {
	/* name of cache provider */
	const char *name;

	/* allocate an object record for a cookie */
	struct fscache_object *(*alloc_object)(struct fscache_cache *cache,
					       struct fscache_cookie *cookie);

	/* look up the object for a cookie
	 * - return -ETIMEDOUT to be requeued
	 */
	int (*lookup_object)(struct fscache_object *object);

	/* finished looking up */
	void (*lookup_complete)(struct fscache_object *object);

	/* increment the usage count on this object (may fail if unmounting) */
	struct fscache_object *(*grab_object)(struct fscache_object *object);

	/* pin an object in the cache */
	int (*pin_object)(struct fscache_object *object);

	/* unpin an object in the cache */
	void (*unpin_object)(struct fscache_object *object);

	/* check the consistency between the backing cache and the FS-Cache
	 * cookie */
	int (*check_consistency)(struct fscache_operation *op);

	/* store the updated auxiliary data on an object */
	void (*update_object)(struct fscache_object *object);

	/* Invalidate an object */
	void (*invalidate_object)(struct fscache_operation *op);

	/* discard the resources pinned by an object and effect retirement if
	 * necessary */
	void (*drop_object)(struct fscache_object *object);

	/* dispose of a reference to an object */
	void (*put_object)(struct fscache_object *object);

	/* sync a cache */
	void (*sync_cache)(struct fscache_cache *cache);

	/* notification that the attributes of a non-index object (such as
	 * i_size) have changed */
	int (*attr_changed)(struct fscache_object *object);

	/* reserve space for an object's data and associated metadata */
	int (*reserve_space)(struct fscache_object *object, loff_t i_size);

	/* request a backing block for a page be read or allocated in the
	 * cache */
	fscache_page_retrieval_func_t read_or_alloc_page;

	/* request backing blocks for a list of pages be read or allocated in
	 * the cache */
	fscache_pages_retrieval_func_t read_or_alloc_pages;

	/* request a backing block for a page be allocated in the cache so that
	 * it can be written directly */
	fscache_page_retrieval_func_t allocate_page;

	/* request backing blocks for pages be allocated in the cache so that
	 * they can be written directly */
	fscache_pages_retrieval_func_t allocate_pages;

	/* write a page to its backing block in the cache */
	int (*write_page)(struct fscache_storage *op, struct page *page);

	/* detach backing block from a page (optional)
	 * - must release the cookie lock before returning
	 * - may sleep
	 */
	void (*uncache_page)(struct fscache_object *object,
			     struct page *page);

	/* dissociate a cache from all the pages it was backing */
	void (*dissociate_pages)(struct fscache_cache *cache);
};

extern struct fscache_cookie fscache_fsdef_index;

/*
 * Event list for fscache_object::{event_mask,events}
 */
enum {
	FSCACHE_OBJECT_EV_NEW_CHILD,	/* T if object has a new child */
	FSCACHE_OBJECT_EV_PARENT_READY,	/* T if object's parent is ready */
	FSCACHE_OBJECT_EV_UPDATE,	/* T if object should be updated */
	FSCACHE_OBJECT_EV_INVALIDATE,	/* T if cache requested object invalidation */
	FSCACHE_OBJECT_EV_CLEARED,	/* T if accessors all gone */
	FSCACHE_OBJECT_EV_ERROR,	/* T if fatal error occurred during processing */
	FSCACHE_OBJECT_EV_KILL,		/* T if netfs relinquished or cache withdrew object */
	NR_FSCACHE_OBJECT_EVENTS
};

#define FSCACHE_OBJECT_EVENTS_MASK ((1UL << NR_FSCACHE_OBJECT_EVENTS) - 1)

/*
 * States for object state machine.
 */
struct fscache_transition {
	unsigned long events;
	const struct fscache_state *transit_to;
};

struct fscache_state {
	char name[24];
	char short_name[8];
	const struct fscache_state *(*work)(struct fscache_object *object,
					    int event);
	const struct fscache_transition transitions[];
};

/*
 * on-disk cache file or index handle
 */
struct fscache_object {
	const struct fscache_state *state;	/* Object state machine state */
	const struct fscache_transition *oob_table; /* OOB state transition table */
	int			debug_id;	/* debugging ID */
	int			n_children;	/* number of child objects */
	int			n_ops;		/* number of extant ops on object */
	int			n_obj_ops;	/* number of object ops outstanding on object */
	int			n_in_progress;	/* number of ops in progress */
	int			n_exclusive;	/* number of exclusive ops queued or in progress */
	atomic_t		n_reads;	/* number of read ops in progress */
	spinlock_t		lock;		/* state and operations lock */

	unsigned long		lookup_jif;	/* time at which lookup started */
	unsigned long		oob_event_mask;	/* OOB events this object is interested in */
	unsigned long		event_mask;	/* events this object is interested in */
	unsigned long		events;		/* events to be processed by this object
						 * (order is important - using fls) */

	unsigned long		flags;
#define FSCACHE_OBJECT_LOCK		0	/* T if object is busy being processed */
#define FSCACHE_OBJECT_PENDING_WRITE	1	/* T if object has pending write */
#define FSCACHE_OBJECT_WAITING		2	/* T if object is waiting on its parent */
#define FSCACHE_OBJECT_IS_LIVE		3	/* T if object is not withdrawn or relinquished */
#define FSCACHE_OBJECT_IS_LOOKED_UP	4	/* T if object has been looked up */
#define FSCACHE_OBJECT_IS_AVAILABLE	5	/* T if object has become active */
#define FSCACHE_OBJECT_RETIRED		6	/* T if object was retired on relinquishment */
#define FSCACHE_OBJECT_KILLED_BY_CACHE	7	/* T if object was killed by the cache */
#define FSCACHE_OBJECT_RUN_AFTER_DEAD	8	/* T if object has been dispatched after death */

	struct list_head	cache_link;	/* link in cache->object_list */
	struct hlist_node	cookie_link;	/* link in cookie->backing_objects */
	struct fscache_cache	*cache;		/* cache that supplied this object */
	struct fscache_cookie	*cookie;	/* netfs's file/index object */
	struct fscache_object	*parent;	/* parent object */
	struct work_struct	work;		/* attention scheduling record */
	struct list_head	dependents;	/* FIFO of dependent objects */
	struct list_head	dep_link;	/* link in parent's dependents list */
	struct list_head	pending_ops;	/* unstarted operations on this object */
#ifdef CONFIG_FSCACHE_OBJECT_LIST
	struct rb_node		objlist_link;	/* link in global object list */
#endif
	pgoff_t			store_limit;	/* current storage limit */
	loff_t			store_limit_l;	/* current storage limit */
};

extern void fscache_object_init(struct fscache_object *, struct fscache_cookie *,
				struct fscache_cache *);
extern void fscache_object_destroy(struct fscache_object *);

extern void fscache_object_lookup_negative(struct fscache_object *object);
extern void fscache_obtained_object(struct fscache_object *object);

static inline bool fscache_object_is_live(struct fscache_object *object)
{
	return test_bit(FSCACHE_OBJECT_IS_LIVE, &object->flags);
}

static inline bool fscache_object_is_dying(struct fscache_object *object)
{
	return !fscache_object_is_live(object);
}

static inline bool fscache_object_is_available(struct fscache_object *object)
{
	return test_bit(FSCACHE_OBJECT_IS_AVAILABLE, &object->flags);
}

static inline bool fscache_cache_is_broken(struct fscache_object *object)
{
	return test_bit(FSCACHE_IOERROR, &object->cache->flags);
}

static inline bool fscache_object_is_active(struct fscache_object *object)
{
	return fscache_object_is_available(object) &&
		fscache_object_is_live(object) &&
		!fscache_cache_is_broken(object);
}

/**
 * fscache_object_destroyed - Note destruction of an object in a cache
 * @cache: The cache from which the object came
 *
 * Note the destruction and deallocation of an object record in a cache.
 */
static inline void fscache_object_destroyed(struct fscache_cache *cache)
{
	if (atomic_dec_and_test(&cache->object_count))
		wake_up_all(&fscache_cache_cleared_wq);
}

/**
 * fscache_object_lookup_error - Note an object encountered an error
 * @object: The object on which the error was encountered
 *
 * Note that an object encountered a fatal error (usually an I/O error) and
 * that it should be withdrawn as soon as possible.
 */
static inline void fscache_object_lookup_error(struct fscache_object *object)
{
	set_bit(FSCACHE_OBJECT_EV_ERROR, &object->events);
}

/**
 * fscache_set_store_limit - Set the maximum size to be stored in an object
 * @object: The object to set the maximum on
 * @i_size: The limit to set in bytes
 *
 * Set the maximum size an object is permitted to reach, implying the highest
 * byte that may be written.  Intended to be called by the attr_changed() op.
 *
 * See Documentation/filesystems/caching/backend-api.txt for a complete
 * description.
 */
static inline
void fscache_set_store_limit(struct fscache_object *object, loff_t i_size)
{
	object->store_limit_l = i_size;
	object->store_limit = i_size >> PAGE_SHIFT;
	if (i_size & ~PAGE_MASK)
		object->store_limit++;
}

/**
 * fscache_end_io - End a retrieval operation on a page
 * @op: The FS-Cache operation covering the retrieval
 * @page: The page that was to be fetched
 * @error: The error code (0 if successful)
 *
 * Note the end of an operation to retrieve a page, as covered by a particular
 * operation record.
 */
static inline void fscache_end_io(struct fscache_retrieval *op,
				  struct page *page, int error)
{
	op->end_io_func(page, op->context, error);
}

static inline void __fscache_use_cookie(struct fscache_cookie *cookie)
{
	atomic_inc(&cookie->n_active);
}

/**
 * fscache_use_cookie - Request usage of cookie attached to an object
 * @object: Object description
 * 
 * Request usage of the cookie attached to an object.  NULL is returned if the
 * relinquishment had reduced the cookie usage count to 0.
 */
static inline bool fscache_use_cookie(struct fscache_object *object)
{
	struct fscache_cookie *cookie = object->cookie;
	return atomic_inc_not_zero(&cookie->n_active) != 0;
}

static inline bool __fscache_unuse_cookie(struct fscache_cookie *cookie)
{
	return atomic_dec_and_test(&cookie->n_active);
}

static inline void __fscache_wake_unused_cookie(struct fscache_cookie *cookie)
{
	wake_up_atomic_t(&cookie->n_active);
}

/**
 * fscache_unuse_cookie - Cease usage of cookie attached to an object
 * @object: Object description
 * 
 * Cease usage of the cookie attached to an object.  When the users count
 * reaches zero then the cookie relinquishment will be permitted to proceed.
 */
static inline void fscache_unuse_cookie(struct fscache_object *object)
{
	struct fscache_cookie *cookie = object->cookie;
	if (__fscache_unuse_cookie(cookie))
		__fscache_wake_unused_cookie(cookie);
}

/*
 * out-of-line cache backend functions
 */
extern __printf(3, 4)
void fscache_init_cache(struct fscache_cache *cache,
			const struct fscache_cache_ops *ops,
			const char *idfmt, ...);

extern int fscache_add_cache(struct fscache_cache *cache,
			     struct fscache_object *fsdef,
			     const char *tagname);
extern void fscache_withdraw_cache(struct fscache_cache *cache);

extern void fscache_io_error(struct fscache_cache *cache);

extern void fscache_mark_page_cached(struct fscache_retrieval *op,
				     struct page *page);

extern void fscache_mark_pages_cached(struct fscache_retrieval *op,
				      struct pagevec *pagevec);

extern bool fscache_object_sleep_till_congested(signed long *timeoutp);

extern enum fscache_checkaux fscache_check_aux(struct fscache_object *object,
					       const void *data,
					       uint16_t datalen);

extern void fscache_object_retrying_stale(struct fscache_object *object);

enum fscache_why_object_killed {
	FSCACHE_OBJECT_IS_STALE,
	FSCACHE_OBJECT_NO_SPACE,
	FSCACHE_OBJECT_WAS_RETIRED,
	FSCACHE_OBJECT_WAS_CULLED,
};
extern void fscache_object_mark_killed(struct fscache_object *object,
				       enum fscache_why_object_killed why);

#endif /* _LINUX_FSCACHE_CACHE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /*
 * i2c-mux-pinctrl platform data
 *
 * Copyright (c) 2012, NVIDIA CORPORATION.  All rights reserved.
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms and conditions of the GNU General Public License,
 * version 2, as published by the Free Software Foundation.
 *
 * This program is distributed in the hope it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
 * more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */

#ifndef _LINUX_I2C_MUX_PINCTRL_H
#define _LINUX_I2C_MUX_PINCTRL_H

/**
 * struct i2c_mux_pinctrl_platform_data - Platform data for i2c-mux-pinctrl
 * @parent_bus_num: Parent I2C bus number
 * @base_bus_num: Base I2C bus number for the child busses. 0 for dynamic.
 * @bus_count: Number of child busses. Also the number of elements in
 *	@pinctrl_states
 * @pinctrl_states: The names of the pinctrl state to select for each child bus
 * @pinctrl_state_idle: The pinctrl state to select when no child bus is being
 *	accessed. If NULL, the most recently used pinctrl state will be left
 *	selected.
 */
struct i2c_mux_pinctrl_platform_data {
	int parent_bus_num;
	int base_bus_num;
	int bus_count;
	const char **pinctrl_states;
	const char *pinctrl_state_idle;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             #ifndef _LINUX_FB_H
#define _LINUX_FB_H

#include <linux/kgdb.h>
#include <uapi/linux/fb.h>

#define FBIO_CURSOR            _IOWR('F', 0x08, struct fb_cursor_user)

#include <linux/fs.h>
#include <linux/init.h>
#include <linux/workqueue.h>
#include <linux/notifier.h>
#include <linux/list.h>
#include <linux/backlight.h>
#include <linux/slab.h>
#include <asm/io.h>

struct vm_area_struct;
struct fb_info;
struct device;
struct file;
struct videomode;
struct device_node;

/* Definitions below are used in the parsed monitor specs */
#define FB_DPMS_ACTIVE_OFF	1
#define FB_DPMS_SUSPEND		2
#define FB_DPMS_STANDBY		4

#define FB_DISP_DDI		1
#define FB_DISP_ANA_700_300	2
#define FB_DISP_ANA_714_286	4
#define FB_DISP_ANA_1000_400	8
#define FB_DISP_ANA_700_000	16

#define FB_DISP_MONO		32
#define FB_DISP_RGB		64
#define FB_DISP_MULTI		128
#define FB_DISP_UNKNOWN		256

#define FB_SIGNAL_NONE		0
#define FB_SIGNAL_BLANK_BLANK	1
#define FB_SIGNAL_SEPARATE	2
#define FB_SIGNAL_COMPOSITE	4
#define FB_SIGNAL_SYNC_ON_GREEN	8
#define FB_SIGNAL_SERRATION_ON	16

#define FB_MISC_PRIM_COLOR	1
#define FB_MISC_1ST_DETAIL	2	/* First Detailed Timing is preferred */
#define FB_MISC_HDMI		4
struct fb_chroma {
	__u32 redx;	/* in fraction of 1024 */
	__u32 greenx;
	__u32 bluex;
	__u32 whitex;
	__u32 redy;
	__u32 greeny;
	__u32 bluey;
	__u32 whitey;
};

struct fb_monspecs {
	struct fb_chroma chroma;
	struct fb_videomode *modedb;	/* mode database */
	__u8  manufacturer[4];		/* Manufacturer */
	__u8  monitor[14];		/* Monitor String */
	__u8  serial_no[14];		/* Serial Number */
	__u8  ascii[14];		/* ? */
	__u32 modedb_len;		/* mode database length */
	__u32 model;			/* Monitor Model */
	__u32 serial;			/* Serial Number - Integer */
	__u32 year;			/* Year manufactured */
	__u32 week;			/* Week Manufactured */
	__u32 hfmin;			/* hfreq lower limit (Hz) */
	__u32 hfmax;			/* hfreq upper limit (Hz) */
	__u32 dclkmin;			/* pixelclock lower limit (Hz) */
	__u32 dclkmax;			/* pixelclock upper limit (Hz) */
	__u16 input;			/* display type - see FB_DISP_* */
	__u16 dpms;			/* DPMS support - see FB_DPMS_ */
	__u16 signal;			/* Signal Type - see FB_SIGNAL_* */
	__u16 vfmin;			/* vfreq lower limit (Hz) */
	__u16 vfmax;			/* vfreq upper limit (Hz) */
	__u16 gamma;			/* Gamma - in fractions of 100 */
	__u16 gtf	: 1;		/* supports GTF */
	__u16 misc;			/* Misc flags - see FB_MISC_* */
	__u8  version;			/* EDID version... */
	__u8  revision;			/* ...and revision */
	__u8  max_x;			/* Maximum horizontal size (cm) */
	__u8  max_y;			/* Maximum vertical size (cm) */
};

struct fb_cmap_user {
	__u32 start;			/* First entry	*/
	__u32 len;			/* Number of entries */
	__u16 __user *red;		/* Red values	*/
	__u16 __user *green;
	__u16 __user *blue;
	__u16 __user *transp;		/* transparency, can be NULL */
};

struct fb_image_user {
	__u32 dx;			/* Where to place image */
	__u32 dy;
	__u32 width;			/* Size of image */
	__u32 height;
	__u32 fg_color;			/* Only used when a mono bitmap */
	__u32 bg_color;
	__u8  depth;			/* Depth of the image */
	const char __user *data;	/* Pointer to image data */
	struct fb_cmap_user cmap;	/* color map info */
};

struct fb_cursor_user {
	__u16 set;			/* what to set */
	__u16 enable;			/* cursor on/off */
	__u16 rop;			/* bitop operation */
	const char __user *mask;	/* cursor mask bits */
	struct fbcurpos hot;		/* cursor hot spot */
	struct fb_image_user image;	/* Cursor image */
};

/*
 * Register/unregister for framebuffer events
 */

/*	The resolution of the passed in fb_info about to change */ 
#define FB_EVENT_MODE_CHANGE		0x01
/*	The display on this fb_info is beeing suspended, no access to the
 *	framebuffer is allowed any more after that call returns
 */
#define FB_EVENT_SUSPEND		0x02
/*	The display on this fb_info was resumed, you can restore the display
 *	if you own it
 */
#define FB_EVENT_RESUME			0x03
/*      An entry from the modelist was removed */
#define FB_EVENT_MODE_DELETE            0x04
/*      A driver registered itself */
#define FB_EVENT_FB_REGISTERED          0x05
/*      A driver unregistered itself */
#define FB_EVENT_FB_UNREGISTERED        0x06
/*      CONSOLE-SPECIFIC: get console to framebuffer mapping */
#define FB_EVENT_GET_CONSOLE_MAP        0x07
/*      CONSOLE-SPECIFIC: set console to framebuffer mapping */
#define FB_EVENT_SET_CONSOLE_MAP        0x08
/*      A hardware display blank change occurred */
#define FB_EVENT_BLANK                  0x09
/*      Private modelist is to be replaced */
#define FB_EVENT_NEW_MODELIST           0x0A
/*	The resolution of the passed in fb_info about to change and
        all vc's should be changed         */
#define FB_EVENT_MODE_CHANGE_ALL	0x0B
/*	A software display blank change occurred */
#define FB_EVENT_CONBLANK               0x0C
/*      Get drawing requirements        */
#define FB_EVENT_GET_REQ                0x0D
/*      Unbind from the console if possible */
#define FB_EVENT_FB_UNBIND              0x0E
/*      CONSOLE-SPECIFIC: remap all consoles to new fb - for vga_switcheroo */
#define FB_EVENT_REMAP_ALL_CONSOLE      0x0F
/*      A hardware display blank early change occured */
#define FB_EARLY_EVENT_BLANK		0x10
/*      A hardware display blank revert early change occured */
#define FB_R_EARLY_EVENT_BLANK		0x11

struct fb_event {
	struct fb_info *info;
	void *data;
};

struct fb_blit_caps {
	u32 x;
	u32 y;
	u32 len;
	u32 flags;
};

#ifdef CONFIG_FB_NOTIFY
extern int fb_register_client(struct notifier_block *nb);
extern int fb_unregister_client(struct notifier_block *nb);
extern int fb_notifier_call_chain(unsigned long val, void *v);
#else
static inline int fb_register_client(struct notifier_block *nb)
{
	return 0;
};

static inline int fb_unregister_client(struct notifier_block *nb)
{
	return 0;
};

static inline int fb_notifier_call_chain(unsigned long val, void *v)
{
	return 0;
};
#endif

/*
 * Pixmap structure definition
 *
 * The purpose of this structure is to translate data
 * from the hardware independent format of fbdev to what
 * format the hardware needs.
 */

#define FB_PIXMAP_DEFAULT 1     /* used internally by fbcon */
#define FB_PIXMAP_SYSTEM  2     /* memory is in system RAM  */
#define FB_PIXMAP_IO      4     /* memory is iomapped       */
#define FB_PIXMAP_SYNC    256   /* set if GPU can DMA       */

struct fb_pixmap {
	u8  *addr;		/* pointer to memory			*/
	u32 size;		/* size of buffer in bytes		*/
	u32 offset;		/* current offset to buffer		*/
	u32 buf_align;		/* byte alignment of each bitmap	*/
	u32 scan_align;		/* alignment per scanline		*/
	u32 access_align;	/* alignment per read/write (bits)	*/
	u32 flags;		/* see FB_PIXMAP_*			*/
	u32 blit_x;             /* supported bit block dimensions (1-32)*/
	u32 blit_y;             /* Format: blit_x = 1 << (width - 1)    */
	                        /*         blit_y = 1 << (height - 1)   */
	                        /* if 0, will be set to 0xffffffff (all)*/
	/* access methods */
	void (*writeio)(struct fb_info *info, void __iomem *dst, void *src, unsigned int size);
	void (*readio) (struct fb_info *info, void *dst, void __iomem *src, unsigned int size);
};

#ifdef CONFIG_FB_DEFERRED_IO
struct fb_deferred_io {
	/* delay between mkwrite and deferred handler */
	unsigned long delay;
	struct mutex lock; /* mutex that protects the page list */
	struct list_head pagelist; /* list of touched pages */
	/* callback */
	void (*first_io)(struct fb_info *info);
	void (*deferred_io)(struct fb_info *info, struct list_head *pagelist);
};
#endif

/*
 * Frame buffer operations
 *
 * LOCKING NOTE: those functions must _ALL_ be called with the console
 * semaphore held, this is the only suitable locking mechanism we have
 * in 2.6. Some may be called at interrupt time at this point though.
 *
 * The exception to this is the debug related hooks.  Putting the fb
 * into a debug state (e.g. flipping to the kernel console) and restoring
 * it must be done in a lock-free manner, so low level drivers should
 * keep track of the initial console (if applicable) and may need to
 * perform direct, unlocked hardware writes in these hooks.
 */

struct fb_ops {
	/* open/release and usage marking */
	struct module *owner;
	int (*fb_open)(struct fb_info *info, int user);
	int (*fb_release)(struct fb_info *info, int user);

	/* For framebuffers with strange non linear layouts or that do not
	 * work with normal memory mapped access
	 */
	ssize_t (*fb_read)(struct fb_info *info, char __user *buf,
			   size_t count, loff_t *ppos);
	ssize_t (*fb_write)(struct fb_info *info, const char __user *buf,
			    size_t count, loff_t *ppos);

	/* checks var and eventually tweaks it to something supported,
	 * DO NOT MODIFY PAR */
	int (*fb_check_var)(struct fb_var_screeninfo *var, struct fb_info *info);

	/* set the video mode according to info->var */
	int (*fb_set_par)(struct fb_info *info);

	/* set color register */
	int (*fb_setcolreg)(unsigned regno, unsigned red, unsigned green,
			    unsigned blue, unsigned transp, struct fb_info *info);

	/* set color registers in batch */
	int (*fb_setcmap)(struct fb_cmap *cmap, struct fb_info *info);

	/* blank display */
	int (*fb_blank)(int blank, struct fb_info *info);

	/* pan display */
	int (*fb_pan_display)(struct fb_var_screeninfo *var, struct fb_info *info);

	/* Draws a rectangle */
	void (*fb_fillrect) (struct fb_info *info, const struct fb_fillrect *rect);
	/* Copy data from area to another */
	void (*fb_copyarea) (struct fb_info *info, const struct fb_copyarea *region);
	/* Draws a image to the display */
	void (*fb_imageblit) (struct fb_info *info, const struct fb_image *image);

	/* Draws cursor */
	int (*fb_cursor) (struct fb_info *info, struct fb_cursor *cursor);

	/* wait for blit idle, optional */
	int (*fb_sync)(struct fb_info *info);

	/* perform fb specific ioctl (optional) */
	int (*fb_ioctl)(struct fb_info *info, unsigned int cmd,
			unsigned long arg);

	/* Handle 32bit compat ioctl (optional) */
	int (*fb_compat_ioctl)(struct fb_info *info, unsigned cmd,
			unsigned long arg);

	/* perform fb specific mmap */
	int (*fb_mmap)(struct fb_info *info, struct vm_area_struct *vma);

	/* get capability given var */
	void (*fb_get_caps)(struct fb_info *info, struct fb_blit_caps *caps,
			    struct fb_var_screeninfo *var);

	/* teardown any resources to do with this framebuffer */
	void (*fb_destroy)(struct fb_info *info);

	/* called at KDB enter and leave time to prepare the console */
	int (*fb_debug_enter)(struct fb_info *info);
	int (*fb_debug_leave)(struct fb_info *info);
};

#ifdef CONFIG_FB_TILEBLITTING
#define FB_TILE_CURSOR_NONE        0
#define FB_TILE_CURSOR_UNDERLINE   1
#define FB_TILE_CURSOR_LOWER_THIRD 2
#define FB_TILE_CURSOR_LOWER_HALF  3
#define FB_TILE_CURSOR_TWO_THIRDS  4
#define FB_TILE_CURSOR_BLOCK       5

struct fb_tilemap {
	__u32 width;                /* width of each tile in pixels */
	__u32 height;               /* height of each tile in scanlines */
	__u32 depth;                /* color depth of each tile */
	__u32 length;               /* number of tiles in the map */
	const __u8 *data;           /* actual tile map: a bitmap array, packed
				       to the nearest byte */
};

struct fb_tilerect {
	__u32 sx;                   /* origin in the x-axis */
	__u32 sy;                   /* origin in the y-axis */
	__u32 width;                /* number of tiles in the x-axis */
	__u32 height;               /* number of tiles in the y-axis */
	__u32 index;                /* what tile to use: index to tile map */
	__u32 fg;                   /* foreground color */
	__u32 bg;                   /* background color */
	__u32 rop;                  /* raster operation */
};

struct fb_tilearea {
	__u32 sx;                   /* source origin in the x-axis */
	__u32 sy;                   /* source origin in the y-axis */
	__u32 dx;                   /* destination origin in the x-axis */
	__u32 dy;                   /* destination origin in the y-axis */
	__u32 width;                /* number of tiles in the x-axis */
	__u32 height;               /* number of tiles in the y-axis */
};

struct fb_tileblit {
	__u32 sx;                   /* origin in the x-axis */
	__u32 sy;                   /* origin in the y-axis */
	__u32 width;                /* number of tiles in the x-axis */
	__u32 height;               /* number of tiles in the y-axis */
	__u32 fg;                   /* foreground color */
	__u32 bg;                   /* background color */
	__u32 length;               /* number of tiles to draw */
	__u32 *indices;             /* array of indices to tile map */
};

struct fb_tilecursor {
	__u32 sx;                   /* cursor position in the x-axis */
	__u32 sy;                   /* cursor position in the y-axis */
	__u32 mode;                 /* 0 = erase, 1 = draw */
	__u32 shape;                /* see FB_TILE_CURSOR_* */
	__u32 fg;                   /* foreground color */
	__u32 bg;                   /* background color */
};

struct fb_tile_ops {
	/* set tile characteristics */
	void (*fb_settile)(struct fb_info *info, struct fb_tilemap *map);

	/* all dimensions from hereon are in terms of tiles */

	/* move a rectangular region of tiles from one area to another*/
	void (*fb_tilecopy)(struct fb_info *info, struct fb_tilearea *area);
	/* fill a rectangular region with a tile */
	void (*fb_tilefill)(struct fb_info *info, struct fb_tilerect *rect);
	/* copy an array of tiles */
	void (*fb_tileblit)(struct fb_info *info, struct fb_tileblit *blit);
	/* cursor */
	void (*fb_tilecursor)(struct fb_info *info,
			      struct fb_tilecursor *cursor);
	/* get maximum length of the tile map */
	int (*fb_get_tilemax)(struct fb_info *info);
};
#endif /* CONFIG_FB_TILEBLITTING */

/* FBINFO_* = fb_info.flags bit flags */
#define FBINFO_MODULE		0x0001	/* Low-level driver is a module */
#define FBINFO_HWACCEL_DISABLED	0x0002
	/* When FBINFO_HWACCEL_DISABLED is set:
	 *  Hardware acceleration is turned off.  Software implementations
	 *  of required functions (copyarea(), fillrect(), and imageblit())
	 *  takes over; acceleration engine should be in a quiescent state */

/* hints */
#define FBINFO_VIRTFB		0x0004 /* FB is System RAM, not device. */
#define FBINFO_PARTIAL_PAN_OK	0x0040 /* otw use pan only for double-buffering */
#define FBINFO_READS_FAST	0x0080 /* soft-copy faster than rendering */

/* hardware supported ops */
/*  semantics: when a bit is set, it indicates that the operation is
 *   accelerated by hardware.
 *  required functions will still work even if the bit is not set.
 *  optional functions may not even exist if the flag bit is not set.
 */
#define FBINFO_HWACCEL_NONE		0x0000
#define FBINFO_HWACCEL_COPYAREA		0x0100 /* required */
#define FBINFO_HWACCEL_FILLRECT		0x0200 /* required */
#define FBINFO_HWACCEL_IMAGEBLIT	0x0400 /* required */
#define FBINFO_HWACCEL_ROTATE		0x0800 /* optional */
#define FBINFO_HWACCEL_XPAN		0x1000 /* optional */
#define FBINFO_HWACCEL_YPAN		0x2000 /* optional */
#define FBINFO_HWACCEL_YWRAP		0x4000 /* optional */

#define FBINFO_MISC_USEREVENT          0x10000 /* event request
						  from userspace */
#define FBINFO_MISC_TILEBLITTING       0x20000 /* use tile blitting */

/* A driver may set this flag to indicate that it does want a set_par to be
 * called every time when fbcon_switch is executed. The advantage is that with
 * this flag set you can really be sure that set_par is always called before
 * any of the functions dependent on the correct hardware state or altering
 * that state, even if you are using some broken X releases. The disadvantage
 * is that it introduces unwanted delays to every console switch if set_par
 * is slow. It is a good idea to try this flag in the drivers initialization
 * code whenever there is a bug report related to switching between X and the
 * framebuffer console.
 */
#define FBINFO_MISC_ALWAYS_SETPAR   0x40000

/* where the fb is a firmware driver, and can be replaced with a proper one */
#define FBINFO_MISC_FIRMWARE        0x80000
/*
 * Host and GPU endianness differ.
 */
#define FBINFO_FOREIGN_ENDIAN	0x100000
/*
 * Big endian math. This is the same flags as above, but with different
 * meaning, it is set by the fb subsystem depending FOREIGN_ENDIAN flag
 * and host endianness. Drivers should not use this flag.
 */
#define FBINFO_BE_MATH  0x100000

/* report to the VT layer that this fb driver can accept forced console
   output like oopses */
#define FBINFO_CAN_FORCE_OUTPUT     0x200000

struct fb_info {
	atomic_t count;
	int node;
	int flags;
	struct mutex lock;		/* Lock for open/release/ioctl funcs */
	struct mutex mm_lock;		/* Lock for fb_mmap and smem_* fields */
	struct fb_var_screeninfo var;	/* Current var */
	struct fb_fix_screeninfo fix;	/* Current fix */
	struct fb_monspecs monspecs;	/* Current Monitor specs */
	struct work_struct queue;	/* Framebuffer event queue */
	struct fb_pixmap pixmap;	/* Image hardware mapper */
	struct fb_pixmap sprite;	/* Cursor hardware mapper */
	struct fb_cmap cmap;		/* Current cmap */
	struct list_head modelist;      /* mode list */
	struct fb_videomode *mode;	/* current mode */

#ifdef CONFIG_FB_BACKLIGHT
	/* assigned backlight device */
	/* set before framebuffer registration, 
	   remove after unregister */
	struct backlight_device *bl_dev;

	/* Backlight level curve */
	struct mutex bl_curve_mutex;	
	u8 bl_curve[FB_BACKLIGHT_LEVELS];
#endif
#ifdef CONFIG_FB_DEFERRED_IO
	struct delayed_work deferred_work;
	struct fb_deferred_io *fbdefio;
#endif

	struct fb_ops *fbops;
	struct device *device;		/* This is the parent */
	struct device *dev;		/* This is this fb device */
	int class_flag;                    /* private sysfs flags */
#ifdef CONFIG_FB_TILEBLITTING
	struct fb_tile_ops *tileops;    /* Tile Blitting */
#endif
	union {
		char __iomem *screen_base;	/* Virtual address */
		char *screen_buffer;
	};
	unsigned long screen_size;	/* Amount of ioremapped VRAM or 0 */ 
	void *pseudo_palette;		/* Fake palette of 16 colors */ 
#define FBINFO_STATE_RUNNING	0
#define FBINFO_STATE_SUSPENDED	1
	u32 state;			/* Hardware state i.e suspend */
	void *fbcon_par;                /* fbcon use-only private area */
	/* From here on everything is device dependent */
	void *par;
	/* we need the PCI or similar aperture base/size not
	   smem_start/size as smem_start may just be an object
	   allocated inside the aperture so may not actually overlap */
	struct apertures_struct {
		unsigned int count;
		struct aperture {
			resource_size_t base;
			resource_size_t size;
		} ranges[0];
	} *apertures;

	bool skip_vt_switch; /* no VT switch on suspend/resume required */
};

static inline struct apertures_struct *alloc_apertures(unsigned int max_num) {
	struct apertures_struct *a = kzalloc(sizeof(struct apertures_struct)
			+ max_num * sizeof(struct aperture), GFP_KERNEL);
	if (!a)
		return NULL;
	a->count = max_num;
	return a;
}

#ifdef MODULE
#define FBINFO_DEFAULT	FBINFO_MODULE
#else
#define FBINFO_DEFAULT	0
#endif

// This will go away
#define FBINFO_FLAG_MODULE	FBINFO_MODULE
#define FBINFO_FLAG_DEFAULT	FBINFO_DEFAULT

/* This will go away
 * fbset currently hacks in FB_ACCELF_TEXT into var.accel_flags
 * when it wants to turn the acceleration engine on.  This is
 * really a separate operation, and should be modified via sysfs.
 *  But for now, we leave it broken with the following define
 */
#define STUPID_ACCELF_TEXT_SHIT

// This will go away
#if defined(__sparc__)

/* We map all of our framebuffers such that big-endian accesses
 * are what we want, so the following is sufficient.
 */

// This will go away
#define fb_readb sbus_readb
#define fb_readw sbus_readw
#define fb_readl sbus_readl
#define fb_readq sbus_readq
#define fb_writeb sbus_writeb
#define fb_writew sbus_writew
#define fb_writel sbus_writel
#define fb_writeq sbus_writeq
#define fb_memset sbus_memset_io
#define fb_memcpy_fromfb sbus_memcpy_fromio
#define fb_memcpy_tofb sbus_memcpy_toio

#elif defined(__i386__) || defined(__alpha__) || defined(__x86_64__) || defined(__hppa__) || defined(__sh__) || defined(__powerpc__) || defined(__avr32__) || defined(__bfin__) || defined(__arm__)

#define fb_readb __raw_readb
#define fb_readw __raw_readw
#define fb_readl __raw_readl
#define fb_readq __raw_readq
#define fb_writeb __raw_writeb
#define fb_writew __raw_writew
#define fb_writel __raw_writel
#define fb_writeq __raw_writeq
#define fb_memset memset_io
#define fb_memcpy_fromfb memcpy_fromio
#define fb_memcpy_tofb memcpy_toio

#else

#define fb_readb(addr) (*(volatile u8 *) (addr))
#define fb_readw(addr) (*(volatile u16 *) (addr))
#define fb_readl(addr) (*(volatile u32 *) (addr))
#define fb_readq(addr) (*(volatile u64 *) (addr))
#define fb_writeb(b,addr) (*(volatile u8 *) (addr) = (b))
#define fb_writew(b,addr) (*(volatile u16 *) (addr) = (b))
#define fb_writel(b,addr) (*(volatile u32 *) (addr) = (b))
#define fb_writeq(b,addr) (*(volatile u64 *) (addr) = (b))
#define fb_memset memset
#define fb_memcpy_fromfb memcpy
#define fb_memcpy_tofb memcpy

#endif

#define FB_LEFT_POS(p, bpp)          (fb_be_math(p) ? (32 - (bpp)) : 0)
#define FB_SHIFT_HIGH(p, val, bits)  (fb_be_math(p) ? (val) >> (bits) : \
						      (val) << (bits))
#define FB_SHIFT_LOW(p, val, bits)   (fb_be_math(p) ? (val) << (bits) : \
						      (val) >> (bits))

    /*
     *  `Generic' versions of the frame buffer device operations
     */

extern int fb_set_var(struct fb_info *info, struct fb_var_screeninfo *var); 
extern int fb_pan_display(struct fb_info *info, struct fb_var_screeninfo *var); 
extern int fb_blank(struct fb_info *info, int blank);
extern void cfb_fillrect(struct fb_info *info, const struct fb_fillrect *rect); 
extern void cfb_copyarea(struct fb_info *info, const struct fb_copyarea *area); 
extern void cfb_imageblit(struct fb_info *info, const struct fb_image *image);
/*
 * Drawing operations where framebuffer is in system RAM
 */
extern void sys_fillrect(struct fb_info *info, const struct fb_fillrect *rect);
extern void sys_copyarea(struct fb_info *info, const struct fb_copyarea *area);
extern void sys_imageblit(struct fb_info *info, const struct fb_image *image);
extern ssize_t fb_sys_read(struct fb_info *info, char __user *buf,
			   size_t count, loff_t *ppos);
extern ssize_t fb_sys_write(struct fb_info *info, const char __user *buf,
			    size_t count, loff_t *ppos);

/* drivers/video/fbmem.c */
extern int register_framebuffer(struct fb_info *fb_info);
extern int unregister_framebuffer(struct fb_info *fb_info);
extern int unlink_framebuffer(struct fb_info *fb_info);
extern int remove_conflicting_framebuffers(struct apertures_struct *a,
					   const char *name, bool primary);
extern int fb_prepare_logo(struct fb_info *fb_info, int rotate);
extern int fb_show_logo(struct fb_info *fb_info, int rotate);
extern char* fb_get_buffer_offset(struct fb_info *info, struct fb_pixmap *buf, u32 size);
extern void fb_pad_unaligned_buffer(u8 *dst, u32 d_pitch, u8 *src, u32 idx,
				u32 height, u32 shift_high, u32 shift_low, u32 mod);
extern void fb_pad_aligned_buffer(u8 *dst, u32 d_pitch, u8 *src, u32 s_pitch, u32 height);
extern void fb_set_suspend(struct fb_info *info, int state);
extern int fb_get_color_depth(struct fb_var_screeninfo *var,
			      struct fb_fix_screeninfo *fix);
extern int fb_get_options(const char *name, char **option);
extern int fb_new_modelist(struct fb_info *info);

extern struct fb_info *registered_fb[FB_MAX];
extern int num_registered_fb;
extern struct class *fb_class;

extern int lock_fb_info(struct fb_info *info);

static inline void unlock_fb_info(struct fb_info *info)
{
	mutex_unlock(&info->lock);
}

static inline void __fb_pad_aligned_buffer(u8 *dst, u32 d_pitch,
					   u8 *src, u32 s_pitch, u32 height)
{
	u32 i, j;

	d_pitch -= s_pitch;

	for (i = height; i--; ) {
		/* s_pitch is a few bytes at the most, memcpy is suboptimal */
		for (j = 0; j < s_pitch; j++)
			*dst++ = *src++;
		dst += d_pitch;
	}
}

/* drivers/video/fb_defio.c */
int fb_deferred_io_mmap(struct fb_info *info, struct vm_area_struct *vma);
extern void fb_deferred_io_init(struct fb_info *info);
extern void fb_deferred_io_open(struct fb_info *info,
				struct inode *inode,
				struct file *file);
extern void fb_deferred_io_cleanup(struct fb_info *info);
extern int fb_deferred_io_fsync(struct file *file, loff_t start,
				loff_t end, int datasync);

static inline bool fb_be_math(struct fb_info *info)
{
#ifdef CONFIG_FB_FOREIGN_ENDIAN
#if defined(CONFIG_FB_BOTH_ENDIAN)
	return info->flags & FBINFO_BE_MATH;
#elif defined(CONFIG_FB_BIG_ENDIAN)
	return true;
#elif defined(CONFIG_FB_LITTLE_ENDIAN)
	return false;
#endif /* CONFIG_FB_BOTH_ENDIAN */
#else
#ifdef __BIG_ENDIAN
	return true;
#else
	return false;
#endif /* __BIG_ENDIAN */
#endif /* CONFIG_FB_FOREIGN_ENDIAN */
}

/* drivers/video/fbsysfs.c */
extern struct fb_info *framebuffer_alloc(size_t size, struct device *dev);
extern void framebuffer_release(struct fb_info *info);
extern int fb_init_device(struct fb_info *fb_info);
extern void fb_cleanup_device(struct fb_info *head);
extern void fb_bl_default_curve(struct fb_info *fb_info, u8 off, u8 min, u8 max);

/* drivers/video/fbmon.c */
#define FB_MAXTIMINGS		0
#define FB_VSYNCTIMINGS		1
#define FB_HSYNCTIMINGS		2
#define FB_DCLKTIMINGS		3
#define FB_IGNOREMON		0x100

#define FB_MODE_IS_UNKNOWN	0
#define FB_MODE_IS_DETAILED	1
#define FB_MODE_IS_STANDARD	2
#define FB_MODE_IS_VESA		4
#define FB_MODE_IS_CALCULATED	8
#define FB_MODE_IS_FIRST	16
#define FB_MODE_IS_FROM_VAR     32

extern int fbmon_dpms(const struct fb_info *fb_info);
extern int fb_get_mode(int flags, u32 val, struct fb_var_screeninfo *var,
		       struct fb_info *info);
extern int fb_validate_mode(const struct fb_var_screeninfo *var,
			    struct fb_info *info);
extern int fb_parse_edid(unsigned char *edid, struct fb_var_screeninfo *var);
extern const unsigned char *fb_firmware_edid(struct device *device);
extern void fb_edid_to_monspecs(unsigned char *edid,
				struct fb_monspecs *specs);
extern void fb_edid_add_monspecs(unsigned char *edid,
				 struct fb_monspecs *specs);
extern void fb_destroy_modedb(struct fb_videomode *modedb);
extern int fb_find_mode_cvt(struct fb_videomode *mode, int margins, int rb);
extern unsigned char *fb_ddc_read(struct i2c_adapter *adapter);

extern int of_get_fb_videomode(struct device_node *np,
			       struct fb_videomode *fb,
			       int index);
extern int fb_videomode_from_videomode(const struct videomode *vm,
				       struct fb_videomode *fbmode);

/* drivers/video/modedb.c */
#define VESA_MODEDB_SIZE 43
#define DMT_SIZE 0x50

extern void fb_var_to_videomode(struct fb_videomode *mode,
				const struct fb_var_screeninfo *var);
extern void fb_videomode_to_var(struct fb_var_screeninfo *var,
				const struct fb_videomode *mode);
extern int fb_mode_is_equal(const struct fb_videomode *mode1,
			    const struct fb_videomode *mode2);
extern int fb_add_videomode(const struct fb_videomode *mode,
			    struct list_head *head);
extern void fb_delete_videomode(const struct fb_videomode *mode,
				struct list_head *head);
extern const struct fb_videomode *fb_match_mode(const struct fb_var_screeninfo *var,
						struct list_head *head);
extern const struct fb_videomode *fb_find_best_mode(const struct fb_var_screeninfo *var,
						    struct list_head *head);
extern const struct fb_videomode *fb_find_nearest_mode(const struct fb_videomode *mode,
						       struct list_head *head);
extern void fb_destroy_modelist(struct list_head *head);
extern void fb_videomode_to_modelist(const struct fb_videomode *modedb, int num,
				     struct list_head *head);
extern const struct fb_videomode *fb_find_best_display(const struct fb_monspecs *specs,
						       struct list_head *head);

/* drivers/video/fbcmap.c */
extern int fb_alloc_cmap(struct fb_cmap *cmap, int len, int transp);
extern int fb_alloc_cmap_gfp(struct fb_cmap *cmap, int len, int transp, gfp_t flags);
extern void fb_dealloc_cmap(struct fb_cmap *cmap);
extern int fb_copy_cmap(const struct fb_cmap *from, struct fb_cmap *to);
extern int fb_cmap_to_user(const struct fb_cmap *from, struct fb_cmap_user *to);
extern int fb_set_cmap(struct fb_cmap *cmap, struct fb_info *fb_info);
extern int fb_set_user_cmap(struct fb_cmap_user *cmap, struct fb_info *fb_info);
extern const struct fb_cmap *fb_default_cmap(int len);
extern void fb_invert_cmaps(void);

struct fb_videomode {
	const char *name;	/* optional */
	u32 refresh;		/* optional */
	u32 xres;
	u32 yres;
	u32 pixclock;
	u32 left_margin;
	u32 right_margin;
	u32 upper_margin;
	u32 lower_margin;
	u32 hsync_len;
	u32 vsync_len;
	u32 sync;
	u32 vmode;
	u32 flag;
};

struct dmt_videomode {
	u32 dmt_id;
	u32 std_2byte_code;
	u32 cvt_3byte_code;
	const struct fb_videomode *mode;
};

extern const char *fb_mode_option;
extern const struct fb_videomode vesa_modes[];
extern const struct fb_videomode cea_modes[65];
extern const struct dmt_videomode dmt_modes[];

struct fb_modelist {
	struct list_head list;
	struct fb_videomode mode;
};

extern int fb_find_mode(struct fb_var_screeninfo *var,
			struct fb_info *info, const char *mode_option,
			const struct fb_videomode *db,
			unsigned int dbsize,
			const struct fb_videomode *default_mode,
			unsigned int default_bpp);

/* Convenience logging macros */
#define fb_err(fb_info, fmt, ...)					\
	pr_err("fb%d: " fmt, (fb_info)->node, ##__VA_ARGS__)
#define fb_notice(info, fmt, ...)					\
	pr_notice("fb%d: " fmt, (fb_info)->node, ##__VA_ARGS__)
#define fb_warn(fb_info, fmt, ...)					\
	pr_warn("fb%d: " fmt, (fb_info)->node, ##__VA_ARGS__)
#define fb_info(fb_info, fmt, ...)					\
	pr_info("fb%d: " fmt, (fb_info)->node, ##__VA_ARGS__)
#define fb_dbg(fb_info, fmt, ...)					\
	pr_debug("fb%d: " fmt, (fb_info)->node, ##__VA_ARGS__)

#endif /* _LINUX_FB_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              /*
 * Remote Processor Framework
 *
 * Copyright(c) 2011 Texas Instruments, Inc.
 * Copyright(c) 2011 Google, Inc.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * * Redistributions of source code must retain the above copyright
 *   notice, this list of conditions and the following disclaimer.
 * * Redistributions in binary form must reproduce the above copyright
 *   notice, this list of conditions and the following disclaimer in
 *   the documentation and/or other materials provided with the
 *   distribution.
 * * Neither the name Texas Instruments nor the names of its
 *   contributors may be used to endorse or promote products derived
 *   from this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
 * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
 * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
 * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
 * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

#ifndef REMOTEPROC_H
#define REMOTEPROC_H

#include <linux/types.h>
#include <linux/mutex.h>
#include <linux/virtio.h>
#include <linux/completion.h>
#include <linux/idr.h>
#include <linux/of.h>

/**
 * struct resource_table - firmware resource table header
 * @ver: version number
 * @num: number of resource entries
 * @reserved: reserved (must be zero)
 * @offset: array of offsets pointing at the various resource entries
 *
 * A resource table is essentially a list of system resources required
 * by the remote processor. It may also include configuration entries.
 * If needed, the remote processor firmware should contain this table
 * as a dedicated ".resource_table" ELF section.
 *
 * Some resources entries are mere announcements, where the host is informed
 * of specific remoteproc configuration. Other entries require the host to
 * do something (e.g. allocate a system resource). Sometimes a negotiation
 * is expected, where the firmware requests a resource, and once allocated,
 * the host should provide back its details (e.g. address of an allocated
 * memory region).
 *
 * The header of the resource table, as expressed by this structure,
 * contains a version number (should we need to change this format in the
 * future), the number of available resource entries, and their offsets
 * in the table.
 *
 * Immediately following this header are the resource entries themselves,
 * each of which begins with a resource entry header (as described below).
 */
struct resource_table {
	u32 ver;
	u32 num;
	u32 reserved[2];
	u32 offset[0];
} __packed;

/**
 * struct fw_rsc_hdr - firmware resource entry header
 * @type: resource type
 * @data: resource data
 *
 * Every resource entry begins with a 'struct fw_rsc_hdr' header providing
 * its @type. The content of the entry itself will immediately follow
 * this header, and it should be parsed according to the resource type.
 */
struct fw_rsc_hdr {
	u32 type;
	u8 data[0];
} __packed;

/**
 * enum fw_resource_type - types of resource entries
 *
 * @RSC_CARVEOUT:   request for allocation of a physically contiguous
 *		    memory region.
 * @RSC_DEVMEM:     request to iommu_map a memory-based peripheral.
 * @RSC_TRACE:	    announces the availability of a trace buffer into which
 *		    the remote processor will be writing logs.
 * @RSC_VDEV:       declare support for a virtio device, and serve as its
 *		    virtio header.
 * @RSC_LAST:       just keep this one at the end
 *
 * For more details regarding a specific resource type, please see its
 * dedicated structure below.
 *
 * Please note that these values are used as indices to the rproc_handle_rsc
 * lookup table, so please keep them sane. Moreover, @RSC_LAST is used to
 * check the validity of an index before the lookup table is accessed, so
 * please update it as needed.
 */
enum fw_resource_type {
	RSC_CARVEOUT	= 0,
	RSC_DEVMEM	= 1,
	RSC_TRACE	= 2,
	RSC_VDEV	= 3,
	RSC_LAST	= 4,
};

#define FW_RSC_ADDR_ANY (-1)

/**
 * struct fw_rsc_carveout - physically contiguous memory request
 * @da: device address
 * @pa: physical address
 * @len: length (in bytes)
 * @flags: iommu protection flags
 * @reserved: reserved (must be zero)
 * @name: human-readable name of the requested memory region
 *
 * This resource entry requests the host to allocate a physically contiguous
 * memory region.
 *
 * These request entries should precede other firmware resource entries,
 * as other entries might request placing other data objects inside
 * these memory regions (e.g. data/code segments, trace resource entries, ...).
 *
 * Allocating memory this way helps utilizing the reserved physical memory
 * (e.g. CMA) more efficiently, and also minimizes the number of TLB entries
 * needed to map it (in case @rproc is using an IOMMU). Reducing the TLB
 * pressure is important; it may have a substantial impact on performance.
 *
 * If the firmware is compiled with static addresses, then @da should specify
 * the expected device address of this memory region. If @da is set to
 * FW_RSC_ADDR_ANY, then the host will dynamically allocate it, and then
 * overwrite @da with the dynamically allocated address.
 *
 * We will always use @da to negotiate the device addresses, even if it
 * isn't using an iommu. In that case, though, it will obviously contain
 * physical addresses.
 *
 * Some remote processors needs to know the allocated physical address
 * even if they do use an iommu. This is needed, e.g., if they control
 * hardware accelerators which access the physical memory directly (this
 * is the case with OMAP4 for instance). In that case, the host will
 * overwrite @pa with the dynamically allocated physical address.
 * Generally we don't want to expose physical addresses if we don't have to
 * (remote processors are generally _not_ trusted), so we might want to
 * change this to happen _only_ when explicitly required by the hardware.
 *
 * @flags is used to provide IOMMU protection flags, and @name should
 * (optionally) contain a human readable name of this carveout region
 * (mainly for debugging purposes).
 */
struct fw_rsc_carveout {
	u32 da;
	u32 pa;
	u32 len;
	u32 flags;
	u32 reserved;
	u8 name[32];
} __packed;

/**
 * struct fw_rsc_devmem - iommu mapping request
 * @da: device address
 * @pa: physical address
 * @len: length (in bytes)
 * @flags: iommu protection flags
 * @reserved: reserved (must be zero)
 * @name: human-readable name of the requested region to be mapped
 *
 * This resource entry requests the host to iommu map a physically contiguous
 * memory region. This is needed in case the remote processor requires
 * access to certain memory-based peripherals; _never_ use it to access
 * regular memory.
 *
 * This is obviously only needed if the remote processor is accessing memory
 * via an iommu.
 *
 * @da should specify the required device address, @pa should specify
 * the physical address we want to map, @len should specify the size of
 * the mapping and @flags is the IOMMU protection flags. As always, @name may
 * (optionally) contain a human readable name of this mapping (mainly for
 * debugging purposes).
 *
 * Note: at this point we just "trust" those devmem entries to contain valid
 * physical addresses, but this isn't safe and will be changed: eventually we
 * want remoteproc implementations to provide us ranges of physical addresses
 * the firmware is allowed to request, and not allow firmwares to request
 * access to physical addresses that are outside those ranges.
 */
struct fw_rsc_devmem {
	u32 da;
	u32 pa;
	u32 len;
	u32 flags;
	u32 reserved;
	u8 name[32];
} __packed;

/**
 * struct fw_rsc_trace - trace buffer declaration
 * @da: device address
 * @len: length (in bytes)
 * @reserved: reserved (must be zero)
 * @name: human-readable name of the trace buffer
 *
 * This resource entry provides the host information about a trace buffer
 * into which the remote processor will write log messages.
 *
 * @da specifies the device address of the buffer, @len specifies
 * its size, and @name may contain a human readable name of the trace buffer.
 *
 * After booting the remote processor, the trace buffers are exposed to the
 * user via debugfs entries (called trace0, trace1, etc..).
 */
struct fw_rsc_trace {
	u32 da;
	u32 len;
	u32 reserved;
	u8 name[32];
} __packed;

/**
 * struct fw_rsc_vdev_vring - vring descriptor entry
 * @da: device address
 * @align: the alignment between the consumer and producer parts of the vring
 * @num: num of buffers supported by this vring (must be power of two)
 * @notifyid is a unique rproc-wide notify index for this vring. This notify
 * index is used when kicking a remote processor, to let it know that this
 * vring is triggered.
 * @pa: physical address
 *
 * This descriptor is not a resource entry by itself; it is part of the
 * vdev resource type (see below).
 *
 * Note that @da should either contain the device address where
 * the remote processor is expecting the vring, or indicate that
 * dynamically allocation of the vring's device address is supported.
 */
struct fw_rsc_vdev_vring {
	u32 da;
	u32 align;
	u32 num;
	u32 notifyid;
	u32 pa;
} __packed;

/**
 * struct fw_rsc_vdev - virtio device header
 * @id: virtio device id (as in virtio_ids.h)
 * @notifyid is a unique rproc-wide notify index for this vdev. This notify
 * index is used when kicking a remote processor, to let it know that the
 * status/features of this vdev have changes.
 * @dfeatures specifies the virtio device features supported by the firmware
 * @gfeatures is a place holder used by the host to write back the
 * negotiated features that are supported by both sides.
 * @config_len is the size of the virtio config space of this vdev. The config
 * space lies in the resource table immediate after this vdev header.
 * @status is a place holder where the host will indicate its virtio progress.
 * @num_of_vrings indicates how many vrings are described in this vdev header
 * @reserved: reserved (must be zero)
 * @vring is an array of @num_of_vrings entries of 'struct fw_rsc_vdev_vring'.
 *
 * This resource is a virtio device header: it provides information about
 * the vdev, and is then used by the host and its peer remote processors
 * to negotiate and share certain virtio properties.
 *
 * By providing this resource entry, the firmware essentially asks remoteproc
 * to statically allocate a vdev upon registration of the rproc (dynamic vdev
 * allocation is not yet supported).
 *
 * Note: unlike virtualization systems, the term 'host' here means
 * the Linux side which is running remoteproc to control the remote
 * processors. We use the name 'gfeatures' to comply with virtio's terms,
 * though there isn't really any virtualized guest OS here: it's the host
 * which is responsible for negotiating the final features.
 * Yeah, it's a bit confusing.
 *
 * Note: immediately following this structure is the virtio config space for
 * this vdev (which is specific to the vdev; for more info, read the virtio
 * spec). the size of the config space is specified by @config_len.
 */
struct fw_rsc_vdev {
	u32 id;
	u32 notifyid;
	u32 dfeatures;
	u32 gfeatures;
	u32 config_len;
	u8 status;
	u8 num_of_vrings;
	u8 reserved[2];
	struct fw_rsc_vdev_vring vring[0];
} __packed;

/**
 * struct rproc_mem_entry - memory entry descriptor
 * @va:	virtual address
 * @dma: dma address
 * @len: length, in bytes
 * @da: device address
 * @priv: associated data
 * @node: list node
 */
struct rproc_mem_entry {
	void *va;
	dma_addr_t dma;
	int len;
	u32 da;
	void *priv;
	struct list_head node;
};

struct rproc;

/**
 * struct rproc_ops - platform-specific device handlers
 * @start:	power on the device and boot it
 * @stop:	power off the device
 * @kick:	kick a virtqueue (virtqueue id given as a parameter)
 * @da_to_va:	optional platform hook to perform address translations
 */
struct rproc_ops {
	int (*start)(struct rproc *rproc);
	int (*stop)(struct rproc *rproc);
	void (*kick)(struct rproc *rproc, int vqid);
	void * (*da_to_va)(struct rproc *rproc, u64 da, int len);
};

/**
 * enum rproc_state - remote processor states
 * @RPROC_OFFLINE:	device is powered off
 * @RPROC_SUSPENDED:	device is suspended; needs to be woken up to receive
 *			a message.
 * @RPROC_RUNNING:	device is up and running
 * @RPROC_CRASHED:	device has crashed; need to start recovery
 * @RPROC_LAST:		just keep this one at the end
 *
 * Please note that the values of these states are used as indices
 * to rproc_state_string, a state-to-name lookup table,
 * so please keep the two synchronized. @RPROC_LAST is used to check
 * the validity of an index before the lookup table is accessed, so
 * please update it as needed too.
 */
enum rproc_state {
	RPROC_OFFLINE	= 0,
	RPROC_SUSPENDED	= 1,
	RPROC_RUNNING	= 2,
	RPROC_CRASHED	= 3,
	RPROC_LAST	= 4,
};

/**
 * enum rproc_crash_type - remote processor crash types
 * @RPROC_MMUFAULT:	iommu fault
 * @RPROC_WATCHDOG:	watchdog bite
 * @RPROC_FATAL_ERROR	fatal error
 *
 * Each element of the enum is used as an array index. So that, the value of
 * the elements should be always something sane.
 *
 * Feel free to add more types when needed.
 */
enum rproc_crash_type {
	RPROC_MMUFAULT,
	RPROC_WATCHDOG,
	RPROC_FATAL_ERROR,
};

/**
 * struct rproc - represents a physical remote processor device
 * @node: list node of this rproc object
 * @domain: iommu domain
 * @name: human readable name of the rproc
 * @firmware: name of firmware file to be loaded
 * @priv: private data which belongs to the platform-specific rproc module
 * @ops: platform-specific start/stop rproc handlers
 * @dev: virtual device for refcounting and common remoteproc behavior
 * @fw_ops: firmware-specific handlers
 * @power: refcount of users who need this rproc powered up
 * @state: state of the device
 * @lock: lock which protects concurrent manipulations of the rproc
 * @dbg_dir: debugfs directory of this rproc device
 * @traces: list of trace buffers
 * @num_traces: number of trace buffers
 * @carveouts: list of physically contiguous memory allocations
 * @mappings: list of iommu mappings we initiated, needed on shutdown
 * @firmware_loading_complete: marks e/o asynchronous firmware loading
 * @bootaddr: address of first instruction to boot rproc with (optional)
 * @rvdevs: list of remote virtio devices
 * @notifyids: idr for dynamically assigning rproc-wide unique notify ids
 * @index: index of this rproc device
 * @crash_handler: workqueue for handling a crash
 * @crash_cnt: crash counter
 * @crash_comp: completion used to sync crash handler and the rproc reload
 * @recovery_disabled: flag that state if recovery was disabled
 * @max_notifyid: largest allocated notify id.
 * @table_ptr: pointer to the resource table in effect
 * @cached_table: copy of the resource table
 * @has_iommu: flag to indicate if remote processor is behind an MMU
 */
struct rproc {
	struct list_head node;
	struct iommu_domain *domain;
	const char *name;
	const char *firmware;
	void *priv;
	const struct rproc_ops *ops;
	struct device dev;
	const struct rproc_fw_ops *fw_ops;
	atomic_t power;
	unsigned int state;
	struct mutex lock;
	struct dentry *dbg_dir;
	struct list_head traces;
	int num_traces;
	struct list_head carveouts;
	struct list_head mappings;
	struct completion firmware_loading_complete;
	u32 bootaddr;
	struct list_head rvdevs;
	struct idr notifyids;
	int index;
	struct work_struct crash_handler;
	unsigned int crash_cnt;
	struct completion crash_comp;
	bool recovery_disabled;
	int max_notifyid;
	struct resource_table *table_ptr;
	struct resource_table *cached_table;
	bool has_iommu;
	bool auto_boot;
};

/* we currently support only two vrings per rvdev */

#define RVDEV_NUM_VRINGS 2

/**
 * struct rproc_vring - remoteproc vring state
 * @va:	virtual address
 * @dma: dma address
 * @len: length, in bytes
 * @da: device address
 * @align: vring alignment
 * @notifyid: rproc-specific unique vring index
 * @rvdev: remote vdev
 * @vq: the virtqueue of this vring
 */
struct rproc_vring {
	void *va;
	dma_addr_t dma;
	int len;
	u32 da;
	u32 align;
	int notifyid;
	struct rproc_vdev *rvdev;
	struct virtqueue *vq;
};

/**
 * struct rproc_vdev - remoteproc state for a supported virtio device
 * @node: list node
 * @rproc: the rproc handle
 * @vdev: the virio device
 * @vring: the vrings for this vdev
 * @rsc_offset: offset of the vdev's resource entry
 */
struct rproc_vdev {
	struct list_head node;
	struct rproc *rproc;
	struct virtio_device vdev;
	struct rproc_vring vring[RVDEV_NUM_VRINGS];
	u32 rsc_offset;
};

struct rproc *rproc_get_by_phandle(phandle phandle);
struct rproc *rproc_alloc(struct device *dev, const char *name,
			  const struct rproc_ops *ops,
			  const char *firmware, int len);
void rproc_put(struct rproc *rproc);
int rproc_add(struct rproc *rproc);
int rproc_del(struct rproc *rproc);
void rproc_free(struct rproc *rproc);

int rproc_boot(struct rproc *rproc);
void rproc_shutdown(struct rproc *rproc);
void rproc_report_crash(struct rproc *rproc, enum rproc_crash_type type);

static inline struct rproc_vdev *vdev_to_rvdev(struct virtio_device *vdev)
{
	return container_of(vdev, struct rproc_vdev, vdev);
}

static inline struct rproc *vdev_to_rproc(struct virtio_device *vdev)
{
	struct rproc_vdev *rvdev = vdev_to_rvdev(vdev);

	return rvdev->rproc;
}

#endif /* REMOTEPROC_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             #ifndef _LINUX_IRQRETURN_H
#define _LINUX_IRQRETURN_H

/**
 * enum irqreturn
 * @IRQ_NONE		interrupt was not from this device or was not handled
 * @IRQ_HANDLED		interrupt was handled by this device
 * @IRQ_WAKE_THREAD	handler requests to wake the handler thread
 */
enum irqreturn {
	IRQ_NONE		= (0 << 0),
	IRQ_HANDLED		= (1 << 0),
	IRQ_WAKE_THREAD		= (1 << 1),
};

typedef enum irqreturn irqreturn_t;
#define IRQ_RETVAL(x)	((x) ? IRQ_HANDLED : IRQ_NONE)

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                /*
 * A generic stack depot implementation
 *
 * Author: Alexander Potapenko <glider@google.com>
 * Copyright (C) 2016 Google, Inc.
 *
 * Based on code by Dmitry Chernenkov.
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#ifndef _LINUX_STACKDEPOT_H
#define _LINUX_STACKDEPOT_H

typedef u32 depot_stack_handle_t;

struct stack_trace;

depot_stack_handle_t depot_save_stack(struct stack_trace *trace, gfp_t flags);

void depot_fetch_stack(depot_stack_handle_t handle, struct stack_trace *trace);

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         #ifndef _VME_H_
#define _VME_H_

/* Resource Type */
enum vme_resource_type {
	VME_MASTER,
	VME_SLAVE,
	VME_DMA,
	VME_LM
};

/* VME Address Spaces */
#define VME_A16		0x1
#define VME_A24		0x2
#define	VME_A32		0x4
#define VME_A64		0x8
#define VME_CRCSR	0x10
#define VME_USER1	0x20
#define VME_USER2	0x40
#define VME_USER3	0x80
#define VME_USER4	0x100

#define VME_A16_MAX	0x10000ULL
#define VME_A24_MAX	0x1000000ULL
#define VME_A32_MAX	0x100000000ULL
#define VME_A64_MAX	0x10000000000000000ULL
#define VME_CRCSR_MAX	0x1000000ULL


/* VME Cycle Types */
#define VME_SCT		0x1
#define VME_BLT		0x2
#define VME_MBLT	0x4
#define VME_2eVME	0x8
#define VME_2eSST	0x10
#define VME_2eSSTB	0x20

#define VME_2eSST160	0x100
#define VME_2eSST267	0x200
#define VME_2eSST320	0x400

#define	VME_SUPER	0x1000
#define	VME_USER	0x2000
#define	VME_PROG	0x4000
#define	VME_DATA	0x8000

/* VME Data Widths */
#define VME_D8		0x1
#define VME_D16		0x2
#define VME_D32		0x4
#define VME_D64		0x8

/* Arbitration Scheduling Modes */
#define VME_R_ROBIN_MODE	0x1
#define VME_PRIORITY_MODE	0x2

#define VME_DMA_PATTERN			(1<<0)
#define VME_DMA_PCI			(1<<1)
#define VME_DMA_VME			(1<<2)

#define VME_DMA_PATTERN_BYTE		(1<<0)
#define VME_DMA_PATTERN_WORD		(1<<1)
#define VME_DMA_PATTERN_INCREMENT	(1<<2)

#define VME_DMA_VME_TO_MEM		(1<<0)
#define VME_DMA_MEM_TO_VME		(1<<1)
#define VME_DMA_VME_TO_VME		(1<<2)
#define VME_DMA_MEM_TO_MEM		(1<<3)
#define VME_DMA_PATTERN_TO_VME		(1<<4)
#define VME_DMA_PATTERN_TO_MEM		(1<<5)

struct vme_dma_attr {
	u32 type;
	void *private;
};

struct vme_resource {
	enum vme_resource_type type;
	struct list_head *entry;
};

extern struct bus_type vme_bus_type;

/* Number of VME interrupt vectors */
#define VME_NUM_STATUSID	256

/* VME_MAX_BRIDGES comes from the type of vme_bus_numbers */
#define VME_MAX_BRIDGES		(sizeof(unsigned int)*8)
#define VME_MAX_SLOTS		32

#define VME_SLOT_CURRENT	-1
#define VME_SLOT_ALL		-2

/**
 * Structure representing a VME device
 * @num: The device number
 * @bridge: Pointer to the bridge device this device is on
 * @dev: Internal device structure
 * @drv_list: List of devices (per driver)
 * @bridge_list: List of devices (per bridge)
 */
struct vme_dev {
	int num;
	struct vme_bridge *bridge;
	struct device dev;
	struct list_head drv_list;
	struct list_head bridge_list;
};

struct vme_driver {
	struct list_head node;
	const char *name;
	int (*match)(struct vme_dev *);
	int (*probe)(struct vme_dev *);
	int (*remove)(struct vme_dev *);
	void (*shutdown)(void);
	struct device_driver driver;
	struct list_head devices;
};

void *vme_alloc_consistent(struct vme_resource *, size_t, dma_addr_t *);
void vme_free_consistent(struct vme_resource *, size_t,  void *,
	dma_addr_t);

size_t vme_get_size(struct vme_resource *);
int vme_check_window(u32 aspace, unsigned long long vme_base,
		     unsigned long long size);

struct vme_resource *vme_slave_request(struct vme_dev *, u32, u32);
int vme_slave_set(struct vme_resource *, int, unsigned long long,
	unsigned long long, dma_addr_t, u32, u32);
int vme_slave_get(struct vme_resource *, int *, unsigned long long *,
	unsigned long long *, dma_addr_t *, u32 *, u32 *);
void vme_slave_free(struct vme_resource *);

struct vme_resource *vme_master_request(struct vme_dev *, u32, u32, u32);
int vme_master_set(struct vme_resource *, int, unsigned long long,
	unsigned long long, u32, u32, u32);
int vme_master_get(struct vme_resource *, int *, unsigned long long *,
	unsigned long long *, u32 *, u32 *, u32 *);
ssize_t vme_master_read(struct vme_resource *, void *, size_t, loff_t);
ssize_t vme_master_write(struct vme_resource *, void *, size_t, loff_t);
unsigned int vme_master_rmw(struct vme_resource *, unsigned int, unsigned int,
	unsigned int, loff_t);
int vme_master_mmap(struct vme_resource *resource, struct vm_area_struct *vma);
void vme_master_free(struct vme_resource *);

struct vme_resource *vme_dma_request(struct vme_dev *, u32);
struct vme_dma_list *vme_new_dma_list(struct vme_resource *);
struct vme_dma_attr *vme_dma_pattern_attribute(u32, u32);
struct vme_dma_attr *vme_dma_pci_attribute(dma_addr_t);
struct vme_dma_attr *vme_dma_vme_attribute(unsigned long long, u32, u32, u32);
void vme_dma_free_attribute(struct vme_dma_attr *);
int vme_dma_list_add(struct vme_dma_list *, struct vme_dma_attr *,
	struct vme_dma_attr *, size_t);
int vme_dma_list_exec(struct vme_dma_list *);
int vme_dma_list_free(struct vme_dma_list *);
int vme_dma_free(struct vme_resource *);

int vme_irq_request(struct vme_dev *, int, int,
	void (*callback)(int, int, void *), void *);
void vme_irq_free(struct vme_dev *, int, int);
int vme_irq_generate(struct vme_dev *, int, int);

struct vme_resource *vme_lm_request(struct vme_dev *);
int vme_lm_count(struct vme_resource *);
int vme_lm_set(struct vme_resource *, unsigned long long, u32, u32);
int vme_lm_get(struct vme_resource *, unsigned long long *, u32 *, u32 *);
int vme_lm_attach(struct vme_resource *, int, void (*callback)(void *), void *);
int vme_lm_detach(struct vme_resource *, int);
void vme_lm_free(struct vme_resource *);

int vme_slot_num(struct vme_dev *);
int vme_bus_num(struct vme_dev *);

int vme_register_driver(struct vme_driver *, unsigned int);
void vme_unregister_driver(struct vme_driver *);


#endif /* _VME_H_ */

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #ifndef _GPIO_KEYS_H
#define _GPIO_KEYS_H

struct device;
struct gpio_desc;

/**
 * struct gpio_keys_button - configuration parameters
 * @code:		input event code (KEY_*, SW_*)
 * @gpio:		%-1 if this key does not support gpio
 * @active_low:		%true indicates that button is considered
 *			depressed when gpio is low
 * @desc:		label that will be attached to button's gpio
 * @type:		input event type (%EV_KEY, %EV_SW, %EV_ABS)
 * @wakeup:		configure the button as a wake-up source
 * @debounce_interval:	debounce ticks interval in msecs
 * @can_disable:	%true indicates that userspace is allowed to
 *			disable button via sysfs
 * @value:		axis value for %EV_ABS
 * @irq:		Irq number in case of interrupt keys
 * @gpiod:		GPIO descriptor
 */
struct gpio_keys_button {
	unsigned int code;
	int gpio;
	int active_low;
	const char *desc;
	unsigned int type;
	int wakeup;
	int debounce_interval;
	bool can_disable;
	int value;
	unsigned int irq;
	struct gpio_desc *gpiod;
};

/**
 * struct gpio_keys_platform_data - platform data for gpio_keys driver
 * @buttons:		pointer to array of &gpio_keys_button structures
 *			describing buttons attached to the device
 * @nbuttons:		number of elements in @buttons array
 * @poll_interval:	polling interval in msecs - for polling driver only
 * @rep:		enable input subsystem auto repeat
 * @enable:		platform hook for enabling the device
 * @disable:		platform hook for disabling the device
 * @name:		input device name
 */
struct gpio_keys_platform_data {
	struct gpio_keys_button *buttons;
	int nbuttons;
	unsigned int poll_interval;
	unsigned int rep:1;
	int (*enable)(struct device *dev);
	void (*disable)(struct device *dev);
	const char *name;
};

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #ifndef _LINUX_USER_NAMESPACE_H
#define _LINUX_USER_NAMESPACE_H

#include <linux/kref.h>
#include <linux/nsproxy.h>
#include <linux/ns_common.h>
#include <linux/sched.h>
#include <linux/err.h>

#define UID_GID_MAP_MAX_EXTENTS 5

struct uid_gid_map {	/* 64 bytes -- 1 cache line */
	u32 nr_extents;
	struct uid_gid_extent {
		u32 first;
		u32 lower_first;
		u32 count;
	} extent[UID_GID_MAP_MAX_EXTENTS];
};

#define USERNS_SETGROUPS_ALLOWED 1UL

#define USERNS_INIT_FLAGS USERNS_SETGROUPS_ALLOWED

struct ucounts;

enum ucount_type {
	UCOUNT_USER_NAMESPACES,
	UCOUNT_PID_NAMESPACES,
	UCOUNT_UTS_NAMESPACES,
	UCOUNT_IPC_NAMESPACES,
	UCOUNT_NET_NAMESPACES,
	UCOUNT_MNT_NAMESPACES,
	UCOUNT_CGROUP_NAMESPACES,
	UCOUNT_COUNTS,
};

struct user_namespace {
	struct uid_gid_map	uid_map;
	struct uid_gid_map	gid_map;
	struct uid_gid_map	projid_map;
	atomic_t		count;
	struct user_namespace	*parent;
	int			level;
	kuid_t			owner;
	kgid_t			group;
	struct ns_common	ns;
	unsigned long		flags;

	/* Register of per-UID persistent keyrings for this namespace */
#ifdef CONFIG_PERSISTENT_KEYRINGS
	struct key		*persistent_keyring_register;
	struct rw_semaphore	persistent_keyring_register_sem;
#endif
	struct work_struct	work;
#ifdef CONFIG_SYSCTL
	struct ctl_table_set	set;
	struct ctl_table_header *sysctls;
#endif
	struct ucounts		*ucounts;
	int ucount_max[UCOUNT_COUNTS];
};

struct ucounts {
	struct hlist_node node;
	struct user_namespace *ns;
	kuid_t uid;
	int count;
	atomic_t ucount[UCOUNT_COUNTS];
};

extern struct user_namespace init_user_ns;

bool setup_userns_sysctls(struct user_namespace *ns);
void retire_userns_sysctls(struct user_namespace *ns);
struct ucounts *inc_ucount(struct user_namespace *ns, kuid_t uid, enum ucount_type type);
void dec_ucount(struct ucounts *ucounts, enum ucount_type type);

#ifdef CONFIG_USER_NS

static inline struct user_namespace *get_user_ns(struct user_namespace *ns)
{
	if (ns)
		atomic_inc(&ns->count);
	return ns;
}

extern int create_user_ns(struct cred *new);
extern int unshare_userns(unsigned long unshare_flags, struct cred **new_cred);
extern void __put_user_ns(struct user_namespace *ns);

static inline void put_user_ns(struct user_namespace *ns)
{
	if (ns && atomic_dec_and_test(&ns->count))
		__put_user_ns(ns);
}

struct seq_operations;
extern const struct seq_operations proc_uid_seq_operations;
extern const struct seq_operations proc_gid_seq_operations;
extern const struct seq_operations proc_projid_seq_operations;
extern ssize_t proc_uid_map_write(struct file *, const char __user *, size_t, loff_t *);
extern ssize_t proc_gid_map_write(struct file *, const char __user *, size_t, loff_t *);
extern ssize_t proc_projid_map_write(struct file *, const char __user *, size_t, loff_t *);
extern ssize_t proc_setgroups_write(struct file *, const char __user *, size_t, loff_t *);
extern int proc_setgroups_show(struct seq_file *m, void *v);
extern bool userns_may_setgroups(const struct user_namespace *ns);
extern bool current_in_userns(const struct user_namespace *target_ns);

struct ns_common *ns_get_owner(struct ns_common *ns);
#else

static inline struct user_namespace *get_user_ns(struct user_namespace *ns)
{
	return &init_user_ns;
}

static inline int create_user_ns(struct cred *new)
{
	return -EINVAL;
}

static inline int unshare_userns(unsigned long unshare_flags,
				 struct cred **new_cred)
{
	if (unshare_flags & CLONE_NEWUSER)
		return -EINVAL;
	return 0;
}

static inline void put_user_ns(struct user_namespace *ns)
{
}

static inline bool userns_may_setgroups(const struct user_namespace *ns)
{
	return true;
}

static inline bool current_in_userns(const struct user_namespace *target_ns)
{
	return true;
}

static inline struct ns_common *ns_get_owner(struct ns_common *ns)
{
	return ERR_PTR(-EPERM);
}
#endif

#endif /* _LINUX_USER_H */
                                                                                                                                                                                                                                                                                         #ifndef __mISDNdsp_H__
#define __mISDNdsp_H__

struct mISDN_dsp_element_arg {
	char	*name;
	char	*def;
	char	*desc;
};

struct mISDN_dsp_element {
	char	*name;
	void	*(*new)(const char *arg);
	void	(*free)(void *p);
	void	(*process_tx)(void *p, unsigned char *data, int len);
	void	(*process_rx)(void *p, unsigned char *data, int len,
			unsigned int txlen);
	int	num_args;
	struct mISDN_dsp_element_arg
		*args;
};

extern int  mISDN_dsp_element_register(struct mISDN_dsp_element *elem);
extern void mISDN_dsp_element_unregister(struct mISDN_dsp_element *elem);

struct dsp_features {
	int	hfc_id; /* unique id to identify the chip (or -1) */
	int	hfc_dtmf; /* set if HFCmulti card supports dtmf */
	int	hfc_conf; /* set if HFCmulti card supports conferences */
	int	hfc_loops; /* set if card supports tone loops */
	int	hfc_echocanhw; /* set if card supports echocancelation*/
	int	pcm_id; /* unique id to identify the pcm bus (or -1) */
	int	pcm_slots; /* number of slots on the pcm bus */
	int	pcm_banks; /* number of IO banks of pcm bus */
	int	unclocked; /* data is not clocked (has jitter/loss) */
	int	unordered; /* data is unordered (packets have index) */
};

#endif

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      #ifndef _LINUX_KDEV_T_H
#define _LINUX_KDEV_T_H

#include <uapi/linux/kdev_t.h>

#define MINORBITS	20
#define MINORMASK	((1U << MINORBITS) - 1)

#define MAJOR(dev)	((unsigned int) ((dev) >> MINORBITS))
#define MINOR(dev)	((unsigned int) ((dev) & MINORMASK))
#define MKDEV(ma,mi)	(((ma) << MINORBITS) | (mi))

#define print_dev_t(buffer, dev)					\
	sprintf((buffer), "%u:%u\n", MAJOR(dev), MINOR(dev))

#define format_dev_t(buffer, dev)					\
	({								\
		sprintf(buffer, "%u:%u", MAJOR(dev), MINOR(dev));	\
		buffer;							\
	})

/* acceptable for old filesystems */
static inline bool old_valid_dev(dev_t dev)
{
	return MAJOR(dev) < 256 && MINOR(dev) < 256;
}

static inline u16 old_encode_dev(dev_t dev)
{
	return (MAJOR(dev) << 8) | MINOR(dev);
}

static inline dev_t old_decode_dev(u16 val)
{
	return MKDEV((val >> 8) & 255, val & 255);
}

static inline u32 new_encode_dev(dev_t dev)
{
	unsigned major = MAJOR(dev);
	unsigned minor = MINOR(dev);
	return (minor & 0xff) | (major << 8) | ((minor & ~0xff) << 12);
}

static inline dev_t new_decode_dev(u32 dev)
{
	unsigned major = (dev & 0xfff00) >> 8;
	unsigned minor = (dev & 0xff) | ((dev >> 12) & 0xfff00);
	return MKDEV(major, minor);
}

static inline u64 huge_encode_dev(dev_t dev)
{
	return new_encode_dev(dev);
}

static inline dev_t huge_decode_dev(u64 dev)
{
	return new_decode_dev(dev);
}

static inline int sysv_valid_dev(dev_t dev)
{
	return MAJOR(dev) < (1<<14) && MINOR(dev) < (1<<18);
}

static inline u32 sysv_encode_dev(dev_t dev)
{
	return MINOR(dev) | (MAJOR(dev) << 18);
}

static inline unsigned sysv_major(u32 dev)
{
	return (dev >> 18) & 0x3fff;
}

static inline unsigned sysv_minor(u32 dev)
{
	return dev & 0x3ffff;
}

#endif
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       /*
 * /proc/kcore definitions
 */
#ifndef _LINUX_KCORE_H
#define _LINUX_KCORE_H

enum kcore_type {
	KCORE_TEXT,
	KCORE_VMALLOC,
	KCORE_RAM,
	KCORE_VMEMMAP,
	KCORE_OTHER,
};

struct kcore_list {
	struct list_head list;
	unsigned long addr;
	size_t size;
	int type;
};

struct vmcore {
	struct list_head list;
	unsigned long long paddr;
	unsigned long long size;
	loff_t offset;
};

#ifdef CONFIG_PROC_KCORE
extern void kclist_add(struct kcore_list *, void *, size_t, int type);
#else
static inline
void kclist_add(struct kcore_list *new, void *addr, size_t size, int type)
{
}
#endif

#endif /* _LINUX_KCORE_H */
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            /*
 * Ftrace header.  For implementation details beyond the random comments
 * scattered below, see: Documentation/trace/ftrace-design.txt
 */

#ifndef _LINUX_FTRACE_H
#define _LINUX_FTRACE_H

#include <linux/trace_clock.h>
#include <linux/kallsyms.h>
#include <linux/linkage.h>
#include <linux/bitops.h>
#include <linux/ptrace.h>
#include <linux/ktime.h>
#include <linux/sched.h>
#include <linux/types.h>
#include <linux/init.h>
#include <linux/fs.h>

#include <asm/ftrace.h>

/*
 * If the arch supports passing the variable contents of
 * function_trace_op as the third parameter back from the
 * mcount call, then the arch should define this as 1.
 */
#ifndef ARCH_SUPPORTS_FTRACE_OPS
#define ARCH_SUPPORTS_FTRACE_OPS 0
#endif

/*
 * If the arch's mcount caller does not support all of ftrace's
 * features, then it must call an indirect function that
 * does. Or at least does enough to prevent any unwelcomed side effects.
 */
#if !ARCH_SUPPORTS_FTRACE_OPS
# define FTRACE_FORCE_LIST_FUNC 1
#else
# define FTRACE_FORCE_LIST_FUNC 0
#endif

/* Main tracing buffer and events set up */
#ifdef CONFIG_TRACING
void trace_init(void);
#else
static inline void trace_init(void) { }
#endif

struct module;
struct ftrace_hash;

#ifdef CONFIG_FUNCTION_TRACER

extern int ftrace_enabled;
extern int
ftrace_enable_sysctl(struct ctl_table *table, int write,
		     void __user *buffer, size_t *lenp,
		     loff_t *ppos);

struct ftrace_ops;

typedef void (*ftrace_func_t)(unsigned long ip, unsigned long parent_ip,
			      struct ftrace_ops *op, struct pt_regs *regs);

ftrace_func_t ftrace_ops_get_func(struct ftrace_ops *ops);

/*
 * FTRACE_OPS_FL_* bits denote the state of ftrace_ops struct and are
 * set in the flags member.
 * CONTROL, SAVE_REGS, SAVE_REGS_IF_SUPPORTED, RECURSION_SAFE, STUB and
 * IPMODIFY are a kind of attribute flags which can be set only before
 * registering the ftrace_ops, and can not be modified while registered.
 * Changing those attribute flags after regsitering ftrace_ops will
 * cause unexpected results.
 *
 * ENABLED - set/unset when ftrace_ops is registered/unregistered
 * DYNAMIC - set when ftrace_ops is registered to denote dynamically
 *           allocated ftrace_ops which need special care
 * PER_CPU - set manualy by ftrace_ops user to denote the ftrace_ops
 *           could be controlled by following calls:
 *             ftrace_function_local_enable
 *             ftrace_function_local_disable
 * SAVE_REGS - The ftrace_ops wants regs saved at each function called
 *            and passed to the callback. If this flag is set, but the
 *            architecture does not support passing regs
 *            (CONFIG_DYNAMIC_FTRACE_WITH_REGS is not defined), then the
 *            ftrace_ops will fail to register, unless the next flag
 *            is set.
 * SAVE_REGS_IF_SUPPORTED - This is the same as SAVE_REGS, but if the
 *            handler can handle an arch that does not save regs
 *            (the handler tests if regs == NULL), then it can set
 *            this flag instead. It will not fail registering the ftrace_ops
 *            but, the regs field will be NULL if the arch does not support
 *            passing regs to the handler.
 *            Note, if this flag is set, the SAVE_REGS flag will automatically
 *            get set upon registering the ftrace_ops, if the arch supports it.
 * RECURSION_SAFE - The ftrace_ops can set this to tell the ftrace infrastructure
 *            that the call back has its own recursion protection. If it does
 *            not set this, then the ftrace infrastructure will add recursion
 *            protection for the caller.
 * STUB   - The ftrace_ops is just a place holder.
 * INITIALIZED - The ftrace_ops has already been initialized (first use time
 *            register_ftrace_function() is called, it will initialized the ops)
 * DELETED - The ops are being deleted, do not let them be registered again.
 * ADDING  - The ops is in the process of being added.
 * REMOVING - The ops is in the process of being removed.
 * MODIFYING - The ops is in the process of changing its filter functions.
 * ALLOC_TRAMP - A dynamic trampoline was allocated by the core code.
 *            The arch specific code sets this flag when it allocated a
 *            trampoline. This lets the arch know that it can update the
 *            trampoline in case the callback function changes.
 *            The ftrace_ops trampoline can be set by the ftrace users, and
 *            in such cases the arch must not modify it. Only the arch ftrace
 *            core code should set this flag.
 * IPMODIFY - The ops can modify the IP register. This can only be set with
 *            SAVE_REGS. If another ops with this flag set is already registered
 *            for any of the functions that this ops will be registered for, then
 *            this ops will fail to register or set_filter_ip.
 * PID     - Is affected by set_ftrace_pid (allows filtering on those pids)
 */
enum {
	FTRACE_OPS_FL_ENABLED			= 1 << 0,
	FTRACE_OPS_FL_DYNAMIC			= 1 << 1,
	FTRACE_OPS_FL_PER_CPU			= 1 << 2,
	FTRACE_OPS_FL_SAVE_REGS			= 1 << 3,
	FTRACE_OPS_FL_SAVE_REGS_IF_SUPPORTED	= 1 << 4,
	FTRACE_OPS_FL_RECURSION_SAFE		= 1 << 5,
	FTRACE_OPS_FL_STUB			= 1 << 6,
	FTRACE_OPS_FL_INITIALIZED		= 1 << 7,
	FTRACE_OPS_FL_DELETED			= 1 << 8,
	FTRACE_OPS_FL_ADDING			= 1 << 9,
	FTRACE_OPS_FL_REMOVING			= 1 << 10,
	FTRACE_OPS_FL_MODIFYING			= 1 << 11,
	FTRACE_OPS_FL_ALLOC_TRAMP		= 1 << 12,
	FTRACE_OPS_FL_IPMODIFY			= 1 << 13,
	FTRACE_OPS_FL_PID			= 1 << 14,
	FTRACE_OPS_FL_RCU			= 1 << 15,
	FTRACE_OPS_FL_IPIPE_EXCLUSIVE		= 1 << 16,
};

#ifdef CONFIG_DYNAMIC_FTRACE
/* The hash used to know what functions callbacks trace */
struct ftrace_ops_hash {
	struct ftrace_hash		*notrace_hash;
	struct ftrace_hash		*filter_hash;
	struct mutex			regex_lock;
};
#endif

/*
 * Note, ftrace_ops can be referenced outside of RCU protection, unless
 * the RCU flag is set. If ftrace_ops is allocated and not part of kernel
 * core data, the unregistering of it will perform a scheduling on all CPUs
 * to make sure that there are no more users. Depending on the load of the
 * system that may take a bit of time.
 *
 * Any private data added must also take care not to be freed and if private
 * data is added to a ftrace_ops that is in core code, the user of the
 * ftrace_ops must perform a schedule_on_each_cpu() before freeing it.
 */
struct ftrace_ops {
	ftrace_func_t			func;
	struct ftrace_ops		*next;
	unsigned long			flags;
	void				*private;
	ftrace_func_t			saved_func;
	int __percpu			*disabled;
#ifdef CONFIG_DYNAMIC_FTRACE
	struct ftrace_ops_hash		local_hash;
	struct ftrace_ops_hash		*func_hash;
	struct ftrace_ops_hash		old_hash;
	unsigned long			trampoline;
	unsigned long			trampoline_size;
#endif
};

/*
 * Type of the current tracing.
 */
enum ftrace_tracing_type_t {
	FTRACE_TYPE_ENTER = 0, /* Hook the call of the function */
	FTRACE_TYPE_RETURN,	/* Hook the return of the function */
};

/* Current tracing type, default is FTRACE_TYPE_ENTER */
extern enum ftrace_tracing_type_t ftrace_tracing_type;

/*
 * The ftrace_ops must be a static and should also
 * be read_mostly.  These functions do modify read_mostly variables
 * so use them sparely. Never free an ftrace_op or modify the
 * next pointer after it has been registered. Even after unregistering
 * it, the next pointer may still be used internally.
 */
int register_ftrace_function(struct ftrace_ops *ops);
int unregister_ftrace_function(struct ftrace_ops *ops);
void clear_ftrace_function(void);

/**
 * ftrace_function_local_enable - enable ftrace_ops on current cpu
 *
 * This function enables tracing on current cpu by decreasing
 * the per cpu control variable.
 * It must be called with preemption disabled and only on ftrace_ops
 * registered with FTRACE_OPS_FL_PER_CPU. If called without preemption
 * disabled, this_cpu_ptr will complain when CONFIG_DEBUG_PREEMPT is enabled.
 */
static inline void ftrace_function_local_enable(struct ftrace_ops *ops)
{
	if (WARN_ON_ONCE(!(ops->flags & FTRACE_OPS_FL_PER_CPU)))
		return;

	(*this_cpu_ptr(ops->disabled))--;
}

/**
 * ftrace_function_local_disable - disable ftrace_ops on current cpu
 *
 * This function disables tracing on current cpu by increasing
 * the per cpu control variable.
 * It must be called with preemption disabled and only on ftrace_ops
 * registered with FTRACE_OPS_FL_PER_CPU. If called without preemption
 * disabled, this_cpu_ptr will complain when CONFIG_DEBUG_PREEMPT is enabled.
 */
static inline void ftrace_function_local_disable(struct ftrace_ops *ops)
{
	if (WARN_ON_ONCE(!(ops->flags & FTRACE_OPS_FL_PER_CPU)))
		return;

	(*this_cpu_ptr(ops->disabled))++;
}

/**
 * ftrace_function_local_disabled - returns ftrace_ops disabled value
 *                                  on current cpu
 *
 * This function returns value of ftrace_ops::disabled on current cpu.
 * It must be called with preemption disabled and only on ftrace_ops
 * registered with FTRACE_OPS_FL_PER_CPU. If called without preemption
 * disabled, this_cpu_ptr will complain when CONFIG_DEBUG_PREEMPT is enabled.
 */
static inline int ftrace_function_local_disabled(struct ftrace_ops *ops)
{
	WARN_ON_ONCE(!(ops->flags & FTRACE_OPS_FL_PER_CPU));
	return *this_cpu_ptr(ops->disabled);
}

extern void ftrace_stub(unsigned long a0, unsigned long a1,
			struct ftrace_ops *op, struct pt_regs *regs);

#else /* !CONFIG_FUNCTION_TRACER */
/*
 * (un)register_ftrace_function must be a macro since the ops parameter
 * must not be evaluated.
 */
#define register_ftrace_function(ops) ({ 0; })
#define unregister_ftrace_function(ops) ({ 0; })
static inline int ftrace_nr_registered_ops(void)
{
	return 0;
}
static inline void clear_ftrace_function(void) { }
static inline void ftrace_kill(void) { }
#endif /* CONFIG_FUNCTION_TRACER */

#ifdef CONFIG_STACK_TRACER

#define STACK_TRACE_ENTRIES 500

struct stack_trace;

extern unsigned stack_trace_index[];
extern struct stack_trace stack_trace_max;
extern unsigned long stack_trace_max_size;
extern arch_spinlock_t stack_trace_max_lock;

extern int stack_tracer_enabled;
void stack_trace_print(void);
int
stack_trace_sysctl(struct ctl_table *table, int write,
		   void __user *buffer, size_t *lenp,
		   loff_t *ppos);
#endif

struct ftrace_func_command {
	struct list_head	list;
	char			*name;
	int			(*func)(struct ftrace_hash *hash,
					char *func, char *cmd,
					char *params, int enable);
};

#ifdef CONFIG_DYNAMIC_FTRACE

int ftrace_arch_code_modify_prepare(void);
int ftrace_arch_code_modify_post_process(void);

struct dyn_ftrace;

enum ftrace_bug_type {
	FTRACE_BUG_UNKNOWN,
	FTRACE_BUG_INIT,
	FTRACE_BUG_NOP,
	FTRACE_BUG_CALL,
	FTRACE_BUG_UPDATE,
};
extern enum ftrace_bug_type ftrace_bug_type;

/*
 * Archs can set this to point to a variable that holds the value that was
 * expected at the call site before calling ftrace_bug().
 */
extern const void *ftrace_expected;

void ftrace_bug(int err, struct dyn_ftrace *rec);

struct seq_file;

struct ftrace_probe_ops {
	void			(*func)(unsigned long ip,
					unsigned long parent_ip,
					void **data);
	int			(*init)(struct ftrace_probe_ops *ops,
					unsigned long ip, void **data);
	void			(*free)(struct ftrace_probe_ops *ops,
					unsigned long ip, void **data);
	int			(*print)(struct seq_file *m,
					 unsigned long ip,
					 struct ftrace_probe_ops *ops,
					 void *data);
};

extern int
register_ftrace_function_probe(char *glob, struct ftrace_probe_ops *ops,
			      void *data);
extern void
unregister_ftrace_function_probe(char *glob, struct ftrace_probe_ops *ops,
				void *data);
extern void
unregister_ftrace_function_probe_func(char *glob, struct ftrace_probe_ops *ops);
extern void unregister_ftrace_function_probe_all(char *glob);

extern int ftrace_text_reserved(const void *start, const void *end);

extern int ftrace_nr_registered_ops(void);

bool is_ftrace_trampoline(unsigned long addr);

/*
 * The dyn_ftrace record's flags field is split into two parts.
 * the first part which is '0-FTRACE_REF_MAX' is a counter of
 * the number of callbacks that have registered the function that
 * the dyn_ftrace descriptor represents.
 *
 * The second part is a mask:
 *  ENABLED - the function is being traced
 *  REGS    - the record wants the function to save regs
 *  REGS_EN - the function is set up to save regs.
 *  IPMODIFY - the record allows for the IP address to be changed.
 *  DISABLED - the record is not ready to be touched yet
 *
 * When a new ftrace_ops is registered and wants a function to save
 * pt_regs, the rec->flag REGS is set. When the function has been
 * set up to save regs, the REG_EN flag is set. Once a function
 * starts saving regs it will do so until all ftrace_ops are removed
 * from tracing that function.
 */
enum {
	FTRACE_FL_ENABLED	= (1UL << 31),
	FTRACE_FL_REGS		= (1UL << 30),
	FTRACE_FL_REGS_EN	= (1UL << 29),
	FTRACE_FL_TRAMP		= (1UL << 28),
	FTRACE_FL_TRAMP_EN	= (1UL << 27),
	FTRACE_FL_IPMODIFY	= (1UL << 26),
	FTRACE_FL_DISABLED	= (1UL << 25),
};

#define FTRACE_REF_MAX_SHIFT	25
#define FTRACE_FL_BITS		7
#define FTRACE_FL_MASKED_BITS	((1UL << FTRACE_FL_BITS) - 1)
#define FTRACE_FL_MASK		(FTRACE_FL_MASKED_BITS << FTRACE_REF_MAX_SHIFT)
#define FTRACE_REF_MAX		((1UL << FTRACE_REF_MAX_SHIFT) - 1)

#define ftrace_rec_count(rec)	((rec)->flags & ~FTRACE_FL_MASK)

struct dyn_ftrace {
	unsigned long		ip; /* address of mcount call-site */
	unsigned long		flags;
	struct dyn_arch_ftrace	arch;
};

int ftrace_force_update(void);
int ftrace_set_filter_ip(struct ftrace_ops *ops, unsigned long ip,
			 int remove, int reset);
int ftrace_set_filter(struct ftrace_ops *ops, unsigned char *buf,
		       int len, int reset);
int ftrace_set_notrace(struct ftrace_ops *ops, unsigned char *buf,
			int len, int reset);
void ftrace_set_global_filter(unsigned char *buf, int len, int reset);
void ftrace_set_global_notrace(unsigned char *buf, int len, int reset);
void ftrace_free_filter(struct ftrace_ops *ops);

int register_ftrace_command(struct ftrace_func_command *cmd);
int unregister_ftrace_command(struct ftrace_func_command *cmd);

enum {
	FTRACE_UPDATE_CALLS		= (1 << 0),
	FTRACE_DISABLE_CALLS		= (1 << 1),
	FTRACE_UPDATE_TRACE_FUNC	= (1 << 2),
	FTRACE_START_FUNC_RET		= (1 << 3),
	FTRACE_STOP_FUNC_RET		= (1 << 4),
};

/*
 * The FTRACE_UPDATE_* enum is used to pass information back
 * from the ftrace_update_record() and ftrace_test_record()
 * functions. These are called by the code update routines
 * to find out what is to be done for a given function.
 *
 *  IGNORE           - The function is already what we want it to be
 *  MAKE_CALL        - Start tracing the function
 *  MODIFY_CALL      - Stop saving regs for the function
 *  MAKE_NOP         - Stop tracing the function
 */
enum {
	FTRACE_UPDATE_IGNORE,
	FTRACE_UPDATE_MAKE_CALL,
	FTRACE_UPDATE_MODIFY_CALL,
	FTRACE_UPDATE_MAKE_NOP,
};

enum {
	FTRACE_ITER_FILTER	= (1 << 0),
	FTRACE_ITER_NOTRACE	= (1 << 1),
	FTRACE_ITER_PRINTALL	= (1 << 2),
	FTRACE_ITER_DO_HASH	= (1 << 3),
	FTRACE_ITER_HASH	= (1 << 4),
	FTRACE_ITER_ENABLED	= (1 << 5),
};

void arch_ftrace_update_code(int command);

struct ftrace_rec_iter;

struct ftrace_rec_iter *ftrace_rec_iter_start(void);
struct ftrace_rec_iter *ftrace_rec_iter_next(struct ftrace_rec_iter *iter);
struct dyn_ftrace *ftrace_rec_iter_record(struct ftrace_rec_iter *iter);

#define for_ftrace_rec_iter(iter)		\
	for (iter = ftrace_rec_iter_start();	\
	     iter;				\
	     iter = ftrace_rec_iter_next(iter))


int ftrace_update_record(struct dyn_ftrace *rec, int enable);
int ftrace_test_record(struct dyn_ftrace *rec, int enable);
void ftrace_run_stop_machine(int command);
unsigned long ftrace_location(unsigned long ip);
unsigned long ftrace_location_range(unsigned long start, unsigned long end);
unsigned long ftrace_get_addr_new(struct dyn_ftrace *rec);
unsigned long ftrace_get_addr_curr(struct dyn_ftrace *rec);

extern ftrace_func_t ftrace_trace_function;

int ftrace_regex_open(struct ftrace_ops *ops, int flag,
		  struct inode *inode, struct file *file);
ssize_t ftrace_filter_write(struct file *file, const char __user *ubuf,
			    size_t cnt, loff_t *ppos);
ssize_t ftrace_notrace_write(struct file *file, const char __user *ubuf,
			     size_t cnt, loff_t *ppos);
int ftrace_regex_release(struct inode *inode, struct file *file);

void __init
ftrace_set_early_filter(struct ftrace_ops *ops, char 